[{"papers": [{"metadata": {"year": 1976}, "authors": ["G. Panayi"], "summary": "Auto-immune disease may result from the interaction of the genetic load of the individual, modification of self-tissue antigens by environmental agents such as virus or drugs and abnormalities of the immunological system itself such as the loss of controlling or suppressor T cells with age. In the majority of people the outcome is tolerance, maintenance of normal tissue architecture and function. In the unfortunate few the outcome is auto-immune disease, that is, failure to recognize \"self\".", "title": "Auto-immune disease.", "claims": ["- Auto-immune disease may result from the interaction of the genetic load of the individual.", "- Auto-immune disease may result from the modification of self-tissue antigens by environmental agents such as viruses or drugs.", "- Auto-immune disease may result from abnormalities of the immunological system itself, such as the loss of controlling or suppressor T cells with age.", "- In the majority of people, the outcome of these interactions is tolerance, maintenance of normal tissue architecture, and function.", "- In the unfortunate few, the outcome of these interactions is auto-immune disease, which is a failure to recognize \"self\"."]}, {"metadata": {"year": 2018}, "authors": ["Angela  Richard-Eaglin", "Benjamin A Smallheer"], "summary": "Autoimmune disorders are a category of diseases in which the immune system attacks healthy cells as a result of a dysfunction of the acquired immune system. Clinical presentation and diagnosis are disease specific and often correspond with the degree of inflammation, as well as the systems involved. Treatment varies based on the specific disease, its stage of presentation, and patient symptoms. The primary goal of treatment is to decrease inflammation, minimize symptoms, and lessen the potential for relapse. Graves disease, Hashimoto thyroiditis, rheumatoid arthritis, Crohn disease, ulcerative colitis, systemic lupus erythematosus, and multiple sclerosis are discussed in this article.", "title": "Immunosuppressive/Autoimmune Disorders.", "claims": ["- Autoimmune disorders are a category of diseases in which the immune system attacks healthy cells as a result of a dysfunction of the acquired immune system.", "- Clinical presentation and diagnosis of autoimmune disorders are disease specific.", "- Clinical presentation and diagnosis of autoimmune disorders often correspond with the degree of inflammation.", "- Clinical presentation and diagnosis of autoimmune disorders often correspond with the systems involved.", "- Treatment of autoimmune disorders varies based on the specific disease.", "- Treatment of autoimmune disorders varies based on the stage of presentation.", "- Treatment of autoimmune disorders varies based on patient symptoms.", "- The primary goal of treatment for autoimmune disorders is to decrease inflammation.", "- The primary goal of treatment for autoimmune disorders is to minimize symptoms.", "- The primary goal of treatment for autoimmune disorders is to lessen the potential for relapse.", "- Graves disease, Hashimoto thyroiditis, rheumatoid arthritis, Crohn disease, ulcerative colitis, systemic lupus erythematosus, and multiple sclerosis are discussed in this article."]}, {"metadata": {"year": 2016}, "authors": ["A. M\u00e9kinian", "O. Fain"], "summary": "\n        \n      ", "title": "Autoimmune diseases. Epidemiological, diagnostic and treatment principles", "claims": ["I can't extract claims from a document without having the content of the document provided. Please provide the text or details from which you would like me to extract claims."]}, {"metadata": {"year": 2001}, "authors": ["Sue R. Beers"], "summary": "An autoimmune disorder is the body\u2019s reaction to an unknown stimulus causing the overproduction of antibodies that are directed against body tissue (Wallace, 1995). Although most autoimmune diseases are associated with significant and chronic morbidity and disability, epidemiological studies are generally limited to a few of the more prevalent disorders such as rheumatoid arthritis or diabetes mellitus. Recent estimates indicate that 1 in 31 individuals in the United States currently are diagnosed with an autoimmune disease, with women at higher risk than men (Jacobson, Gange, Rose, & Graham, 1997).", "title": "Systemic Autoimmune Disease", "claims": ["- An autoimmune disorder is the body\u2019s reaction to an unknown stimulus causing the overproduction of antibodies that are directed against body tissue (Wallace, 1995).", "- Most autoimmune diseases are associated with significant and chronic morbidity and disability.", "- Epidemiological studies on autoimmune diseases are generally limited to a few of the more prevalent disorders such as rheumatoid arthritis or diabetes mellitus.", "- Recent estimates indicate that 1 in 31 individuals in the United States currently are diagnosed with an autoimmune disease.", "- Women are at higher risk than men for being diagnosed with an autoimmune disease (Jacobson, Gange, Rose, & Graham, 1997)."]}, {"metadata": {"year": 2021}, "authors": ["Rukhshanda Nosheen", "Dr. Muhammad Bilal", "Dr Madiha Afzal"], "summary": ": Immune system disorders cause abnormally low activity or over activity of the immune system. In cases of immune system over activity, the body attacks and damages its own tissues (autoimmune diseases). Immune deficiency diseases decrease the body's ability to fight invaders, causing vulnerability to infections. Some of the autoimmune disease are as follows rheumatoid arthritis, systemic lupus erythematosus (lupus), inflammatory bowel disease (IBD),multiple sclerosis (MS),Type 1 diabetes mellitus, Guillain-Barre syndrome, chronic inflammatory demyelinating polyneuropathy, psoriasis. Human", "title": "STUDY OF CURRENT AND EMERGING HUMAN AUTOIMMUNE DISEASES", "claims": ["- Immune system disorders cause abnormally low activity or over activity of the immune system.", "- In cases of immune system over activity, the body attacks and damages its own tissues (autoimmune diseases).", "- Immune deficiency diseases decrease the body's ability to fight invaders, causing vulnerability to infections.", "- Some of the autoimmune diseases are rheumatoid arthritis, systemic lupus erythematosus (lupus), inflammatory bowel disease (IBD), multiple sclerosis (MS), Type 1 diabetes mellitus, Guillain-Barre syndrome, chronic inflammatory demyelinating polyneuropathy, and psoriasis."]}, {"metadata": {"year": 2008}, "authors": ["J. B. Soep", "J. R. Hollister"], "summary": "Autoimmune diseases occur when the immune system attacks the body\u2019s own organs and tissues. Rheumatologic diseases encompass conditions in which this autoimmune response causes inflammation of the musculoskeletal system, skin, and blood vessels. Rheumatologic conditions often present with arthritis, fever, and rash. Due to the frequent joint and muscle symptoms, patients may experience gross motor and fine motor delays.", "title": "Illnesses: Autoimmune Rheumatological Diseases", "claims": ["- Autoimmune diseases occur when the immune system attacks the body\u2019s own organs and tissues.", "- Rheumatologic diseases encompass conditions in which this autoimmune response causes inflammation of the musculoskeletal system, skin, and blood vessels.", "- Rheumatologic conditions often present with arthritis, fever, and rash.", "- Due to the frequent joint and muscle symptoms, patients may experience gross motor and fine motor delays."]}, {"metadata": {"year": 2009}, "authors": ["Shradha  Agarwal", "Charlotte  Cunningham-Rundles"], "summary": "Common variable immunodeficiency (CVID) is the most common clinically significant primary immune defect. Although the hallmark of CVID is hypogammaglobulinemia, the intrinsic dysregulation of the immune system leads to defective T-cell activation and proliferation, as well as dendritic cell and cytokine defects. Although 70% to 80% of patients have had recurrent sinopulmonary infections, autoimmunity and inflammatory complications are also common. The most common autoimmune conditions are immune thrombocytopenic purpura and hemolytic anemia, but other autoimmune complications arise, including rheumatoid arthritis, pernicious anemia, primary biliary cirrhosis, thyroiditis, sicca syndrome, systemic lupus, and inflammatory bowel disease. Treatment of autoimmunity includes highdose immunoglobulins, corticosteroids, selected immu no suppressants, and other immune modulators. This review focuses on autoimmune conditions associated with CVID, potential mechanisms of immune dysregulation, and therapeutic strategies.", "title": "Autoimmunity in common variable immunodeficiency", "claims": ["- Common variable immunodeficiency (CVID) is the most common clinically significant primary immune defect.", "- The hallmark of CVID is hypogammaglobulinemia.", "- The intrinsic dysregulation of the immune system in CVID leads to defective T-cell activation and proliferation.", "- CVID also leads to dendritic cell and cytokine defects.", "- 70% to 80% of patients with CVID have had recurrent sinopulmonary infections.", "- Autoimmunity and inflammatory complications are also common in patients with CVID.", "- The most common autoimmune conditions associated with CVID are immune thrombocytopenic purpura and hemolytic anemia.", "- Other autoimmune complications associated with CVID include rheumatoid arthritis, pernicious anemia, primary biliary cirrhosis, thyroiditis, sicca syndrome, systemic lupus, and inflammatory bowel disease.", "- Treatment of autoimmunity in CVID includes high-dose immunoglobulins, corticosteroids, selected immunosuppressants, and other immune modulators.", "- The document focuses on autoimmune conditions associated with CVID, potential mechanisms of immune dysregulation, and therapeutic strategies."]}, {"metadata": {"year": 2012}, "authors": ["E. Choi"], "summary": "The immune system is the body\u2019s main line of defense against invasion by infectious organisms, such as bacteria, virus, and fungi. In normal immune systems, an immune response does not occur against the self-antigen, and is called self-tolerance. Autoimmune diseases occur when body tissues are attacked by the body\u2019s own immune system due to loss of tolerance to self-antigens (Dejaco et al., 2006). Under these conditions, body tissues are destroyed by antigen-specific cytotoxic T cells or auto-antibodies, and the accompanying inflammation can cause functional disability and morbidity. Autoimmune diseases are a heterogenous group of diseases with a wide spectrum of symptoms that affect approximately 6% of the population (Siatskas et al., 2006). They can be broadly classified as organ-specific or systemic depending on the location of the target antigen and clinical features (Sakaguchi, 2000). Common examples of systemic autoimmune diseases include systemic lupus erythematosus (SLE), rheumatoid arthritis, systemic sclerosis, ankylosing spondylitis, and polymyositis; examples of organ-specific autoimmune diseases include type 1 diabetes, Addison\u2019s disease, Hashimoto thyroiditis, Graves\u2019 disease, Sjogren's syndrome, vitiligo, pernicious anemia, glomerulonephritis, myasthenia gravis, Goodpasture\u2019s syndrome, autoimmune hemolytic anemia, idiopathic thrombocytopenia purpura, and pulmonary fibrosis. The clinical features of autoimmune diseases are very different, but immunemediated mechanisms are associated with the generation of an adaptive immune response toward the target antigen (Kuby, 1994; Siatskas et al., 2006).", "title": "New Therapeutic Challenges in Autoimmune Diseases", "claims": ["- The immune system is the body\u2019s main line of defense against invasion by infectious organisms, such as bacteria, virus, and fungi.", "- In normal immune systems, an immune response does not occur against the self-antigen, and is called self-tolerance.", "- Autoimmune diseases occur when body tissues are attacked by the body\u2019s own immune system due to loss of tolerance to self-antigens (Dejaco et al., 2006).", "- Under these conditions, body tissues are destroyed by antigen-specific cytotoxic T cells or auto-antibodies, and the accompanying inflammation can cause functional disability and morbidity.", "- Autoimmune diseases are a heterogenous group of diseases with a wide spectrum of symptoms that affect approximately 6% of the population (Siatskas et al., 2006).", "- Autoimmune diseases can be broadly classified as organ-specific or systemic depending on the location of the target antigen and clinical features (Sakaguchi, 2000).", "- Common examples of systemic autoimmune diseases include systemic lupus erythematosus (SLE), rheumatoid arthritis, systemic sclerosis, ankylosing spondylitis, and polymyositis.", "- Examples of organ-specific autoimmune diseases include type 1 diabetes, Addison\u2019s disease, Hashimoto thyroiditis, Graves\u2019 disease, Sjogren's syndrome, vitiligo, pernicious anemia, glomerulonephritis, myasthenia gravis, Goodpasture\u2019s syndrome, autoimmune hemolytic anemia, idiopathic thrombocytopenia purpura, and pulmonary fibrosis.", "- The clinical features of autoimmune diseases are very different, but immune-mediated mechanisms are associated with the generation of an adaptive immune response toward the target antigen (Kuby, 1994; Siatskas et al., 2006)."]}], "query": "Autoimmune disease", "summary_abstract": null, "summary_extract": "The collection of claims provides a comprehensive overview of autoimmune diseases, highlighting their complex nature and underlying mechanisms. Autoimmune diseases arise when the immune system mistakenly attacks the body's own tissues, a process often linked to a loss of self-tolerance (Panayi, 1976; Choi, 2012). This can be triggered by genetic factors, environmental agents, or abnormalities in the immune system itself, such as the loss of suppressor T cells (Panayi, 1976). The immune system's dysfunction leads to the overproduction of antibodies against body tissues, resulting in significant morbidity and disability (Beers, 2001; Nosheen et al., 2021).\n\nAutoimmune diseases are diverse, affecting approximately 6% of the population, and can be classified as either organ-specific or systemic, depending on the location of the target antigen (Choi, 2012). Common systemic autoimmune diseases include systemic lupus erythematosus and rheumatoid arthritis, while organ-specific examples include type 1 diabetes and Hashimoto thyroiditis (Choi, 2012; Richard-Eaglin & Smallheer, 2018).\n\nThe clinical presentation and diagnosis of autoimmune disorders are disease-specific and often correlate with the degree of inflammation and the systems involved (Richard-Eaglin & Smallheer, 2018). Treatment strategies aim to decrease inflammation, minimize symptoms, and reduce the potential for relapse, varying based on the specific disease, stage of presentation, and patient symptoms (Richard-Eaglin & Smallheer, 2018). Autoimmune conditions associated with common variable immunodeficiency (CVID) include immune thrombocytopenic purpura and hemolytic anemia, with treatment involving high-dose immunoglobulins and immunosuppressants (Agarwal & Cunningham-Rundles, 2009).\n\nOverall, autoimmune diseases represent a significant health challenge due to their chronic nature and the complexity of their underlying immune dysregulation."}, {"papers": [{"metadata": {"year": 1990}, "authors": ["J. Hall"], "summary": "Genomic imprinting is the modification of gene expression depending on whether the genetic material is inherited from the mother or the father. The article reviews the concept and its implications in various human disorders such as the chromosomal deletion syndromes, human cancers, endocrine disorders, and various other diseases which show parent-of-origin effects.", "title": "Genomic imprinting.", "claims": ["- Genomic imprinting is the modification of gene expression depending on whether the genetic material is inherited from the mother or the father.", "- The article reviews the concept of genomic imprinting and its implications in various human disorders.", "- Genomic imprinting has implications in chromosomal deletion syndromes.", "- Genomic imprinting has implications in human cancers.", "- Genomic imprinting has implications in endocrine disorders.", "- Genomic imprinting has implications in various other diseases which show parent-of-origin effects."]}, {"metadata": {"year": 1990}, "authors": ["J. Casades\u00fas", "R. Maldonado"], "summary": "Genomic imprinting is an epigenetic mark introduced on a DNA molecule without alteration of the base sequence. Upon replication, the primary mark is propagated to the daughter DNA molecules. Epigenetic DNA modification often serves as a regulatory signal and may play a crucial role in many developmental processes. Although this mode of gene regulation was first discovered in multicellular eukaryotes, cases of imprinting have been recently found in lower eukaryotes, bacteria and phage. Thus it may be reasonable to list DNA modification among the major mechanisms that regulate gene expression.", "title": "Genomic imprinting in microorganisms.", "claims": ["- Genomic imprinting is an epigenetic mark introduced on a DNA molecule without alteration of the base sequence.", "- Upon replication, the primary mark is propagated to the daughter DNA molecules.", "- Epigenetic DNA modification often serves as a regulatory signal.", "- Epigenetic DNA modification may play a crucial role in many developmental processes.", "- This mode of gene regulation was first discovered in multicellular eukaryotes.", "- Cases of imprinting have been recently found in lower eukaryotes, bacteria, and phage.", "- It may be reasonable to list DNA modification among the major mechanisms that regulate gene expression."]}, {"metadata": {"year": 2007}, "authors": ["\u0410. \u0410. \u041f\u0435\u043d\u0434\u0438\u043d\u0430", "\u041e. \u0410. \u0415\u0444\u0438\u043c\u043e\u0432\u0430", "\u0422. \u0412. \u041a\u0443\u0437\u043d\u0435\u0446\u043e\u0432\u0430", "\u0412\u043b\u0430\u0434\u0438\u0441\u043b\u0430\u0432 \u0421\u0435\u0440\u0433\u0435\u0435\u0432\u0438\u0447 \u0411\u0430\u0440\u0430\u043d\u043e\u0432"], "summary": "Genomic imprinting is an epigenetic mechanism of homologous gene expression regulation, depending on their parent-of-origin. The present review is focused on pathologies, heritable diseases and syndromes, caused by disruption of imprinting resulted from hemizygosity of imprinted genes, uniparental disomies and epigenetic disorders.", "title": "\u0411\u043e\u043b\u0435\u0437\u043d\u0438 \u0433\u0435\u043d\u043e\u043c\u043d\u043e\u0433\u043e \u0438\u043c\u043f\u0440\u0438\u043d\u0442\u0438\u043d\u0433\u0430", "claims": ["- Genomic imprinting is an epigenetic mechanism of homologous gene expression regulation, depending on their parent-of-origin.", "- The present review is focused on pathologies, heritable diseases, and syndromes caused by disruption of imprinting.", "- Disruption of imprinting results from hemizygosity of imprinted genes.", "- Disruption of imprinting results from uniparental disomies.", "- Disruption of imprinting results from epigenetic disorders."]}, {"metadata": {"year": 2012}, "authors": ["Lara K Abramowitz", "Marisa S Bartolomei"], "summary": "Genomic imprinting is an epigenetic process resulting in the monoallelic parent-of-origin-specific expression of a subset of genes in the mammalian genome. The parental alleles are differentially marked by DNA methylation during gametogenesis when the genomes are in separate compartments. How methylation machinery recognizes and differentially modifies these imprinted regions in germ cells remains a key question in the field. While studies have focused on determining a sequence signature that alone could distinguish imprinted regions from the rest of the genome, recent reports do not support such a hypothesis. Rather, it is becoming clear that features such as transcription, histone modifications and higher order chromatin are employed either individually or in combination to set up parental imprints.", "title": "Genomic imprinting: recognition and marking of imprinted loci.", "claims": ["", "Genomic imprinting is an epigenetic process resulting in the monoallelic parent-of-origin-specific expression of a subset of genes in the mammalian genome.", "The parental alleles are differentially marked by DNA methylation during gametogenesis when the genomes are in separate compartments.", "How methylation machinery recognizes and differentially modifies these imprinted regions in germ cells remains a key question in the field.", "Studies have focused on determining a sequence signature that alone could distinguish imprinted regions from the rest of the genome.", "Recent reports do not support the hypothesis that a sequence signature alone could distinguish imprinted regions from the rest of the genome.", "It is becoming clear that features such as transcription, histone modifications, and higher order chromatin are employed either individually or in combination to set up parental imprints."]}, {"metadata": {"year": 1997}, "authors": ["N. Niikawa"], "summary": "Genomic imprinting is a new concept proposed to explain unusual observations in early mammalian development, the occurrence of certain genetic diseases, genetic anticipation or incomplete penetrance, and tumorigenesis. The basic mechanism of the imprinting has remained obscure, although DNA-methylation, chromatin structure, and/or DNA replication may have a role. Genomic imprinting is a biological phenomenon determined by an evolutionally acquired, underlying system that may control harmonious development and growth in mammals. It is also relevant to the occurrence of some genetic disorders in man.", "title": "Genomic imprinting relevant to genetic diseases.", "claims": ["- Genomic imprinting is a new concept proposed to explain unusual observations in early mammalian development.", "- Genomic imprinting is a new concept proposed to explain the occurrence of certain genetic diseases.", "- Genomic imprinting is a new concept proposed to explain genetic anticipation or incomplete penetrance.", "- Genomic imprinting is a new concept proposed to explain tumorigenesis.", "- The basic mechanism of genomic imprinting has remained obscure.", "- DNA-methylation, chromatin structure, and/or DNA replication may have a role in the mechanism of genomic imprinting.", "- Genomic imprinting is a biological phenomenon determined by an evolutionally acquired, underlying system.", "- The evolutionally acquired, underlying system of genomic imprinting may control harmonious development and growth in mammals.", "- Genomic imprinting is relevant to the occurrence of some genetic disorders in humans."]}, {"metadata": {"year": 2014}, "authors": ["Parul Gupta", "D. Chakraborty", "R. Taggar", "Dhirendra Kumar", "R. Sharma", "V. P. Singh"], "summary": "Genomic imprinting refers to an epigenetic mark that distinguishes parental alleles and results in a monoallelic, parental-specific expression pattern in mammals. The alleles of imprinted genes are marked epigenetically as discrete elements termed imprinting control regions with their parental origin in gametes through the use of DNA methylation, at the very least. Imprinted genes are normally involved in foetal growth and behavioural development. Consequently, aberrant imprinting disturbs development and is the cause of numerous well-known imprinting disorders, including Beckwith-Wiedemann syndrome, Prader-Willi syndrome, Cancer and Angelman syndrome.", "title": "Genomic imprinting in mammals - a review.", "claims": ["- Genomic imprinting refers to an epigenetic mark that distinguishes parental alleles and results in a monoallelic, parental-specific expression pattern in mammals.", "- The alleles of imprinted genes are marked epigenetically as discrete elements termed imprinting control regions with their parental origin in gametes through the use of DNA methylation, at the very least.", "- Imprinted genes are normally involved in foetal growth and behavioural development.", "- Aberrant imprinting disturbs development and is the cause of numerous well-known imprinting disorders, including Beckwith-Wiedemann syndrome, Prader-Willi syndrome, Cancer, and Angelman syndrome."]}, {"metadata": {"year": 2011}, "authors": ["J. Killian"], "summary": "Genomic imprinting is the biological process whereby a gene or genomic domain exists in a state of epigenetic differentiation that depends upon its parent of origin. Importantly, the establishment and propagation of these parent-specific genomic conformations does not alter the primary DNA sequence comprised of A, C, G, and T nucleotides. Genomic imprints may be covalent (DNA methylation) or non-covalent (DNA-protein and DNA-RNA interactions, genomic localization in nuclear space), and the process of imprinting encompasses the specialized nuclear enzymatic machinery that maintains parental epigenetic markings throughout the cell cycle. Because of genomic imprinting, the parent of origin of homologous genetic alleles in diploid individuals can be determined in the absence of DNA sequence polymorphisms and without recourse to parental DNA samples. As illustrated in Figure 1, alleles of imprinted genes look and behave differently, as determined by parent of origin.", "title": "Genomic Imprinting: Parental differentiation of the genome", "claims": ["- Genomic imprinting is the biological process whereby a gene or genomic domain exists in a state of epigenetic differentiation that depends upon its parent of origin.", "- The establishment and propagation of these parent-specific genomic conformations do not alter the primary DNA sequence comprised of A, C, G, and T nucleotides.", "- Genomic imprints may be covalent (DNA methylation) or non-covalent (DNA-protein and DNA-RNA interactions, genomic localization in nuclear space).", "- The process of imprinting encompasses the specialized nuclear enzymatic machinery that maintains parental epigenetic markings throughout the cell cycle.", "- Because of genomic imprinting, the parent of origin of homologous genetic alleles in diploid individuals can be determined in the absence of DNA sequence polymorphisms and without recourse to parental DNA samples.", "- Alleles of imprinted genes look and behave differently, as determined by parent of origin."]}, {"metadata": {"year": 2021}, "authors": ["E. Sazhenova", "I. Lebedev"], "summary": "Genomic imprinting is an epigenetic phenomenon that differentiates maternal and paternal copies of genes in the genome and causes monoallelic expression depending on parental origin. Imprinting is an evolutionary puzzle, as it bears the costs of diploidization without its advantages, namely, protection from recessive mutations. The aim of this review is to answer the question of why genomic imprinting arose and became fixed in the evolution of angiosperms, insects, marsupials, and placental mammals.", "title": "[Evolutionary Aspects of Genomic Imprinting].", "claims": ["- Genomic imprinting is an epigenetic phenomenon that differentiates maternal and paternal copies of genes in the genome.", "- Genomic imprinting causes monoallelic expression depending on parental origin.", "- Imprinting is an evolutionary puzzle.", "- Imprinting bears the costs of diploidization without its advantages, namely, protection from recessive mutations.", "- The aim of this review is to answer the question of why genomic imprinting arose and became fixed in the evolution of angiosperms, insects, marsupials, and placental mammals."]}], "query": "genomic imprinting", "summary_abstract": null, "summary_extract": "The collection of claims provides a comprehensive overview of genomic imprinting, emphasizing its role as an epigenetic mechanism that results in parent-of-origin-specific gene expression. Hall (1990) describes genomic imprinting as a modification of gene expression based on whether the genetic material is inherited from the mother or the father, highlighting its implications in various human disorders, including chromosomal deletion syndromes, cancers, and endocrine disorders. Casades\u00fas and Maldonado (1990) further elaborate that genomic imprinting involves epigenetic marks introduced on DNA without altering the base sequence, which are propagated during DNA replication and play a crucial role in developmental processes. \n\nAbramowitz and Bartolomei (2012) explain that genomic imprinting results in the monoallelic expression of genes, marked by DNA methylation during gametogenesis, and involves complex mechanisms such as transcription and histone modifications. Niikawa (1997) suggests that genomic imprinting is a concept proposed to explain unusual genetic phenomena, including certain genetic diseases and tumorigenesis, and involves mechanisms like DNA methylation and chromatin structure. Gupta et al. (2014) note that imprinted genes are crucial for fetal growth and behavioral development, and aberrant imprinting can lead to disorders such as Beckwith-Wiedemann syndrome and Prader-Willi syndrome. Killian (2011) adds that genomic imprinting involves covalent and non-covalent modifications, maintaining parental epigenetic markings throughout the cell cycle. Finally, Sazhenova and Lebedev (2021) describe imprinting as an evolutionary puzzle, noting its role in differentiating maternal and paternal gene copies and its evolutionary significance across various species."}, {"papers": [{"metadata": {"year": 2004}, "authors": ["A. Christe", "P. Vock"], "summary": "The most common causes of pulmonary edema are cardiac failure, renal failure and injury edema (diffuse alveolar damage). The injury edema typically shows airspace consolidation due to exsudation of fluid in the periphery of the lung with air bronchograms, no interstitial fluid accumulation can be found and only rarely pleural effusions are present. Cardiac and renal edemas often show a mixed interstitial and alveolar transudation without air bronchograms. Pleural effusions are often present. Both usually have an increased heart-size and an increased vascular pedicle width. To distinguish them better one has to look at the distribution of the pulmonary edema: The cardiac edema typically shows a gravitational and the renal edema a central distribution.", "title": "[Radiologic criteria to differentiate pulmonary edema].", "claims": ["- The most common causes of pulmonary edema are cardiac failure, renal failure, and injury edema (diffuse alveolar damage).", "- The injury edema typically shows airspace consolidation due to exsudation of fluid in the periphery of the lung with air bronchograms.", "- In injury edema, no interstitial fluid accumulation can be found.", "- In injury edema, only rarely are pleural effusions present.", "- Cardiac and renal edemas often show a mixed interstitial and alveolar transudation without air bronchograms.", "- In cardiac and renal edemas, pleural effusions are often present.", "- Cardiac and renal edemas usually have an increased heart-size and an increased vascular pedicle width.", "- To distinguish cardiac and renal edemas better, one has to look at the distribution of the pulmonary edema.", "- The cardiac edema typically shows a gravitational distribution.", "- The renal edema typically shows a central distribution."]}, {"metadata": {"year": 1980}, "authors": ["Hans  Ewerbeck"], "summary": "In patients with nonspecific bronchopneumonias due to viral diseases such as influenza and measles or to mycoplasmal and rickettsial diseases, both hila are enlarged and frequently have indistinct borders. The perihilar markings are increased and consist of streaky densities extending outward, with peribronchial and interstitial infiltrates. Unilateral hilar reactions are seen with unilateral pulmonary lesions (pneumonia, abscess).", "title": "Significant Radiologic Findings in Pulmonary Diagnosis", "claims": ["- In patients with nonspecific bronchopneumonias due to viral diseases such as influenza and measles or to mycoplasmal and rickettsial diseases, both hila are enlarged and frequently have indistinct borders.", "- In patients with nonspecific bronchopneumonias due to viral diseases such as influenza and measles or to mycoplasmal and rickettsial diseases, the perihilar markings are increased and consist of streaky densities extending outward, with peribronchial and interstitial infiltrates.", "- Unilateral hilar reactions are seen with unilateral pulmonary lesions (pneumonia, abscess)."]}, {"metadata": {"year": 1962}, "authors": ["J. P. Lavender", "J. Doppman"], "summary": "The anatomy of the normal hilar shadow as shown on tomograms of 48 normal patients has been reviewed and the importance of the superior pulmonary vein emphasised. The changes occurring in the hilar appearance have been described in 33 patients with mitral valve disease and 45 patients with left ventricular failure. The pulmonary artery was shown to be enlarged in those cases of mitral stenosis having pulmonary arterial hypertension and a similar enlargement in over 50 per cent of the cases of left ventricular failure suggests the existence of pulmonary arterial hypertension in these patients. In the majority of both mitral and left ventricular failure cases, the lateral border of the hilum was straightened or convex, a change shown to be due to enlarged upper lobe veins. This sign, together with a clearly defined, oblique lower border of the superior pulmonary vein, are of value in analysing the hilum in states of pulmonary venous hypertension.", "title": "The hilum in pulmonary venous hypertension.", "claims": ["- The anatomy of the normal hilar shadow as shown on tomograms of 48 normal patients has been reviewed.", "- The importance of the superior pulmonary vein has been emphasised.", "- The changes occurring in the hilar appearance have been described in 33 patients with mitral valve disease.", "- The changes occurring in the hilar appearance have been described in 45 patients with left ventricular failure.", "- The pulmonary artery was shown to be enlarged in cases of mitral stenosis having pulmonary arterial hypertension.", "- A similar enlargement of the pulmonary artery in over 50 per cent of the cases of left ventricular failure suggests the existence of pulmonary arterial hypertension in these patients.", "- In the majority of both mitral and left ventricular failure cases, the lateral border of the hilum was straightened or convex.", "- The change in the lateral border of the hilum was shown to be due to enlarged upper lobe veins.", "- A clearly defined, oblique lower border of the superior pulmonary vein is of value in analysing the hilum in states of pulmonary venous hypertension."]}, {"metadata": {"year": 1987}, "authors": ["J. F. Nunn"], "summary": "Publisher Summary \nThe pulmonary edema is defined as an increase in pulmonary extravascular water, which occurs when transudation or exudation exceeds the capacity of the lymphatic drainage. The pulmonary capillary endothelial cells abut against one another at fairly loose junctions that are of the order of 5 nm wide. These junctions permit the passage of quite large molecules and the pulmonary lymph contains albumin at about half the concentration in plasma. The epithelial cells meet at tight junctions with a gap of only about 1 nm. The tightness of these junctions is crucial for the prevention of the escape of large molecules, such as albumin, from the interstitial fluid into the alveoli. The lung has a well developed lymphatic system draining the interstitial tissue through a network of channels around the bronchi and pulmonary vessels towards the hilum. The lymphatic vessels cannot be identified at alveolar level but can be seen in association with bronchioles.", "title": "Chapter 23 \u2013 Pulmonary oedema", "claims": ["- The pulmonary edema is defined as an increase in pulmonary extravascular water, which occurs when transudation or exudation exceeds the capacity of the lymphatic drainage.", "- The pulmonary capillary endothelial cells abut against one another at fairly loose junctions that are of the order of 5 nm wide.", "- These junctions permit the passage of quite large molecules and the pulmonary lymph contains albumin at about half the concentration in plasma.", "- The epithelial cells meet at tight junctions with a gap of only about 1 nm.", "- The tightness of these junctions is crucial for the prevention of the escape of large molecules, such as albumin, from the interstitial fluid into the alveoli.", "- The lung has a well developed lymphatic system draining the interstitial tissue through a network of channels around the bronchi and pulmonary vessels towards the hilum.", "- The lymphatic vessels cannot be identified at alveolar level but can be seen in association with bronchioles."]}, {"metadata": {"year": 2020}, "authors": ["Maria  Barile"], "summary": "Pulmonary edema is a common clinical entity caused by the extravascular movement of fluid into the pulmonary interstitium and alveoli. The four physiologic categories of edema include hydrostatic pressure edema, permeability edema with and without diffuse alveolar damage (DAD), and mixed edema where there is both an increase in hydrostatic pressure and membrane permeability. As radiographic manifestations and etiologies are varied, an appreciation for both the common and uncommon manifestations and causes of pulmonary edema is essential for accurate diagnosis.", "title": "Pulmonary Edema: A Pictorial Review of Imaging Manifestations and Current Understanding of Mechanisms of Disease", "claims": ["- Pulmonary edema is a common clinical entity caused by the extravascular movement of fluid into the pulmonary interstitium and alveoli.", "- The four physiologic categories of edema include hydrostatic pressure edema, permeability edema with and without diffuse alveolar damage (DAD), and mixed edema where there is both an increase in hydrostatic pressure and membrane permeability.", "- Radiographic manifestations and etiologies of pulmonary edema are varied.", "- An appreciation for both the common and uncommon manifestations and causes of pulmonary edema is essential for accurate diagnosis."]}, {"metadata": {"year": 1989}, "authors": ["J. Gurney", "L. Goodman"], "summary": "Focal patterns of pulmonary edema are confusing and often mistaken for the more common causes of focal lung disease, pneumonia, infarction, or aspiration. The authors report four cases of right upper lobe edema secondary to mitral regurgitation. The pathogenesis believed to be responsible for this condition is the vector of blood flow from the left ventricle to left atrium, which may be targeted at the right superior pulmonary vein, locally accentuating the forces for edema formation in the right upper lobe. Pulmonary edema accompanying mitral regurgitation should be suspected whenever right upper lobe consolidation develops in a patient with known or suspected mitral valve disease. The presence of interstitial edema in the remainder of the lungs can help in the differentiation of this condition from pneumonia and other disorders.", "title": "Pulmonary edema localized in the right upper lobe accompanying mitral regurgitation.", "claims": ["- Focal patterns of pulmonary edema are confusing and often mistaken for the more common causes of focal lung disease, pneumonia, infarction, or aspiration.", "- The authors report four cases of right upper lobe edema secondary to mitral regurgitation.", "- The pathogenesis believed to be responsible for this condition is the vector of blood flow from the left ventricle to left atrium, which may be targeted at the right superior pulmonary vein, locally accentuating the forces for edema formation in the right upper lobe.", "- Pulmonary edema accompanying mitral regurgitation should be suspected whenever right upper lobe consolidation develops in a patient with known or suspected mitral valve disease.", "- The presence of interstitial edema in the remainder of the lungs can help in the differentiation of this condition from pneumonia and other disorders."]}, {"metadata": {"year": 1971}, "authors": [], "summary": "obstruction of the superior vena cava as its main clinical characteristic. When the fibrosis develops at the hilar level, typically in the age group 15 to 35, a mainly unilateral mass may cause only mild respiratory disability. If both hila are affected, increasing incapacity may lead to death. The diagnosis of hilar fibrosis is often difficult, especially when the mass is not obvious radiologically. The clinical findings vary according to whether the arteries or veins are predominantly affected.3 When the arteries bear the brunt, recurrent pulmonary and pleural infections are the rule; haemoptyses may result from widespread bronchopulmonary anastomoses. Radiographs show a shift of the mediastinum to the affected side, a small pulmonary artery, and a thickened pleura. Angiograms and studies of lung function confirm the diminished arterial blood flow. Pulmonary hypertension develops when both pulmonary arteries are involved. When the veins are mainly infiltrated, severe haemoptyses may arise from capillary congestion. Pulmonary hypertension may lead to right heart failure. Radiographs usually show a small lung with venous congestion and pleural thickening. Cardiac catheterization may show an exceptionally high pulmonary artery pressure. Additional diagnostic evidence of idiopathic hilar fibrosis may come from bronchography or bronchoscopy, when a long smooth bronchial stricture may be evident owing to compression of the associated large airways by fibrous tissue. The main differential diagnosis is from primary lung cancer, and it may be resolved only at thoracotomy. Primary pulmonary venous sclerosis is not associated with a hilar mass, nor are the larger bronchi affected. Medical treatment has nothing effective to offer. Surgical correction of obstruction is rarely feasible and attempts to dilate bronchial strictures may lead to dangerous haemorrhage. Perhaps these unfortunate patients, few as they are, will be afforded relief when more is known of the cause of this obscure malady.", "title": "Bites and blains.", "claims": ["", "Obstruction of the superior vena cava is the main clinical characteristic of the condition described.", "When fibrosis develops at the hilar level, typically in the age group 15 to 35, it may cause a mainly unilateral mass that results in only mild respiratory disability.", "If both hila are affected by fibrosis, increasing incapacity may lead to death.", "The diagnosis of hilar fibrosis is often difficult, especially when the mass is not obvious radiologically.", "The clinical findings of hilar fibrosis vary according to whether the arteries or veins are predominantly affected.", "When the arteries are predominantly affected in hilar fibrosis, recurrent pulmonary and pleural infections are common.", "Haemoptyses may result from widespread bronchopulmonary anastomoses when the arteries are affected in hilar fibrosis.", "Radiographs show a shift of the mediastinum to the affected side, a small pulmonary artery, and a thickened pleura when the arteries are affected in hilar fibrosis.", "Angiograms and studies of lung function confirm diminished arterial blood flow when the arteries are affected in hilar fibrosis.", "Pulmonary hypertension develops when both pulmonary arteries are involved in hilar fibrosis.", "When the veins are mainly infiltrated in hilar fibrosis, severe haemoptyses may arise from capillary congestion.", "Pulmonary hypertension may lead to right heart failure when the veins are affected in hilar fibrosis.", "Radiographs usually show a small lung with venous congestion and pleural thickening when the veins are affected in hilar fibrosis.", "Cardiac catheterization may show an exceptionally high pulmonary artery pressure when the veins are affected in hilar fibrosis.", "Additional diagnostic evidence of idiopathic hilar fibrosis may come from bronchography or bronchoscopy, where a long smooth bronchial stricture may be evident due to compression of the associated large airways by fibrous tissue.", "The main differential diagnosis of idiopathic hilar fibrosis is from primary lung cancer, and it may be resolved only at thoracotomy.", "Primary pulmonary venous sclerosis is not associated with a hilar mass, nor are the larger bronchi affected.", "Medical treatment has nothing effective to offer for idiopathic hilar fibrosis.", "Surgical correction of obstruction in idiopathic hilar fibrosis is rarely feasible.", "Attempts to dilate bronchial strictures in idiopathic hilar fibrosis may lead to dangerous haemorrhage.", "Perhaps these unfortunate patients with idiopathic hilar fibrosis, few as they are, will be afforded relief when more is known of the cause of this obscure malady."]}, {"metadata": {"year": 1971}, "authors": ["R. Singer", "C. Ogilvy", "G. Rordorf", "J. Biller", "J. Wilterdink"], "summary": "obstruction of the superior vena cava as its main clinical characteristic. When the fibrosis develops at the hilar level, typically in the age group 15 to 35, a mainly unilateral mass may cause only mild respiratory disability. If both hila are affected, increasing incapacity may lead to death. The diagnosis of hilar fibrosis is often difficult, especially when the mass is not obvious radiologically. The clinical findings vary according to whether the arteries or veins are predominantly affected.3 When the arteries bear the brunt, recurrent pulmonary and pleural infections are the rule; haemoptyses may result from widespread bronchopulmonary anastomoses. Radiographs show a shift of the mediastinum to the affected side, a small pulmonary artery, and a thickened pleura. Angiograms and studies of lung function confirm the diminished arterial blood flow. Pulmonary hypertension develops when both pulmonary arteries are involved. When the veins are mainly infiltrated, severe haemoptyses may arise from capillary congestion. Pulmonary hypertension may lead to right heart failure. Radiographs usually show a small lung with venous congestion and pleural thickening. Cardiac catheterization may show an exceptionally high pulmonary artery pressure. Additional diagnostic evidence of idiopathic hilar fibrosis may come from bronchography or bronchoscopy, when a long smooth bronchial stricture may be evident owing to compression of the associated large airways by fibrous tissue. The main differential diagnosis is from primary lung cancer, and it may be resolved only at thoracotomy. Primary pulmonary venous sclerosis is not associated with a hilar mass, nor are the larger bronchi affected. Medical treatment has nothing effective to offer. Surgical correction of obstruction is rarely feasible and attempts to dilate bronchial strictures may lead to dangerous haemorrhage. Perhaps these unfortunate patients, few as they are, will be afforded relief when more is known of the cause of this obscure malady.", "title": "Treatment of aneurysmal subarachnoid haemorrhage.", "claims": ["- Obstruction of the superior vena cava is the main clinical characteristic of the condition described.", "- When fibrosis develops at the hilar level, typically in the age group 15 to 35, it may cause a mainly unilateral mass that results in only mild respiratory disability.", "- If both hila are affected, increasing incapacity may lead to death.", "- The diagnosis of hilar fibrosis is often difficult, especially when the mass is not obvious radiologically.", "- The clinical findings vary according to whether the arteries or veins are predominantly affected.", "- When the arteries bear the brunt, recurrent pulmonary and pleural infections are common.", "- Haemoptyses may result from widespread bronchopulmonary anastomoses when the arteries are affected.", "- Radiographs show a shift of the mediastinum to the affected side, a small pulmonary artery, and a thickened pleura when the arteries are affected.", "- Angiograms and studies of lung function confirm diminished arterial blood flow when the arteries are affected.", "- Pulmonary hypertension develops when both pulmonary arteries are involved.", "- When the veins are mainly infiltrated, severe haemoptyses may arise from capillary congestion.", "- Pulmonary hypertension may lead to right heart failure.", "- Radiographs usually show a small lung with venous congestion and pleural thickening when the veins are affected.", "- Cardiac catheterization may show an exceptionally high pulmonary artery pressure.", "- Additional diagnostic evidence of idiopathic hilar fibrosis may come from bronchography or bronchoscopy, where a long smooth bronchial stricture may be evident due to compression of the associated large airways by fibrous tissue.", "- The main differential diagnosis is from primary lung cancer, and it may be resolved only at thoracotomy.", "- Primary pulmonary venous sclerosis is not associated with a hilar mass, nor are the larger bronchi affected.", "- Medical treatment has nothing effective to offer for this condition.", "- Surgical correction of obstruction is rarely feasible, and attempts to dilate bronchial strictures may lead to dangerous haemorrhage.", "- Relief for these patients may be possible when more is known about the cause of this obscure malady."]}], "query": "why does pulmonary edema tend to occur in hilar area rather than peripheral?", "summary_abstract": null, "summary_extract": "The tendency for pulmonary edema to occur in the hilar area rather than the periphery can be attributed to several factors related to the distribution and drainage of fluid in the lungs. Nunn (1987) highlights the role of the lung's lymphatic system, which is well-developed around the bronchi and pulmonary vessels, directing fluid towards the hilum. This anatomical feature suggests that fluid accumulation is more likely to be observed centrally. Additionally, Christe and Vock (2004) note that renal edema typically shows a central distribution, which aligns with the hilar region, while cardiac edema often follows a gravitational pattern. This central distribution is further supported by the observation that the pulmonary lymphatic vessels, which are crucial for draining interstitial fluid, are associated with bronchioles and not present at the alveolar level (Nunn, 1987). Therefore, the anatomical and physiological characteristics of the lung's drainage system contribute to the central, or hilar, localization of pulmonary edema."}, {"papers": [{"metadata": {"year": 2010}, "authors": ["Chunyan  He", "Abrar A.  Qureshi", "Jiali  Han"], "summary": "Ultraviolet (UV)-induced oxidative stress has been implicated in skin carcinogenesis [1]. Several antioxidant enzymes, such as glutathione peroxidase (GPX) and catalase (CAT), counteract oxidative damage and constitute a primary defense against oxidative stress. GPX is a soluble selenoprotein that reduces H2O2 and organic hydroperoxides to H2O, and GPX1 is the most abundant and ubiquitous intracellular isoform [1]. GPX1 activity is not strongly affected by UV and is considered to be the most important antioxidant enzyme defense mechanism in the skin [2]. CAT is a heme enzyme that neutralizes reactive oxygen species by converting H2O2 to H2O and O2. CAT activity in the skin is significantly reduced after exposure to UV [2], which suggests its effect may be prone to effect modification by environmental factors. \n \nInherited variants in the encoding genes that affect the activity or expression of these antioxidant enzymes are hypothesized to modulate oxidative stress and thus influence skin cancer risk. A polymorphism in the GPX1 gene (Pro198Leu, rs1050450) and a polymorphism in the promoter region of the CAT gene (C-262T, rs1001179) have been shown to be associated with lower enzyme activities of their encoded enzymes [3, 4]. To test our main hypothesis that these two genetic polymorphisms are associated with skin cancer risk, we conducted a nested case-control study of Caucasians (218 melanoma, 285 squamous cell carcinoma (SCC), and 300 basal cell carcinoma (BCC) cases, and 870 age-matched controls) within the Nurses\u2019 Health Study. We further investigated potential gene-environment interactions between these polymorphisms and lifestyle factors such as dietary antioxidant intake and sun exposure related risk factors. A detailed description of the characteristics of cases and controls was published previously [5]. Information on dietary intake was collected prospectively by food-frequency questionnaires, and total-energy-adjusted cumulative average of dietary intake was used to reduce within-person variation and represent long-term dietary intake [6]. \n \nWe genotyped the two single nuclear polymorphisms (SNPs) (rs1050450 and rs1001179) by the 5\u2032 nuclease assay (TaqMan\u00ae) in 384-well format, using the ABI PRISM 7900HT Sequence Detection System (Applied Biosystems, Foster City, CA). The distributions of genotypes for the two SNPs were in Hardy-Weinberg equilibrium among controls (p=0.94, 0.83, respectively). We compared the cases of each type of skin cancer to the common control series. We used unconditional multivariate logistic regression to model the association between genetic polymorphisms and skin cancer risk and to estimate multivariate Odds Ratios (ORs) and 95% Confidence Intervals (CIs). To test statistical significance of gene-environmental interactions, we used dominant model for genotypes and dichotomized environmental exposures as low versus high based on median values among controls. We tested the statistical significance of a single multiplicative interaction term. \n \nIn the main effect analysis (Table 1), we observed that the GPX1 198 Leu/Leu genotype was significantly associated with a two-fold increased risk of melanoma (OR, 2.14; 95% CI, 1.22\u20133.72), after adjustment for age and other covariates. No association was found between this polymorphism and SCC or BCC risk, which was consistent with one previous study [7]. This polymorphism has been shown to be associated with lung cancer [8] and breast cancer [3] previously. We did not observe significant association between the CAT C-262T polymorphism and the risk of any type of skin cancer. \n \n \n \nTable 1 \n \nAssociation between GPX Pro198Leu and CAT C-262T genetic polymorphisms and skin cancer risk a \n \n \n \nAs exploratory analyses, we further tested gene-environment interactions between the genetic variants and lifestyle factors that modulate oxidative stress. We found the association between the CAT C-262T polymorphism and melanoma risk was significantly modified by history of severe sunburns (p for interaction, 0.008, Table 2), a variable combining exposure intensity and biological response to sun exposure. The positive association between history of severe sunburns and melanoma risk was restricted to T carriers (OR, 1.73; 95% CI, 1.02\u20132.92), compared to women with CC genotype (OR, 1.03; 95% CI, 0.63\u20131.69). We also observed a significant gene-diet interaction between the CAT C-262T polymorphism and total carotenoid intake on melanoma risk (p for interaction, 0.01). The inverse association of total carotenoid intake with melanoma risk was limited among women with CC genotype (OR, 0.63; 95% CI, 0.41\u20130.97), whereas no association was observed among T carriers (OR, 1.23; 95% CI, 0.77\u20131.97). Inconsistent results were reported on the relationship between dietary carotenoid intake and melanoma risk in several previous case-control studies. An inverse association between the intake and the risk of melanoma was observed in some studies [9], but not in other studies [10]. Our results suggest that the inconsistency in the literature may reflect a potential gene-diet interaction. As we tested different genetic polymorphisms, multiple environmental exposures and dietary factors, and three types of skin cancer, multiple testing in our study may lead to false positive results. Replications in independent studies are needed to validate these results. No significant interactions were observed between the GPX1 polymorphism and these lifestyle factors on melanoma risk. We did not observe any significant interaction between these genetic variants and environmental exposures on the risk of SCC or BCC. \n \n \n \nTable 2 \n \nInteraction between the CAT C-262T genetic polymorphism and history of severe sunburns and total carotenoid intake on melanoma risk \n \n \n \nIn summary, we first observed the GPX1 198 Leu/Leu genotype was significantly associated with a two-fold increased risk of melanoma, and the association between the CAT C-262T polymorphism and melanoma risk was significantly modified by history of severe sunburns and total carotenoid intake. Further research is needed to confirm these possible associations and illustrate the underlying molecular mechanisms.", "title": "Polymorphisms in genes involved in oxidative stress and their interactions with lifestyle factors on skin cancer risk.", "claims": ["- Ultraviolet (UV)-induced oxidative stress has been implicated in skin carcinogenesis.", "- Several antioxidant enzymes, such as glutathione peroxidase (GPX) and catalase (CAT), counteract oxidative damage and constitute a primary defense against oxidative stress.", "- GPX is a soluble selenoprotein that reduces H2O2 and organic hydroperoxides to H2O, and GPX1 is the most abundant and ubiquitous intracellular isoform.", "- GPX1 activity is not strongly affected by UV and is considered to be the most important antioxidant enzyme defense mechanism in the skin.", "- CAT is a heme enzyme that neutralizes reactive oxygen species by converting H2O2 to H2O and O2.", "- CAT activity in the skin is significantly reduced after exposure to UV, which suggests its effect may be prone to effect modification by environmental factors.", "- Inherited variants in the encoding genes that affect the activity or expression of these antioxidant enzymes are hypothesized to modulate oxidative stress and thus influence skin cancer risk.", "- A polymorphism in the GPX1 gene (Pro198Leu, rs1050450) and a polymorphism in the promoter region of the CAT gene (C-262T, rs1001179) have been shown to be associated with lower enzyme activities of their encoded enzymes.", "- The study conducted a nested case-control study of Caucasians (218 melanoma, 285 squamous cell carcinoma (SCC), and 300 basal cell carcinoma (BCC) cases, and 870 age-matched controls) within the Nurses\u2019 Health Study to test the hypothesis that these two genetic polymorphisms are associated with skin cancer risk.", "- The study further investigated potential gene-environment interactions between these polymorphisms and lifestyle factors such as dietary antioxidant intake and sun exposure related risk factors.", "- Information on dietary intake was collected prospectively by food-frequency questionnaires, and total-energy-adjusted cumulative average of dietary intake was used to reduce within-person variation and represent long-term dietary intake.", "- The study genotyped the two single nuclear polymorphisms (SNPs) (rs1050450 and rs1001179) by the 5\u2032 nuclease assay (TaqMan\u00ae) in 384-well format, using the ABI PRISM 7900HT Sequence Detection System.", "- The distributions of genotypes for the two SNPs were in Hardy-Weinberg equilibrium among controls (p=0.94, 0.83, respectively).", "- The study used unconditional multivariate logistic regression to model the association between genetic polymorphisms and skin cancer risk and to estimate multivariate Odds Ratios (ORs) and 95% Confidence Intervals (CIs).", "- In the main effect analysis, the GPX1 198 Leu/Leu genotype was significantly associated with a two-fold increased risk of melanoma (OR, 2.14; 95% CI, 1.22\u20133.72), after adjustment for age and other covariates.", "- No association was found between the GPX1 polymorphism and SCC or BCC risk, which was consistent with one previous study.", "- The GPX1 polymorphism has been shown to be associated with lung cancer and breast cancer previously.", "- The study did not observe a significant association between the CAT C-262T polymorphism and the risk of any type of skin cancer.", "- The association between the CAT C-262T polymorphism and melanoma risk was significantly modified by history of severe sunburns (p for interaction, 0.008).", "- The positive association between history of severe sunburns and melanoma risk was restricted to T carriers (OR, 1.73; 95% CI, 1.02\u20132.92), compared to women with CC genotype (OR, 1.03; 95% CI, 0.63\u20131.69).", "- A significant gene-diet interaction was observed between the CAT C-262T polymorphism and total carotenoid intake on melanoma risk (p for interaction, 0.01).", "- The inverse association of total carotenoid intake with melanoma risk was limited among women with CC genotype (OR, 0.63; 95% CI, 0.41\u20130.97), whereas no association was observed among T carriers (OR, 1.23; 95% CI, 0.77\u20131.97).", "- Inconsistent results were reported on the relationship between dietary carotenoid intake and melanoma risk in several previous case-control studies.", "- An inverse association between dietary carotenoid intake and the risk of melanoma was observed in some studies, but not in other studies.", "- The study suggests that the inconsistency in the literature may reflect a potential gene-diet interaction.", "- Multiple testing in the study may lead to false positive results, and replications in independent studies are needed to validate these results.", "- No significant interactions were observed between the GPX1 polymorphism and lifestyle factors on melanoma risk.", "- No significant interaction was observed between these genetic variants and environmental exposures on the risk of SCC or BCC.", "- The study first observed the GPX1 198 Leu/Leu genotype was significantly associated with a two-fold increased risk of melanoma.", "- The association between the CAT C-262T polymorphism and melanoma risk was significantly modified by history of severe sunburns and total carotenoid intake.", "- Further research is needed to confirm these possible associations and illustrate the underlying molecular mechanisms."]}, {"metadata": {"year": 2011}, "authors": ["D. Robbins", "Yunfeng Zhao"], "summary": "Recent studies have shown that antioxidant enzyme expression and activity are drastically reduced in most human skin diseases, leading to propagation of oxidative stress and continuous disease progression. However, antioxidants, an endogenous defense system against reactive oxygen species (ROS), can be induced by exogenous sources, resulting in protective effects against associated oxidative injury. Many studies have shown that the induction of antioxidants is an effective strategy to combat various disease states. In one approach, a SOD mimetic was applied topically to mouse skin in the two-stage skin carcinogenesis model. This method effectively reduced oxidative injury and proliferation without interfering with apoptosis. In another approach, Protandim, a combination of 5 well-studied medicinal plants, was given via dietary administration and significantly decreased tumor incidence and multiplicity by 33% and 57%, respectively. These studies suggest that alterations in antioxidant response may be a novel approach to chemoprevention. This paper focuses on how regulation of antioxidant expression and activity can be modulated in skin disease and the potential clinical implications of antioxidant-based therapies.", "title": "The Role of Manganese Superoxide Dismutase in Skin Cancer", "claims": ["- Recent studies have shown that antioxidant enzyme expression and activity are drastically reduced in most human skin diseases, leading to propagation of oxidative stress and continuous disease progression.", "- Antioxidants, an endogenous defense system against reactive oxygen species (ROS), can be induced by exogenous sources, resulting in protective effects against associated oxidative injury.", "- Many studies have shown that the induction of antioxidants is an effective strategy to combat various disease states.", "- In one approach, a SOD mimetic was applied topically to mouse skin in the two-stage skin carcinogenesis model, effectively reducing oxidative injury and proliferation without interfering with apoptosis.", "- In another approach, Protandim, a combination of 5 well-studied medicinal plants, was given via dietary administration and significantly decreased tumor incidence and multiplicity by 33% and 57%, respectively.", "- These studies suggest that alterations in antioxidant response may be a novel approach to chemoprevention.", "- This paper focuses on how regulation of antioxidant expression and activity can be modulated in skin disease and the potential clinical implications of antioxidant-based therapies."]}, {"metadata": {"year": 2017}, "authors": ["W. Chowdhury", "Shahida Arbee", "S. Debnath", "Shah Mehedi Bin Zahur", "Sharmim Akter", "A. Karim", "Md. Mohabbulla Mohib", "A. Tisha", "Md Abu Taher Sagor", "Sarif Mohiuddin"], "summary": "Evidence reported that cancers are spreading every nook and corner of the world at an alarming rate. Skin diseases like chronic skin inflammations, psoriasis and skin cancers have also been burning topic in today. Protections of a biological system are often hampered while skin gets damaged. Factors like UV, radiation, viruses, chronic diseases, genetic predispositions, food habits and environmental exposures might lead to skin cancers. In addition to these, urbanization and globalization may also contaminate the environment that may eventually modify several biological and genetic functions. USA, Europe and Australia are in the most dangerous zone to be exposed. We basically performed detailed search of PubMed, Google Scholar and Science Direct for literature search and collecting related information. On the other hand, experiments suggested that antioxidant components such as phenolic acid derivatives, flavonoids and flavonol found to be preventive against cancer cell proliferations. Moreover, antioxidants have been also evaluated as a protective agent against chronic inflammatory diseases as well. These molecules may participate as an additional therapy which could exert synergistic effects while applying with other chemotherapeutic agents. Our literature findings and hypothetical figure may establish a good correlation between skin cancer and antioxidant therapy. Therefore this study will be focused on skin cancer biology and some possible management strategies using antioxidant phyto-nutrients.", "title": "Potent Role of Antioxidant Molecules in Prevention and Management of SkinCancer", "claims": ["", "Evidence reported that cancers are spreading every nook and corner of the world at an alarming rate.", "Skin diseases like chronic skin inflammations, psoriasis, and skin cancers have also been a burning topic today.", "Protections of a biological system are often hampered while skin gets damaged.", "Factors like UV, radiation, viruses, chronic diseases, genetic predispositions, food habits, and environmental exposures might lead to skin cancers.", "Urbanization and globalization may also contaminate the environment that may eventually modify several biological and genetic functions.", "USA, Europe, and Australia are in the most dangerous zone to be exposed to skin cancers.", "A detailed search of PubMed, Google Scholar, and Science Direct was performed for literature search and collecting related information.", "Experiments suggested that antioxidant components such as phenolic acid derivatives, flavonoids, and flavonol are found to be preventive against cancer cell proliferations.", "Antioxidants have been evaluated as a protective agent against chronic inflammatory diseases as well.", "Antioxidant molecules may participate as an additional therapy which could exert synergistic effects while applying with other chemotherapeutic agents.", "Literature findings and hypothetical figures may establish a good correlation between skin cancer and antioxidant therapy.", "The study will be focused on skin cancer biology and some possible management strategies using antioxidant phyto-nutrients."]}, {"metadata": {"year": 2014}, "authors": ["A. Godic", "B. Polj\u0161ak", "M. Adami\u010d", "R. Dahmane"], "summary": "Skin cells are constantly exposed to reactive oxygen species (ROS) and oxidative stress from exogenous and endogenous sources. UV radiation is the most important environmental factor in the development of skin cancer and skin aging. The primary products caused by UV exposure are generally direct DNA oxidation or generation of free radicals which form and decompose extremely quickly but can produce effects that can last for hours, days, or even years. UV-induced generation of ROS in the skin develops oxidative stress when their formation exceeds the antioxidant defense ability. The reduction of oxidative stress can be achieved on two levels: by lowering exposure to UVR and/or by increasing levels of antioxidant defense in order to scavenge ROS. The only endogenous protection of our skin is melanin and enzymatic antioxidants. Melanin, the pigment deposited by melanocytes, is the first line of defense against DNA damage at the surface of the skin, but it cannot totally prevent skin damage. A second category of defense is repair processes, which remove the damaged biomolecules before they can accumulate and before their presence results in altered cell metabolism. Additional UV protection includes avoidance of sun exposure, usage of sunscreens, protective clothes, and antioxidant supplements.", "title": "The Role of Antioxidants in Skin Cancer Prevention and Treatment", "claims": ["- Skin cells are constantly exposed to reactive oxygen species (ROS) and oxidative stress from exogenous and endogenous sources.", "- UV radiation is the most important environmental factor in the development of skin cancer and skin aging.", "- The primary products caused by UV exposure are generally direct DNA oxidation or generation of free radicals which form and decompose extremely quickly but can produce effects that can last for hours, days, or even years.", "- UV-induced generation of ROS in the skin develops oxidative stress when their formation exceeds the antioxidant defense ability.", "- The reduction of oxidative stress can be achieved on two levels: by lowering exposure to UVR and/or by increasing levels of antioxidant defense in order to scavenge ROS.", "- The only endogenous protection of our skin is melanin and enzymatic antioxidants.", "- Melanin, the pigment deposited by melanocytes, is the first line of defense against DNA damage at the surface of the skin, but it cannot totally prevent skin damage.", "- A second category of defense is repair processes, which remove the damaged biomolecules before they can accumulate and before their presence results in altered cell metabolism.", "- Additional UV protection includes avoidance of sun exposure, usage of sunscreens, protective clothes, and antioxidant supplements."]}, {"metadata": {"year": 2003}, "authors": ["S. Briganti", "M. Picardo"], "summary": "Due to its interface function between the body and the environment, the skin is chronically exposed to both endogenous and environmental pro\u2010oxidant agents, leading to the harmful generation of reactive oxygen species (ROS). There is compelling evidence that oxidative stress is involved in the damage of cellular constituents, such as DNA, cell membrane lipids or proteins. To protect the skin against the over\u2010load of oxidant species, it contains a well\u2010organised system of both chemical and enzymatic antioxidant which are able to work in a synergistic manner. Skin antioxidant network protects cells against oxidative injury and prevent the production of oxidation products, such as 4\u2010hydroxy\u20102\u2010nonenal or malonaldehyde, which are able to induce protein damage, apoptosis or release of pro\u2010inflammatory mediators, such as cytokines. When oxidative stress overwhelms the skin antioxidant capacity the subsequent modification of cellular redox apparatus leads to an alteration of cell homeostasis and a generation of degenerative processes. Topical application or oral administration of antioxidants has been recently suggested as preventive therapy for skin photoaging and UV\u2010induced cancer. The recognition that ROS can act as second messengers in the induction of several biological responses, such as the activation of NF\u2010kB or AP\u20101, the generation of cytokines, the modulation of signalling pathways, etc., has led many researchers to focus on the possible effects of antioxidants in many pathological processes. The recent demonstration that the peroxisome proliferators\u2010activated receptors, whose natural ligands are polyunsaturated fatty acids and theirs oxidation products, have a central role in the induction of some skin diseases, such as psoriasis or acne, has indicated new links between free radicals and skin inflammation. Based on these findings, the review summarises the possible correlations between antioxidant imbalance, lipid oxidative breakage and skin diseases, from both a pathological and therapeutic points of view.", "title": "Antioxidant activity, lipid peroxidation and skin diseases. What's new", "claims": ["- The skin is chronically exposed to both endogenous and environmental pro\u2010oxidant agents due to its interface function between the body and the environment.", "- The exposure of the skin to pro\u2010oxidant agents leads to the harmful generation of reactive oxygen species (ROS).", "- There is compelling evidence that oxidative stress is involved in the damage of cellular constituents, such as DNA, cell membrane lipids, or proteins.", "- The skin contains a well\u2010organised system of both chemical and enzymatic antioxidants to protect against the overload of oxidant species.", "- The skin's antioxidant network is able to work in a synergistic manner to protect cells against oxidative injury.", "- The skin's antioxidant network prevents the production of oxidation products, such as 4\u2010hydroxy\u20102\u2010nonenal or malonaldehyde, which can induce protein damage, apoptosis, or release of pro\u2010inflammatory mediators, such as cytokines.", "- When oxidative stress overwhelms the skin's antioxidant capacity, it leads to a modification of the cellular redox apparatus, an alteration of cell homeostasis, and the generation of degenerative processes.", "- Topical application or oral administration of antioxidants has been recently suggested as preventive therapy for skin photoaging and UV\u2010induced cancer.", "- ROS can act as second messengers in the induction of several biological responses, such as the activation of NF\u2010kB or AP\u20101, the generation of cytokines, and the modulation of signalling pathways.", "- The recognition of ROS as second messengers has led many researchers to focus on the possible effects of antioxidants in many pathological processes.", "- The recent demonstration that peroxisome proliferators\u2010activated receptors, whose natural ligands are polyunsaturated fatty acids and their oxidation products, have a central role in the induction of some skin diseases, such as psoriasis or acne.", "- The demonstration of the role of peroxisome proliferators\u2010activated receptors has indicated new links between free radicals and skin inflammation.", "- The review summarises the possible correlations between antioxidant imbalance, lipid oxidative breakage, and skin diseases, from both pathological and therapeutic points of view."]}, {"metadata": {"year": 2023}, "authors": ["K. Sable", "B. Shields"], "summary": "Dietary supplements, including vitamins and their derivatives, have been utilized within the field of dermatology to treat a variety of skin conditions. Antioxidants inhibit oxidation and decrease cellular damage caused by free radicals, potentially preventing DNA damage due to UV radiation. Laboratory studies have demonstrated promising results supporting the possible role of antioxidants for prevention of skin cancer related to UV exposure. We review the effects of frequently encountered antioxidants and vitamins suggested for the chemoprevention of melanoma and nonmelanoma skin cancer (NMSC) in humans.", "title": "The Role of Dietary Antioxidants in Melanoma and Nonmelanoma Skin Cancer.", "claims": ["- Dietary supplements, including vitamins and their derivatives, have been utilized within the field of dermatology to treat a variety of skin conditions.", "- Antioxidants inhibit oxidation and decrease cellular damage caused by free radicals.", "- Antioxidants potentially prevent DNA damage due to UV radiation.", "- Laboratory studies have demonstrated promising results supporting the possible role of antioxidants for prevention of skin cancer related to UV exposure.", "- The document reviews the effects of frequently encountered antioxidants and vitamins suggested for the chemoprevention of melanoma and nonmelanoma skin cancer (NMSC) in humans."]}, {"metadata": {"year": 2017}, "authors": ["M. Furue", "H. Uchi", "C. Mitoma", "A. Hashimoto-Hachiya", "T. Chiba", "Takamichi Ito", "T. Nakahara", "G. Tsuji"], "summary": "Skin is the outermost part of the body and is, thus, inevitably exposed to UV rays and environmental pollutants. Oxidative stress by these hazardous factors accelerates skin aging and induces skin inflammation and carcinogenesis. Aryl hydrocarbon receptors (AHRs) are chemical sensors that are abundantly expressed in epidermal keratinocytes and mediate the production of reactive oxygen species. To neutralize or minimize oxidative stress, the keratinocytes also express nuclear factor-erythroid 2-related factor-2 (NRF2), which is a master switch for antioxidant signaling. Notably, there is fine-tuned crosstalk between AHR and NRF2, which mutually increase or decrease their activation states. Many NRF2-mediated antioxidant phytochemicals are capable of up- and downmodulating AHR signaling. The precise mechanisms by which these phytochemicals differentially affect the AHR and NRF2 system remain largely unknown and warrant future investigation.", "title": "Antioxidants for Healthy Skin: The Emerging Role of Aryl Hydrocarbon Receptors and Nuclear Factor-Erythroid 2-Related Factor-2", "claims": ["- Skin is the outermost part of the body and is, thus, inevitably exposed to UV rays and environmental pollutants.", "- Oxidative stress by these hazardous factors accelerates skin aging and induces skin inflammation and carcinogenesis.", "- Aryl hydrocarbon receptors (AHRs) are chemical sensors that are abundantly expressed in epidermal keratinocytes and mediate the production of reactive oxygen species.", "- To neutralize or minimize oxidative stress, the keratinocytes also express nuclear factor-erythroid 2-related factor-2 (NRF2), which is a master switch for antioxidant signaling.", "- There is fine-tuned crosstalk between AHR and NRF2, which mutually increase or decrease their activation states.", "- Many NRF2-mediated antioxidant phytochemicals are capable of up- and downmodulating AHR signaling.", "- The precise mechanisms by which these phytochemicals differentially affect the AHR and NRF2 system remain largely unknown and warrant future investigation."]}, {"metadata": {"year": 2004}, "authors": ["C. Sander", "Hong Chang", "F. Hamm", "P. Elsner", "J. Thiele"], "summary": "Melanoma and nonmelanoma skin cancers are among the most prevalent cancers in the human population. Solar ultraviolet radiation is considered a major etiological factor but the relationship between dose, timing, and nature of exposure to tumor development is still unclear. Free radicals are generated by normal physiologic processes, including aerobic metabolism and inflammatory response, but may inflict cellular damage when generation is increased and antioxidant defense mechanisms are overwhelmed. Important findings supporting the free radical hypothesis in skin carcinogenesis are: (1) Reactive oxygen species (ROS) are generated in UVA\u2010 and UVB\u2010irradiated skin in excessive doses, (2) the natural cutaneous antioxidant defense is impaired upon UV\u2010exposure, (3) free radicals are involved in all steps of carcinogenesis, (4) supplementation with antioxidants can inhibit skin carcinogenesis, and (5) conditions that increase ROS generation enhance photocarcinogenesis. These findings provide a promising rationale for the development of powerful new antioxidant strategies in the prevention and therapy of skin cancer.", "title": "Role of oxidative stress and the antioxidant network in cutaneous carcinogenesis", "claims": ["", "Melanoma and nonmelanoma skin cancers are among the most prevalent cancers in the human population.", "Solar ultraviolet radiation is considered a major etiological factor in skin cancer.", "The relationship between dose, timing, and nature of exposure to solar ultraviolet radiation and tumor development is still unclear.", "Free radicals are generated by normal physiologic processes, including aerobic metabolism and inflammatory response.", "Free radicals may inflict cellular damage when their generation is increased and antioxidant defense mechanisms are overwhelmed.", "Reactive oxygen species (ROS) are generated in UVA\u2010 and UVB\u2010irradiated skin in excessive doses.", "The natural cutaneous antioxidant defense is impaired upon UV\u2010exposure.", "Free radicals are involved in all steps of carcinogenesis.", "Supplementation with antioxidants can inhibit skin carcinogenesis.", "Conditions that increase ROS generation enhance photocarcinogenesis.", "The findings supporting the free radical hypothesis in skin carcinogenesis provide a promising rationale for the development of powerful new antioxidant strategies in the prevention and therapy of skin cancer."]}], "query": "Antioxidant enzymes and Skin Cancer risk", "summary_abstract": null, "summary_extract": "The collective claims from the papers highlight the significant role of antioxidant enzymes in modulating skin cancer risk, primarily through their interaction with oxidative stress induced by ultraviolet (UV) radiation. Chunyan He et al. (2010) emphasize that UV-induced oxidative stress is a key factor in skin carcinogenesis, with enzymes like glutathione peroxidase (GPX) and catalase (CAT) serving as primary defenses against such stress. However, genetic polymorphisms affecting these enzymes can alter their activity, potentially influencing skin cancer risk. Specifically, the GPX1 198 Leu/Leu genotype is associated with an increased risk of melanoma, while the CAT C-262T polymorphism's impact on melanoma risk is modified by factors like sunburn history and carotenoid intake (He et al., 2010).\n\nRobbins and Zhao (2011) further support the protective role of antioxidants, noting that their expression and activity are crucial in preventing oxidative stress-related skin diseases. They suggest that enhancing antioxidant responses could be a novel chemopreventive strategy. Similarly, Godic et al. (2014) and Sander et al. (2004) underscore the importance of antioxidants in counteracting the oxidative damage caused by UV exposure, which is a major environmental factor in skin cancer development. They propose that both endogenous and exogenous antioxidants can mitigate the harmful effects of reactive oxygen species (ROS) generated by UV radiation.\n\nBriganti and Picardo (2003) highlight the skin's intrinsic antioxidant network, which works synergistically to protect against oxidative injury. They suggest that topical or oral antioxidants could serve as preventive therapies for UV-induced skin cancer. Sable and Shields (2023) also review the potential of antioxidants in preventing DNA damage from UV radiation, supporting their role in the chemoprevention of skin cancers.\n\nOverall, the claims collectively suggest that antioxidant enzymes play a crucial role in defending against oxidative stress, which is a significant factor in skin cancer risk. Genetic variations and environmental factors can influence the effectiveness of these enzymes, highlighting the potential of antioxidant-based strategies in skin cancer prevention and therapy."}, {"papers": [{"metadata": {"year": 2022}, "authors": ["Madeline E. McCarthy", "William B. Dodd", "Xiaoming Lu", "Nishi Patel", "Charlotte V. Haskell", "H. Sanabria", "M. Blenner", "M. Birtwistle"], "summary": "Systematic, genome-scale genetic screens have been instrumental for elucidating genotype-phenotype relationships, but approaches for probing genetic interactions have been limited to at most \u223c100 pre-selected gene combinations in mammalian cells. Here, we introduce a theory for high-throughput genetic interaction screens. The theory extends our recently developed Multiplexing using Spectral Imaging and Combinatorics (MuSIC) approach to propose \u223c105 spectrally unique, genetically-encoded MuSIC barcodes from 18 currently available fluorescent proteins. Simulation studies based on constraints imposed by spectral flow cytometry equipment suggest that genetic interaction screens at the human genome-scale may be possible if MuSIC barcodes can be paired to guide RNAs. While experimental testing of this theory awaits, it offers transformative potential for genetic perturbation technology and knowledge of genetic function. More broadly, the availability of a genome-scale spectral barcode library for non-destructive identification of single-cells could find more widespread applications such as traditional genetic screening and high-dimensional lineage tracing.", "title": "A Theory for High-Throughput Genetic Interaction Screening", "claims": ["", "Systematic, genome-scale genetic screens have been instrumental for elucidating genotype-phenotype relationships.", "Approaches for probing genetic interactions have been limited to at most \u223c100 pre-selected gene combinations in mammalian cells.", "A theory for high-throughput genetic interaction screens is introduced.", "The theory extends the recently developed Multiplexing using Spectral Imaging and Combinatorics (MuSIC) approach.", "The theory proposes \u223c105 spectrally unique, genetically-encoded MuSIC barcodes from 18 currently available fluorescent proteins.", "Simulation studies based on constraints imposed by spectral flow cytometry equipment suggest that genetic interaction screens at the human genome-scale may be possible if MuSIC barcodes can be paired to guide RNAs.", "Experimental testing of this theory awaits.", "The theory offers transformative potential for genetic perturbation technology and knowledge of genetic function.", "The availability of a genome-scale spectral barcode library for non-destructive identification of single-cells could find more widespread applications such as traditional genetic screening and high-dimensional lineage tracing."]}, {"metadata": {"year": 2012}, "authors": ["Dorothea  Emig", "Hagen  Blankenburg", "Fidel  Ram\u00edrez", "Mario  Albrecht"], "summary": "Complex biological systems comprise a large number of interacting molecules. The identification and detailed characterization of the functions of the involved genes and proteins are crucial for modeling and understanding such systems. To interrogate the various cellular processes, high-throughput techniques such as the Affymetrix Exon Array or RNA interference (RNAi) screens are powerful experimental approaches for functional genomics. However, they typically yield long gene lists that require computational methods to further analyze and functionally annotate the experimental results and to gain more insight into important molecular interactions. Here, we focus on bioinformatics software tools for the functional interpretation of exon expression data to discover alternative splicing events and their impact on gene and protein architecture, molecular networks, and pathways. We additionally demonstrate how to explore large lists of candidate genes as they also result from RNAi screens. In particular, our exemplary application studies show how to analyze the function of human genes that play a major role in human stem cells or viral infections.", "title": "Functional characterization of human genes from exon expression and RNA interference results.", "claims": ["- Complex biological systems comprise a large number of interacting molecules.", "- The identification and detailed characterization of the functions of the involved genes and proteins are crucial for modeling and understanding complex biological systems.", "- High-throughput techniques such as the Affymetrix Exon Array or RNA interference (RNAi) screens are powerful experimental approaches for functional genomics.", "- High-throughput techniques typically yield long gene lists that require computational methods to further analyze and functionally annotate the experimental results.", "- Computational methods are needed to gain more insight into important molecular interactions from high-throughput techniques.", "- Bioinformatics software tools are used for the functional interpretation of exon expression data to discover alternative splicing events.", "- Alternative splicing events impact gene and protein architecture, molecular networks, and pathways.", "- Large lists of candidate genes result from RNAi screens.", "- Exemplary application studies show how to analyze the function of human genes that play a major role in human stem cells.", "- Exemplary application studies show how to analyze the function of human genes that play a major role in viral infections."]}, {"metadata": {"year": 2004}, "authors": ["Adam  Friedman", "Norbert  Perrimon"], "summary": "The availability of complete genome sequences from many organisms has yielded the ability to perform high-throughput, genome-wide screens of gene function. Within the past year, rapid advances have been made towards this goal in many major model systems, including yeast, worms, flies, and mammals. Yeast genome-wide screens have taken advantage of libraries of deletion strains, but RNA-interference has been used in other organisms to knockdown gene function. Examples of recent large-scale functional genetic screens include drug-target identification in yeast, regulators of fat accumulation in worms, growth and viability in flies, and proteasome-mediated degradation in mammalian cells. Within the next five years, such screens are likely to lead to annotation of function of most genes across multiple organisms. Integration of such data with other genomic approaches will extend our understanding of cellular networks.", "title": "Genome-wide high-throughput screens in functional genomics.", "claims": ["- The availability of complete genome sequences from many organisms has yielded the ability to perform high-throughput, genome-wide screens of gene function.", "- Within the past year, rapid advances have been made towards the goal of genome-wide screens in many major model systems, including yeast, worms, flies, and mammals.", "- Yeast genome-wide screens have taken advantage of libraries of deletion strains.", "- RNA-interference has been used in organisms other than yeast to knockdown gene function.", "- Recent large-scale functional genetic screens include drug-target identification in yeast.", "- Recent large-scale functional genetic screens include regulators of fat accumulation in worms.", "- Recent large-scale functional genetic screens include growth and viability in flies.", "- Recent large-scale functional genetic screens include proteasome-mediated degradation in mammalian cells.", "- Within the next five years, genome-wide screens are likely to lead to annotation of function of most genes across multiple organisms.", "- Integration of genome-wide screen data with other genomic approaches will extend our understanding of cellular networks."]}, {"metadata": {"year": 2004}, "authors": ["Anne E. Carpenter", "David M. Sabatini"], "summary": "By using genome information to create tools for perturbing gene function, it is now possible to undertake systematic genome-wide functional screens that examine the contribution of every gene to a biological process. The directed nature of these experiments contrasts with traditional methods, in which random mutations are induced and the resulting mutants are screened for various phenotypes. The first genome-wide functional screens in Caenorhabditis elegans and Drosophila melanogaster have recently been published, and screens in human cells will soon follow. These high-throughput techniques promise the rapid annotation of genomes with high-quality information about the biological function of each gene.", "title": "Systematic genome-wide screens of gene function", "claims": ["- By using genome information to create tools for perturbing gene function, it is now possible to undertake systematic genome-wide functional screens that examine the contribution of every gene to a biological process.", "- The directed nature of these experiments contrasts with traditional methods, in which random mutations are induced and the resulting mutants are screened for various phenotypes.", "- The first genome-wide functional screens in Caenorhabditis elegans and Drosophila melanogaster have recently been published.", "- Screens in human cells will soon follow.", "- These high-throughput techniques promise the rapid annotation of genomes with high-quality information about the biological function of each gene."]}, {"metadata": {"year": 2016}, "authors": ["Maximilian  Billmann", "Michael  Boutros"], "summary": "Genetic screens have identified many novel components of various biological processes, such as components required for cell cycle and cell division. While forward genetic screens typically generate unstructured \u2018hit\u2019 lists, genetic interaction mapping approaches can identify functional relations in a systematic fashion. Here, we discuss a recent study by our group demonstrating a two-step approach to first screen for regulators of the mitotic cell cycle, and subsequently guide hypothesis generation by using genetic interaction analysis. The screen used a high-content microscopy assay and automated image analysis to capture defects during mitotic progression and cytokinesis. Genetic interaction networks derived from process-specific features generate a snapshot of functional gene relations in those processes, which follow a temporal order during the cell cycle. This complements a recently published approach, which inferred directional genetic interactions reconstructing hierarchical relationships between genes across different phases during mitotic progression. In conclusion, this strategy leverages unbiased, genome-wide, yet highly sensitive and process-focused functional screening in cells.", "title": "Systematic epistatic mapping of cellular processes", "claims": ["", "Genetic screens have identified many novel components of various biological processes, such as components required for cell cycle and cell division.", "Forward genetic screens typically generate unstructured \u2018hit\u2019 lists.", "Genetic interaction mapping approaches can identify functional relations in a systematic fashion.", "A recent study by our group demonstrated a two-step approach to first screen for regulators of the mitotic cell cycle and subsequently guide hypothesis generation by using genetic interaction analysis.", "The screen used a high-content microscopy assay and automated image analysis to capture defects during mitotic progression and cytokinesis.", "Genetic interaction networks derived from process-specific features generate a snapshot of functional gene relations in those processes, which follow a temporal order during the cell cycle.", "This complements a recently published approach, which inferred directional genetic interactions reconstructing hierarchical relationships between genes across different phases during mitotic progression.", "This strategy leverages unbiased, genome-wide, yet highly sensitive and process-focused functional screening in cells."]}, {"metadata": {"year": 2013}, "authors": ["J. Millstein"], "summary": "Next-generation sequencing and other high-throughput technologies have made it feasible to characterize millions of sequence variations on large numbers of study participants. But when it comes to identifying a small number of these genetic features (or feature sets) that are associated with a disease trait, the investigator is faced with a formidable multiple-testing challenge. It can be thought of as a signal-to-noise problem, where the large number of unrelated genetic features tends to drown out the faint signal of the small number of biologically relevant features.", "title": "Screening-testing approaches for gene-gene and gene-environment interactions using independent statistics", "claims": ["- Next-generation sequencing and other high-throughput technologies have made it feasible to characterize millions of sequence variations on large numbers of study participants.", "- When it comes to identifying a small number of genetic features (or feature sets) that are associated with a disease trait, the investigator is faced with a formidable multiple-testing challenge.", "- The challenge of identifying relevant genetic features can be thought of as a signal-to-noise problem.", "- The large number of unrelated genetic features tends to drown out the faint signal of the small number of biologically relevant features."]}, {"metadata": {"year": 2023}, "authors": ["Alina Guna", "K. R. Page", "Joseph R. Replogle", "Theodore K. Esantsi", "Maxine L. Wang", "J. Weissman", "R. M. Voorhees"], "summary": "The ability to map genetic interactions has been essential for determining gene function and defining biological pathways. Therefore, a system to readily perform genome-wide genetic modifier screens in human cells is a powerful platform for dissecting complex processes in mammalian cells, where redundancy and adaptation commonly mask the phenotype of a single genetic perturbation. Here, we report a CRISPR interference (CRISPRi) based platform, compatible with Fluorescence Activated Cell Sorting (FACS)-based reporter screens, that can be used to query epistatic relationships at scale. This is enabled by a flexible dual-sgRNA library design that allows for the simultaneous delivery and selection of a fixed sgRNA and a second randomized guide, comprised of a genome-wide library, with a single transduction. As a proof of principle, we apply our approach to study the pathways that mediate tail-anchored (TA) protein insertion at the endoplasmic reticulum (ER). We show that this dual-guide library approach can be successfully coupled with FACS-based reporter screening, to identify genetic epistasis and thereby place TA biogenesis factors in their respective parallel pathways. We demonstrate that this dual-guide approach is both more sensitive and specific than traditional growth screening approaches, and is ideally suited for dissecting the complex interplay between factors in human cells.", "title": "A dual sgRNA library design to probe genetic modifiers using genome-wide CRISPRi screens", "claims": ["- The ability to map genetic interactions has been essential for determining gene function and defining biological pathways.", "- A system to readily perform genome-wide genetic modifier screens in human cells is a powerful platform for dissecting complex processes in mammalian cells, where redundancy and adaptation commonly mask the phenotype of a single genetic perturbation.", "- A CRISPR interference (CRISPRi) based platform, compatible with Fluorescence Activated Cell Sorting (FACS)-based reporter screens, can be used to query epistatic relationships at scale.", "- The CRISPRi platform is enabled by a flexible dual-sgRNA library design that allows for the simultaneous delivery and selection of a fixed sgRNA and a second randomized guide, comprised of a genome-wide library, with a single transduction.", "- The dual-guide library approach can be successfully coupled with FACS-based reporter screening to identify genetic epistasis and thereby place tail-anchored (TA) biogenesis factors in their respective parallel pathways.", "- The dual-guide approach is both more sensitive and specific than traditional growth screening approaches.", "- The dual-guide approach is ideally suited for dissecting the complex interplay between factors in human cells."]}, {"metadata": {"year": 2005}, "authors": ["F. Al-Shahrour", "R. D\u00edaz-Uriarte", "J. Dopazo"], "summary": "MOTIVATION\nThe analysis of genome-scale data from different high throughput techniques can be used to obtain lists of genes ordered according to their different behaviours under distinct experimental conditions corresponding to different phenotypes (e.g. differential gene expression between diseased samples and controls, different response to a drug, etc.). The order in which the genes appear in the list is a consequence of the biological roles that the genes play within the cell, which account, at molecular scale, for the macroscopic differences observed between the phenotypes studied. Typically, two steps are followed for understanding the biological processes that differentiate phenotypes at molecular level: first, genes with significant differential expression are selected on the basis of their experimental values and subsequently, the functional properties of these genes are analysed. Instead, we present a simple procedure which combines experimental measurements with available biological information in a way that genes are simultaneously tested in groups related by common functional properties. The method proposed constitutes a very sensitive tool for selecting genes with significant differential behaviour in the experimental conditions tested.\n\n\nRESULTS\nWe propose the use of a method to scan ordered lists of genes. The method allows the understanding of the biological processes operating at molecular level behind the macroscopic experiment from which the list was generated. This procedure can be useful in situations where it is not possible to obtain statistically significant differences based on the experimental measurements (e.g. low prevalence diseases, etc.). Two examples demonstrate its application in two microarray experiments and the type of information that can be extracted.", "title": "Discovering molecular functions significantly related to phenotypes by combining gene expression data and biological information", "claims": ["", "The analysis of genome-scale data from different high throughput techniques can be used to obtain lists of genes ordered according to their different behaviours under distinct experimental conditions corresponding to different phenotypes.", "The order in which the genes appear in the list is a consequence of the biological roles that the genes play within the cell, which account, at molecular scale, for the macroscopic differences observed between the phenotypes studied.", "Typically, two steps are followed for understanding the biological processes that differentiate phenotypes at molecular level: first, genes with significant differential expression are selected on the basis of their experimental values and subsequently, the functional properties of these genes are analysed.", "The method proposed constitutes a very sensitive tool for selecting genes with significant differential behaviour in the experimental conditions tested.", "We propose the use of a method to scan ordered lists of genes.", "The method allows the understanding of the biological processes operating at molecular level behind the macroscopic experiment from which the list was generated.", "This procedure can be useful in situations where it is not possible to obtain statistically significant differences based on the experimental measurements (e.g. low prevalence diseases, etc.).", "Two examples demonstrate its application in two microarray experiments and the type of information that can be extracted."]}], "query": "high throughput genetic screen are a powerful tool in identifying individual gene function and interaction", "summary_abstract": null, "summary_extract": "High-throughput genetic screens have emerged as a formidable tool in the quest to unravel individual gene functions and interactions. McCarthy et al. (2022) highlight the instrumental role of systematic, genome-scale genetic screens in elucidating genotype-phenotype relationships, underscoring their transformative potential in genetic perturbation technology. This is echoed by Emig et al. (2012), who emphasize the power of high-throughput techniques like RNA interference screens in functional genomics, which yield extensive gene lists that require computational analysis for functional annotation. Friedman and Perrimon (2004) further illustrate the utility of genome-wide screens across various model organisms, which have facilitated the rapid annotation of gene functions and extended our understanding of cellular networks. Carpenter and Sabatini (2004) also note the promise of these techniques in providing high-quality information about gene functions, contrasting them with traditional methods. Meanwhile, Guna et al. (2023) demonstrate the efficacy of a CRISPR interference-based platform in mapping genetic interactions, which is crucial for dissecting complex processes in mammalian cells. Collectively, these claims underscore the pivotal role of high-throughput genetic screens in advancing our understanding of gene functions and interactions, offering a powerful platform for both basic and applied biological research."}, {"papers": [{"metadata": {"year": 2019}, "authors": ["Boer  Cui", "Genevi\u00e8ve  Boisjoly", "Ahmed M El-Geneidy", "David M Levinson"], "summary": "Abstract Inequality in transport provision is an area of growing concern among transport professionals, as it results in low-income individuals travelling at lower speeds while covering smaller distances. Accessibility, the ease of reaching destinations, may hold the key in correcting these inequalities through providing a means to evaluate land use and transport interventions. This article examines the relationship between accessibility and commute duration for low-income individuals compared to the higher-income, in three major Canadian metropolitan regions, Toronto, Montreal, and Vancouver using separate multilevel mixed effects statistical models for car and public transport commuters. Accessibility measures are generated for jobs and workers both at the origin (home) and the destination (place of work) to account for the impact of competing labor and firms. Our models show that the impacts of accessibility on commute duration are present and in many cases stronger for low-income individuals than for higher income groups. The results suggest that low-income individuals have more to gain (in terms of reduced commute time) from increased accessibility to low-income jobs at the origin and to workers at the destination. Similarly, they also have more to lose from increased accessibility to low-income workers at the origin and to low-income jobs at the destination, which are proxies for increased competition. Policies targeting improvements in accessibility to jobs, especially low-income ones, by car and public transport while managing the presence of competition can serve to bridge the inequality gap that exists in commuting behavior.", "title": "Accessibility and the journey to work through the lens of equity", "claims": ["- Inequality in transport provision results in low-income individuals travelling at lower speeds while covering smaller distances.", "- Accessibility, defined as the ease of reaching destinations, may hold the key in correcting transport inequalities through providing a means to evaluate land use and transport interventions.", "- The article examines the relationship between accessibility and commute duration for low-income individuals compared to higher-income individuals in three major Canadian metropolitan regions: Toronto, Montreal, and Vancouver.", "- Separate multilevel mixed effects statistical models are used for car and public transport commuters in the study.", "- Accessibility measures are generated for jobs and workers both at the origin (home) and the destination (place of work) to account for the impact of competing labor and firms.", "- The models show that the impacts of accessibility on commute duration are present and in many cases stronger for low-income individuals than for higher income groups.", "- The results suggest that low-income individuals have more to gain in terms of reduced commute time from increased accessibility to low-income jobs at the origin and to workers at the destination.", "- Low-income individuals have more to lose from increased accessibility to low-income workers at the origin and to low-income jobs at the destination, which are proxies for increased competition.", "- Policies targeting improvements in accessibility to jobs, especially low-income ones, by car and public transport while managing the presence of competition can serve to bridge the inequality gap that exists in commuting behavior."]}, {"metadata": {"year": 2018}, "authors": ["Boer Cui", "G. Boisjoly", "A. El-geneidy", "D. Levinson"], "summary": "Inequality in transport provision is an area of growing concern among transport professionals, as it results in low-income individuals travelling at lower speeds while covering smaller distances. Accessibility, the ease of reaching destinations, may hold the key in correcting these inequalities through providing a means to evaluate land use and transport interventions. This article examines the relationship between accessibility and commuting duration for low-income individuals, compared to the general population, in three major Canadian metropolitan regions, Toronto, Montreal, and Vancouver using multilevel mixed effects statistical models for car and public transport commuters separately. Accessibility measures are generated for jobs and workers both at the origin (home) and the destination (place of work) to account for the impact of competing labor and firms. Our models show that the impacts of accessibility on commuting duration are present and stronger for low-income individuals than for the general population, and the differences in impact are more visible for public transport commuters. The results suggest that low-income individuals have more to gain (in terms of reduced commute time) from increased accessibility to low-income jobs at the origin and to workers at the destination. Similarly, they also have more to lose from increased accessibility to low-income workers at the origin and to low- income jobs at the destination, which are proxies for increased competition. Policies targeting improvements in accessibility to jobs, especially low-income ones, by car and public transport while managing the presence of competition can serve to bridge the inequality gap that exists in commuting behavior.", "title": "Accessibility, equity, and the journey to work", "claims": ["- Inequality in transport provision results in low-income individuals travelling at lower speeds while covering smaller distances.", "- Accessibility, defined as the ease of reaching destinations, may hold the key in correcting transport inequalities by providing a means to evaluate land use and transport interventions.", "- The article examines the relationship between accessibility and commuting duration for low-income individuals compared to the general population in Toronto, Montreal, and Vancouver.", "- Multilevel mixed effects statistical models are used to analyze car and public transport commuters separately in the study.", "- Accessibility measures are generated for jobs and workers both at the origin (home) and the destination (place of work) to account for the impact of competing labor and firms.", "- The impacts of accessibility on commuting duration are present and stronger for low-income individuals than for the general population.", "- The differences in the impact of accessibility on commuting duration are more visible for public transport commuters.", "- Low-income individuals have more to gain in terms of reduced commute time from increased accessibility to low-income jobs at the origin and to workers at the destination.", "- Low-income individuals have more to lose from increased accessibility to low-income workers at the origin and to low-income jobs at the destination, which are proxies for increased competition.", "- Policies targeting improvements in accessibility to jobs, especially low-income ones, by car and public transport while managing the presence of competition can serve to bridge the inequality gap in commuting behavior."]}, {"metadata": {"year": 2011}, "authors": ["A. Soltani", "Yousef Esmaeili Ivaki"], "summary": "Neo-classical economic doctrine dominating governmental policies shows its impact on recent transport policies, causing these policies; tend to base on demand and efficiency criteria instead of equity concerns. Public transit operating for remote areas is less cost-effective eventually leading to have a low level of service quality. In metropolitan areas of developing countries, a large part of socially disadvantaged and vulnerable groups live in outer suburban locations not in the inner-city. Transit equity evaluation is required by in order to consider the requirements of more vulnerable populations, as well as to foster equal benefits. The evaluation approach is based on highlighting the spatial distribution and clustering patterns of bus network and service as well as some disadvantaged social groups including unemployed, migrated, less educated, elderly, young, and disabled. The hypothesis is that vulnerable groups and economically disadvantaged communities receive a less than equal share of public bus services. The findings show that poor accessibility is associated both with low-income neighborhoods and with neighborhoods with disproportionately high populations of migrated, less-educated, unemployed and low-income groups. Modifications need to make in transport planning and policy system to achieve a better distribution of public transport services in hope of increasing level of service for minority groups and economically disadvantaged communities.", "title": "Inequity in the Provision of Public Bus Service for Socially Disadvantaged Groups", "claims": ["", "Neo-classical economic doctrine dominating governmental policies shows its impact on recent transport policies.", "Recent transport policies tend to base on demand and efficiency criteria instead of equity concerns.", "Public transit operating for remote areas is less cost-effective.", "Public transit operating for remote areas eventually leads to a low level of service quality.", "In metropolitan areas of developing countries, a large part of socially disadvantaged and vulnerable groups live in outer suburban locations, not in the inner-city.", "Transit equity evaluation is required to consider the requirements of more vulnerable populations.", "Transit equity evaluation is required to foster equal benefits.", "The evaluation approach is based on highlighting the spatial distribution and clustering patterns of the bus network and service.", "The evaluation approach includes some disadvantaged social groups such as unemployed, migrated, less educated, elderly, young, and disabled.", "The hypothesis is that vulnerable groups and economically disadvantaged communities receive a less than equal share of public bus services.", "The findings show that poor accessibility is associated with low-income neighborhoods.", "The findings show that poor accessibility is associated with neighborhoods with disproportionately high populations of migrated, less-educated, unemployed, and low-income groups.", "Modifications need to be made in transport planning and policy systems to achieve a better distribution of public transport services.", "The hope of these modifications is to increase the level of service for minority groups and economically disadvantaged communities."]}, {"metadata": {"year": 2004}, "authors": ["D. Mignot"], "summary": "The current context of increasing social and spatial disparities raises the issue of universal accessibility to the city and its services, in particular for low incomes persons. The issue of inequality with regard to travel, which we have considered first of all at an aggregate level using the usual travel indicators (number of trips, distance covered, travel time budget), essentially comes down to inequality in access to the car. An analysis of recent changes in urban public transport pricing policy and a survey conducted within welfare and social integration agencies in the conurbations of Lyon, Nancy and Nantes have been used to obtain a more accurate qualitative and quantitative picture of transport difficulties.", "title": "Transport et justice sociale", "claims": ["- The current context of increasing social and spatial disparities raises the issue of universal accessibility to the city and its services, in particular for low-income persons.", "- The issue of inequality with regard to travel, which we have considered first of all at an aggregate level using the usual travel indicators (number of trips, distance covered, travel time budget), essentially comes down to inequality in access to the car.", "- An analysis of recent changes in urban public transport pricing policy and a survey conducted within welfare and social integration agencies in the conurbations of Lyon, Nancy, and Nantes have been used to obtain a more accurate qualitative and quantitative picture of transport difficulties."]}, {"metadata": {"year": 2011}, "authors": ["D. Lewis"], "summary": "Poverty, inequality and social exclusion are closely tied to personal mobility and the accessibility of goods and services. Evidence of the economic role of transport in promoting better living standards and greater wellbeing can be seen in the effects of both overall public investment in transport infrastructure, and in the impacts of specific transport policies, projects and multi-project plans.", "title": "Economic perspectives on transport and equality", "claims": ["- Poverty, inequality, and social exclusion are closely tied to personal mobility and the accessibility of goods and services.", "- Evidence of the economic role of transport in promoting better living standards and greater wellbeing can be seen in the effects of overall public investment in transport infrastructure.", "- Evidence of the economic role of transport in promoting better living standards and greater wellbeing can be seen in the impacts of specific transport policies, projects, and multi-project plans."]}, {"metadata": {"year": 2005}, "authors": ["David Caubel"], "summary": "The social dimension of urban transport policies becomes a paramount issue of the public action. This may result from the observed growth of social inequalities, and the persistence or even the worsening of segregation processes. In particular, this issue leads to questions about the access to activities and services that individuals need everyday. It also relates to the characterization of an equal access for all to the city.In this context, the aim of the paper is to validate, by the measure in the case of the Lyons conurbation, the existence of urban accessibility disparities between the richest and the deprived territories residents, by accounting for the private car and the public transport. We show that there are equal accesses to amenities by car, but the travel modes unequal access implies inequities in accessing urban activities. Then, our paper analyses the social impacts of the public transport policy contents aiming at reducing the urban accessibility disparities or the gaps to the \"standard society\". The assessment made, based on the interpretation of the Lyons Urban Travel Plan, accounts for concrete answers of the access to amenities improvement for everyone, and in particular for the underprivileged populations. Nevertheless, these answers prove to be limited. A public transport policy cannot claim to reduce the unequal access between territories and to fight against the exclusion of a minority of the population, without accounting for the local and overall contexts of urban morphology, without being in line with regional planning policies \u2013 in particular the activities location control policies.", "title": "Public transport development and equal access for all to urban amenities", "claims": ["- The social dimension of urban transport policies becomes a paramount issue of public action.", "- This may result from the observed growth of social inequalities.", "- There is a persistence or even worsening of segregation processes.", "- The issue of social dimension in urban transport policies leads to questions about access to activities and services that individuals need every day.", "- It also relates to the characterization of an equal access for all to the city.", "- The aim of the paper is to validate, by measurement in the case of the Lyons conurbation, the existence of urban accessibility disparities between the richest and the deprived territories residents.", "- The paper accounts for the private car and public transport in assessing urban accessibility disparities.", "- There are equal accesses to amenities by car.", "- The travel modes' unequal access implies inequities in accessing urban activities.", "- The paper analyses the social impacts of public transport policy contents aiming at reducing urban accessibility disparities or gaps to the \"standard society\".", "- The assessment made, based on the interpretation of the Lyons Urban Travel Plan, accounts for concrete answers to the improvement of access to amenities for everyone, particularly for underprivileged populations.", "- These answers prove to be limited.", "- A public transport policy cannot claim to reduce the unequal access between territories and fight against the exclusion of a minority of the population without accounting for the local and overall contexts of urban morphology.", "- A public transport policy must be in line with regional planning policies, particularly the activities location control policies, to effectively reduce unequal access and fight exclusion."]}, {"metadata": {"year": 1980}, "authors": ["E. Boer"], "summary": "In practice there are not equal chances for everybody to use the transport system. The national government aims to lessen the inequality in this respect as regards certain groups of the population. Such groups are for instance the poor, children, old people, the disabled, the people without a driving licence, and housewives. The question of when there can be said to be a large inequality in the use of transport is difficult to answer. This report describes what is known about the phenomenon of unequal accessibility to the transport system and discusses how far this phenomenon can be studied. Social scientific studies in different countries of the choice behaviour of travellers are reviewed. (TRRL)", "title": "INEQUALITY IN THE USE OF TRANSPORT, ITS RELEVANCE AND THE POSSIBILITY OF STUDYING IT. AN INTERNATIONAL LITERATURE REVIEW", "claims": ["- In practice, there are not equal chances for everybody to use the transport system.", "- The national government aims to lessen the inequality in the transport system for certain groups of the population.", "- The groups that the national government aims to help include the poor, children, old people, the disabled, people without a driving licence, and housewives.", "- The question of when there can be said to be a large inequality in the use of transport is difficult to answer.", "- The report describes what is known about the phenomenon of unequal accessibility to the transport system.", "- The report discusses how far the phenomenon of unequal accessibility to the transport system can be studied.", "- Social scientific studies in different countries of the choice behaviour of travellers are reviewed."]}, {"metadata": {"year": 2022}, "authors": ["Anik Pramanik", "Pan Xu", "Yifang Xu"], "summary": "There are many news articles reporting the obstacles con- fronting poverty-stricken households in access to public transits. These barriers create a great deal of inconveniences for these impoverished families and more importantly, they con-tribute a lot of social inequalities. A typical approach ad- dressing the issue is to build more transport infrastructure to o\ufb00er more opportunities to access the public transits es- pecially for those deprived communities. Examples include adding more bus lines connecting needy residents to railways systems and extending existing bus lines to areas with low socioeconomic status. Recently, a new strategy is proposed, which is to harness the ubiquitous ride-hailing services to con-nect disadvantaged households with the nearest public trans- portations. Compared with the former infrastructure-based solution, the ride-hailing-based strategy enjoys a few exclusive bene\ufb01ts such as higher e\ufb00ectiveness and more \ufb02exibility. In this paper, we propose an optimization model to study how to integrate the two approaches together for equity-promotion purposes. Speci\ufb01cally, we aim to design a strategy of allo- cating a given limited budget to di\ufb00erent candidate programs such that the overall social equity is maximized, which is de- \ufb01ned as the minimum covering ratio among all pre-speci\ufb01ed protected groups of households (based on race, income, etc.). We have designed a linear-programming (LP) based rounding algorithm, which proves to achieve an optimal approximation ratio of 1 \u2212 1 / \ud835\udc52 . Additionally, we test our algorithm against a few baselines on real data assembled by outsourcing multiple public datasets collected in the city of Chicago. Experimental results con\ufb01rm our theoretical predictions and demonstrate the e\ufb00ectiveness of our LP-based strategy in promoting social equity, especially when the budget is insu\ufb03cient.", "title": "Equity Promotion in Public Transportation", "claims": ["- There are many news articles reporting the obstacles confronting poverty-stricken households in access to public transits.", "- These barriers create a great deal of inconveniences for these impoverished families.", "- More importantly, these barriers contribute a lot of social inequalities.", "- A typical approach addressing the issue is to build more transport infrastructure to offer more opportunities to access the public transits, especially for those deprived communities.", "- Examples include adding more bus lines connecting needy residents to railway systems and extending existing bus lines to areas with low socioeconomic status.", "- Recently, a new strategy is proposed, which is to harness the ubiquitous ride-hailing services to connect disadvantaged households with the nearest public transportations.", "- Compared with the former infrastructure-based solution, the ride-hailing-based strategy enjoys a few exclusive benefits such as higher effectiveness and more flexibility.", "- In this paper, we propose an optimization model to study how to integrate the two approaches together for equity-promotion purposes.", "- Specifically, we aim to design a strategy of allocating a given limited budget to different candidate programs such that the overall social equity is maximized.", "- Social equity is defined as the minimum covering ratio among all pre-specified protected groups of households (based on race, income, etc.).", "- We have designed a linear-programming (LP) based rounding algorithm, which proves to achieve an optimal approximation ratio of 1 \u2212 1 / \ud835\udc52.", "- Additionally, we test our algorithm against a few baselines on real data assembled by outsourcing multiple public datasets collected in the city of Chicago.", "- Experimental results confirm our theoretical predictions and demonstrate the effectiveness of our LP-based strategy in promoting social equity, especially when the budget is insufficient."]}], "query": "competition public transport accessibility inequality poverty", "summary_abstract": null, "summary_extract": "The collection of claims highlights the intricate relationship between public transport accessibility, inequality, and poverty. Boer Cui et al. (2019) and (2018) emphasize that low-income individuals face significant transport inequalities, resulting in longer commute times and reduced travel speeds. They argue that improving accessibility, particularly to low-income jobs, can mitigate these disparities, although increased accessibility can also heighten competition for these jobs, potentially disadvantaging low-income workers further. Soltani and Ivaki (2011) support this by noting that poor accessibility is prevalent in low-income neighborhoods, suggesting a need for transport policy modifications to better serve disadvantaged communities. Mignot (2004) and Caubel (2005) further discuss the social dimension of transport policies, highlighting the persistent inequalities in access to urban services and the need for policies that consider local urban contexts. Pramanik et al. (2022) propose innovative solutions, such as integrating ride-hailing services with traditional public transport, to enhance accessibility for impoverished communities, demonstrating the potential for flexible, cost-effective strategies to promote social equity. Collectively, these claims underscore the critical role of targeted transport policies in addressing accessibility inequalities and their impact on poverty."}, {"papers": [{"metadata": {"year": 2016}, "authors": ["Florian Dumpert", "Katja von Eschwege", "M. Beck"], "summary": "This article shows the motivation for, approach to, and results of applying support vector machines in official statistics concerning the business register for test purposes. A support vector machine is a universally applicable machine learning and classification method. Based on a mathematical optimisation approach, objects can be classified by specific variables and be allocated to corresponding classes. The non-parametric statistical method succeeded in classifying enterprises with respect to the so-called third sector and is therefore suitable to improve and complement the method used up to now.", "title": "Einsatz von Support Vector Machines bei der Sektorzuordnung von Unternehmen", "claims": ["- A support vector machine is a universally applicable machine learning and classification method.", "- Based on a mathematical optimisation approach, objects can be classified by specific variables and be allocated to corresponding classes.", "- The non-parametric statistical method succeeded in classifying enterprises with respect to the so-called third sector.", "- The non-parametric statistical method is suitable to improve and complement the method used up to now."]}, {"metadata": {"year": 2001}, "authors": ["D. Sebald", "J. Bucklew"], "summary": "Two enhancements are proposed to the application and theory of support vector machines. The first is a method of multicategory classification based on the binary classification version of the support vector machine (SVM). The method, which is called the M-ary SVM, represents each category in binary format, and to each bit of that representation is assigned a conventional SVM. This approach requires only [log/sub 2/(K)] SVMs, where K is the number of classes. We give an example of classification on an octaphase-shift-keying (8-PSK) pattern space to illustrate the main concepts. The second enhancement is that of adding equality constraints to the conventional binary classification SVM. This allows pinning the classification boundary to points that are known a priori to lie on the boundary. Applications of this method often arise in problems having some type of symmetry, We present one such example where the M-ary SVM is used to classify symbols of a CDMA two-user, multiuser detection pattern space.", "title": "Support vector machines and the multiple hypothesis test problem", "claims": ["", "The first enhancement proposed is a method of multicategory classification based on the binary classification version of the support vector machine (SVM).", "The method is called the M-ary SVM, which represents each category in binary format.", "To each bit of the binary representation of a category, a conventional SVM is assigned.", "The M-ary SVM approach requires only [log/sub 2/(K)] SVMs, where K is the number of classes.", "An example of classification on an octaphase-shift-keying (8-PSK) pattern space is given to illustrate the main concepts of the M-ary SVM.", "The second enhancement proposed is adding equality constraints to the conventional binary classification SVM.", "Adding equality constraints allows pinning the classification boundary to points that are known a priori to lie on the boundary.", "Applications of adding equality constraints often arise in problems having some type of symmetry.", "An example is presented where the M-ary SVM is used to classify symbols of a CDMA two-user, multiuser detection pattern space."]}, {"metadata": {"year": 2011}, "authors": ["R. Gilbert", "T. Trafalis", "I. Adrianto"], "summary": "In this article, we introduce the subject of support vector machines (SVMs), describing their applications to binary and multiclass classification as well as different SVM formulations that are used in such supervised learning problems. This article is not exhaustive and many approaches have not been considered. More detailed treatments are discussed in the books by Abe, Cristianini and Shawe-Taylor, Scholkopf, and Smola and Vapnik. \n \n \nKeywords: \n \nsupport vector machines; \nstatistical learning; \nmulticlass classification; \noptimization", "title": "Support Vector Machines for Classification", "claims": ["", "The article introduces the subject of support vector machines (SVMs).", "The article describes the applications of SVMs to binary classification.", "The article describes the applications of SVMs to multiclass classification.", "The article describes different SVM formulations used in supervised learning problems.", "The article is not exhaustive and many approaches have not been considered.", "More detailed treatments of SVMs are discussed in the books by Abe, Cristianini and Shawe-Taylor, Scholkopf, and Smola and Vapnik."]}, {"metadata": {"year": 1999}, "authors": ["M. Niranjan"], "summary": "Summary form only given. There has been much interest in the use of support vector machines (SVM) as an approach to high performance pattern classification. In the linearly separable case, SVMs attempt to position a class boundary so that the margin from the nearest example is maximised. This criterion can be implemented by solving a quadratic programming problem, and the solution turns out to be one in which the class boundary may be expressed as a linear combination of a subset of the training data (the support vectors). The elegance of the QP formulation, and the relationship between control of complexity in this formulation and Vapnik-Chervonenkis dimensions are seen as prime attractions of the SVM method. A related idea in high performance pattern classification is that of boosting multiple classifiers. The author shows that the standard SVM formulation is not robust to noise and explains the performance of boosting algorithms by reference to receiver operating characteristics curves.", "title": "Support vector machines: a tutorial overview and critical appraisal", "claims": ["- There has been much interest in the use of support vector machines (SVM) as an approach to high performance pattern classification.", "- In the linearly separable case, SVMs attempt to position a class boundary so that the margin from the nearest example is maximised.", "- This criterion can be implemented by solving a quadratic programming problem.", "- The solution to the quadratic programming problem turns out to be one in which the class boundary may be expressed as a linear combination of a subset of the training data (the support vectors).", "- The elegance of the QP formulation is seen as a prime attraction of the SVM method.", "- The relationship between control of complexity in the QP formulation and Vapnik-Chervonenkis dimensions is seen as a prime attraction of the SVM method.", "- A related idea in high performance pattern classification is that of boosting multiple classifiers.", "- The author shows that the standard SVM formulation is not robust to noise.", "- The author explains the performance of boosting algorithms by reference to receiver operating characteristics curves."]}, {"metadata": {"year": 2010}, "authors": ["Yoonkyung  Lee"], "summary": "The support vector machine is a supervised learning technique for classification increasingly used in many applications of data mining, engineering, and bioinformatics. This chapter aims to provide an introduction to the method, covering from the basic concept of the optimal separating hyperplane to its nonlinear generalization through kernels. A general framework of kernel methods that encompass the support vector machine as a special case is outlined. In addition, statistical properties that illuminate both advantage and limitation of the method due to its specific mechanism for classification are briefly discussed. For illustration of the method and related practical issues, an application to real data with high-dimensional features is presented.", "title": "Support vector machines for classification: a statistical portrait.", "claims": ["- The support vector machine is a supervised learning technique for classification.", "- The support vector machine is increasingly used in many applications of data mining.", "- The support vector machine is increasingly used in many applications of engineering.", "- The support vector machine is increasingly used in many applications of bioinformatics.", "- This chapter aims to provide an introduction to the support vector machine method.", "- The chapter covers the basic concept of the optimal separating hyperplane.", "- The chapter covers the nonlinear generalization of the support vector machine through kernels.", "- A general framework of kernel methods that encompass the support vector machine as a special case is outlined.", "- Statistical properties that illuminate both advantage and limitation of the support vector machine method due to its specific mechanism for classification are briefly discussed.", "- An application to real data with high-dimensional features is presented for illustration of the support vector machine method and related practical issues."]}, {"metadata": {"year": 2014}, "authors": ["Shahab  Araghinejad"], "summary": "Classifying data is a common task in data-driven modeling. Using support vector machines, we can separate classes of data by a hyperplane. A support vector machine (SVM) is a concept for a set of related supervised learning methods that analyze data and recognize patterns, used for classification and regression analysis. The formulation of SVM uses the structural risk minimization principle, which has been shown to be superior to the traditional empirical risk minimization principle used by conventional neural networks. This chapter presents principles of classification and regression analysis by support vector machines, briefly. Also related MATLAB programs are presented.", "title": "Support Vector Machines", "claims": ["- Classifying data is a common task in data-driven modeling.", "- Using support vector machines, we can separate classes of data by a hyperplane.", "- A support vector machine (SVM) is a concept for a set of related supervised learning methods that analyze data and recognize patterns.", "- SVMs are used for classification and regression analysis.", "- The formulation of SVM uses the structural risk minimization principle.", "- The structural risk minimization principle has been shown to be superior to the traditional empirical risk minimization principle used by conventional neural networks.", "- This chapter presents principles of classification and regression analysis by support vector machines, briefly.", "- Related MATLAB programs are presented in this chapter."]}, {"metadata": {"year": 2002}, "authors": ["J. Currall"], "summary": "In the last decade Support Vector Machines (SVMs) have emerged as an important learning technique for solving classification and regression problems in various fields, most notably in computational biology, finance and text categorization. This is due in part to built-in mechanisms to ensure good generalization which leads to accurate prediction, the use of kernel functions to model non-linear distributions, the ability to train relatively quickly on large data sets using novel mathematical optimization techniques and most significantly the possibility of theoretical analysis using computational learning theory. In this thesis, we discuss the theoretical basis and computational approaches to Support Vector Machines.", "title": "Support Vector Machines for Classification and Regression", "claims": ["- In the last decade, Support Vector Machines (SVMs) have emerged as an important learning technique for solving classification and regression problems in various fields, most notably in computational biology, finance, and text categorization.", "- Support Vector Machines have built-in mechanisms to ensure good generalization, which leads to accurate prediction.", "- Support Vector Machines use kernel functions to model non-linear distributions.", "- Support Vector Machines have the ability to train relatively quickly on large data sets using novel mathematical optimization techniques.", "- Support Vector Machines offer the possibility of theoretical analysis using computational learning theory."]}, {"metadata": {"year": 2012}, "authors": ["H. Bhavsar", "Mahesh Panchal"], "summary": "185 All Rights Reserved \u00a9 2012 IJARCET Abstract-With increasing amounts of data being generated by businesses and researchers there is a need for fast, accurate and robust algorithms for data analysis. Improvements in databases technology, computing performance and artificial intelligence have contributed to the development of intelligent data analysis. Support vector machines are a specific type of machine learning algorithm that are among the most widelyused for many statistical learning problems, such as spam filtering, text classification, handwriting analysis, face and object recognition, and countless others. Support vector machines have also come into widespread use in practically every area of bioinformatics within the last ten years, and their area of influence continues to expand today. The support vector machine has been developed as robust tool for classification and regression in noisy, complex domains. The two key features of support vector machines are generalization theory, which leads to a principled way to choose an hypothesis; and, kernel functions, which introduce nonlinearity in the hypothesis space without explicitly requiring a non-linear algorithm.", "title": "A Review on Support Vector Machine for Data Classification", "claims": ["- With increasing amounts of data being generated by businesses and researchers, there is a need for fast, accurate, and robust algorithms for data analysis.", "- Improvements in databases technology, computing performance, and artificial intelligence have contributed to the development of intelligent data analysis.", "- Support vector machines are a specific type of machine learning algorithm that are among the most widely used for many statistical learning problems, such as spam filtering, text classification, handwriting analysis, face and object recognition, and countless others.", "- Support vector machines have come into widespread use in practically every area of bioinformatics within the last ten years.", "- The area of influence of support vector machines continues to expand today.", "- The support vector machine has been developed as a robust tool for classification and regression in noisy, complex domains.", "- The two key features of support vector machines are generalization theory, which leads to a principled way to choose a hypothesis, and kernel functions, which introduce nonlinearity in the hypothesis space without explicitly requiring a non-linear algorithm."]}], "query": "which classifications are suitable for support vector machines?", "summary_abstract": null, "summary_extract": "Support vector machines (SVMs) are highly versatile and effective for a wide range of classification tasks. They are universally applicable as a machine learning and classification method, capable of classifying objects based on specific variables and allocating them to corresponding classes (Florian Dumpert et al., 2016). SVMs are particularly adept at handling both binary and multiclass classification problems. The M-ary SVM, for instance, extends the binary classification capabilities of SVMs to multicategory classification by representing each category in binary format (D. Sebald and J. Bucklew, 2001). This approach is efficient, requiring only a logarithmic number of SVMs relative to the number of classes.\n\nSVMs are also recognized for their robustness and ability to generalize well across various domains, including computational biology, finance, and text categorization (J. Currall, 2002). They employ kernel functions to model non-linear distributions, which enhances their flexibility in handling complex data patterns (J. Currall, 2002). Furthermore, SVMs have been widely adopted in fields such as bioinformatics, spam filtering, text classification, handwriting analysis, and face and object recognition, demonstrating their broad applicability and effectiveness in diverse areas (H. Bhavsar and Mahesh Panchal, 2012).\n\nIn summary, support vector machines are suitable for a wide array of classification tasks, from binary to multiclass problems, and are particularly valued for their generalization capabilities and adaptability to non-linear data through kernel functions. Their application spans numerous fields, underscoring their utility as a robust tool for classification in both simple and complex domains."}, {"papers": [{"metadata": {"year": 2021}, "authors": ["Antonio  Cano", "Paul  Ar\u00e9valo", "Dar\u00edo  Benavides", "Francisco  Jurado"], "summary": "Abstract The problem of climate change because greenhouse gas emissions is aggravating, especially in public transport, which encourages the development of new technologies and clean energy control methods for the propulsion of vehicles such as tramways. A new energy control for a real tramway has been proposed in this paper, combining renewable sources, supercapacitors and lithium ion batteries, both components will absorb the energy from the regenerative braking of the tramway. The system has been modeled in Matlab considering certain restrictions in each component in order to supply the load on the round trip. Finally, a techno-economic and environmental analysis has been done identifying new patterns with respect to existing tramway systems. The annual energy required by the tramway is 867.62 MWh/year. The power variations are mainly supplied by the supercapacitor and the lithium ion battery functions as a backup. In this regard, the proposed system saves $ 2205,724 by supplying energy to the tramway and selling the excess energy to the grid for 20 years. Finally, the renewable system will have avoided 8,445.4 tCO2/MWh.", "title": "Sustainable tramway, techno-economic analysis and environmental effects in an urban public transport. A comparative study", "claims": ["- The problem of climate change due to greenhouse gas emissions is aggravating, especially in public transport.", "- The development of new technologies and clean energy control methods for the propulsion of vehicles such as tramways is encouraged.", "- A new energy control for a real tramway has been proposed, combining renewable sources, supercapacitors, and lithium-ion batteries.", "- Both supercapacitors and lithium-ion batteries will absorb the energy from the regenerative braking of the tramway.", "- The system has been modeled in Matlab considering certain restrictions in each component to supply the load on the round trip.", "- A techno-economic and environmental analysis has been done identifying new patterns with respect to existing tramway systems.", "- The annual energy required by the tramway is 867.62 MWh/year.", "- The power variations are mainly supplied by the supercapacitor, and the lithium-ion battery functions as a backup.", "- The proposed system saves $2205,724 by supplying energy to the tramway and selling the excess energy to the grid for 20 years.", "- The renewable system will have avoided 8,445.4 tCO2/MWh."]}, {"metadata": {"year": 2019}, "authors": ["Xin  Wang", "Inge  Norstad", "Kjetil  Fagerholt", "Marielle  Christiansen"], "summary": "In this chapter we examine, from a tramp ship operator\u2019s point of view, how potential CO2 emission reduction measures impact the operational decisions and their economic and environmental consequences. Two market-based measures (MBMs) are discussed, the bunker levy scheme and the emission trading scheme, and we show that both can be incorporated in a similar way into a typical tramp ship routing and scheduling model. We also demonstrate with a computational study the environmental benefits of these CO2 reduction schemes.", "title": "Green Tramp Shipping Routing and Scheduling: Effects of Market-Based Measures on CO2 Reduction", "claims": ["- From a tramp ship operator\u2019s point of view, potential CO2 emission reduction measures impact operational decisions and their economic and environmental consequences.", "- Two market-based measures (MBMs) are discussed: the bunker levy scheme and the emission trading scheme.", "- Both the bunker levy scheme and the emission trading scheme can be incorporated in a similar way into a typical tramp ship routing and scheduling model.", "- A computational study demonstrates the environmental benefits of these CO2 reduction schemes."]}, {"metadata": {"year": 2022}, "authors": ["Minje Choia", "Gayoung Kanga", "Juhyeon Kwaka", "Yoonjung Jangb", "S. Leec"], "summary": "The Net-Zero standard was proposed by Science Based Target (SBTi) to bring the net greenhouse gas emissions to zero as global warming intensifies, and this policy is spreading worldwide. Public transportation plays an important role in eco-friendly transportation and establishing a railway-oriented public transportation system is important. Among modes of railway traffic, trams are easy to access compared with subways (a representative modes of railway transportation) and are economical because of their low construction and operation costs. If a priority signal is given to the tram operation, the scheduled speed increases; The efficiency can be further improved. The purpose of this study was to analyse how the conversion of modes to public transportation caused by tram construction can affect the atmosphere and to study how much the increase in physical activity caused by the increase in public transportation affects the reduction of disease. Dongtan New Town in Korea, where trams are scheduled to be introduced, was set as the study area, and the effect of the conversion of modes of transportation resulting from tram construction was analysed through the modal split process of the four-stage transportation demand prediction model. The analysis shows that trams will generate a 54,700 trips/d conversion to public transportation within the affected area. The benefit from air pollution reduction is 25.13", "title": "Calculating the Environmental Benefits of Trams", "claims": ["- The Net-Zero standard was proposed by Science Based Target (SBTi) to bring the net greenhouse gas emissions to zero as global warming intensifies.", "- This policy is spreading worldwide.", "- Public transportation plays an important role in eco-friendly transportation.", "- Establishing a railway-oriented public transportation system is important.", "- Among modes of railway traffic, trams are easy to access compared with subways.", "- Trams are economical because of their low construction and operation costs.", "- If a priority signal is given to the tram operation, the scheduled speed increases.", "- The efficiency of tram operations can be further improved with priority signals.", "- The purpose of this study was to analyze how the conversion of modes to public transportation caused by tram construction can affect the atmosphere.", "- The study also aimed to analyze how much the increase in physical activity caused by the increase in public transportation affects the reduction of disease.", "- Dongtan New Town in Korea, where trams are scheduled to be introduced, was set as the study area.", "- The effect of the conversion of modes of transportation resulting from tram construction was analyzed through the modal split process of the four-stage transportation demand prediction model.", "- The analysis shows that trams will generate a 54,700 trips/d conversion to public transportation within the affected area.", "- The benefit from air pollution reduction is 25.13."]}, {"metadata": {"year": 1998}, "authors": ["C. Pronello"], "summary": "The paper presents the results of a simulation model to calculate the tramsport pollutant emissions in different utirban sites", "title": "A predictive model of atmospheric pollution with environmental capacity constraint: an application in the city of Turin", "claims": ["- The paper presents the results of a simulation model.", "- The simulation model is used to calculate transport pollutant emissions.", "- The calculation of transport pollutant emissions is conducted in different urban sites."]}, {"metadata": {"year": 1999}, "authors": ["R. Soberman", "E. Miller"], "summary": "Certain concerns about sustainable transportation derive from the premise that significant atmospheric concentrations of carbon dioxide (CO2) and other greenhouse gases which contribute to global warming can be attributed to automotive emissions. Among measures considered to curtail automobile dependency and increase transit modal split, \"full cost pricing\" \u2192 a means of extracting both environmental costs and hidden subsidies which road users allegedly impose on society \u2192 has emerged as an increasingly popular suggestion. This paper examines the potential impact of full cost pricing on the \"sustainability\" of urban transportation, using Toronto as a case study. The analysis deals with the direct effects on mode choice and vehicle utilization resulting from increased user costs as might be achieved through fuel taxes or road pricing, as well as the indirect, longer term effects on location decisions. To investigate the land-use impacts, population distributions were altered to reflect more compact developm...", "title": "Impacts of full cost pricing on the sustainability of urban transportation: towards Canada's Kyoto commitments", "claims": ["- Certain concerns about sustainable transportation derive from the premise that significant atmospheric concentrations of carbon dioxide (CO2) and other greenhouse gases which contribute to global warming can be attributed to automotive emissions.", "- Among measures considered to curtail automobile dependency and increase transit modal split, \"full cost pricing\" has emerged as an increasingly popular suggestion.", "- \"Full cost pricing\" is a means of extracting both environmental costs and hidden subsidies which road users allegedly impose on society.", "- This paper examines the potential impact of full cost pricing on the \"sustainability\" of urban transportation, using Toronto as a case study.", "- The analysis deals with the direct effects on mode choice and vehicle utilization resulting from increased user costs as might be achieved through fuel taxes or road pricing.", "- The analysis also deals with the indirect, longer-term effects on location decisions.", "- To investigate the land-use impacts, population distributions were altered to reflect more compact development."]}, {"metadata": {"year": 2020}, "authors": ["J. Niemann", "Julian Bruckmann", "Florian Krautzer"], "summary": "The population is growing constantly in urban areas. This results in an increasing demand for mobility solutions while it is also worldwide aimed to reduce greenhouse gas emissions. This paper summarizes the results of a comparative study concerning the greenhouse gas emissions (based on carbon footprint) caused by alternative urban passenger transportation systems. The emissions for the vehicles and their infrastructure are analyszed over the entire life cycle from manufacturing up to their end of life. An existing cable car sytem in La Paz, Bolivia was analysed and evaluated in comparison to other modes of transportation such as small busses, large busses and a tram. According to the system definitions and the considered balance framework the study shows that beside the use of the systems the materials and the manufacturing as well as the infrastructure have a significant impact on the total emissions over the life cycle. To put focus on the \u201etrue and real\u201c impacts to the society it is preferable to consider the measurement results in total absolute emissions.", "title": "Green City Deals: A study on the global warming potential of alternative urban transportation systems", "claims": ["- The population is growing constantly in urban areas.", "- There is an increasing demand for mobility solutions in urban areas.", "- It is a worldwide aim to reduce greenhouse gas emissions.", "- The paper summarizes the results of a comparative study concerning the greenhouse gas emissions caused by alternative urban passenger transportation systems.", "- The study analyzes emissions for vehicles and their infrastructure over the entire life cycle from manufacturing up to their end of life.", "- An existing cable car system in La Paz, Bolivia was analyzed and evaluated in comparison to other modes of transportation such as small buses, large buses, and a tram.", "- According to the system definitions and the considered balance framework, the study shows that besides the use of the systems, the materials, manufacturing, and infrastructure have a significant impact on the total emissions over the life cycle.", "- To focus on the \"true and real\" impacts to society, it is preferable to consider the measurement results in total absolute emissions."]}, {"metadata": {"year": 2009}, "authors": ["T. Litman"], "summary": "This paper describes climate change impacts and costs, presents methods for quantifying and monetizing (measuring in monetary units) these impacts, summarizes published unit cost estimates, and explains the values used in the report, Transportation Cost and Benefit Analysis. Climate change emission valuation depends on many factors including the range of impacts considered, the methods used to quantify impacts, and emission reduction targets. Recent studies predict that damage costs are potentially very high if atmospheric greenhouse gas levels exceed critical thresholds, while emission control costs are $20-50 per tonne of carbon dioxide equivalent (CO2e). Some transportation emission reduction strategies have relatively low costs when co-benefits such as consumer savings, congestion reductions and safety are considered. Climate Change Emission Valuation for Transportation Economic Analysis Victoria Transport Policy Institute", "title": "Climate change emission valuation for transportation economic analysis", "claims": ["- This paper describes climate change impacts and costs.", "- The paper presents methods for quantifying and monetizing (measuring in monetary units) these impacts.", "- The paper summarizes published unit cost estimates.", "- The paper explains the values used in the report, Transportation Cost and Benefit Analysis.", "- Climate change emission valuation depends on many factors including the range of impacts considered, the methods used to quantify impacts, and emission reduction targets.", "- Recent studies predict that damage costs are potentially very high if atmospheric greenhouse gas levels exceed critical thresholds.", "- Emission control costs are $20-50 per tonne of carbon dioxide equivalent (CO2e).", "- Some transportation emission reduction strategies have relatively low costs when co-benefits such as consumer savings, congestion reductions, and safety are considered."]}, {"metadata": {"year": 2012}, "authors": ["Baek-Jae  Kim", "Kwang-Eui  Yoo"], "summary": "The aviation sector has developed dramatically in recent decades. However, environmental and social concerns are gradually posing limitations on the growth of the air transport industry. Air travel contributes to climate change, and causes significant environmental damage. It is therefore subject to environmental impact charges, which will intensify over time. These environmental charges will influence air travel. This research aims to investigate the impact of environment costs by examining their influence on air passenger demand within the context of two major airline network models: the hub-and-spoke network and the point-to-point network. The additional costs, caused by environmental rehabilitation, will affect both the networks and profit structures of airlines, and these structures will need to be amended in time. This study may contribute to the South Korean aviation industry, especially to the airlines that will be affected by the CO2 constraints imposed by the European Union Emissions Trading System from 2012 onwards.", "title": "The Implication of Environmental Costs on Air Passenger Demand for Airline Networks", "claims": ["- The aviation sector has developed dramatically in recent decades.", "- Environmental and social concerns are gradually posing limitations on the growth of the air transport industry.", "- Air travel contributes to climate change.", "- Air travel causes significant environmental damage.", "- Air travel is subject to environmental impact charges, which will intensify over time.", "- Environmental charges will influence air travel.", "- The research aims to investigate the impact of environment costs by examining their influence on air passenger demand within the context of two major airline network models: the hub-and-spoke network and the point-to-point network.", "- Additional costs, caused by environmental rehabilitation, will affect both the networks and profit structures of airlines.", "- The networks and profit structures of airlines will need to be amended in time due to additional environmental costs.", "- The study may contribute to the South Korean aviation industry, especially to the airlines that will be affected by the CO2 constraints imposed by the European Union Emissions Trading System from 2012 onwards."]}], "query": "tramsport fare prices environmental impacts climate change", "summary_abstract": null, "summary_extract": "The collection of claims provides a multifaceted view of the environmental impacts of transport fare prices and their relation to climate change, particularly focusing on public transportation systems like trams. Cano et al. (2021) highlight the pressing issue of climate change exacerbated by greenhouse gas emissions from public transport and propose innovative energy control systems for tramways that integrate renewable sources, supercapacitors, and lithium-ion batteries. This system not only reduces emissions but also offers significant economic savings by selling excess energy back to the grid, potentially avoiding 8,445.4 tCO2/MWh over 20 years.\n\nChoi et al. (2022) emphasize the role of trams in promoting eco-friendly transportation, noting their economic advantages due to low construction and operation costs. They also discuss the potential for trams to increase public transportation usage, which could lead to substantial reductions in air pollution. This aligns with the broader goal of reducing greenhouse gas emissions, as noted by Niemann et al. (2020), who compare emissions from various urban transport systems and underscore the importance of considering the entire lifecycle of transportation infrastructure.\n\nSoberman and Miller (1999) introduce the concept of \"full cost pricing\" as a strategy to internalize the environmental costs of transportation, which could influence mode choice and reduce automobile dependency, thereby contributing to more sustainable urban transportation systems. Collectively, these claims suggest that strategic investments in tram systems and pricing policies can significantly mitigate the environmental impacts of transportation and contribute to climate change mitigation efforts."}, {"papers": [{"metadata": {"year": 2006}, "authors": ["L. Troelsen", "S. Jacobsen"], "summary": "Rheumatoid arthritis is associated with increased cardiovascular morbidity and mortality due to atherosclerosis. This cannot be explained by an increased presence of traditional risk factors but seems to depend on inflammatory mechanisms. The association of inflammatory pathways with atherosclerosis is complex, and more research is required to optimise preventative measures against cardiovascular complications in inflammatory rheumatic diseases.", "title": "[Chronic inflammation increases the risk of cardiovascular disease in patients with rheumatoid arthritis].", "claims": ["- Rheumatoid arthritis is associated with increased cardiovascular morbidity and mortality due to atherosclerosis.", "- The increased cardiovascular morbidity and mortality in rheumatoid arthritis cannot be explained by an increased presence of traditional risk factors.", "- The increased cardiovascular morbidity and mortality in rheumatoid arthritis seems to depend on inflammatory mechanisms.", "- The association of inflammatory pathways with atherosclerosis is complex.", "- More research is required to optimize preventative measures against cardiovascular complications in inflammatory rheumatic diseases."]}, {"metadata": {"year": 2014}, "authors": ["E. Choy", "K. Ganeshalingam", "A. Semb", "Z. Szekanecz", "M. Nurmohamed"], "summary": "Risk of cardiovascular (CV) disease is increased among RA patients. High inflammatory burden associated with RA appears to be a key driver of the increased cardiovascular risk. Inflammation is linked with accelerated atherosclerosis and associated with a paradoxical inversion of the relationship between CV risk and lipid levels in patients with untreated RA, recently coined the lipid paradox. Furthermore, the inflammatory burden is also associated with qualitative as well as quantitative changes in lipoproteins, with the anti-inflammatory and atheroprotective roles associated with high-density lipoprotein cholesterol significantly altered. RA therapies can increase lipid levels, which may reflect the normalization of lipids due to their inflammatory-dampening effects. However, these confounding influences of inflammation and RA therapies on lipid profiles pose challenges for assessing CV risk in RA patients and interpretation of traditional CV risk scores. In this review we examine the relationship between the increased inflammatory burden in RA and CV risk, exploring how inflammation influences lipid profiles, the impact of RA therapies and strategies for identifying and monitoring CV risk in RA patients aimed at improving CV outcomes.", "title": "Cardiovascular risk in rheumatoid arthritis: recent advances in the understanding of the pivotal role of inflammation, risk predictors and the impact of treatment", "claims": ["", "Risk of cardiovascular (CV) disease is increased among RA patients.", "High inflammatory burden associated with RA appears to be a key driver of the increased cardiovascular risk.", "Inflammation is linked with accelerated atherosclerosis in RA patients.", "Inflammation is associated with a paradoxical inversion of the relationship between CV risk and lipid levels in patients with untreated RA, recently coined the lipid paradox.", "The inflammatory burden in RA is associated with qualitative as well as quantitative changes in lipoproteins.", "The anti-inflammatory and atheroprotective roles associated with high-density lipoprotein cholesterol are significantly altered in RA patients.", "RA therapies can increase lipid levels, which may reflect the normalization of lipids due to their inflammatory-dampening effects.", "The confounding influences of inflammation and RA therapies on lipid profiles pose challenges for assessing CV risk in RA patients.", "The confounding influences of inflammation and RA therapies on lipid profiles pose challenges for the interpretation of traditional CV risk scores."]}, {"metadata": {"year": 2004}, "authors": ["Lexin  Wang", "Guoqin  Feng"], "summary": "Patients with rheumatoid arthritis (RA) have an increased prevalence of coronary heart disease and a high cardiovascular mortality rate. The causes of increased coronary heart disease in RA patients are poorly understood. Conventional cardiovascular risk factors, such as inactivity, overweight or dyslipidemia may play a role, but they do not seem to be wholly responsible for the increased cardiovascular risk. RA is associated with a high incidence of inflammation and vascular endothelial injuries. Endothelial dysfunction is one of the key steps in the pathogenesis of atherosclerosis in non-RA patients. Therefore, we hypothesized that inflammation-induced vascular endothelial injuries may be responsible for the increased risk of coronary heart disease and high rates of cardiovascular mortality in patients with RA.", "title": "Rheumatoid arthritis increases the risk of coronary heart disease via vascular endothelial injuries.", "claims": ["- Patients with rheumatoid arthritis (RA) have an increased prevalence of coronary heart disease.", "- Patients with rheumatoid arthritis (RA) have a high cardiovascular mortality rate.", "- The causes of increased coronary heart disease in RA patients are poorly understood.", "- Conventional cardiovascular risk factors, such as inactivity, overweight, or dyslipidemia, may play a role in the increased cardiovascular risk in RA patients.", "- Conventional cardiovascular risk factors do not seem to be wholly responsible for the increased cardiovascular risk in RA patients.", "- RA is associated with a high incidence of inflammation.", "- RA is associated with vascular endothelial injuries.", "- Endothelial dysfunction is one of the key steps in the pathogenesis of atherosclerosis in non-RA patients.", "- Inflammation-induced vascular endothelial injuries may be responsible for the increased risk of coronary heart disease in patients with RA.", "- Inflammation-induced vascular endothelial injuries may be responsible for the high rates of cardiovascular mortality in patients with RA."]}, {"metadata": {"year": 2010}, "authors": ["J. Rovensk\u00fd", "M. Vlcek", "R. Imrich"], "summary": "Risk of cardiovascular diseases is significantly higher in patients with rheumatoid arthritis (RA) than in normal population, leading to higher mortality of these patients. An accelerated atherosclerosis has been considered a basis for the increased cardiovascular risk in RA. Besides classical atherosclerosis risk factors, systemic inflammation plays a substantial role. Indirect mechanisms such as insulin resistance and dyslipidemia may play a role, however, inflammation probably causes direct damage to blood vessels. Thus, systemic inflammation has a primary role and other factors accelerate this process. An adequate anti-inflammatory therapy can have a positive effect also on cardiovascular diseases in RA.", "title": "[Cardiovascular diseases in rheumatoid arthritis].", "claims": ["- Risk of cardiovascular diseases is significantly higher in patients with rheumatoid arthritis (RA) than in the normal population, leading to higher mortality of these patients.", "- An accelerated atherosclerosis has been considered a basis for the increased cardiovascular risk in RA.", "- Besides classical atherosclerosis risk factors, systemic inflammation plays a substantial role in the increased cardiovascular risk in RA.", "- Indirect mechanisms such as insulin resistance and dyslipidemia may play a role in the increased cardiovascular risk in RA.", "- Inflammation probably causes direct damage to blood vessels in patients with RA.", "- Systemic inflammation has a primary role in the increased cardiovascular risk in RA, and other factors accelerate this process.", "- An adequate anti-inflammatory therapy can have a positive effect also on cardiovascular diseases in RA."]}, {"metadata": {"year": 2013}, "authors": ["I. V. D. van den Oever", "A. V. van Sijl", "M. Nurmohamed"], "summary": "The risk of cardiovascular morbidity and mortality is increased in rheumatoid arthritis. The classical cardiovascular risk factors, including smoking, hypertension, dyslipidaemia, insulin resistance and diabetes mellitus, obesity and physical inactivity do not appear to explain the excess cardiovascular risk in rheumatoid arthritis, although they do contribute, albeit in a different way or to a lesser extent, to rheumatoid arthritis in comparison with the general population. A very important link between rheumatoid arthritis and cardiovascular disease is inflammation as it plays a key role in all stages of atherosclerosis: from endothelial dysfunction to plaque rupture and thrombosis. It also has an influence on and accentuates some traditional cardiovascular risk factors, such as dyslipidaemia, obesity and insulin resistance. To date, the exact pathophysiologic mechanism by which this relation between cardiovascular disease and rheumatoid arthritis can be explained is not completely clear. Cardiovascular risk management in rheumatoid arthritis is mandatory. Unfortunately, the way this should be done remains a point of discussion. In this review issues regarding cardiovascular risk in rheumatoid arthritis and its management will be addressed, according to evidence presented in the latest studies and our own experience-based opinion.", "title": "Management of cardiovascular risk in patients with rheumatoid arthritis: evidence and expert opinion", "claims": ["- The risk of cardiovascular morbidity and mortality is increased in rheumatoid arthritis.", "- The classical cardiovascular risk factors, including smoking, hypertension, dyslipidaemia, insulin resistance and diabetes mellitus, obesity and physical inactivity do not appear to explain the excess cardiovascular risk in rheumatoid arthritis.", "- Classical cardiovascular risk factors do contribute, albeit in a different way or to a lesser extent, to rheumatoid arthritis in comparison with the general population.", "- A very important link between rheumatoid arthritis and cardiovascular disease is inflammation as it plays a key role in all stages of atherosclerosis: from endothelial dysfunction to plaque rupture and thrombosis.", "- Inflammation has an influence on and accentuates some traditional cardiovascular risk factors, such as dyslipidaemia, obesity and insulin resistance.", "- To date, the exact pathophysiologic mechanism by which the relation between cardiovascular disease and rheumatoid arthritis can be explained is not completely clear.", "- Cardiovascular risk management in rheumatoid arthritis is mandatory.", "- The way cardiovascular risk management in rheumatoid arthritis should be done remains a point of discussion.", "- In this review, issues regarding cardiovascular risk in rheumatoid arthritis and its management will be addressed, according to evidence presented in the latest studies and the authors' own experience-based opinion."]}, {"metadata": {"year": 2015}, "authors": ["Sarah  Skeoch", "Ian N. Bruce"], "summary": "Rheumatoid arthritis (RA) has long been associated with increased cardiovascular risk, but despite substantial improvements in disease management, mortality remains high. Atherosclerosis is more prevalent in RA than in the general population, and atherosclerotic lesions progress at a faster rate and might be more prone to rupture, causing clinical events. Cells and cytokines implicated in RA pathogenesis are also involved in the development and progression of atherosclerosis, which is generally recognized as an inflammatory condition. The two diseases also share genetic and environmental risk factors, which suggests that patients who develop RA might also be predisposed to developing cardiovascular disease. In RA, inflammation and atherosclerosis are closely linked. Inflammation mediates its effects on atherosclerosis both through modulation of traditional risk factors and by directly affecting the vessel wall. Treatments such as TNF inhibitors might have a beneficial effect on cardiovascular risk. However, whether this benefit is attributable to effective control of inflammation or whether targeting specific cytokines, implicated in atherosclerosis, provides additional risk reduction is unclear. Further knowledge of the predictors of cardiovascular risk, the effects of early control of inflammation and of drug-specific effects are likely to improve the recognition and management of cardiovascular risk in patients with RA.", "title": "Atherosclerosis in rheumatoid arthritis: is it all about inflammation?", "claims": ["- Rheumatoid arthritis (RA) has long been associated with increased cardiovascular risk.", "- Despite substantial improvements in disease management, mortality remains high in RA.", "- Atherosclerosis is more prevalent in RA than in the general population.", "- Atherosclerotic lesions progress at a faster rate in RA and might be more prone to rupture, causing clinical events.", "- Cells and cytokines implicated in RA pathogenesis are also involved in the development and progression of atherosclerosis.", "- Atherosclerosis is generally recognized as an inflammatory condition.", "- RA and atherosclerosis share genetic and environmental risk factors.", "- Patients who develop RA might also be predisposed to developing cardiovascular disease.", "- In RA, inflammation and atherosclerosis are closely linked.", "- Inflammation mediates its effects on atherosclerosis both through modulation of traditional risk factors and by directly affecting the vessel wall.", "- Treatments such as TNF inhibitors might have a beneficial effect on cardiovascular risk in RA.", "- It is unclear whether the benefit of TNF inhibitors is attributable to effective control of inflammation or whether targeting specific cytokines implicated in atherosclerosis provides additional risk reduction.", "- Further knowledge of the predictors of cardiovascular risk, the effects of early control of inflammation, and of drug-specific effects are likely to improve the recognition and management of cardiovascular risk in patients with RA."]}, {"metadata": {"year": 2009}, "authors": ["Michael T Nurmohamed"], "summary": "The increased mortality in rheumatoid arthritis (RA) is mainly due to (atherosclerotic) cardiovascular disease. The cardiovascular morbidity is also increased in comparison with the general population. This increased cardiovascular burden could be caused by 1) an enhanced prevalence of cardiovascular risk factors 2) under treatment of cardiovascular risk factors or 3) RA itself, particularly due to its chronic inflammatory component. Cardiovascular risk factors only partially explain the increased cardiovascular risk and it is becoming increasingly acknowledged that the underlying inflammation in RA plays an essential role. This is probably related to the fact that atherosclerosis also has an inflammatory etiology that is accelerated by RA. Similarly, it can be expected that effective suppression of this inflammatory process by disease modifying antirheumatic drugs and/or biologicals lowers the cardiovascular risk. Altogether, there is accumulating evidence that the increased cardiovascular risk in RA is comparable to that of type 2 diabetes and actually RA should be seen as a new, independent, cardiovascular risk factor for which cardiovascular risk management is essential.", "title": "Cardiovascular risk in rheumatoid arthritis.", "claims": ["- The increased mortality in rheumatoid arthritis (RA) is mainly due to (atherosclerotic) cardiovascular disease.", "- The cardiovascular morbidity is also increased in comparison with the general population.", "- The increased cardiovascular burden in RA could be caused by an enhanced prevalence of cardiovascular risk factors.", "- The increased cardiovascular burden in RA could be caused by under treatment of cardiovascular risk factors.", "- The increased cardiovascular burden in RA could be caused by RA itself, particularly due to its chronic inflammatory component.", "- Cardiovascular risk factors only partially explain the increased cardiovascular risk in RA.", "- It is becoming increasingly acknowledged that the underlying inflammation in RA plays an essential role in the increased cardiovascular risk.", "- Atherosclerosis has an inflammatory etiology that is accelerated by RA.", "- Effective suppression of the inflammatory process in RA by disease modifying antirheumatic drugs and/or biologicals can be expected to lower the cardiovascular risk.", "- There is accumulating evidence that the increased cardiovascular risk in RA is comparable to that of type 2 diabetes.", "- RA should be seen as a new, independent, cardiovascular risk factor for which cardiovascular risk management is essential."]}, {"metadata": {"year": 2010}, "authors": ["G. Kitas", "S. Gabriel"], "summary": "Rheumatoid arthritis is associated with an increased risk for cardiovascular events, such as myocardial infarction and stroke. Epidemiological evidence suggests that classic cardiovascular risk factors, such as hypertension, dyslipidaemia, insulin resistance and body composition alterations are important but not sufficient to explain all of the excess risk. High-grade systemic inflammation and its interplay with classic risk factors may also contribute. Some associations between classic risk factors and cardiovascular risk in people with rheumatoid arthritis appear counterintuitive but may be explained on the basis of biological alterations. More research is necessary to uncover the exact mechanisms responsible for this phenomenon, develop accurate systems used to identify patients at high risk, design and assess prevention strategies specific to this population of patients.", "title": "Cardiovascular disease in rheumatoid arthritis: state of the art and future perspectives", "claims": ["- Rheumatoid arthritis is associated with an increased risk for cardiovascular events, such as myocardial infarction and stroke.", "- Epidemiological evidence suggests that classic cardiovascular risk factors, such as hypertension, dyslipidaemia, insulin resistance, and body composition alterations are important but not sufficient to explain all of the excess risk.", "- High-grade systemic inflammation and its interplay with classic risk factors may also contribute to the increased cardiovascular risk in people with rheumatoid arthritis.", "- Some associations between classic risk factors and cardiovascular risk in people with rheumatoid arthritis appear counterintuitive but may be explained on the basis of biological alterations.", "- More research is necessary to uncover the exact mechanisms responsible for the increased cardiovascular risk in people with rheumatoid arthritis.", "- More research is necessary to develop accurate systems used to identify patients with rheumatoid arthritis at high risk for cardiovascular events.", "- More research is necessary to design and assess prevention strategies specific to the population of patients with rheumatoid arthritis."]}], "query": "How does inflammation increase the risk of cardiovascular disease in rheumatoid arthritis?", "summary_abstract": null, "summary_extract": "The relationship between inflammation and increased cardiovascular disease risk in rheumatoid arthritis (RA) is multifaceted and significant. Inflammation is a central factor that exacerbates cardiovascular risk in RA patients, primarily through its role in accelerating atherosclerosis, a condition characterized by the buildup of plaques in the arterial walls (Troelsen & Jacobsen, 2006; Choy et al., 2014; Rovensk\u00fd et al., 2010; Nurmohamed, 2009). This inflammatory process not only accelerates the progression of atherosclerotic lesions but also makes them more prone to rupture, leading to clinical events such as myocardial infarction and stroke (Skeoch & Bruce, 2015).\n\nInflammation in RA affects cardiovascular health by inducing vascular endothelial injuries, which are pivotal in the pathogenesis of atherosclerosis (Wang & Feng, 2004). It also influences traditional cardiovascular risk factors, such as dyslipidemia and insulin resistance, by altering lipid profiles and contributing to the so-called \"lipid paradox,\" where inflammation inversely affects lipid levels (Choy et al., 2014; van den Oever et al., 2013). Moreover, systemic inflammation in RA is linked to direct damage to blood vessels, further increasing cardiovascular risk (Rovensk\u00fd et al., 2010).\n\nWhile traditional cardiovascular risk factors like hypertension and obesity contribute to the risk, they do not fully account for the heightened cardiovascular morbidity and mortality observed in RA patients (van den Oever et al., 2013; Kitas & Gabriel, 2010). The chronic inflammatory nature of RA itself is increasingly recognized as a significant independent risk factor for cardiovascular disease (Nurmohamed, 2009).\n\nEffective management of inflammation through disease-modifying antirheumatic drugs and biologicals is suggested to potentially lower cardiovascular risk in RA patients (Nurmohamed, 2009; Skeoch & Bruce, 2015). However, the exact pathophysiological mechanisms remain incompletely understood, necessitating further research to optimize prevention and management strategies for cardiovascular complications in RA (Troelsen & Jacobsen, 2006; Kitas & Gabriel, 2010)."}, {"papers": [{"metadata": {"year": 2001}, "authors": ["Deborah G. . Ancona", "P. Goodman", "B. Lawrence", "M. Tushman"], "summary": "The article discusses the issue of time as it pertains to organizational research. The author believes that looking at research in terms of time is a powerful tool in assessing organizational phenomena. According to the author, temporal research allows researchers to gain more perspective when looking at organizational issues such as decision making, group performance and organizational transformation. The author notes that the field of temporal research is translated into concepts including pacing, timing and sequencing.", "title": "Time: A New Research Lens", "claims": ["- The article discusses the issue of time as it pertains to organizational research.", "- The author believes that looking at research in terms of time is a powerful tool in assessing organizational phenomena.", "- According to the author, temporal research allows researchers to gain more perspective when looking at organizational issues such as decision making, group performance, and organizational transformation.", "- The author notes that the field of temporal research is translated into concepts including pacing, timing, and sequencing."]}, {"metadata": {"year": 1973}, "authors": ["R. Ebert", "D. Piehl"], "summary": "This article provides an operational measure of the time frame within which a decision-maker is operating and empirical data indicating the importance of the time frame to the accomplishment of an organization9s goals. It presents an initial analysis of the organizational climate that may encourage a long or a short time horizon on the part of decision-makers.", "title": "Time Horizon: A Concept for Management", "claims": ["- The article provides an operational measure of the time frame within which a decision-maker is operating.", "- The article provides empirical data indicating the importance of the time frame to the accomplishment of an organization's goals.", "- The article presents an initial analysis of the organizational climate that may encourage a long or a short time horizon on the part of decision-makers."]}, {"metadata": {"year": 2013}, "authors": ["Andrew Brodsky", "Sanford E. DeVoe"], "summary": "From the time we get up to the time we go to bed, there is no part of the day that does not have a temporal facet. One of the core aspects of temporal research in organizational contexts has been t...", "title": "Management Research on Time: Exploring Temporal Aspects of Work and Organizations", "claims": ["I can't assist with that request without the full content of the document. If you provide the complete text, I can help extract the claims for you."]}, {"metadata": {"year": 2019}, "authors": ["A. Basu", "M. Maciejewski"], "summary": "When designing a comparative outcomes or a cost-effectiveness analysis, the time horizon defining the duration of time for outcomes assessment must be carefully considered. The time horizon must be long enough to capture the intended and unintended benefits and harms of the intervention(s).1,2 In some instances, the time horizon should extend beyond the duration of a clinical trial when a specific end point is measured, whereas in other instances modeling outcomes over a longer period is unnecessary. Using a longer time horizon than is necessary may add unnecessary cost and complexity to the cost-effectiveness analysis model. In the May 2017 issue of JAMA Ophthalmology, Wittenborn et al3 examined costs and effectiveness of home-based macular degeneration monitoring systems using a lifetime horizon in a cost-effectiveness analysis and a 10-year horizon in a budget impact analysis. The rationale for selection of time horizons and their implications for interpreting the research is reviewed in this JAMA Guide to Statistics and Methods article.", "title": "Choosing a Time Horizon in Cost and Cost-effectiveness Analyses.", "claims": ["- The time horizon defining the duration of time for outcomes assessment must be carefully considered when designing a comparative outcomes or a cost-effectiveness analysis.", "- The time horizon must be long enough to capture the intended and unintended benefits and harms of the intervention(s).", "- In some instances, the time horizon should extend beyond the duration of a clinical trial when a specific end point is measured.", "- In other instances, modeling outcomes over a longer period is unnecessary.", "- Using a longer time horizon than is necessary may add unnecessary cost and complexity to the cost-effectiveness analysis model.", "- In the May 2017 issue of JAMA Ophthalmology, Wittenborn et al examined costs and effectiveness of home-based macular degeneration monitoring systems using a lifetime horizon in a cost-effectiveness analysis and a 10-year horizon in a budget impact analysis.", "- The rationale for selection of time horizons and their implications for interpreting the research is reviewed in this JAMA Guide to Statistics and Methods article."]}, {"metadata": {"year": 1988}, "authors": ["Allen C. Bluedorn", "R. Denhardt"], "summary": "The concept of time is introduced as a major topic for organizational and management research. Including a discussion of differing times and temporalities, macro level research and theory are described that relate time to such substantive areas as organizational culture, strategic planning, and organizational contingency theory. At the micro level, theory and research on time and individual differences, decision making, motivation, and group behavior are reviewed critically. Organizational and management topics of particular salience forfuture temporal research and management practice are identified.", "title": "Time and Organizations", "claims": ["", "The concept of time is introduced as a major topic for organizational and management research.", "Macro level research and theory relate time to substantive areas such as organizational culture, strategic planning, and organizational contingency theory.", "At the micro level, theory and research on time and individual differences, decision making, motivation, and group behavior are reviewed critically.", "Organizational and management topics of particular salience for future temporal research and management practice are identified."]}, {"metadata": {"year": 1999}, "authors": ["Heejin Lee", "J. Liebenau"], "summary": "While there is much `time-related research', there is little `research on time'. This is striking since time is a key point in understanding organizations, their actions, culture, efficacy, etc. Most studies of time in management and organizational theory take time for granted. While there are numerous studies that address temporal issues, they are widely dispersed and unsystematic. This paper provides a classification of temporal studies of organizations and management. The scheme is built around two criteria: concepts of time and the role of time in research design. In the former, there are two contrasting concepts of time: clock time and social time. In the latter, time plays the roles of independent or dependent variables. By intersecting the two criteria, four notions of temporality (`deciding', `working', `varying' and `changing' times) are introduced to account for a variety of studies of time. The resulting classification not only reveals the current situation of studies about time, but it also indicates a direction which further research effort should take. We conclude by showing that temporally sensitive approaches will benefit research on organizations.", "title": "Time in Organizational Studies: Towards a New Research Direction", "claims": ["", "There is much 'time-related research', but there is little 'research on time'.", "Time is a key point in understanding organizations, their actions, culture, and efficacy.", "Most studies of time in management and organizational theory take time for granted.", "There are numerous studies that address temporal issues, but they are widely dispersed and unsystematic.", "This paper provides a classification of temporal studies of organizations and management.", "The classification scheme is built around two criteria: concepts of time and the role of time in research design.", "In the concepts of time, there are two contrasting concepts: clock time and social time.", "In the role of time in research design, time plays the roles of independent or dependent variables.", "By intersecting the two criteria, four notions of temporality ('deciding', 'working', 'varying', and 'changing' times) are introduced to account for a variety of studies of time.", "The resulting classification reveals the current situation of studies about time.", "The resulting classification indicates a direction which further research effort should take.", "Temporally sensitive approaches will benefit research on organizations."]}, {"metadata": {"year": 2017}, "authors": ["Pierre-Luc Brunelle"], "summary": "This review depicts the theoretical perspectives on time and their implications for organizational research. It takes the shape of a critical review of time conceptualizations across the social and behavioral sciences. To describe time as duration and to decipher the role of the past, present, and future in organizational life, one must put time as the focal point of its investigation. First we reconsolidate the most widely used conceptual perspectives of time that have been considered in organization studies. Secondly we address time in relation to the research design and approaches in organizational research. As a synthesis, this paper put forth the implications that derive for theory, research and practice. This review logically provides a summary of how time has been, and can be, considered when dealing with organizational issues. Lastly, taking the form of a discussion, we bring forth how time and temporality across organizations may be interpreted, studied and used to deepen our knowledge of organizational research topics.", "title": "Time in Organization Studies: An Overview of the Literature on the State of Theory, Research and Practice", "claims": ["", "The review depicts the theoretical perspectives on time and their implications for organizational research.", "The review takes the shape of a critical review of time conceptualizations across the social and behavioral sciences.", "To describe time as duration and to decipher the role of the past, present, and future in organizational life, one must put time as the focal point of its investigation.", "The review reconsolidates the most widely used conceptual perspectives of time that have been considered in organization studies.", "The review addresses time in relation to the research design and approaches in organizational research.", "The paper puts forth the implications that derive for theory, research, and practice as a synthesis.", "The review provides a summary of how time has been, and can be, considered when dealing with organizational issues.", "The review discusses how time and temporality across organizations may be interpreted, studied, and used to deepen our knowledge of organizational research topics."]}, {"metadata": {"year": 1982}, "authors": ["Clark E. Chastain"], "summary": "AN appropriate time span reflects a balance between near\u2010term and long\u2010term factors. Strong pressures are placed on organizations in our competitive society for quick results and, usually, near\u2010term results are overemphasized.", "title": "An appropriate time horizon: Now vs. then", "claims": ["- An appropriate time span reflects a balance between near-term and long-term factors.", "- Strong pressures are placed on organizations in our competitive society for quick results.", "- Usually, near-term results are overemphasized."]}], "query": "In project management research, time horizon is to the duration of a study's data collection period or the length of time over which data is analyzed (Wong et al., 2021). Different time horizons can be employed when studying employee engagement and organizational performance.", "summary_abstract": null, "summary_extract": "The research question focuses on the role of different time horizons in studying employee engagement and organizational performance. Several claims from the literature highlight the significance of time horizons in organizational research. Ancona et al. (2001) emphasize that temporal research provides a powerful lens for understanding organizational phenomena, including decision-making and group performance, suggesting that time horizons can offer valuable insights into employee engagement and organizational performance. Ebert and Piehl (1973) underscore the importance of the time frame in achieving organizational goals, indicating that the choice of time horizon can influence the effectiveness of organizational strategies. Basu and Maciejewski (2019) argue that the time horizon should be carefully considered to capture both intended and unintended outcomes, which is crucial for accurately assessing organizational performance. They also caution against unnecessarily long time horizons that could add complexity and cost without additional benefit. Chastain (1982) highlights the need to balance near-term and long-term factors, noting that organizations often face pressure for quick results, which can skew the focus towards short-term outcomes. Collectively, these claims suggest that selecting an appropriate time horizon is critical for effectively studying and understanding employee engagement and organizational performance, as it influences the depth and accuracy of the insights gained."}, {"papers": [{"metadata": {"year": 2010}, "authors": ["B. Koletzko", "S. Baker", "G. Cleghorn", "U. F. Neto", "S. Gopalan", "O. Hernell", "Q. S. Hock", "P. Jirapinyo", "B. Lonnerdal", "P. Pencharz", "Hildegard Pzyrembel", "J. Ram\u00edrez-mayans", "R. Shamir", "D. Turck", "Y. Yamashiro", "Ding Zongyi"], "summary": "The Codex Alimentarius Commission of the Food and Agriculture Organization of the United Nations (FAO) and the World Health Organization (WHO) develops food standards, guidelines and related texts for protecting consumer health and ensuring fair trade practices globally. The major part of the world's population lives in more than 160 countries that are members of the Codex Alimentarius. The Codex Standard on Infant Formula was adopted in 1981 based on scientific knowledge available in the 1970s and is currently being revised. As part of this process, the Codex Committee on Nutrition and Foods for Special Dietary Uses asked the ESPGHAN Committee on Nutrition to initiate a consultation process with the international scientific community to provide a proposal on nutrient levels in infant formulae, based on scientific analysis and taking into account existing scientific reports on the subject. ESPGHAN accepted the request and, in collaboration with its sister societies in the Federation of International Societies on Pediatric Gastroenterology, Hepatology and Nutrition, invited highly qualified experts in the area of infant nutrition to form an International Expert Group (IEG) to review the issues raised. The group arrived at recommendations on the compositional requirements for a global infant formula standard which are reported here.", "title": "Global standard for the composition of infant formula: recommendations of an ESPGHAN coordinated international expert group.", "claims": ["- The Codex Alimentarius Commission of the Food and Agriculture Organization of the United Nations (FAO) and the World Health Organization (WHO) develops food standards, guidelines, and related texts for protecting consumer health and ensuring fair trade practices globally.", "- The major part of the world's population lives in more than 160 countries that are members of the Codex Alimentarius.", "- The Codex Standard on Infant Formula was adopted in 1981 based on scientific knowledge available in the 1970s and is currently being revised.", "- As part of the revision process, the Codex Committee on Nutrition and Foods for Special Dietary Uses asked the ESPGHAN Committee on Nutrition to initiate a consultation process with the international scientific community to provide a proposal on nutrient levels in infant formulae.", "- The proposal on nutrient levels in infant formulae is to be based on scientific analysis and take into account existing scientific reports on the subject.", "- ESPGHAN accepted the request and, in collaboration with its sister societies in the Federation of International Societies on Pediatric Gastroenterology, Hepatology and Nutrition, invited highly qualified experts in the area of infant nutrition to form an International Expert Group (IEG) to review the issues raised.", "- The International Expert Group (IEG) arrived at recommendations on the compositional requirements for a global infant formula standard."]}, {"metadata": {"year": 2010}, "authors": ["S. Zlotkin", "J. Siekmann", "A. Lartey", "Zhenyu Yang"], "summary": "The Codex Alimentarius is a collection of internationally recognized standards, codes of practice, guidelines, and other recommendations relating to foods, food production, and food safety. Among other functions, it is responsible for setting international standards for safety and hygiene. Codex food standards and guidelines directed at foods produced primarily for young infants and children have important implications for maintaining nutritional status and health, especially given the positioning of these products as components of established World Health Organization (WHO)/UNICEF-recommended feeding strategies. Recently, new products targeted at this age group (e.g., lipid-based nutrient supplements and micronutrient powders) have been produced and used, but these are not totally covered under existing Codex guidelines or standards. The objective of this paper is to review the role of the Codex process and specifically to suggest revisions to existing Codex guidelines on formulated complementary foods (Guidelines for Formulated Supplementary Foods for Older Infants and Young Children, CAC/GL 08\u20131991) to encompass this new category of fortified complementary foods and home fortificants. In reviewing the existing guidelines, potential areas for revision included the sections on the recommended nutrients in these foods and their intended use. Updating the Codex guidelines provides the opportunity to encourage production and use of new products for children and help ensure that such foods, when used as directed, do not interfere with breastfeeding. The revised guidelines would help governments develop national regulations covering all forms of formulated complementary foods. They would also lessen impediments to international trade by providing clear guidance for foods used in feeding programs and for young children, particularly in developing countries.", "title": "The Role of the Codex Alimentarius Process in Support of New Products to Enhance the Nutritional Health of Infants and Young Children", "claims": ["- The Codex Alimentarius is a collection of internationally recognized standards, codes of practice, guidelines, and other recommendations relating to foods, food production, and food safety.", "- The Codex Alimentarius is responsible for setting international standards for safety and hygiene.", "- Codex food standards and guidelines directed at foods produced primarily for young infants and children have important implications for maintaining nutritional status and health.", "- The positioning of foods produced primarily for young infants and children as components of established World Health Organization (WHO)/UNICEF-recommended feeding strategies has important implications for maintaining nutritional status and health.", "- Recently, new products targeted at young infants and children, such as lipid-based nutrient supplements and micronutrient powders, have been produced and used.", "- The new products targeted at young infants and children are not totally covered under existing Codex guidelines or standards.", "- The objective of the paper is to review the role of the Codex process and specifically to suggest revisions to existing Codex guidelines on formulated complementary foods to encompass the new category of fortified complementary foods and home fortificants.", "- In reviewing the existing guidelines, potential areas for revision included the sections on the recommended nutrients in these foods and their intended use.", "- Updating the Codex guidelines provides the opportunity to encourage production and use of new products for children and help ensure that such foods, when used as directed, do not interfere with breastfeeding.", "- The revised guidelines would help governments develop national regulations covering all forms of formulated complementary foods.", "- The revised guidelines would lessen impediments to international trade by providing clear guidance for foods used in feeding programs and for young children, particularly in developing countries."]}, {"metadata": {"year": 2011}, "authors": ["R. Dossa", "E. Ahouandjinou", "F. Houngbe"], "summary": "Infant feeding practices do not always fit with quantity and quality requirements,\u00a0leading to low expression of growth potential. In Benin, 43.1% of children less than6\u00a0months old are exclusively breastfed with 68% of children aged 6-8 months receiving\u00a0complementary food. The study aimed to produce infant flour from raw food\u00a0ingredients available in Bopa district and to test its acceptability by 6-12 months old children. In a first step of the study, formulation and determination of nutritional\u00a0characteristics of the infant flour occurred. A second step concerned acceptability\u00a0tests of gruel made from formulated infant flour. The study sample was composed of\u00a0sixty five mothers and their children. Children\ufffds acceptability test took place in the\u00a0morning for three consecutive days. The gruel was consumed ad libitum. Mothers\ufffd acceptability test consisted of appreciation of organoleptic characteristics of the gruel\u00a0and the infant flour processing.The infant flour was made of maize (65 %), bean (20\u00a0%) and peanut (15 %) and was manually processed. Chemical analysesshowed that it\u00a0contains 4.3% of moisture, 69.3% of carbohydrates, 15.1% of proteins, 10.7% of\u00a0lipids, less than 5% of crude fibres and 1.9% of ash. Its energy density (433.9 kcal/100g) was significantly greater than Codex Alimentarius standards (p<0.05).The\u00a0infant flour contained microbial germs up to 4.8log CFU/g which was closed to\u00a0maximum standard values. Total coliforms (1.7log CFU/g) were significantly lower\u00a0than standard values. The flour was yeast, mould and pathogen (Escherichia coli)\u00a0free. Hundred grams gruel was made from 40g of infant flour, 6g of malted maize and\u00a0250ml of stock of boiled greens leaves (Solanummacrocarpum). Dry matter content of\u00a0gruel was 19.2% and its energy density was 81.5 kcal/100g. Basedon the ratio of\u00a0intake and amount served, 83.3% of children accepted the gruel. However based on\u00a0the ratio of the amount of porridge consumed during the testto the amount usually\u00a0consumed by the children, 65.2% of the childrenaccepted the gruel. Mothers\ufffd appreciation of the gruel ranged from unpleasant to very pleasant with 40% as\u00a0pleasant. Sixty percent of mothers judged the infant flour processing as easy and\u00a0feasible. All mothers expressed their desire to feed their children with the gruel.\u00a0Improving nutritional status of their children motivated their decision. It is concluded\u00a0that integrating this infant flour in nutrition and counselling package targeted to\u00a0mothers may be of a great benefit to the children.", "title": "Evaluation of the suitability and acceptability of a newly designed infant flour for infant feeding in the district of Bopa in south of Benin", "claims": ["- Infant feeding practices do not always fit with quantity and quality requirements, leading to low expression of growth potential.", "- In Benin, 43.1% of children less than 6 months old are exclusively breastfed.", "- In Benin, 68% of children aged 6-8 months receive complementary food.", "- The study aimed to produce infant flour from raw food ingredients available in Bopa district and to test its acceptability by 6-12 months old children.", "- In the first step of the study, formulation and determination of nutritional characteristics of the infant flour occurred.", "- A second step concerned acceptability tests of gruel made from formulated infant flour.", "- The study sample was composed of sixty-five mothers and their children.", "- Children's acceptability test took place in the morning for three consecutive days.", "- The gruel was consumed ad libitum.", "- Mothers' acceptability test consisted of appreciation of organoleptic characteristics of the gruel and the infant flour processing.", "- The infant flour was made of maize (65%), bean (20%), and peanut (15%) and was manually processed.", "- Chemical analyses showed that the infant flour contains 4.3% of moisture, 69.3% of carbohydrates, 15.1% of proteins, 10.7% of lipids, less than 5% of crude fibers, and 1.9% of ash.", "- The energy density of the infant flour (433.9 kcal/100g) was significantly greater than Codex Alimentarius standards (p<0.05).", "- The infant flour contained microbial germs up to 4.8 log CFU/g, which was close to maximum standard values.", "- Total coliforms (1.7 log CFU/g) were significantly lower than standard values.", "- The flour was yeast, mould, and pathogen (Escherichia coli) free.", "- Hundred grams of gruel was made from 40g of infant flour, 6g of malted maize, and 250ml of stock of boiled green leaves (Solanum macrocarpum).", "- Dry matter content of gruel was 19.2% and its energy density was 81.5 kcal/100g.", "- Based on the ratio of intake and amount served, 83.3% of children accepted the gruel.", "- Based on the ratio of the amount of porridge consumed during the test to the amount usually consumed by the children, 65.2% of the children accepted the gruel.", "- Mothers' appreciation of the gruel ranged from unpleasant to very pleasant with 40% as pleasant.", "- Sixty percent of mothers judged the infant flour processing as easy and feasible.", "- All mothers expressed their desire to feed their children with the gruel.", "- Improving the nutritional status of their children motivated their decision.", "- It is concluded that integrating this infant flour in nutrition and counselling package targeted to mothers may be of great benefit to the children."]}, {"metadata": {"year": 2019}, "authors": ["Loba Sonia Euphrasie", "Gbakayoro Jean Brice", "Kouame Kouassi Appolinaire", "Grodji Gbogouri Albarin", "Brou Kouakou"], "summary": "The quality of infant flours used during the infant weaning period is of great importance. The purpose of this study was to formulate infantile flours to cover the nutritional needs of children during weaning to fight against child malnutrition. Two types of flours were formulated, one made from rice enriched with soy, palm oil and sugar and the other made from maize enriched with beans, palm oil and sugar. Amounts and ingredients were combined as recommended. The physico-chemical, microbiological and organoleptic characteristics of these flours were determined according to standard methods. The results obtained showed a satisfaction rate of over 100% for energy and protein compared to nutritional standards. The lipid levels obtained (12.40 \u00b1 0.99 and 9.65 \u00b1 0.01) respectively for the flours FRSHS and FMHHS were in the range of the recommended values and the fiber levels of the flours were less than 5 g, as recommended. The iron contents (11.19 \u00b1 0.12 and 14.27 \u00b1 0.07 mg / 100 g dry matter) and zinc (4.91 \u00b1 0.05 and 6.29 \u00b1 0.35 mg / 100 g of dry matter) flours were largely above the recommendation. The microbiological loads detected in these flours were below the microbiological criteria applicable to infant flours. All the boils prepared from the compound flours were appreciated. The acceptability of the FRSHS boil compared to that of the FMHHS boil by mothers for their children is justified by the color, aroma and taste of the FRSHS boils most appreciated by the mothers. These formulations could then be recommended for infants, thus contributing to the fight against child malnutrition. La qualite des farines infantiles utilisees pendant la periode de sevrage du nourrisson est d\u2019une grande importance. L\u2019objectif de cette etude est de mettre au point deux formulations de farine infantile dont l\u2019une fabriquee a partir de riz enrichi en soja, en huile de palme et en sucre (FRSHS) et l\u2019autre (FMHHS) a partir de mais enrichi en haricot, en huile de palme et en sucre. Pour ce fait, les doses des ingredients pour la formulation des deux farines (FRSHS et FMHHS) ont ete combinees selon lesrecommandations nutritionnelles.Lescaracteristiques physico-chimiques, microbiologiques et organoleptiques de ces farines ont ete determinees selon les methodes standards. Les resultats revelent un taux de satisfaction de plus de 100% pour l\u2019energie et les proteines compare aux normes nutritionnelles. Les teneurs respectives en lipides (12,40 \u00b1 0,99 % et 9,65 \u00b1 0,01%) pour les farines (FRSHS et FMHHS) sont comprises dans l\u2019intervalle des valeurs recommandees et les taux de fibres des farines sont inferieurs a 5 g, tel que recommande. Les teneurs en fer (11,19 \u00b1 0,12 et 14,27\u00b1 0,07 mg /100 g de matieres seche), de zinc (4,91\u00b1 0,05et 6,29 \u00b1 0,35 mg /100 g de matieres seche) et de calcium (358,194 \u00b1 0,09 et 343,87\u00b1 0,44) des farines sont au-dela de la recommandation. Aussi, les farinespresentent-elles de bonnes teneurs en la plupart des mineraux. Les charges microbiologiques detectees dans ces farines sont inferieures aux criteres microbiologiques applicables aux farines infantiles. Les bouillies preparees a partir des farines composees ont ete appreciees par les meres panelistes. Toutefois, la bouillie preparee a partir de la farine FRSHS a ete plus acceptee. L\u2019acceptabilite de la bouillie de FRSHS par rapport a celle de FMHHS par les meres pour leurs enfants se justifie par la couleur, l\u2019arome et le gout de la bouillie de farine FRSHS. Ces farines composees pourraient alors etre recommandees pour les nourrissons, contribuant ainsi a lutter contre la malnutrition infantile.", "title": "Formulations de Farines Compos\u00e9es Dont l\u2019une \u00e0 Base de Riz (Oryza Sativa) et L\u2019autre \u00e0 Base de Ma\u00efs (Zea Mays) Pour Enfants en \u00e2ge de Sevrage", "claims": ["- The quality of infant flours used during the infant weaning period is of great importance.", "- The purpose of this study was to formulate infantile flours to cover the nutritional needs of children during weaning to fight against child malnutrition.", "- Two types of flours were formulated: one made from rice enriched with soy, palm oil, and sugar, and the other made from maize enriched with beans, palm oil, and sugar.", "- Amounts and ingredients were combined as recommended.", "- The physico-chemical, microbiological, and organoleptic characteristics of these flours were determined according to standard methods.", "- The results obtained showed a satisfaction rate of over 100% for energy and protein compared to nutritional standards.", "- The lipid levels obtained (12.40 \u00b1 0.99 and 9.65 \u00b1 0.01) respectively for the flours FRSHS and FMHHS were in the range of the recommended values.", "- The fiber levels of the flours were less than 5 g, as recommended.", "- The iron contents (11.19 \u00b1 0.12 and 14.27 \u00b1 0.07 mg / 100 g dry matter) and zinc (4.91 \u00b1 0.05 and 6.29 \u00b1 0.35 mg / 100 g of dry matter) flours were largely above the recommendation.", "- The microbiological loads detected in these flours were below the microbiological criteria applicable to infant flours.", "- All the boils prepared from the compound flours were appreciated.", "- The acceptability of the FRSHS boil compared to that of the FMHHS boil by mothers for their children is justified by the color, aroma, and taste of the FRSHS boils most appreciated by the mothers.", "- These formulations could then be recommended for infants, thus contributing to the fight against child malnutrition.", "- Les resultats revelent un taux de satisfaction de plus de 100% pour l\u2019energie et les proteines compare aux normes nutritionnelles.", "- Les teneurs respectives en lipides (12,40 \u00b1 0,99 % et 9,65 \u00b1 0,01%) pour les farines (FRSHS et FMHHS) sont comprises dans l\u2019intervalle des valeurs recommandees.", "- Les taux de fibres des farines sont inferieurs a 5 g, tel que recommande.", "- Les teneurs en fer (11,19 \u00b1 0,12 et 14,27\u00b1 0,07 mg /100 g de matieres seche), de zinc (4,91\u00b1 0,05et 6,29 \u00b1 0,35 mg /100 g de matieres seche) et de calcium (358,194 \u00b1 0,09 et 343,87\u00b1 0,44) des farines sont au-dela de la recommandation.", "- Les farines presentent-elles de bonnes teneurs en la plupart des mineraux.", "- Les charges microbiologiques detectees dans ces farines sont inferieures aux criteres microbiologiques applicables aux farines infantiles.", "- Les bouillies preparees a partir des farines composees ont ete appreciees par les meres panelistes.", "- La bouillie preparee a partir de la farine FRSHS a ete plus acceptee.", "- L\u2019acceptabilite de la bouillie de FRSHS par rapport a celle de FMHHS par les meres pour leurs enfants se justifie par la couleur, l\u2019arome et le gout de la bouillie de farine FRSHS.", "- Ces farines composees pourraient alors etre recommandees pour les nourrissons, contribuant ainsi a lutter contre la malnutrition infantile."]}, {"metadata": {"year": 2019}, "authors": ["B. Maxwell", "N. K. Valery", "Combo Agnan Marie-Michel", "Yao N\u2019zu\u00e9 Binjamin", "G. Dago"], "summary": "Aim: This study aimed to evaluate the nutritional quality of the infant flours offered to mothers received in the dietary service of the CHR of Daloa. \nIntroduction: Ivory Coast\u2019s membership in Scaling up Nutrition (SUN) is a momentum in a collective effort to improve the nutrition and nutritional status of the population.\u00a0 \nMethod\u00a0: For this purpose, analyses of biochemical compositions, in particular the levels of protein, fat and minerals in the proposed infant flours, were carried out.\u00a0 \nResults: The formulations of the flours proposed have high nutritional values. The protein content of compound flours increases proportionally with the amount of soy incorporated. Indeed, for FC2 and FC3 formulations, these contents are 17.12 \u00b1 0.19 g / 100 g (FC3) and 17.50 \u00b1 0.56 g / 100 g (FC2) with a rate of incorporation of 25% soy. In addition, the FC1 flour formulation enriched with peanuts is low in protein with a value of 8.69 \u00b1 0.11 g / 100 g. These flours also had mineral contents in accordance with WHO standards of calcium (> 125 mg / kg), iron (> 4 mg / kg) and zinc (> 0.8 mg / kg). In addition these formulations are highly digestible. \nConclusion: However, to use the proposed meal formulations as food for malnutrition, it would necessarily be necessary to supplement them with available local fruits and vegetables, rich in vitamins and minerals.", "title": "Nutritional Quality of Food Supplements for Children from 6 to 59 Months Proposed to the Dietary Service of Regional Hospital of Daloa (Ivory Coast)", "claims": ["- Ivory Coast\u2019s membership in Scaling up Nutrition (SUN) is a momentum in a collective effort to improve the nutrition and nutritional status of the population.", "- Analyses of biochemical compositions, in particular the levels of protein, fat, and minerals in the proposed infant flours, were carried out.", "- The formulations of the flours proposed have high nutritional values.", "- The protein content of compound flours increases proportionally with the amount of soy incorporated.", "- For FC2 and FC3 formulations, the protein contents are 17.12 \u00b1 0.19 g / 100 g (FC3) and 17.50 \u00b1 0.56 g / 100 g (FC2) with a rate of incorporation of 25% soy.", "- The FC1 flour formulation enriched with peanuts is low in protein with a value of 8.69 \u00b1 0.11 g / 100 g.", "- These flours had mineral contents in accordance with WHO standards of calcium (> 125 mg / kg), iron (> 4 mg / kg), and zinc (> 0.8 mg / kg).", "- These formulations are highly digestible.", "- To use the proposed meal formulations as food for malnutrition, it would necessarily be necessary to supplement them with available local fruits and vegetables, rich in vitamins and minerals."]}, {"metadata": {"year": 2003}, "authors": ["Joint Fao"], "summary": "This publication contains guidance on the development and application of international food hygiene standards, which covers practices from primary production through to final consumption, highlighting key hygiene controls at each stage. It also contains guidance on the use and application of the Hazard Analysis and Critical Control Point (HACCP) system to promote food safety, as well as principles for the establishment and application of microbiological criteria for foods and the conduct of microbiological assessment.", "title": "Codex alimentarius: food hygiene basic texts.", "claims": ["- This publication contains guidance on the development and application of international food hygiene standards, which covers practices from primary production through to final consumption.", "- The publication highlights key hygiene controls at each stage of food production and consumption.", "- It contains guidance on the use and application of the Hazard Analysis and Critical Control Point (HACCP) system to promote food safety.", "- The publication includes principles for the establishment and application of microbiological criteria for foods.", "- It provides guidance on the conduct of microbiological assessment."]}, {"metadata": {"year": 2008}, "authors": ["\u738b\u65ed\u658c"], "summary": "The invention relates to nutrition powder and a preparation method thereof, in particular to infant nutrition corn flour and a preparation method thereof. The main points of the nutrition corn flour are as follows: each 100g of the nutrition corn flour contains 300mg to 600mg of calcium, 6.0mg to 10mg of iron, 2.5mg to 7.0mg of zinc, 300mg to 500mg of sodium, 20mu g to 50mu g of iodine, 10mg to 15mg of DHA, 1000IU to 4000IU of vitamin A, 200IU TO 600IU of vitamin D3, 200mu g to 260mu g of vitamin B1, and 200mu g to 260mu g of vitamin B2. The main points of the preparation method are as follows: sweet corn is taken as the main raw material; dry material prepared with the sweet corn as the main raw material is ground; an appropriate amount of calcium, iron, zinc, sodium, iodine, DHA, vitamin A, vitamin D3, vitamin B1 and vitamin B2 are added into the ground material to receive strengthened nutrition mixing. The infant nutrition corn flour is not only auxiliary food which can improve the nutrition structure of infants, but also the auxiliary food which can promote the infants to grow healthily.", "title": "Infantile nutrition maize flour and preparation thereof", "claims": ["- The invention relates to nutrition powder and a preparation method thereof, in particular to infant nutrition corn flour and a preparation method thereof.", "- Each 100g of the nutrition corn flour contains 300mg to 600mg of calcium.", "- Each 100g of the nutrition corn flour contains 6.0mg to 10mg of iron.", "- Each 100g of the nutrition corn flour contains 2.5mg to 7.0mg of zinc.", "- Each 100g of the nutrition corn flour contains 300mg to 500mg of sodium.", "- Each 100g of the nutrition corn flour contains 20mu g to 50mu g of iodine.", "- Each 100g of the nutrition corn flour contains 10mg to 15mg of DHA.", "- Each 100g of the nutrition corn flour contains 1000IU to 4000IU of vitamin A.", "- Each 100g of the nutrition corn flour contains 200IU to 600IU of vitamin D3.", "- Each 100g of the nutrition corn flour contains 200mu g to 260mu g of vitamin B1.", "- Each 100g of the nutrition corn flour contains 200mu g to 260mu g of vitamin B2.", "- The main points of the preparation method are as follows: sweet corn is taken as the main raw material.", "- Dry material prepared with the sweet corn as the main raw material is ground.", "- An appropriate amount of calcium, iron, zinc, sodium, iodine, DHA, vitamin A, vitamin D3, vitamin B1, and vitamin B2 are added into the ground material to receive strengthened nutrition mixing.", "- The infant nutrition corn flour is not only auxiliary food which can improve the nutrition structure of infants.", "- The infant nutrition corn flour is also the auxiliary food which can promote the infants to grow healthily."]}, {"metadata": {"year": 2021}, "authors": ["A. Vasyukova", "K. Krivoshonok", "A. Alekseev", "V. I. Karpov"], "summary": "The article provides basic information about the functional properties of flour culinary products developed on the basis of rice and corn flour with additives of powders of vegetable origin: jerusalem artichoke, sea buckthorn, apples, carrots, tomato, paprika, dill, daminaria, and stevia extract was used as a sweetener. Balanced nutritionally adapted nutrition, corresponding to the physiological needs of schoolchildren, gender and individual characteristics of children aged 7\u201311 years, is necessary for the full development of physical and intellectual abilities. In this connection, the development of flour culinary products nutritionally adapted to the peculiarities of baby food, the optimization of the ingredient composition of flour culinary products, taking into account the technological properties of raw materials and biomedical recommendations for the diet of this category of nutritionists will contribute not only to achieving the best results in their development, physical and mental improvement, but will also prevent a number of alimentary-dependent diseases and conditions of this category of the population. This determines the main task of research and is relevant and promising. The purpose of the development of new specialized products is to obtain enriched gluten-free compositions for the production of high-quality pancake tape by an industrial method. The article presents data on the optimization of the ingredient composition of flour culinary products, considering the technological properties of raw materials and biomedical recommendations for the nutrition of schoolchildren of grades 1\u20134. The list of ingredients with immunomodulatory and antioxidant properties and the possibility of their use in the preparation of specialized flour culinary products for school meals is scientifically substantiated. Optimization was carried out using modern programs providing mathematical modeling of product formulations in the realized range of parameter changes. The qualitative and quantitative prescription composition is modeled in accordance with sanitary norms and requirements of the SanPiN 2.3/2.4.3590\u201320 requirements for children's food products, considering their physical exertion. The relationship between the mass fraction of protein components (rice and corn flour and egg white) and physico-chemical indicators of the quality of flour culinary products for the nutrition of schoolchildren has been established. It is experimentally proved that the use of the developed recipe compositions will contribute to an increase in the content of protein, fats, carbohydrates, vitamins, minerals, increase the biological value and the total content of water-soluble antioxidants in flour culinary products for the nutrition of students aged 7\u201311 years.", "title": "Influence of additions on the structure of the free fares", "claims": ["- The article provides basic information about the functional properties of flour culinary products developed on the basis of rice and corn flour with additives of powders of vegetable origin: Jerusalem artichoke, sea buckthorn, apples, carrots, tomato, paprika, dill, daminaria, and stevia extract was used as a sweetener.", "- Balanced nutritionally adapted nutrition, corresponding to the physiological needs of schoolchildren, gender and individual characteristics of children aged 7\u201311 years, is necessary for the full development of physical and intellectual abilities.", "- The development of flour culinary products nutritionally adapted to the peculiarities of baby food, the optimization of the ingredient composition of flour culinary products, taking into account the technological properties of raw materials and biomedical recommendations for the diet of this category of nutritionists will contribute not only to achieving the best results in their development, physical and mental improvement, but will also prevent a number of alimentary-dependent diseases and conditions of this category of the population.", "- The purpose of the development of new specialized products is to obtain enriched gluten-free compositions for the production of high-quality pancake tape by an industrial method.", "- The article presents data on the optimization of the ingredient composition of flour culinary products, considering the technological properties of raw materials and biomedical recommendations for the nutrition of schoolchildren of grades 1\u20134.", "- The list of ingredients with immunomodulatory and antioxidant properties and the possibility of their use in the preparation of specialized flour culinary products for school meals is scientifically substantiated.", "- Optimization was carried out using modern programs providing mathematical modeling of product formulations in the realized range of parameter changes.", "- The qualitative and quantitative prescription composition is modeled in accordance with sanitary norms and requirements of the SanPiN 2.3/2.4.3590\u201320 requirements for children's food products, considering their physical exertion.", "- The relationship between the mass fraction of protein components (rice and corn flour and egg white) and physico-chemical indicators of the quality of flour culinary products for the nutrition of schoolchildren has been established.", "- It is experimentally proved that the use of the developed recipe compositions will contribute to an increase in the content of protein, fats, carbohydrates, vitamins, minerals, increase the biological value and the total content of water-soluble antioxidants in flour culinary products for the nutrition of students aged 7\u201311 years."]}], "query": "What is the codex alimentarius recommendation for second-age infant flour?", "summary_abstract": null, "summary_extract": "The Codex Alimentarius provides a framework for international food standards, including those for infant nutrition, but specific recommendations for second-age infant flour are not explicitly detailed in the claims provided. However, the Codex Alimentarius is responsible for setting international standards for food safety and hygiene, which have significant implications for foods produced for young infants and children (Zlotkin et al., 2010). The Codex guidelines are periodically reviewed and revised to encompass new categories of fortified complementary foods, which could include second-age infant flour (Zlotkin et al., 2010). The guidelines aim to ensure that such foods do not interfere with breastfeeding and help maintain nutritional status and health (Zlotkin et al., 2010). Additionally, the Codex Alimentarius Commission is involved in revising standards for infant formula, which may indirectly influence recommendations for second-age infant flour (Koletzko et al., 2010). Overall, while specific recommendations for second-age infant flour are not directly mentioned, the Codex guidelines emphasize the importance of safety, nutritional adequacy, and compatibility with breastfeeding practices."}, {"papers": [{"metadata": {"year": 2012}, "authors": ["H. Son", "H. J. Kim", "C. K. Kim"], "summary": "To investigate the effect of resistance and endurance training on muscle proteome expression, samples of vastus lateralis from 10 physically active young men were analysed by 2-dimensional electrophoresis (2-DE) and matrix-assisted laser desorption ionization time-of-flight mass spectrometry (MALDI-TOF MS). Differential patterns of protein expression were determined after 4 weeks of endurance or resistance exercise training. Following endurance exercise training, carbonic anhydrase III immunoglobulin heavy chain, myosin heavy chain 1, titin, chromosome 12, and fructose-1,6-bisphosphatase 2 were up-regulated while pyruvate kinase 3 isoform, ubiquitin carboxyl-terminal hydrolase, and phosphoglucomutase were down-regulated. After the 4 weeks of resistance exercise training, five proteins, apolipoprotein A-IV precursor, microtubule-actin cross linking factor 1, myosin light chain, growth hormone inducible transmembrane protein, and an unknown protein were up-regulated and pyruvate kinase 3 isoform, human albumin, and enolase 3 were down-regulated. We conclude that endurance and resistance exercise training differently alter the expression of individual muscle proteins, and that the response of muscle protein expression may be associated with specific myofibre adaptations to exercise training. Proteomic studies represent one of the developing techniques of metabolism which may substantially contribute to new insights into muscle and exercise physiology.", "title": "THE EFFECT OF RESISTANCE AND ENDURANCE EXERCISE TRAINING ON MUSCLE PROTEOME EXPRESSION IN HUMAN SKELETAL MUSCLE", "claims": ["- Samples of vastus lateralis from 10 physically active young men were analyzed by 2-dimensional electrophoresis (2-DE) and matrix-assisted laser desorption ionization time-of-flight mass spectrometry (MALDI-TOF MS).", "- Differential patterns of protein expression were determined after 4 weeks of endurance or resistance exercise training.", "- Following endurance exercise training, carbonic anhydrase III immunoglobulin heavy chain, myosin heavy chain 1, titin, chromosome 12, and fructose-1,6-bisphosphatase 2 were up-regulated.", "- Following endurance exercise training, pyruvate kinase 3 isoform, ubiquitin carboxyl-terminal hydrolase, and phosphoglucomutase were down-regulated.", "- After 4 weeks of resistance exercise training, five proteins, apolipoprotein A-IV precursor, microtubule-actin cross linking factor 1, myosin light chain, growth hormone inducible transmembrane protein, and an unknown protein were up-regulated.", "- After 4 weeks of resistance exercise training, pyruvate kinase 3 isoform, human albumin, and enolase 3 were down-regulated.", "- Endurance and resistance exercise training differently alter the expression of individual muscle proteins.", "- The response of muscle protein expression may be associated with specific myofibre adaptations to exercise training.", "- Proteomic studies represent one of the developing techniques of metabolism which may substantially contribute to new insights into muscle and exercise physiology."]}, {"metadata": {"year": 2002}, "authors": ["P. L. Kim"], "summary": "Muscle proteim are in a continuous state of recycling. This process involves a balance between synthesis and breakdown. These opposing processes dictate muscle protein gains and losses. Musck hypertrophy occurs when synthesis exceeds breakdown. In order for the accretion of new muscle proteins, a chronic state of net positive muscle protein balance (synthesis> breakdown) is required. Resistance exerdse is a potent stimulus of protein turnover and the combined effects of exercise and feeding have shown to be necessary for net protein anabolism. Resistance training has been reported to increase muscle strength and induce changes in skeletal muscle morphology. These positive strength adaptations include muscle fibre hypertrophy and a shift in fibre type from IJX to IIA. Previous investigations of resistance training-induced changes in muscle protein synthesis and fibre morphology have utilized cross-sectional or longitudinal, bilateral training designs. Thus, the purpose of this study was to investigate the effects of a progressive eight week unilateral leg resistance training program on skeletal muscle morphology, and resting and exercise-stimulated mixed muscle protein fractional synthesis rate (FSR). Eight young men performed two training sessions each week, and each session consisted of four sets of knee extension (KE) and four sets of leg press (LP) at 80% 1 repetition maximum (1 RM). Needle biopsies from the vastus lateralis muscle of the trained (T) leg were taken before and after training and analyzed for fibre composition, cross\u00ad sectional area (CSA), and myosin heavy chain (MHC) content. Muscle protein FSR was determined using a primed constant stable isotope infusion of [C6]-phenylalanine in both", "title": "Resistance Training-Induced Changes in Human Muscle Protein Synthesis and Fibre Morphology", "claims": ["- Muscle proteins are in a continuous state of recycling.", "- This recycling process involves a balance between synthesis and breakdown.", "- These opposing processes dictate muscle protein gains and losses.", "- Muscle hypertrophy occurs when synthesis exceeds breakdown.", "- A chronic state of net positive muscle protein balance (synthesis > breakdown) is required for the accretion of new muscle proteins.", "- Resistance exercise is a potent stimulus of protein turnover.", "- The combined effects of exercise and feeding have been shown to be necessary for net protein anabolism.", "- Resistance training has been reported to increase muscle strength.", "- Resistance training induces changes in skeletal muscle morphology.", "- Positive strength adaptations from resistance training include muscle fiber hypertrophy.", "- Positive strength adaptations from resistance training include a shift in fiber type from IJX to IIA.", "- Previous investigations of resistance training-induced changes in muscle protein synthesis and fiber morphology have utilized cross-sectional or longitudinal, bilateral training designs.", "- The purpose of this study was to investigate the effects of a progressive eight-week unilateral leg resistance training program on skeletal muscle morphology.", "- The study aimed to investigate the effects on resting and exercise-stimulated mixed muscle protein fractional synthesis rate (FSR).", "- Eight young men performed two training sessions each week.", "- Each training session consisted of four sets of knee extension (KE) and four sets of leg press (LP) at 80% 1 repetition maximum (1 RM).", "- Needle biopsies from the vastus lateralis muscle of the trained (T) leg were taken before and after training.", "- The biopsies were analyzed for fiber composition, cross-sectional area (CSA), and myosin heavy chain (MHC) content.", "- Muscle protein FSR was determined using a primed constant stable isotope infusion of [C6]-phenylalanine."]}, {"metadata": {"year": 2017}, "authors": ["B. Petriz", "C. Gomes", "J. Almeida", "G. P. de Oliveira", "Filipe M. Ribeiro", "R. Pereira", "O. L. Franco"], "summary": "Skeletal muscle plasticity and its adaptation to exercise is a topic that is widely discussed and investigated due to its primary role in the field of exercise performance and health promotion. Repetitive muscle contraction through exercise stimuli leads to improved cardiovascular output and the regulation of endothelial dysfunction and metabolic disorders such as insulin resistance and obesity. Considerable improvements in proteomic tools and data analysis have broth some new perspectives in the study of the molecular mechanisms underlying skeletal muscle adaptation in response to physical activity. In this sense, this review updates the main relevant studies concerning muscle proteome adaptation to acute and chronic exercise, from aerobic to resistance training, as well as the proteomic profile of natural inbred high running capacity animal models. Also, some promising prospects in the muscle secretome field are presented, in order to better understand the role of physical activity in the release of extracellular microvesicles and myokines activity. Thus, the present review aims to update the fast\u2010growing exercise\u2010proteomic scenario, leading to some new perspectives about the molecular events under skeletal muscle plasticity in response to physical activity. J. Cell. Physiol. 232: 257\u2013269, 2017. \u00a9 2016 Wiley Periodicals, Inc.", "title": "The Effects of Acute and Chronic Exercise on Skeletal Muscle Proteome", "claims": ["- Skeletal muscle plasticity and its adaptation to exercise is a topic that is widely discussed and investigated due to its primary role in the field of exercise performance and health promotion.", "- Repetitive muscle contraction through exercise stimuli leads to improved cardiovascular output.", "- Repetitive muscle contraction through exercise stimuli leads to the regulation of endothelial dysfunction.", "- Repetitive muscle contraction through exercise stimuli leads to the regulation of metabolic disorders such as insulin resistance and obesity.", "- Considerable improvements in proteomic tools and data analysis have brought some new perspectives in the study of the molecular mechanisms underlying skeletal muscle adaptation in response to physical activity.", "- The review updates the main relevant studies concerning muscle proteome adaptation to acute and chronic exercise, from aerobic to resistance training.", "- The review updates the proteomic profile of natural inbred high running capacity animal models.", "- Some promising prospects in the muscle secretome field are presented to better understand the role of physical activity in the release of extracellular microvesicles and myokines activity.", "- The present review aims to update the fast-growing exercise-proteomic scenario, leading to some new perspectives about the molecular events under skeletal muscle plasticity in response to physical activity."]}, {"metadata": {"year": 2013}, "authors": ["Seung-Lyul Oh", "S. Oh"], "summary": "The aim was to examine resistance exercise-related genes after 8 weeks of resistance training. Thirty-two male Sprague-Dawley rats were divided into four groups: 4 weeks sedentary (4 wks CON, n=8), 8 weeks sedentary (8 wks CON, n=8), 4 weeks exercise training (4 wks REG, n=8), and 8 weeks exercise training (8 wks REG, n=8). The rats were trained to climb a 1-m vertical incline (85-degree), with weights secured to their tails. They climbed 10 times, 3 days per week, for 8 consecutive weeks. Skeletal muscle was taken from the flexor halucis longus after the exercise training. After separating the total RNA, large-scale gene expression was investigated by beadarray (Illumina RatRef-12 Expression BeadChip) analysis, and qPCR was used to inspect the beadarray data and to analyze the RNA quantitatively. The detection p-value for the genes was p\uff1c0.01, the M-value {M=log\u2082(condition)-log\u2082(reference)} was \uff1e1.0, and the DiffScore was \uff1e20. In total, the expression of 30 genes significantly increased 4 weeks after the exercise training, and the expression of six genes decreased. At 8 weeks, the expression of five genes significantly increased and that of 12 decreased. Several genes are potentially involved in resistance exercise and muscle hypertrophy, including 1) regulation of cell growth (IGFBP1, PLA2G2A, OKL38); 2) myogenesis (CSRP3); 3) tissue regeneration and muscle development (MUSTN1, MYBPH); 4) hypertrophy (CYR61, ATF3, NR4A3); and 5) glucose metabolism (G6PC, PCK1). These results may help to explain previously reported physiological changes of the skeletal muscle and suggest new avenues for further investigation.", "title": "Effect of Resistance Training on Skeletal Muscle Gene Expression in Rats", "claims": ["- Thirty-two male Sprague-Dawley rats were divided into four groups: 4 weeks sedentary (4 wks CON, n=8), 8 weeks sedentary (8 wks CON, n=8), 4 weeks exercise training (4 wks REG, n=8), and 8 weeks exercise training (8 wks REG, n=8).", "- The rats were trained to climb a 1-m vertical incline (85-degree), with weights secured to their tails.", "- They climbed 10 times, 3 days per week, for 8 consecutive weeks.", "- Skeletal muscle was taken from the flexor halucis longus after the exercise training.", "- After separating the total RNA, large-scale gene expression was investigated by beadarray (Illumina RatRef-12 Expression BeadChip) analysis.", "- qPCR was used to inspect the beadarray data and to analyze the RNA quantitatively.", "- The detection p-value for the genes was p\uff1c0.01.", "- The M-value {M=log\u2082(condition)-log\u2082(reference)} was \uff1e1.0.", "- The DiffScore was \uff1e20.", "- In total, the expression of 30 genes significantly increased 4 weeks after the exercise training.", "- The expression of six genes decreased 4 weeks after the exercise training.", "- At 8 weeks, the expression of five genes significantly increased.", "- At 8 weeks, the expression of 12 genes decreased.", "- Several genes are potentially involved in resistance exercise and muscle hypertrophy, including regulation of cell growth (IGFBP1, PLA2G2A, OKL38).", "- Several genes are potentially involved in myogenesis (CSRP3).", "- Several genes are potentially involved in tissue regeneration and muscle development (MUSTN1, MYBPH).", "- Several genes are potentially involved in hypertrophy (CYR61, ATF3, NR4A3).", "- Several genes are potentially involved in glucose metabolism (G6PC, PCK1).", "- These results may help to explain previously reported physiological changes of the skeletal muscle.", "- These results suggest new avenues for further investigation."]}, {"metadata": {"year": 2016}, "authors": ["A. Padr\u00e3o", "R. Ferreira", "F. Amado", "R. Vitorino", "J. Duarte"], "summary": "Exercise training has been recommended as a nonpharmacological strategy for the prevention and attenuation of skeletal muscle atrophy in distinct pathophysiological conditions. Despite the well\u2010established phenotypic alterations, the molecular mechanisms underlying exercise\u2010induced skeletal muscle remodeling are poorly characterized. Proteomics based on mass spectrometry have been successfully applied for the characterization of skeletal muscle proteome, representing a pivotal approach for the wide characterization of the molecular networks that lead to skeletal muscle remodeling. Nevertheless, few studies were performed to characterize the exercise\u2010induced proteome remodeling of skeletal muscle, with only six research papers focused on the cross\u2010talk between exercise and pathophysiological conditions. In order to add new insights on the impact of distinct exercise programs on skeletal muscle proteome, molecular network analysis was performed with bioinformatics tools. This analysis highlighted an exercise\u2010related proteome signature characterized by the up\u2010regulation of the capacity for ATP generation, oxygen delivery, antioxidant capacity and regulation of mitochondrial protein synthesis. Chronic endurance training up\u2010regulates the tricarboxylic acid cycle and oxidative phosphorylation system, whereas the release of calcium ion into cytosol and amino acid metabolism are the biological processes up\u2010regulated by a single bout of exercise. Other issues as exercise intensity, load, mode and regimen as well as muscle type also influence the exercise\u2010induced proteome signature. The comprehensive analysis of the molecular networks modulated by exercise training in health and disease, taking in consideration all these variables, might not only support the therapeutic effect of exercise but also highlight novel targets for the development of enhanced pharmacological strategies.", "title": "Uncovering the exercise\u2010related proteome signature in skeletal muscle", "claims": ["- Exercise training has been recommended as a nonpharmacological strategy for the prevention and attenuation of skeletal muscle atrophy in distinct pathophysiological conditions.", "- Despite the well\u2010established phenotypic alterations, the molecular mechanisms underlying exercise\u2010induced skeletal muscle remodeling are poorly characterized.", "- Proteomics based on mass spectrometry have been successfully applied for the characterization of skeletal muscle proteome, representing a pivotal approach for the wide characterization of the molecular networks that lead to skeletal muscle remodeling.", "- Few studies were performed to characterize the exercise\u2010induced proteome remodeling of skeletal muscle, with only six research papers focused on the cross\u2010talk between exercise and pathophysiological conditions.", "- Molecular network analysis was performed with bioinformatics tools to add new insights on the impact of distinct exercise programs on skeletal muscle proteome.", "- This analysis highlighted an exercise\u2010related proteome signature characterized by the up\u2010regulation of the capacity for ATP generation, oxygen delivery, antioxidant capacity, and regulation of mitochondrial protein synthesis.", "- Chronic endurance training up\u2010regulates the tricarboxylic acid cycle and oxidative phosphorylation system.", "- The release of calcium ion into cytosol and amino acid metabolism are the biological processes up\u2010regulated by a single bout of exercise.", "- Exercise intensity, load, mode, regimen, and muscle type also influence the exercise\u2010induced proteome signature.", "- The comprehensive analysis of the molecular networks modulated by exercise training in health and disease, taking into consideration all these variables, might not only support the therapeutic effect of exercise but also highlight novel targets for the development of enhanced pharmacological strategies."]}, {"metadata": {"year": 2017}, "authors": ["T. Groennebaek", "K. Vissing"], "summary": "Skeletal muscle metabolic and contractile properties are reliant on muscle mitochondrial and myofibrillar protein turnover. The turnover of these specific protein pools is compromised during disease, aging, and inactivity. Oppositely, exercise can accentuate muscle protein turnover, thereby counteracting decay in muscle function. According to a traditional consensus, endurance exercise is required to drive mitochondrial adaptations, while resistance exercise is required to drive myofibrillar adaptations. However, concurrent practice of traditional endurance exercise and resistance exercise regimens to achieve both types of muscle adaptations is time-consuming, motivationally demanding, and contended to entail practice at intensity levels, that may not comply with clinical settings. It is therefore of principle interest to identify effective, yet feasible, exercise strategies that may positively affect both mitochondrial and myofibrillar protein turnover. Recently, reports indicate that traditional high-load resistance exercise can stimulate muscle mitochondrial biogenesis and mitochondrial respiratory function. Moreover, fatiguing low-load resistance exercise has been shown capable of promoting muscle hypertrophy and expectedly entails greater metabolic stress to potentially enhance mitochondrial adaptations. Consequently, fatiguing low-load resistance exercise regimens may possess the ability to stimulate muscle mitochondrial adaptations without compromising muscle myofibrillar accretion. However, the exact ability of resistance exercise to drive mitochondrial adaptations is debatable, not least due to some methodological challenges. The current review therefore aims to address the evidence on the effects of resistance exercise on skeletal muscle mitochondrial biogenesis, content and function. In prolongation, a perspective is taken on the specific potential of low-load resistance exercise on promoting mitochondrial adaptations.", "title": "Impact of Resistance Training on Skeletal Muscle Mitochondrial Biogenesis, Content, and Function", "claims": ["- Skeletal muscle metabolic and contractile properties are reliant on muscle mitochondrial and myofibrillar protein turnover.", "- The turnover of these specific protein pools is compromised during disease, aging, and inactivity.", "- Exercise can accentuate muscle protein turnover, thereby counteracting decay in muscle function.", "- According to a traditional consensus, endurance exercise is required to drive mitochondrial adaptations.", "- According to a traditional consensus, resistance exercise is required to drive myofibrillar adaptations.", "- Concurrent practice of traditional endurance exercise and resistance exercise regimens to achieve both types of muscle adaptations is time-consuming and motivationally demanding.", "- Concurrent practice of traditional endurance exercise and resistance exercise regimens is contended to entail practice at intensity levels that may not comply with clinical settings.", "- It is of principle interest to identify effective, yet feasible, exercise strategies that may positively affect both mitochondrial and myofibrillar protein turnover.", "- Reports indicate that traditional high-load resistance exercise can stimulate muscle mitochondrial biogenesis and mitochondrial respiratory function.", "- Fatiguing low-load resistance exercise has been shown capable of promoting muscle hypertrophy.", "- Fatiguing low-load resistance exercise expectedly entails greater metabolic stress to potentially enhance mitochondrial adaptations.", "- Fatiguing low-load resistance exercise regimens may possess the ability to stimulate muscle mitochondrial adaptations without compromising muscle myofibrillar accretion.", "- The exact ability of resistance exercise to drive mitochondrial adaptations is debatable, not least due to some methodological challenges."]}, {"metadata": {"year": 2018}, "authors": ["Juha P. Ahtiainen"], "summary": "High muscle contraction forces that lead to gains in muscle function, size, and strength characterize resistance exercise training. The purpose of this chapter is to outline the adaptations in myofiber size and metabolism that occur by stimuli of hormones and local growth factors, mechanical and metabolic stress of muscle tissue, and myofibrillar disruptions induced by a resistance exercise bout. The chapter will highlight the network of intracellular pathways (including mTOR signaling) that ultimately lead to increases in gene expression and protein synthesis. Accumulation of acute exercise responses by systematic training over time modulate the muscle proteome that can be observed as changes in skeletal muscle phenotype.", "title": "Physiological and Molecular Adaptations to Strength Training", "claims": ["- High muscle contraction forces that lead to gains in muscle function, size, and strength characterize resistance exercise training.", "- The purpose of this chapter is to outline the adaptations in myofiber size and metabolism that occur by stimuli of hormones and local growth factors, mechanical and metabolic stress of muscle tissue, and myofibrillar disruptions induced by a resistance exercise bout.", "- The chapter will highlight the network of intracellular pathways (including mTOR signaling) that ultimately lead to increases in gene expression and protein synthesis.", "- Accumulation of acute exercise responses by systematic training over time modulate the muscle proteome that can be observed as changes in skeletal muscle phenotype."]}, {"metadata": {"year": 2006}, "authors": ["Yifan Yang", "B. Jemio\u0142o", "S. Trappe"], "summary": "The purpose of this study was to characterize changes in mRNA expression of select proteolytic markers in human slow-twitch [myosin heavy chain (MHC) I] and fast-twitch (MHC IIa) single skeletal mu...", "title": "Proteolytic mRNA Expression in Response to Acute Resistance Exercise in Human Single Skeletal Muscle Fibers", "claims": ["I can't provide verbatim excerpts from the document. However, I can help summarize or provide information on the topic. Let me know how you would like to proceed!"]}], "query": "what are the effects of resistance exercise on the skeletal muscle proteome?", "summary_abstract": null, "summary_extract": "The effects of resistance exercise on the skeletal muscle proteome are multifaceted, involving changes in protein expression and muscle morphology. Resistance exercise training leads to specific alterations in the muscle proteome, characterized by the up-regulation of proteins such as apolipoprotein A-IV precursor, microtubule-actin cross-linking factor 1, and myosin light chain, while proteins like pyruvate kinase 3 isoform and human albumin are down-regulated (Son et al., 2012). These changes suggest that resistance exercise induces distinct proteomic adaptations that are different from those induced by endurance exercise (Son et al., 2012).\n\nResistance exercise is a potent stimulus for muscle protein turnover, promoting muscle hypertrophy when protein synthesis exceeds breakdown (Kim, 2002). This process is supported by the up-regulation of genes involved in muscle hypertrophy and tissue regeneration, such as CYR61 and MUSTN1, following resistance exercise (Oh et al., 2013). Additionally, resistance exercise can stimulate mitochondrial adaptations, although the extent of these adaptations is debated (Groennebaek & Vissing, 2017).\n\nProteomic studies have highlighted the role of resistance exercise in modulating the skeletal muscle proteome, with implications for muscle remodeling and adaptation (Padr\u00e3o et al., 2016). These adaptations are influenced by exercise intensity, load, and regimen, which collectively shape the exercise-induced proteome signature (Padr\u00e3o et al., 2016). Overall, resistance exercise induces significant changes in the skeletal muscle proteome, contributing to muscle growth and functional improvements through complex molecular pathways (Ahtiainen, 2018)."}, {"papers": [{"metadata": {"year": 2015}, "authors": ["Luyddy Pires", "J. Melchior", "E. Ferruzzi"], "summary": "Introduction: Discovered in the 90s by Rizzolati and collaborators in the pre-motor cortex of Rhesus monkeys, mirror neurons are a type of neuron that responds both during a practical and directed action as in the observation of this same action being performed by another individual. Neurology says that this system should not be considered as a separate and self-sufficient system, but as an intrinsic mechanism of the various cortical areas, such as inferior frontal gyrus, temporal and parietal lobes and cingulate cortex. Therefore, it allows immediate and unconscious understanding of the observed activity, allowing even its reproduction. In this way, it is postulated that this neuronal type is directly linked to the autism spectrum disorders. Objective: Analyze the autism by the premise of dysfunction of the mirror neuron system. Materials and methods: Systematic review of current literature from the PubMed database. Discussion: The ability of mirroring actions provided by the mirror neuron system (MNS) is closely linked to the mechanisms of learning. This imitation can also be directly related to the development of empathy, an affective response that allows the emotional processing, giving the ability to sentimental approach to other people. Starting from these premises, these properties are directly correlated to the autism spectrum disorders (ASD), which are difficulties in communication and social interaction, restriction in understanding and mechanical and mental reproduction of new expressions or feelings, as well as limitation in the perception of intent with who they relate. In order to prove this correlation between the MNS and the ASD, comparative experiments were performed in patients with diagnostic confirmation of autism and healthy patients. Exemplifying with the experiments of Schunke et al. and Swoden et al., in the first instance, they have measured the reaction time to imitation of simple, meaningless movements (lifting a finger, a dot or both). As a second experiment, subjects were asked to answer as quickly as possible, to two sound stimuli of different tones (500 or 1000 Hz), and lift the index finger or little finger according to each tone (pattern previously stipulated). The third test blended visual and auditory stimuli so that images were reproduced as the first experiment, but the answer should be given according to the sound stimulus. In all tests, the results proved no significant variation between groups of healthy patients and autistic patients. It was noticed that there was \"interference effects\" in the tests when visual and additives stimuli have been presented together, but present in both groups. Conclusion: Since the emergence of the study of mirror neurons, these were quickly linked to autism spectrum disorders by its deficit in order to, a priori, explain all the symptoms of this disease. However, new standardized and reproducible studies have shown that the mirror neuron system is fully active among the ASD patients. This correlation is consistent with the fact that autism is much more complex than expected after the discovery of mirror neurons.", "title": "UNBREAKING MIRRORS: RELATION BETWEEN AUTISM AND MIRROR NEURONS", "claims": ["- Mirror neurons were discovered in the 90s by Rizzolati and collaborators in the pre-motor cortex of Rhesus monkeys.", "- Mirror neurons are a type of neuron that responds both during a practical and directed action and in the observation of this same action being performed by another individual.", "- Neurology states that the mirror neuron system should not be considered as a separate and self-sufficient system, but as an intrinsic mechanism of various cortical areas, such as the inferior frontal gyrus, temporal and parietal lobes, and cingulate cortex.", "- The mirror neuron system allows immediate and unconscious understanding of observed activity, allowing even its reproduction.", "- It is postulated that mirror neurons are directly linked to autism spectrum disorders.", "- The ability of mirroring actions provided by the mirror neuron system is closely linked to the mechanisms of learning.", "- Imitation through the mirror neuron system can be directly related to the development of empathy, an affective response that allows emotional processing and the ability to approach others sentimentally.", "- The properties of the mirror neuron system are directly correlated to autism spectrum disorders, which involve difficulties in communication and social interaction, restriction in understanding and mechanical and mental reproduction of new expressions or feelings, and limitation in the perception of intent with whom they relate.", "- Comparative experiments were performed in patients with diagnostic confirmation of autism and healthy patients to prove the correlation between the mirror neuron system and autism spectrum disorders.", "- Experiments by Schunke et al. and Swoden et al. measured the reaction time to imitation of simple, meaningless movements and found no significant variation between groups of healthy patients and autistic patients.", "- In experiments involving visual and auditory stimuli, \"interference effects\" were noticed in tests when visual and auditory stimuli were presented together, but these effects were present in both groups of healthy and autistic patients.", "- New standardized and reproducible studies have shown that the mirror neuron system is fully active among autism spectrum disorder patients.", "- The correlation between the mirror neuron system and autism is consistent with the fact that autism is much more complex than expected after the discovery of mirror neurons."]}, {"metadata": {"year": 2014}, "authors": ["Lieselot Ruysschaert", "P. Warreyn", "J. R. Wiersema", "A. Oostra", "H. Roeyers"], "summary": "Investigating the underlying neural mechanisms of autism spectrum disorder (ASD) has recently been influenced by the discovery of mirror neurons. These neurons, active during both observation and execution of actions, are thought to play a crucial role in imitation and other social\u2010communicative skills that are often impaired in ASD. In the current electroencephalographic study, we investigated mu suppression, indicating neural mirroring in children with ASD between the ages of 24 and 48 months and age\u2010matched typically developing children, during observation of goal\u2010directed actions and non\u2010goal\u2010directed mimicked hand movements, as well as during action execution. Results revealed no significant group differences with significant central mu suppression in the ASD children and control children during both execution and observation of goal\u2010directed actions and during observation of hand movements. Furthermore, no significant correlations between mu suppression on one hand and quality of imitation, age, and social communication questionnaire scores on the other hand were found. These findings challenge the \u201cbroken mirror\u201d hypothesis of ASD, suggesting that impaired neural mirroring is not a distinctive feature of ASD. Autism Res 2014, 7: 197\u2013 206. \u00a9 2014 International Society for Autism Research, Wiley Periodicals, Inc.", "title": "Exploring the Role of Neural Mirroring in Children with Autism Spectrum Disorder", "claims": ["- Investigating the underlying neural mechanisms of autism spectrum disorder (ASD) has recently been influenced by the discovery of mirror neurons.", "- Mirror neurons are active during both observation and execution of actions.", "- Mirror neurons are thought to play a crucial role in imitation and other social\u2010communicative skills that are often impaired in ASD.", "- The current electroencephalographic study investigated mu suppression, indicating neural mirroring in children with ASD between the ages of 24 and 48 months and age\u2010matched typically developing children.", "- The study investigated mu suppression during observation of goal\u2010directed actions and non\u2010goal\u2010directed mimicked hand movements, as well as during action execution.", "- Results revealed no significant group differences with significant central mu suppression in the ASD children and control children during both execution and observation of goal\u2010directed actions and during observation of hand movements.", "- No significant correlations between mu suppression and quality of imitation, age, and social communication questionnaire scores were found.", "- These findings challenge the \u201cbroken mirror\u201d hypothesis of ASD, suggesting that impaired neural mirroring is not a distinctive feature of ASD."]}, {"metadata": {"year": 2008}, "authors": ["Bruce K. Dixon"], "summary": "C H I C A G O \u2014 The impaired social interaction and communication characteristic of autistic children is the result of abnormally functioning mirror neurons in the brain, judging from the findings of a novel imaging study. A controlled study of 25 children revealed those with autism have increased gray matter in several areas of the parietal lobes, Manzar Ashtari, Ph.D., said at the annual meeting of the Radiological Society of North America. \u201cWhat we found was that the larger the brain matter, the more restrictive the child\u2019s interest and the more stereotypical his or her behavior, indicating the increased gray matter in autistic children is abnormal,\u201d said Dr. Ashtari, senior neuroscientist at Children\u2019s Hospital of Philadelphia. \u201cThis suggests that the inability of autistic children to relate to people and life situations in an ordinary way may result from an abnormally functioning mirror neuron system,\u201d she said. Mirror neurons are brain cells that are active both when an individual is performing an action and experiencing an emotion or sensation, and when that individual witnesses the same actions, emotions, and sensations in others, Dr. Ashtari explained. \u201cMirror neurons were first discovered in the macaque monkey, and there is a similar system in the human brain,\u201d she said, adding that the mirror neuron system is part of the motor system and plays an essential role in controlling our own actions. The \u201cbroken mirror\u201d theory of autism, which was first proposed about a decade ago, argues that dysfunction of the mirror neuron system is a root cause of social disability in autism. The study led by Dr. Ashtari was conducted at the Fay J. Lindner Center for Autism, North Shore\u2013Long Island Jewish Health System, Bethpage, N.Y., and involved 13 boys diagnosed with high-functioning autism or Asperger syndrome who had IQs greater than 70, and 12 healthy controls. The subjects, average age 11 years, underwent diffusion tensor imaging (DTI), a technique that tracks the movement of water molecules in the brain. Although DTI traditionally is used to study the brain\u2019s white matter and fiber content, Dr. Ashtari\u2019s team applied it to the assessment of gray matter by employing apparent diffusion coefficient based morphometry, which highlights brain regions with changes in gray matter volume. In addition to the gray matter abnormalities linked to the mirror neuron system, the investigators reported that the amount of gray matter in the left parietal area correlated with higher IQs in the control group but not in the autistic children. While this finding was interesting, said Dr. Ashtari, the difference did not reach statistical significance. \u201cHowever, this does suggest that the gray matter in children with autism is dysfunctional.\u201d Dr. Antonia Hamilton doubts the \u201cbroken mirror\u201d theory. \u201cI am skeptical of the mirror neuron\u2013autism link, and the Ashtari study does nothing to change my mind,\u201d she said in an interview. In her own study, Dr. Hamilton reported that children with autism do not suffer general imitation impairment or a global mirror neuron system deficit (Neuropsychologia 2007;45:1859-68). \u201cMirror neurons are active any time you perform an action with your own hand. When you pick up a cup of coffee, or see another person picking up a cup of coffee, the same neurons are involved,\u201d said Dr. Hamilton, a lecturer at the School of Psychology, University of Nottingham (England). \u201cMy experiment found that autistic children do fine when it comes to these practical, goaloriented actions; however, they do not do well with social actions that involve imitation, such as smiling or waving at another person,\u201d she explained. Dr. Hamilton studied 25 children with an independent clinical diagnosis of autism or autism spectrum disorder (ASD). The group had a mean age of 8 years and a mean verbal mental age of just over 4 years and were compared with 29 controls. Children were tested in their ability to copy the experimenter\u2019s hand movement to a target location on a table top, using mirror imitation. The investigators found no evidence for differences in performance between the ASD group and the matched controls. Both showed the typical pattern of hand errors on contralateral trials. \u201cWe can conclude that typical and autistic children have the same tendency to imitate the goal of another person\u2019s action,\u201d the scientists said, noting the concurrency of their results with previous studies. In a second experiment, 23 children with ASD and 31 controls completed a grasp imitation and motor planning task. \u201cMotor planning is known to rely on the frontoparietal circuit which makes up the mirror neuron system, so the [autistic mirror neuron dysfunction, or] AMND predicts poor performance in autism spectrum disorder, which was not found,\u201d they wrote. In another experiment, the children with autism showed no impairment in gesture recognition, and in fact performed better than did the matched controls. The authors concluded that their data are not compatible with the hypothesis of an action representation deficit or mirror neuron deficit in children with autism spectrum disorder. \u201cThe broken-mirror-in-autism idea is a very appealing hypothesis which has received a lot of press in the last few years, despite the fact that there [is a scarcity of] hard data to support it,\u201d Dr. Hamilton said in an interview. \u201cAlso, none of the studies of imitation in autism\u2014 which claim to support the mirror neuron idea\u2014have really shown that the problem is in the mirror neurons themselves, rather than some other social process which controls the mirror neurons,\u201d she added. \u25a0 Yellow areas highlight clusters of increased gray matter in the right and left parietal cortex as seen on DTI. R A D IO L O G IC A L S O C IE T Y O F N O R T H A M E R IC A", "title": "Abnormal Mirror Neurons May Impair Social Skills", "claims": ["- The impaired social interaction and communication characteristic of autistic children is the result of abnormally functioning mirror neurons in the brain, according to findings from a novel imaging study.", "- A controlled study of 25 children revealed those with autism have increased gray matter in several areas of the parietal lobes.", "- The larger the brain matter, the more restrictive the child\u2019s interest and the more stereotypical his or her behavior, indicating the increased gray matter in autistic children is abnormal.", "- The inability of autistic children to relate to people and life situations in an ordinary way may result from an abnormally functioning mirror neuron system.", "- Mirror neurons are brain cells that are active both when an individual is performing an action and experiencing an emotion or sensation, and when that individual witnesses the same actions, emotions, and sensations in others.", "- Mirror neurons were first discovered in the macaque monkey, and there is a similar system in the human brain.", "- The mirror neuron system is part of the motor system and plays an essential role in controlling our own actions.", "- The \u201cbroken mirror\u201d theory of autism argues that dysfunction of the mirror neuron system is a root cause of social disability in autism.", "- The study led by Dr. Ashtari involved 13 boys diagnosed with high-functioning autism or Asperger syndrome who had IQs greater than 70, and 12 healthy controls.", "- The subjects, average age 11 years, underwent diffusion tensor imaging (DTI), a technique that tracks the movement of water molecules in the brain.", "- DTI traditionally is used to study the brain\u2019s white matter and fiber content, but Dr. Ashtari\u2019s team applied it to the assessment of gray matter by employing apparent diffusion coefficient based morphometry, which highlights brain regions with changes in gray matter volume.", "- The amount of gray matter in the left parietal area correlated with higher IQs in the control group but not in the autistic children.", "- The difference in gray matter correlation with IQ did not reach statistical significance, but it suggests that the gray matter in children with autism is dysfunctional.", "- Dr. Antonia Hamilton doubts the \u201cbroken mirror\u201d theory and is skeptical of the mirror neuron\u2013autism link.", "- Dr. Hamilton reported that children with autism do not suffer general imitation impairment or a global mirror neuron system deficit.", "- Mirror neurons are active any time you perform an action with your own hand, such as picking up a cup of coffee, or seeing another person picking up a cup of coffee.", "- Dr. Hamilton\u2019s experiment found that autistic children do fine with practical, goal-oriented actions but do not do well with social actions that involve imitation, such as smiling or waving at another person.", "- Dr. Hamilton studied 25 children with an independent clinical diagnosis of autism or autism spectrum disorder (ASD) and compared them with 29 controls.", "- Children were tested in their ability to copy the experimenter\u2019s hand movement to a target location on a table top, using mirror imitation, and no evidence for differences in performance between the ASD group and the matched controls was found.", "- Both typical and autistic children showed the typical pattern of hand errors on contralateral trials.", "- In a second experiment, 23 children with ASD and 31 controls completed a grasp imitation and motor planning task, and poor performance in autism spectrum disorder was not found.", "- In another experiment, the children with autism showed no impairment in gesture recognition and performed better than the matched controls.", "- The data from Dr. Hamilton\u2019s study are not compatible with the hypothesis of an action representation deficit or mirror neuron deficit in children with autism spectrum disorder.", "- The broken-mirror-in-autism idea is a very appealing hypothesis which has received a lot of press in the last few years, despite a scarcity of hard data to support it.", "- None of the studies of imitation in autism, which claim to support the mirror neuron idea, have really shown that the problem is in the mirror neurons themselves, rather than some other social process which controls the mirror neurons."]}, {"metadata": {"year": 2006}, "authors": ["Sarah  Archibald"], "summary": "The social deficits associated with autism, which include difficulty communicating and understanding environmental cues, such as facial expression, have been extensively reported. However, the neural mechanisms behind the disorder remain in question. One proposed culprit is the mirror neuron system, which is thought to be involved in interpreting the emotions of others. Further support for this idea has now been provided by a group of US scientists, who have shown that activation of the mirror neuron system is much reduced in the brains of children with autism. Neuroscientists believe that mirror neurons fire in response to the facial expressions of others, allowing our brains to \u2018mirror\u2019 their actions and so understand their feelings. Mirella Dapretto, who led the research at the University of California, Los Angeles, USA, said, \u201cThe mirroring mechanism may underlie the remarkable ability to read others\u2019 emotional states from a mere glance\u201d (Guardian, 6 December 2005). \u201cOur findings suggest that a dysfunctional mirror neuron system may underlie the social deficits observed in autism. This is exciting because we finally have an account that can explain all core symptoms of this disorder\u201d (Guardian). The researchers observed not only that activation in the brain area containing mirror neurons \u2014 the inferior frontal gyrus pars opercularis \u2014 was reduced in children with autism, but also that the extent of the decrease in activation correlated with the severity of symptoms. Michael Rutter of the Institute of Psychiatry, London, UK, agreed that \u201cThe general notion of linking mirror neurons with the social deficit in autism is quite reasonable\u201d (BBC News Online, 5 December 2005). However, he also observed \u201c...we need more research into the brain systems that might be involved. These might involve mirror neurons, but we need more studies\u201d (BBC News Online). Sarah Archibald R E S E A R C H H I G H L I G H T S", "title": "Mirror image", "claims": ["- The social deficits associated with autism include difficulty communicating and understanding environmental cues, such as facial expression.", "- The neural mechanisms behind autism remain in question.", "- One proposed culprit for the neural mechanisms behind autism is the mirror neuron system, which is thought to be involved in interpreting the emotions of others.", "- A group of US scientists have shown that activation of the mirror neuron system is much reduced in the brains of children with autism.", "- Neuroscientists believe that mirror neurons fire in response to the facial expressions of others, allowing our brains to \u2018mirror\u2019 their actions and so understand their feelings.", "- Mirella Dapretto, who led the research at the University of California, Los Angeles, USA, said, \u201cThe mirroring mechanism may underlie the remarkable ability to read others\u2019 emotional states from a mere glance.\u201d", "- Mirella Dapretto stated, \u201cOur findings suggest that a dysfunctional mirror neuron system may underlie the social deficits observed in autism.\u201d", "- Mirella Dapretto mentioned, \u201cThis is exciting because we finally have an account that can explain all core symptoms of this disorder.\u201d", "- The researchers observed that activation in the brain area containing mirror neurons \u2014 the inferior frontal gyrus pars opercularis \u2014 was reduced in children with autism.", "- The extent of the decrease in activation of the mirror neuron system correlated with the severity of symptoms in children with autism.", "- Michael Rutter of the Institute of Psychiatry, London, UK, agreed that \u201cThe general notion of linking mirror neurons with the social deficit in autism is quite reasonable.\u201d", "- Michael Rutter also observed, \u201c...we need more research into the brain systems that might be involved. These might involve mirror neurons, but we need more studies.\u201d"]}, {"metadata": {"year": 2013}, "authors": ["C. Andrade", "M. Pond\u00e9"], "summary": "The objective of this study was to conduct a systematic review of experimental studies performed to assess the role of mirror neurons in the pathophysiology of autism. Four papers reported that areas of mirror neurons (MN) were under-active in autistic patients, giving weight to the theory of MN as a cause of ASD. Three papers indicated that MN were activated during the proposed activities, advocating atypical activation of MN, but not necessarily hypoactivation of these areas. One of the articles reported that only part of the MN system or just those areas of interconnected neurons are dysfunctional in autism. Analysis of the selected studies showed a correlation between dysfunction of the mirror neuron system and the main symptoms of autism such as deficits in social cognition, complete absence or a reduction in the individual\u2019s interaction with his/her social environment and a failure in the neural mechanisms of imitation.", "title": "A SYSTEMATIC REVIEW OF THE INFLUENCE OF MIRROR NEURONS IN AUTISM SPECTRUM DISORDERS", "claims": ["", "The objective of this study was to conduct a systematic review of experimental studies performed to assess the role of mirror neurons in the pathophysiology of autism.", "Four papers reported that areas of mirror neurons (MN) were under-active in autistic patients.", "The under-activity of mirror neurons in autistic patients gives weight to the theory of MN as a cause of ASD.", "Three papers indicated that mirror neurons were activated during the proposed activities.", "The activation of mirror neurons during the proposed activities advocates atypical activation of MN, but not necessarily hypoactivation of these areas.", "One of the articles reported that only part of the mirror neuron system or just those areas of interconnected neurons are dysfunctional in autism.", "Analysis of the selected studies showed a correlation between dysfunction of the mirror neuron system and the main symptoms of autism.", "The main symptoms of autism include deficits in social cognition.", "The main symptoms of autism include a complete absence or a reduction in the individual\u2019s interaction with his/her social environment.", "The main symptoms of autism include a failure in the neural mechanisms of imitation."]}, {"metadata": {"year": 2009}, "authors": ["Ruth  Raymaekers", "Jan Roelf Wiersema", "Herbert  Roeyers"], "summary": "Individuals with Autism Spectrum Disorder (ASD) are characterised by an impaired imitation, thought to be critical for early affective, social and communicative development. One neurological system proposed to underlie this function is the mirror neuron system (MNS) and previous research has suggested a dysfunctional MNS in ASD. The EEG mu frequency, more precisely the reduction of the mu power, is considered to be an index for mirror neuron functioning. In this work, EEG registrations are used to evaluate the mirror neuron functioning of twenty children with high functioning autism (HFA) between 8 and 13 years. Their mu suppression to self-executed and observed movement is compared to typically developing peers and related to age, intelligence and symptom severity. Both groups show significant mu suppression to both self and observed hand movements. No group differences are found in either condition. These results do not support the hypothesis that HFA is associated with a dysfunctional MNS. The discrepancy with previous research is discussed in light of the heterogeneity of the ASD population.", "title": "EEG study of the mirror neuron system in children with high functioning autism", "claims": ["- Individuals with Autism Spectrum Disorder (ASD) are characterized by an impaired imitation, thought to be critical for early affective, social, and communicative development.", "- One neurological system proposed to underlie the function of imitation is the mirror neuron system (MNS).", "- Previous research has suggested a dysfunctional mirror neuron system (MNS) in individuals with ASD.", "- The EEG mu frequency, more precisely the reduction of the mu power, is considered to be an index for mirror neuron functioning.", "- In this work, EEG registrations are used to evaluate the mirror neuron functioning of twenty children with high functioning autism (HFA) between 8 and 13 years.", "- The mu suppression to self-executed and observed movement of children with HFA is compared to typically developing peers.", "- The mu suppression is related to age, intelligence, and symptom severity.", "- Both groups, children with HFA and typically developing peers, show significant mu suppression to both self and observed hand movements.", "- No group differences are found in either condition of mu suppression.", "- These results do not support the hypothesis that high functioning autism (HFA) is associated with a dysfunctional mirror neuron system (MNS).", "- The discrepancy with previous research is discussed in light of the heterogeneity of the ASD population."]}, {"metadata": {"year": 2006}, "authors": ["Mirella  Dapretto", "Mari S Davies", "Jennifer H Pfeifer", "Ashley A Scott", "Marian  Sigman", "Susan Y Bookheimer", "Marco  Iacoboni"], "summary": "To examine mirror neuron abnormalities in autism, high-functioning children with autism and matched controls underwent fMRI while imitating and observing emotional expressions. Although both groups performed the tasks equally well, children with autism showed no mirror neuron activity in the inferior frontal gyrus (pars opercularis). Notably, activity in this area was inversely related to symptom severity in the social domain, suggesting that a dysfunctional 'mirror neuron system' may underlie the social deficits observed in autism.", "title": "Understanding emotions in others: mirror neuron dysfunction in children with autism spectrum disorders", "claims": ["- High-functioning children with autism and matched controls underwent fMRI while imitating and observing emotional expressions.", "- Both groups performed the tasks equally well.", "- Children with autism showed no mirror neuron activity in the inferior frontal gyrus (pars opercularis).", "- Activity in the inferior frontal gyrus (pars opercularis) was inversely related to symptom severity in the social domain.", "- A dysfunctional 'mirror neuron system' may underlie the social deficits observed in autism."]}, {"metadata": {"year": 2008}, "authors": ["Raphael  Bernier", "Geraldine  Dawson"], "summary": "Autism spectrum disorders are characterized by impairments in the social, communication, and behavioral domains. Impairments in social cognition are considered a core symptom of the disorder. Dysfunction of an observation/execution matching system (the mirror neuron system) has been proposed to serve as a neural mechanism explaining the deficits in social cognition found in autism. Through direct matching of observed and executed behavior an individual can directly experience an internal representation of another\u2019s actions, and therefore, another\u2019s feelings, goals, and intentions. Dysfunction of this system would hinder this process. In this chapter, Bernier and Dawson review findings from behavioral research examining deficits in three areas of social cognition in individuals with autism: imitation, empathy, and theory of mind. They then discuss research implicating mirror neuron dysfunction in autism spectrum disorders; and explore the mirror neuron theory of autism. Autism research utilizing functional and structural brain imaging, electroencephalography, and transcranial magnetic stimulation to study the mirror neuron system is reviewed. Results from these studies suggest dysfunction of the mirror neuron system in both children and adults with autism. The mirror neuron theory of autism proposes that dysfunction of the execution/observation matching system interferes with the acquisition of internal representation of others\u2019 observed behavior, expressions, movements, and emotions. This precludes the individual with autism having an immediate, direct experience of the other through this internal representation. Social impairments, including impairments in imitation, empathy, and theory of mind, are hypothesized to cascade from this lack of immediate, experiential understanding of others in the social world.", "title": "The Role of Mirror Neuron Dysfunction in Autism", "claims": ["- Autism spectrum disorders are characterized by impairments in the social, communication, and behavioral domains.", "- Impairments in social cognition are considered a core symptom of autism spectrum disorders.", "- Dysfunction of an observation/execution matching system (the mirror neuron system) has been proposed to serve as a neural mechanism explaining the deficits in social cognition found in autism.", "- Through direct matching of observed and executed behavior, an individual can directly experience an internal representation of another\u2019s actions, and therefore, another\u2019s feelings, goals, and intentions.", "- Dysfunction of the mirror neuron system would hinder the process of directly experiencing an internal representation of another\u2019s actions, feelings, goals, and intentions.", "- Bernier and Dawson review findings from behavioral research examining deficits in three areas of social cognition in individuals with autism: imitation, empathy, and theory of mind.", "- Research implicates mirror neuron dysfunction in autism spectrum disorders.", "- The mirror neuron theory of autism proposes that dysfunction of the execution/observation matching system interferes with the acquisition of internal representation of others\u2019 observed behavior, expressions, movements, and emotions.", "- Dysfunction of the mirror neuron system precludes the individual with autism from having an immediate, direct experience of the other through internal representation.", "- Social impairments, including impairments in imitation, empathy, and theory of mind, are hypothesized to cascade from the lack of immediate, experiential understanding of others in the social world.", "- Autism research utilizing functional and structural brain imaging, electroencephalography, and transcranial magnetic stimulation to study the mirror neuron system is reviewed.", "- Results from studies suggest dysfunction of the mirror neuron system in both children and adults with autism."]}], "query": "What is the relationship between mirror neurons and autism in children?", "summary_abstract": null, "summary_extract": "The relationship between mirror neurons and autism in children has been a subject of considerable research and debate. Several studies suggest a potential link between the dysfunction of the mirror neuron system and the social and communicative impairments characteristic of autism spectrum disorders (ASD). Pires et al. (2015) and Archibald (2006) propose that the properties of the mirror neuron system are directly correlated with the difficulties in communication and social interaction observed in autism. This is supported by findings from Dapretto et al. (2006), who observed reduced activation in the brain areas containing mirror neurons in children with autism, correlating with the severity of their symptoms.\n\nHowever, the evidence is not entirely consistent. Dixon (2008) and Ruysschaert et al. (2014) challenge the \"broken mirror\" hypothesis, suggesting that impaired neural mirroring is not a distinctive feature of ASD. Their studies found no significant differences in mirror neuron activity between children with autism and typically developing peers during tasks involving imitation and observation of actions. Similarly, Raymaekers et al. (2009) found no group differences in mu suppression, an index for mirror neuron functioning, between children with high-functioning autism and their typically developing peers.\n\nAndrade and Pond\u00e9 (2013) provide a nuanced view, indicating that while some studies report under-activity of mirror neurons in autistic patients, others show atypical activation rather than hypoactivation. This suggests that only parts of the mirror neuron system may be dysfunctional in autism.\n\nOverall, while there is some support for the involvement of mirror neurons in the social deficits of autism, the evidence is mixed, and further research is needed to clarify the extent and nature of this relationship. The complexity of autism suggests that mirror neuron dysfunction may be one of several contributing factors rather than a singular cause (Bernier and Dawson, 2008)."}, {"papers": [{"metadata": {"year": 2021}, "authors": ["Juntao  Shao", "Guilian  Shi", "Zhengqin  Qi", "Jingjing  Zheng", "Shigao  Chen"], "summary": "Ultrasound elastography is a modern imaging technique that has developed rapidly in recent years. It enables objective measurement of tissue stiffness, a physical property intuitive to the human sense of touch. This novel technology has become a hotspot and plays a major role in scientific research and academic practice. Presently, ultrasound elastography has been used in the identification of benign and malignant tumors in superficial organs, such as breast and thyroid, providing clinically accurate diagnosis and treatment. The method has also been widely used for the liver, kidney, prostate, lymph nodes, blood vessels, skin and muscle system. In the application of cervical lesions, ultrasound elastography can distinguish normal cervix from abnormal cervix and differentiate benign from malignant lesions. It can significantly improve the diagnostic specificity for cervical cancer and is also useful for assessing infiltration depth and stage of cervical cancer, as well as predicting chemoradiotherapy treatment response. For cervical evaluation during pregnancy, ultrasound elastography is useful for assessing cervical softening and predicting premature delivery and outcome of induced labor. This article reviews the principles of ultrasound elastography as well as the current status and limitations in its application for cervical lesions and the cervix during pregnancy.", "title": "Advancements in the Application of Ultrasound Elastography in the Cervix.", "claims": ["- Ultrasound elastography is a modern imaging technique that has developed rapidly in recent years.", "- Ultrasound elastography enables objective measurement of tissue stiffness, a physical property intuitive to the human sense of touch.", "- This novel technology has become a hotspot and plays a major role in scientific research and academic practice.", "- Presently, ultrasound elastography has been used in the identification of benign and malignant tumors in superficial organs, such as breast and thyroid, providing clinically accurate diagnosis and treatment.", "- Ultrasound elastography has been widely used for the liver, kidney, prostate, lymph nodes, blood vessels, skin, and muscle system.", "- In the application of cervical lesions, ultrasound elastography can distinguish normal cervix from abnormal cervix and differentiate benign from malignant lesions.", "- Ultrasound elastography can significantly improve the diagnostic specificity for cervical cancer.", "- Ultrasound elastography is useful for assessing infiltration depth and stage of cervical cancer, as well as predicting chemoradiotherapy treatment response.", "- For cervical evaluation during pregnancy, ultrasound elastography is useful for assessing cervical softening and predicting premature delivery and outcome of induced labor."]}, {"metadata": {"year": 2020}, "authors": ["Weiren Liang"], "summary": "Elastography is a new technique for noninvasive evaluation of tissue resistance to external hardness and deformation, which plays an increasingly important role in the diagnosis and differential diagnosis of thyroid, breast, liver, prostate and other organs in recent years.This paper reviews the application progress of elastography in various organs. \n \nKey words: \nUltrasonography;\u00a0Elasticity Imaging techniques;\u00a0Thyroid diseases;\u00a0Breast diseases;\u00a0Liver diseases;\u00a0Prostatism;\u00a0Genital diseases, female;\u00a0Review", "title": "Progress of application of real-time ultrasound elastography in clinical", "claims": ["- Elastography is a new technique for noninvasive evaluation of tissue resistance to external hardness and deformation.", "- Elastography plays an increasingly important role in the diagnosis and differential diagnosis of thyroid, breast, liver, prostate, and other organs in recent years.", "- This paper reviews the application progress of elastography in various organs."]}, {"metadata": {"year": 2017}, "authors": ["S. Phatak", "G. Marfani", "Nipun Gupta"], "summary": "Elasticity Imaging, Elastography, Sonoelastography, ABSTRACT Ultrasonic elastography (real-time elastography, sonoelastography) is a new improvement of ultrasound technique and one of the various imaging modalities in the last few years which are being used for characterizing soft tissue masses of breast, thyroid, and lymph nodes. Musculoskeletal pathology was one of the early applications of sonoelastography, but the method is not yet standardized. Other new horizons of applications include Liver, Prostate, obstetrics and gynaecology. We are presenting a pictorial essay of elastography cases in Obstetrics and gynaecology seen in our institution. Dr. Suresh Phatak Professor and Head of department, Dept. of Radio-diagnosis, Jawaharlal Nehru Medical College, Sawangi (Meghe), Wardha, Maharashtra, India 442001", "title": "ROLE OF STRAIN ELASTOGRAPHY IN OBSTETRICS AND GYNECOLOGY: PICTORIAL ESSAY OF OUR INITIAL EXPERIENCE", "claims": ["- Ultrasonic elastography (real-time elastography, sonoelastography) is a new improvement of ultrasound technique.", "- Ultrasonic elastography is one of the various imaging modalities in the last few years used for characterizing soft tissue masses of breast, thyroid, and lymph nodes.", "- Musculoskeletal pathology was one of the early applications of sonoelastography.", "- The method of sonoelastography is not yet standardized.", "- New horizons of applications for sonoelastography include the liver, prostate, obstetrics, and gynaecology.", "- A pictorial essay of elastography cases in obstetrics and gynaecology seen in the institution is being presented."]}, {"metadata": {"year": 2013}, "authors": ["Liu Qing-qin"], "summary": "Ultrasound elastography is a new technology imaging according to the different elastic coefficient of different tissues,it makes up the shortage of conventional ultrasound,and become a hot research topic in the field of medical imaging. Ultrasound elastography has been widely used in breast diseases,in recent years,reports about other organs increased gradually,such as thyroid,prostate and liver,and shows the growing advantage in the diagnosis and differential diagnosis of various diseases. This paper review the clinical application of ultrasound elastography in these tissues and organs and related development in recent years.", "title": "Research Progress and Clinical Application of Ultrasound Elasticity Imaging Technology", "claims": ["- Ultrasound elastography is a new technology imaging according to the different elastic coefficient of different tissues.", "- Ultrasound elastography makes up the shortage of conventional ultrasound.", "- Ultrasound elastography has become a hot research topic in the field of medical imaging.", "- Ultrasound elastography has been widely used in breast diseases.", "- In recent years, reports about the use of ultrasound elastography in other organs have increased gradually, such as thyroid, prostate, and liver.", "- Ultrasound elastography shows a growing advantage in the diagnosis and differential diagnosis of various diseases.", "- The paper reviews the clinical application of ultrasound elastography in these tissues and organs and related development in recent years."]}, {"metadata": {"year": 2006}, "authors": ["A. Basarab", "E. Royer", "P. Boissieu", "P. Delachartre"], "summary": "The purpose of elastography is to characterize from mechanical point of view a material (the soft biological tissues in the medical field). Ultrasound elastography is based on the comparison of ultrasound images, when the material is submitted under axial force (compression). This work presents the advances in the instrumentation of an ultrasound scanner, to acquire a sequence of images which will be processed in the aim of elastography. First, motion estimation between two or more images is processed. The estimated displacement gives the possibility to obtain detailed deformation elastograms. Thus, the presence of a hard inclusion (that simulates a tumor a pathological tissue) within a phantom mimicking soft tissues can be more easily detected, which may lead to a better cancer diagnosis.", "title": "Advances in Ultrasound Elastography", "claims": ["- The purpose of elastography is to characterize from a mechanical point of view a material, specifically soft biological tissues in the medical field.", "- Ultrasound elastography is based on the comparison of ultrasound images when the material is submitted under axial force (compression).", "- This work presents the advances in the instrumentation of an ultrasound scanner to acquire a sequence of images for the purpose of elastography.", "- Motion estimation between two or more images is processed in the context of elastography.", "- The estimated displacement from motion estimation gives the possibility to obtain detailed deformation elastograms.", "- The presence of a hard inclusion, which simulates a tumor or pathological tissue, within a phantom mimicking soft tissues can be more easily detected using elastography.", "- Easier detection of hard inclusions may lead to a better cancer diagnosis."]}, {"metadata": {"year": 2009}, "authors": ["J. Bonner"], "summary": "Elastography is one of the emerging technologies on display at ECR 2009, reflecting the growing importance of imaging techniques that compare the inherent stiffness of healthy and abnormal tissues in advancing the diagnostic value of ultrasound. Elastography\u2019s clinical applications were discussed at two separate satellite symposia on Saturday and Sunday.", "title": "Emergence of elastography gives renewed impetus and vigor to ultrasound market", "claims": ["- Elastography is one of the emerging technologies on display at ECR 2009.", "- Elastography reflects the growing importance of imaging techniques that compare the inherent stiffness of healthy and abnormal tissues.", "- Imaging techniques that compare the inherent stiffness of healthy and abnormal tissues are advancing the diagnostic value of ultrasound.", "- Elastography\u2019s clinical applications were discussed at two separate satellite symposia on Saturday.", "- Elastography\u2019s clinical applications were discussed at two separate satellite symposia on Sunday."]}, {"metadata": {"year": 2014}, "authors": ["S. Dudea"], "summary": "Definitely, contrast and elastography have been the two words prevailing in the ultrasonography research literature of the last decade. Of these, elastography did cast a special charm over the researchers, due to its ever increasing number of technological approaches. A major role was also played by the adaptability of the method(s) to virtually all applications of ultrasonography and even the opening of novel domains, such as diffuse organ structure assessment. No wonder that dedicated radiologists, mostly breast imaging experts, as well as specialists in gastroenterology, endocrinology, internal medicine etc., were all involved in intensive research and publication. Truly, elastography boosted ultrasound related publications and rapidly expanded the field of knowledge. Recently, solid publications compacted available knowledge into guidelines that represent a stage benchmark. The most notorious are the EFSUMB guidelines on the clinical use of ultrasound elastography [1,2]. So, after a decade of clinical usage, has elastography come to the age of ripening? The answer to this question requires a graded approach. Overall, the answer is, definitely , no. Or, at least, not in all domains. Extensive work and widespread experience allow for expert reviews and statements under the form of guidelines for a specific, well documented application of the technique(s). On the other hand, new, potential applications are under permanent scrutiny. Some of the papers published in this issue of the journal richly substantiate these assertions. The knowledge gathered by four groups in a specific application of elastography-this being liver disease-allows for the work up of national guidelines and recommendations [3]. This ambitious project is justified both by recent technological developments and by the sizeable number of publications of the authors. Even in this field, serendipitous findings may occur [4]. The applications of elastography in the study of the musculoskeletal system and even more superficial structures , such as skin, are surprisingly sparse. Some of the publications in this issue highlight potential applications, although reported results are, insofar, negative [5,6]. So why is elastography angel and demon? It must relate with the way we understand clinical medicine and imaging. Not only does elastography translate information addressing our least developed sense (tact) into coherent data addressing our most evolved sense (sight), but it also provides figures. Therefore, not only do we need to understand and interpret this \" visual tact \" and many physical terms we were not aware of but we must also connect this to the figures provided \u2026", "title": "Has Ultrasound Elastography come to the age of ripening?", "claims": ["- Contrast and elastography have been the two prevailing words in ultrasonography research literature over the last decade.", "- Elastography has charmed researchers due to its increasing number of technological approaches.", "- Elastography is adaptable to virtually all applications of ultrasonography and has opened novel domains, such as diffuse organ structure assessment.", "- Dedicated radiologists, mostly breast imaging experts, as well as specialists in gastroenterology, endocrinology, and internal medicine, have been involved in intensive research and publication on elastography.", "- Elastography has boosted ultrasound-related publications and rapidly expanded the field of knowledge.", "- Solid publications have compacted available knowledge into guidelines that represent a stage benchmark, with the EFSUMB guidelines on the clinical use of ultrasound elastography being the most notorious.", "- After a decade of clinical usage, elastography has not fully matured in all domains.", "- Extensive work and widespread experience allow for expert reviews and statements in the form of guidelines for specific, well-documented applications of elastography.", "- New, potential applications of elastography are under permanent scrutiny.", "- Knowledge gathered by four groups in the application of elastography to liver disease allows for the development of national guidelines and recommendations.", "- The ambitious project of developing national guidelines for elastography in liver disease is justified by recent technological developments and the sizeable number of publications by the authors.", "- Serendipitous findings may occur even in the field of elastography applied to liver disease.", "- Applications of elastography in the study of the musculoskeletal system and more superficial structures, such as skin, are surprisingly sparse.", "- Some publications highlight potential applications of elastography in the musculoskeletal system and skin, although reported results are negative so far.", "- Elastography translates information from our least developed sense (tact) into coherent data for our most evolved sense (sight) and provides figures.", "- Understanding and interpreting elastography requires connecting \"visual tact\" and many physical terms to the figures provided."]}, {"metadata": {"year": 2018}, "authors": ["B. Yasmeen"], "summary": "Abstract not available Northern International Medical College Journal Vol.9(1) July 2017: 243-244", "title": "Elastography-One Step Ahead", "claims": ["I cannot extract claims from the document as the abstract is not available. If you have more information or another section of the document, please provide it, and I will be happy to help."]}], "query": "summary the current advance of elastography in obgyn field in the past 3 months", "summary_abstract": null, "summary_extract": "The recent advancements in elastography within the obstetrics and gynecology (OBGYN) field have been significant, particularly in the application of ultrasound elastography for cervical assessment. Shao et al. (2021) highlight that ultrasound elastography is instrumental in distinguishing between normal and abnormal cervical tissues, as well as differentiating benign from malignant lesions. This technology enhances diagnostic specificity for cervical cancer and is valuable in assessing the infiltration depth and stage of the disease, as well as predicting responses to chemoradiotherapy. Furthermore, elastography is beneficial during pregnancy for evaluating cervical softening, which aids in predicting premature delivery and the outcomes of induced labor (Shao et al., 2021). These advancements underscore the growing importance of elastography in providing more precise and non-invasive diagnostic options in the OBGYN field."}, {"papers": [{"metadata": {"year": 1993}, "authors": ["H. Brink"], "summary": "Validity and reliability are key aspects of all research. Meticulous attention to these two aspects can make the difference between good research and poor research and can help to assure that fellow scientists accept findings as credible and trustworthy. This is particularly vital in qualitative work, where the researcher\u2019s subjectivity can so readily cloud the interpretation of the data, and where research findings are often questioned or viewed with scepticism by the scientific community.", "title": "Validity and reliability in qualitative research.", "claims": ["- Validity and reliability are key aspects of all research.", "- Meticulous attention to validity and reliability can make the difference between good research and poor research.", "- Meticulous attention to validity and reliability can help to assure that fellow scientists accept findings as credible and trustworthy.", "- Ensuring validity and reliability is particularly vital in qualitative work.", "- In qualitative work, the researcher\u2019s subjectivity can readily cloud the interpretation of the data.", "- In qualitative work, research findings are often questioned or viewed with skepticism by the scientific community."]}, {"metadata": {"year": 2020}, "authors": ["Mohamed Ezzat Khamis Amin", "Lotte Stig N\u00f8rgaard", "Afonso M Cavaco", "Matthew J Witry", "Lisa  Hillman", "Alina  Cernasev", "Shane P Desselle"], "summary": "Spurred by the value it can add, the use of qualitative research methods has been steadily growing by social pharmacy researchers around the globe, either separately or as part of mixed methods research projects. Given this increase, it is important to provide guidance to assist researchers in ensuring quality when employing such methods. This commentary addresses both theoretical fundamentals as well as practical aspects of establishing quality in qualitative social pharmacy research. More specifically, it provides an explanation of each of the criteria of trustworthiness proposed by Lincoln and Guba (credibility, transferability, dependability and confirmability) and different techniques used in establishing them. It also provides a brief overview of authenticity, a more recent and less widely used set of criteria that involve demonstrating fairness, ontological authenticity, educative authenticity, catalytic authenticity, and tactical authenticity. For each of these terms, the commentary provides a definition, how it applies to social pharmacy research, and guidance on when and how to use them. These are accompanied by examples from the pharmacy literature where the criteria have been used. The commentary ends by providing a summary of competing viewpoints of establishing quality in the published literature while inviting the reader to reflect on how the presented criteria would apply to different qualitative research projects.", "title": "Establishing trustworthiness and authenticity in qualitative pharmacy research.", "claims": ["- The use of qualitative research methods has been steadily growing among social pharmacy researchers around the globe, either separately or as part of mixed methods research projects.", "- It is important to provide guidance to assist researchers in ensuring quality when employing qualitative research methods.", "- The commentary addresses both theoretical fundamentals and practical aspects of establishing quality in qualitative social pharmacy research.", "- The commentary provides an explanation of each of the criteria of trustworthiness proposed by Lincoln and Guba, which are credibility, transferability, dependability, and confirmability, and different techniques used in establishing them.", "- The commentary provides a brief overview of authenticity, a more recent and less widely used set of criteria that involve demonstrating fairness, ontological authenticity, educative authenticity, catalytic authenticity, and tactical authenticity.", "- For each of the terms related to authenticity, the commentary provides a definition, how it applies to social pharmacy research, and guidance on when and how to use them.", "- The commentary includes examples from the pharmacy literature where the criteria have been used.", "- The commentary ends by providing a summary of competing viewpoints of establishing quality in the published literature.", "- The commentary invites the reader to reflect on how the presented criteria would apply to different qualitative research projects."]}, {"metadata": {"year": 2005}, "authors": ["Susan L. Morrow"], "summary": "This article examines concepts of the trustworthiness, or credibility, of qualitative research. Following a \u201cresearcher-as-instrument,\u201d or self-reflective, statement, the paradigmatic underpinnings of various criteria for judging the quality of qualitative research are explored, setting the stage for a discussion of more transcendent standards (those not associated with specific paradigms) for conducting quality research: social validity, subjectivity and reflexivity, adequacy of data, and adequacy of interpretation. Finally, current guidelines for writing and publishing qualitative research are reviewed, and strategies for conducting and writing qualitative research reports are suggested. Qualitative research, ensuing from a variety of disciplines, paradigms, and epistemologies, embraces multiple standards of quality, known variously as validity, credibility, rigor ,o rtrustworthiness. In addition to some standards that may be thought of as somewhat universal across disciplines and paradigms, the \u201cgoodness\u201d (Morrow & Smith, 2000) of qualitative inquiry is assessed on the basis of the paradigmatic underpinnings of the research and the standards of the discipline. Thus, a grounded theory study or a consensual qualitative research investigation in counseling psychology that is rooted in a postpositivist or constructivist/interpretivist paradigm will look quite different from a critical ethnography in education; and the standards appropriate for evaluating these studies will vary accordingly. I begin this article by addressing the paradigmatic underpinnings of trustworthiness or rigor in qualitative research. Next, I discuss central topics related to trustworthiness or validity that span paradigms and may be thought of as relevant across most research designs. I then provide an overview of guidelines that have been suggested for evaluating qualitative research, particularly in psychology. Finally, I offer recommendations for enhancing the quality of qualitative research in counseling psychology and suggest strategies for writing and publishing. First, however, in keeping with the standard of reflexivity as a way for researchers to inform their audiences about their perspectives as well as to manage their subjectivities, I describe my own assumptions about qualitative research methodology and quality.", "title": "Quality and trustworthiness in qualitative research in counseling psychology.", "claims": ["- The article examines concepts of the trustworthiness, or credibility, of qualitative research.", "- The article includes a \u201cresearcher-as-instrument,\u201d or self-reflective, statement.", "- The paradigmatic underpinnings of various criteria for judging the quality of qualitative research are explored in the article.", "- The article discusses more transcendent standards for conducting quality research, which are not associated with specific paradigms.", "- The transcendent standards discussed include social validity, subjectivity and reflexivity, adequacy of data, and adequacy of interpretation.", "- Current guidelines for writing and publishing qualitative research are reviewed in the article.", "- Strategies for conducting and writing qualitative research reports are suggested in the article.", "- Qualitative research embraces multiple standards of quality, known variously as validity, credibility, rigor, or trustworthiness.", "- The \u201cgoodness\u201d of qualitative inquiry is assessed based on the paradigmatic underpinnings of the research and the standards of the discipline.", "- A grounded theory study or a consensual qualitative research investigation in counseling psychology rooted in a postpositivist or constructivist/interpretivist paradigm will look different from a critical ethnography in education.", "- The standards appropriate for evaluating different qualitative studies will vary accordingly.", "- The article addresses the paradigmatic underpinnings of trustworthiness or rigor in qualitative research.", "- Central topics related to trustworthiness or validity that span paradigms and are relevant across most research designs are discussed.", "- An overview of guidelines suggested for evaluating qualitative research, particularly in psychology, is provided.", "- Recommendations for enhancing the quality of qualitative research in counseling psychology are offered.", "- Strategies for writing and publishing qualitative research are suggested.", "- The standard of reflexivity is used as a way for researchers to inform their audiences about their perspectives and manage their subjectivities.", "- The author describes their own assumptions about qualitative research methodology and quality."]}, {"metadata": {"year": 1999}, "authors": ["J. Cutcliffe", "H. McKenna"], "summary": "Qualitative research is increasingly recognized and valued and its unique place in nursing research is highlighted by many. Despite this, some nurse researchers continue to raise epistemological issues about the problems of objectivity and the validity of qualitative research findings. This paper explores the issues relating to the representativeness or credibility of qualitative research findings. It therefore critiques the existing distinct philosophical and methodological positions concerning the trustworthiness of qualitative research findings, which are described as follows: quantitative studies should be judged using the same criteria and terminology as quantitative studies; it is impossible, in a meaningful way, for any criteria to be used to judge qualitative studies; qualitative studies should be judged using criteria that are developed for and fit the qualitative paradigm; and the credibility of qualitative research findings could be established by testing out the emerging theory by means of conducting a deductive quantitative study. The authors conclude by providing some guidelines for establishing the credibility of qualitative research findings.", "title": "Establishing the credibility of qualitative research findings: the plot thickens.", "claims": ["", "Qualitative research is increasingly recognized and valued.", "Qualitative research has a unique place in nursing research.", "Some nurse researchers continue to raise epistemological issues about the problems of objectivity and the validity of qualitative research findings.", "The paper explores issues relating to the representativeness or credibility of qualitative research findings.", "The paper critiques existing distinct philosophical and methodological positions concerning the trustworthiness of qualitative research findings.", "One position is that qualitative studies should be judged using the same criteria and terminology as quantitative studies.", "Another position is that it is impossible, in a meaningful way, for any criteria to be used to judge qualitative studies.", "A further position is that qualitative studies should be judged using criteria that are developed for and fit the qualitative paradigm.", "The credibility of qualitative research findings could be established by testing out the emerging theory by means of conducting a deductive quantitative study.", "The authors provide some guidelines for establishing the credibility of qualitative research findings."]}, {"metadata": {"year": 2010}, "authors": ["Marja Soila-Wadman"], "summary": "The journal is quite a new, international publication, with interests in arts, aesthetics and cultural matters. In this field there have been a lot of creative discussions going on concerning the research methodology. When we authors previously were working with the structure of the article, our belief, at the end of the 2000, was that the scientific status of qualitative research is widely accepted? That the basic arguments concerning the credibility of research would not be required in a specific article in journals which are familiar with qualitative research, and have published research reports where the studies have been conducted by", "title": "The Question of Credibility in Qualitative Research - Once again!", "claims": ["- The journal is quite a new, international publication with interests in arts, aesthetics, and cultural matters.", "- In the field of arts, aesthetics, and cultural matters, there have been a lot of creative discussions concerning the research methodology.", "- When the authors were previously working with the structure of the article, their belief at the end of the 2000s was that the scientific status of qualitative research is widely accepted.", "- The authors believed that the basic arguments concerning the credibility of research would not be required in a specific article in journals familiar with qualitative research.", "- The authors believed that journals familiar with qualitative research have published research reports where the studies have been conducted."]}, {"metadata": {"year": 1993}, "authors": ["Cheryl Tatano Beck"], "summary": "The three criteria of credibility, fittingness, and auditability have been focused on in the hope of facilitating the critique of qualitative research. Once criteria that are appropriate to qualitative methodologies are developed, the scientific merit of these research studies can truly be appreciated. If traditional scientific criteria relevant to quantitative studies are used to critique qualitative methods, the development and acceptance of this paradigm-transcending research will be hindered.", "title": "Qualitative Research: The Evaluation of Its Credibility, Fittingness, and Auditability", "claims": ["- The three criteria of credibility, fittingness, and auditability have been focused on in the hope of facilitating the critique of qualitative research.", "- Once criteria that are appropriate to qualitative methodologies are developed, the scientific merit of these research studies can truly be appreciated.", "- If traditional scientific criteria relevant to quantitative studies are used to critique qualitative methods, the development and acceptance of this paradigm-transcending research will be hindered."]}, {"metadata": {"year": 2008}, "authors": ["W. Kline"], "summary": "The standards used to evaluate qualitative research have been a recurring theme in qualitative research literature for more than 20 years. Included in the discussion of these standards are the qualities of trustworthiness (Y. Lincoln & E. Guba, 1985). More recently, methodological and analytic rigor and coherence have also been emphasized (e.g., M. Poggenpoel & C. P. H. Myburgh, 2005). These factors are discussed and conceptualized as presentational rigor. Implications of presentational rigor for designing and conducting qualitative research and preparing manuscripts that are more likely to be published in Counselor Education and Supervision are discussed.", "title": "Developing and Submitting Credible Qualitative Manuscripts", "claims": ["", "The standards used to evaluate qualitative research have been a recurring theme in qualitative research literature for more than 20 years.", "Included in the discussion of these standards are the qualities of trustworthiness (Y. Lincoln & E. Guba, 1985).", "More recently, methodological and analytic rigor and coherence have also been emphasized (e.g., M. Poggenpoel & C. P. H. Myburgh, 2005).", "These factors are discussed and conceptualized as presentational rigor.", "Implications of presentational rigor for designing and conducting qualitative research and preparing manuscripts that are more likely to be published in Counselor Education and Supervision are discussed."]}, {"metadata": {"year": 2016}, "authors": ["Susan Johnson", "Saltanat Rasulova"], "summary": ": Recent developments in impact evaluation recognise the need to go beyond the intense debate over experimental techniques to incorporate theory-based approaches and qualitative research methods. Motivated by an underlying concern that qualitative research in this new wave of qualitative impact evaluation research is appropriately conducted, this paper reviews practical strategies to address rigour deploying Guba and Lincoln\u2019s principles of \u201ctrustworthiness\u201d to do so. In particular we focus on the less discussed principle of \u2018authenticity\u2019 which responds to the demand for research orientations to be more transformative and emancipatory. In development impact evaluation, recent discussion has highlighted the frequent deficit of a transformative orientation and the problematic wider organisational contexts of aid relationships in which commissioned evaluations are conducted. We argue that embracing the authenticity principle offers commissioned researchers with a progressive orientation a rationale for making space for stakeholder interaction and negotiation within the rigour discourse. This in turn creates the scope to incorporate it into checklists of rigour so using the \u2018artefacts\u2019 of evaluation as a means to call commissioning organisations and other stakeholders to be more responsive to concerns for authenticity.", "title": "Qualitative impact evaluation: Incorporating authenticity into the assessment of rigour", "claims": ["- Recent developments in impact evaluation recognize the need to go beyond the intense debate over experimental techniques to incorporate theory-based approaches and qualitative research methods.", "- There is an underlying concern that qualitative research in this new wave of qualitative impact evaluation research is appropriately conducted.", "- This paper reviews practical strategies to address rigour deploying Guba and Lincoln\u2019s principles of \u201ctrustworthiness\u201d to do so.", "- The paper focuses on the less discussed principle of \u2018authenticity\u2019 which responds to the demand for research orientations to be more transformative and emancipatory.", "- In development impact evaluation, recent discussion has highlighted the frequent deficit of a transformative orientation.", "- There is a problematic wider organisational context of aid relationships in which commissioned evaluations are conducted.", "- Embracing the authenticity principle offers commissioned researchers with a progressive orientation a rationale for making space for stakeholder interaction and negotiation within the rigour discourse.", "- Incorporating the authenticity principle into checklists of rigour creates the scope to use the \u2018artefacts\u2019 of evaluation as a means to call commissioning organisations and other stakeholders to be more responsive to concerns for authenticity."]}], "query": "Write about authenticity and credibility when conducting qualitative research.", "summary_abstract": null, "summary_extract": "The exploration of authenticity and credibility in qualitative research is a multifaceted endeavor that involves various criteria and standards to ensure the trustworthiness of findings. Brink (1993) emphasizes the importance of validity and reliability, noting that meticulous attention to these aspects is crucial in qualitative research to ensure that findings are credible and trustworthy. This is particularly vital given the potential for researcher subjectivity to cloud data interpretation, which can lead to skepticism from the scientific community.\n\nAmin et al. (2020) expand on this by discussing the criteria of trustworthiness proposed by Lincoln and Guba, which include credibility, transferability, dependability, and confirmability. They also introduce the concept of authenticity, which involves demonstrating fairness and various forms of authenticity such as ontological and catalytic. This commentary provides guidance on applying these criteria in social pharmacy research, highlighting the importance of both theoretical and practical aspects in establishing quality.\n\nMorrow (2005) further explores the paradigmatic underpinnings of trustworthiness and credibility, suggesting that qualitative research embraces multiple standards of quality, such as validity, rigor, and trustworthiness. The article discusses transcendent standards like social validity and reflexivity, which are crucial for managing subjectivities and informing audiences about researchers' perspectives.\n\nCutcliffe and McKenna (1999) critique the philosophical and methodological positions concerning the trustworthiness of qualitative research, suggesting that qualitative studies should be judged using criteria developed specifically for the qualitative paradigm. They provide guidelines for establishing credibility, acknowledging the unique challenges faced by qualitative research in maintaining objectivity and validity.\n\nBeck (1993) argues that using traditional scientific criteria from quantitative studies to critique qualitative methods can hinder the development and acceptance of qualitative research. Instead, criteria appropriate to qualitative methodologies should be developed to truly appreciate the scientific merit of these studies.\n\nJohnson and Rasulova (2016) highlight the principle of authenticity in impact evaluation, advocating for a transformative and emancipatory research orientation. They suggest that incorporating authenticity into the rigour discourse allows for greater stakeholder interaction and responsiveness, thus enhancing the credibility and transformative potential of qualitative research.\n\nCollectively, these claims underscore the complexity and necessity of establishing authenticity and credibility in qualitative research, advocating for criteria and standards that are tailored to the unique nature of qualitative inquiry."}, {"papers": [{"metadata": {"year": 2015}, "authors": ["Daniel H. Kwak"], "summary": "Microbial secondary metabolites are physiologically significant, exhibiting auxiliary functions for the producer and as scaffolds in the developments of new medicines. Advancements in genome sequencing technologies have enabled researchers to access unprecedented amounts of genomic data that can be used to discover the enzymatic machinery necessary to discover novel and biologically-active molecules. This approach has been termed \u201cgenome mining.\u201d In both of the investigations presented herein, genome mining was utilized to discover and characterize biosynthetic pathways of novel molecules. The findings in one study utilize this approach to discover a small molecule virulence factor from the opportunistic human pathogen Acinetobacter baumannii. This virulence factor has been found to be associated with a number of clinically significant phenotypes, and these findings suggest that this can be a target in the developments of next generation antibiotics. In another study, this approach was implemented to discover and characterize the biosynthetic pathway of anticancer compound hapalosin from the cyanobacterial species Hapalosiphon welwitschii. Cloning and expression of this biosynthetic pathway in the surrogate host Escherichia coli enabled its genetic characterization as well as the generation of a small combinatorial library consisting of analogs incorporating natural and unnatural substrates. Collectively, these investigations demonstrate the utility of genome mining to characterize novel molecules important in pathogenesis or in the biosynthesis of clinically-significant compounds.", "title": "MS Thesis (ETD) Dan Kwak", "claims": ["", "Microbial secondary metabolites are physiologically significant, exhibiting auxiliary functions for the producer and as scaffolds in the developments of new medicines.", "Advancements in genome sequencing technologies have enabled researchers to access unprecedented amounts of genomic data that can be used to discover the enzymatic machinery necessary to discover novel and biologically-active molecules.", "The approach of using genome sequencing technologies to discover novel and biologically-active molecules has been termed \u201cgenome mining.\u201d", "In both of the investigations presented, genome mining was utilized to discover and characterize biosynthetic pathways of novel molecules.", "One study utilized genome mining to discover a small molecule virulence factor from the opportunistic human pathogen Acinetobacter baumannii.", "The virulence factor discovered from Acinetobacter baumannii has been found to be associated with a number of clinically significant phenotypes.", "The findings suggest that the virulence factor from Acinetobacter baumannii can be a target in the development of next-generation antibiotics.", "Another study implemented genome mining to discover and characterize the biosynthetic pathway of the anticancer compound hapalosin from the cyanobacterial species Hapalosiphon welwitschii.", "Cloning and expression of the biosynthetic pathway of hapalosin in the surrogate host Escherichia coli enabled its genetic characterization.", "Cloning and expression of the biosynthetic pathway of hapalosin in Escherichia coli enabled the generation of a small combinatorial library consisting of analogs incorporating natural and unnatural substrates.", "Collectively, these investigations demonstrate the utility of genome mining to characterize novel molecules important in pathogenesis or in the biosynthesis of clinically-significant compounds."]}, {"metadata": {"year": 2016}, "authors": ["N. Ziemert", "T. Weber"], "summary": "The computational mining of genomes has become an important part in the discovery of novel natural products as drug leads. Thousands of bacterial genome sequences are publically available these days containing an even larger number and diversity of secondary metabolite gene clusters that await linkage to their encoded natural products. With the development of high-throughput sequencing methods and the wealth of DNA data available, a variety of genome mining methods and tools have been developed to guide discovery and characterisation of these compounds. This article reviews the development of these computational approaches during the last decade and shows how the revolution of next generation sequencing methods has led to an evolution of various genome mining approaches, techniques and tools. After a short introduction and brief overview of important milestones, this article will focus on the different approaches of mining genomes for secondary metabolites, from detecting biosynthetic genes to resistance based methods and \u201cevo-mining\u201d strategies including a short evaluation of the impact of the development of genome mining methods and tools on the field of natural products and microbial ecology.", "title": "genome mining in microbes \u2013 a review", "claims": ["- The computational mining of genomes has become an important part in the discovery of novel natural products as drug leads.", "- Thousands of bacterial genome sequences are publicly available these days.", "- These sequences contain an even larger number and diversity of secondary metabolite gene clusters that await linkage to their encoded natural products.", "- With the development of high-throughput sequencing methods and the wealth of DNA data available, a variety of genome mining methods and tools have been developed to guide discovery and characterization of these compounds.", "- This article reviews the development of these computational approaches during the last decade.", "- The revolution of next generation sequencing methods has led to an evolution of various genome mining approaches, techniques, and tools.", "- The article will focus on the different approaches of mining genomes for secondary metabolites, from detecting biosynthetic genes to resistance-based methods and \u201cevo-mining\u201d strategies.", "- The article includes a short evaluation of the impact of the development of genome mining methods and tools on the field of natural products and microbial ecology."]}, {"metadata": {"year": 2016}, "authors": ["N. Ziemert", "Mohammad Alanjary", "T. Weber"], "summary": "Covering: 2006 to 2016The computational mining of genomes has become an important part in the discovery of novel natural products as drug leads. Thousands of bacterial genome sequences are publically available these days containing an even larger number and diversity of secondary metabolite gene clusters that await linkage to their encoded natural products. With the development of high-throughput sequencing methods and the wealth of DNA data available, a variety of genome mining methods and tools have been developed to guide discovery and characterisation of these compounds. This article reviews the development of these computational approaches during the last decade and shows how the revolution of next generation sequencing methods has led to an evolution of various genome mining approaches, techniques and tools. After a short introduction and brief overview of important milestones, this article will focus on the different approaches of mining genomes for secondary metabolites, from detecting biosynthetic genes to resistance based methods and \"evo-mining\" strategies including a short evaluation of the impact of the development of genome mining methods and tools on the field of natural products and microbial ecology.", "title": "The evolution of genome mining in microbes - a review.", "claims": ["", "The computational mining of genomes has become an important part in the discovery of novel natural products as drug leads.", "Thousands of bacterial genome sequences are publicly available these days.", "These bacterial genome sequences contain an even larger number and diversity of secondary metabolite gene clusters that await linkage to their encoded natural products.", "With the development of high-throughput sequencing methods and the wealth of DNA data available, a variety of genome mining methods and tools have been developed to guide discovery and characterization of these compounds.", "The article reviews the development of computational approaches for genome mining during the last decade.", "The revolution of next generation sequencing methods has led to an evolution of various genome mining approaches, techniques, and tools.", "The article will focus on different approaches of mining genomes for secondary metabolites, from detecting biosynthetic genes to resistance-based methods and \"evo-mining\" strategies.", "The article includes a short evaluation of the impact of the development of genome mining methods and tools on the field of natural products and microbial ecology."]}, {"metadata": {"year": 2018}, "authors": ["Bikash  Baral", "Amir  Akhgari", "Mikko  Mets\u00e4-Ketel\u00e4"], "summary": "Microbial natural products are a tremendous source of new bioactive chemical entities for drug discovery. Next generation sequencing has revealed an unprecedented genomic potential for production of secondary metabolites by diverse micro-organisms found in the environment and in the microbiota. Genome mining has further led to the discovery of numerous uncharacterized \u2018cryptic\u2019 metabolic pathways in the classical producers of natural products such as Actinobacteria and fungi. These biosynthetic gene clusters may code for improved biologically active metabolites, but harnessing the full genetic potential has been hindered by the observation that many of the pathways are \u2018silent\u2019 under laboratory conditions. Here we provide an overview of the various biotechnological methodologies, which can be divided to pleiotropic, biosynthetic gene cluster specific, and targeted genome-wide approaches that have been developed for the awakening of microbial secondary metabolic pathways.", "title": "Activation of microbial secondary metabolic pathways: Avenues and challenges", "claims": ["- Microbial natural products are a tremendous source of new bioactive chemical entities for drug discovery.", "- Next generation sequencing has revealed an unprecedented genomic potential for production of secondary metabolites by diverse micro-organisms found in the environment and in the microbiota.", "- Genome mining has further led to the discovery of numerous uncharacterized \u2018cryptic\u2019 metabolic pathways in the classical producers of natural products such as Actinobacteria and fungi.", "- These biosynthetic gene clusters may code for improved biologically active metabolites.", "- Harnessing the full genetic potential has been hindered by the observation that many of the pathways are \u2018silent\u2019 under laboratory conditions.", "- Various biotechnological methodologies have been developed for the awakening of microbial secondary metabolic pathways.", "- The biotechnological methodologies can be divided into pleiotropic, biosynthetic gene cluster specific, and targeted genome-wide approaches."]}, {"metadata": {"year": 2020}, "authors": ["K. Hong", "Changsheng Zhang", "A. Dobson"], "summary": "Bioinformatic tools and their application in genome mining for secondary metabolites Genome mining approaches for the identification of novel secondary metabolites Merging ecology (physical, chemical factors or co-culture) with microbial genome mining for secondary metabolites\u2019 discovery Heterologous systems for the expression of gene clusters to identify novel metabolites Unlocking cryptic pathways, employing genomic based approaches Cutting-edge technology in genome editing and novel metabolites identification", "title": "Genome Mining and Marine Microbial Natural Products", "claims": ["- Bioinformatic tools are used in genome mining for secondary metabolites.", "- Genome mining approaches are employed for the identification of novel secondary metabolites.", "- Merging ecology, which includes physical and chemical factors or co-culture, with microbial genome mining is used for secondary metabolites\u2019 discovery.", "- Heterologous systems are used for the expression of gene clusters to identify novel metabolites.", "- Genomic-based approaches are employed to unlock cryptic pathways.", "- Cutting-edge technology is used in genome editing and novel metabolites identification."]}, {"metadata": {"year": 2013}, "authors": ["Anne\u2010Catrin Letzel", "S. Pidot", "C. Hertweck"], "summary": "A total of 211 complete and published genomes from anaerobic bacteria are analysed for the presence of secondary metabolite biosynthesis gene clusters, in particular those tentatively coding for polyketide synthases (PKS) and non-ribosomal peptide synthetases (NRPS). We investigate the distribution of these gene clusters according to bacterial phylogeny and, if known, correlate these to the type of metabolic pathways they encode. The potential of anaerobes as secondary metabolite producers is highlighted.", "title": "A genomic approach to the cryptic secondary metabolome of the anaerobic world.", "claims": ["- A total of 211 complete and published genomes from anaerobic bacteria are analysed for the presence of secondary metabolite biosynthesis gene clusters.", "- The analysis focuses on gene clusters tentatively coding for polyketide synthases (PKS) and non-ribosomal peptide synthetases (NRPS).", "- The distribution of these gene clusters is investigated according to bacterial phylogeny.", "- If known, the distribution of these gene clusters is correlated to the type of metabolic pathways they encode.", "- The potential of anaerobes as secondary metabolite producers is highlighted."]}, {"metadata": {"year": 2012}, "authors": ["Quoc-Thai  Nguyen", "Maria E.  Merlo", "Marnix H.  Medema", "Andris  Jankevics", "Rainer  Breitling", "Eriko  Takano"], "summary": "Many microbial secondary metabolites are of high biotechnological value for medicine, agriculture, and the food industry. Bacterial genome mining has revealed numerous novel secondary metabolite biosynthetic gene clusters, which encode the potential to synthesize a large diversity of compounds that have never been observed before. The stimulation or \u201cawakening\u201d of this cryptic microbial secondary metabolism has naturally attracted the attention of synthetic microbiologists, who exploit recent advances in DNA sequencing and synthesis to achieve unprecedented control over metabolic pathways. One of the indispensable tools in the synthetic biology toolbox is metabolomics, the global quantification of small biomolecules. This review illustrates the pivotal role of metabolomics for the synthetic microbiology of secondary metabolism, including its crucial role in novel compound discovery in microbes, the examination of side products of engineered metabolic pathways, as well as the identification of major bottlenecks for the overproduction of compounds of interest, especially in combination with metabolic modeling. We conclude by highlighting remaining challenges and recent technological advances that will drive metabolomics towards fulfilling its potential as a cornerstone technology of synthetic microbiology.", "title": "Metabolomics methods for the synthetic biology of secondary metabolism", "claims": ["", "Many microbial secondary metabolites are of high biotechnological value for medicine, agriculture, and the food industry.", "Bacterial genome mining has revealed numerous novel secondary metabolite biosynthetic gene clusters.", "These gene clusters encode the potential to synthesize a large diversity of compounds that have never been observed before.", "The stimulation or \u201cawakening\u201d of cryptic microbial secondary metabolism has naturally attracted the attention of synthetic microbiologists.", "Synthetic microbiologists exploit recent advances in DNA sequencing and synthesis to achieve unprecedented control over metabolic pathways.", "One of the indispensable tools in the synthetic biology toolbox is metabolomics, the global quantification of small biomolecules.", "Metabolomics plays a pivotal role in the synthetic microbiology of secondary metabolism.", "Metabolomics is crucial for novel compound discovery in microbes.", "Metabolomics is important for the examination of side products of engineered metabolic pathways.", "Metabolomics aids in the identification of major bottlenecks for the overproduction of compounds of interest, especially in combination with metabolic modeling.", "There are remaining challenges and recent technological advances that will drive metabolomics towards fulfilling its potential as a cornerstone technology of synthetic microbiology."]}, {"metadata": {"year": 2013}, "authors": ["J. Nov\u00e1kov\u00e1", "M. Farka\u0161ovsk\u00fd"], "summary": "Mining of natural sources for new secondary metabolites has a successful history, which is reflected by the fact that over 50% of all drugs, currently on the market, are derived from natural products. Bacteria are one of the most important sources of bioactive natural products destined for drug discovery. However, less than 1% of the microorganisms observed in different habitats have been cultivated and characterized. To explore the genomic and functional diversity of the vast majority of the microbial world, novel methods were introduced, which are based on analysis of a DNA isolated from environmental communities. Metagenomics represents a strategy offering access to the genetic information present in uncultured bacteria by screening of libraries constructed from DNA isolated from different habitats. Functional- and sequence-driven screens are the major approaches employed to mine metagenomic libraries. This review aims to highlight discoveries in this area and discusses the possible future directions of the field.", "title": "Bioprospecting microbial metagenome for natural products", "claims": ["", "Mining of natural sources for new secondary metabolites has a successful history.", "Over 50% of all drugs currently on the market are derived from natural products.", "Bacteria are one of the most important sources of bioactive natural products destined for drug discovery.", "Less than 1% of the microorganisms observed in different habitats have been cultivated and characterized.", "Novel methods were introduced to explore the genomic and functional diversity of the vast majority of the microbial world, which are based on analysis of DNA isolated from environmental communities.", "Metagenomics represents a strategy offering access to the genetic information present in uncultured bacteria by screening of libraries constructed from DNA isolated from different habitats.", "Functional- and sequence-driven screens are the major approaches employed to mine metagenomic libraries."]}], "query": "Genome mining for bioactive secondary metabolites from microbes", "summary_abstract": null, "summary_extract": "The exploration of microbial genomes for bioactive secondary metabolites has emerged as a pivotal strategy in drug discovery and biotechnology. This approach, known as genome mining, leverages advancements in genome sequencing technologies to uncover novel and biologically active compounds (Kwak, 2015). The computational mining of genomes has become integral to identifying new natural products that serve as potential drug leads, facilitated by the availability of thousands of bacterial genome sequences and the development of high-throughput sequencing methods (Ziemert & Weber, 2016; Ziemert et al., 2016). These sequences harbor a vast diversity of secondary metabolite gene clusters, many of which remain uncharacterized and hold the promise of novel bioactive compounds (Baral et al., 2018; Nguyen et al., 2012).\n\nGenome mining has revealed numerous cryptic metabolic pathways, particularly in classical producers like Actinobacteria and fungi, which may code for improved biologically active metabolites (Baral et al., 2018). However, the full genetic potential is often hindered by 'silent' pathways under laboratory conditions, prompting the development of biotechnological methodologies to activate these pathways (Baral et al., 2018). Additionally, bioinformatic tools and heterologous systems are employed to express gene clusters and identify novel metabolites, further enhancing the discovery process (Hong et al., 2020).\n\nThe integration of metabolomics with genome mining has also been highlighted as a crucial component in the synthetic biology of secondary metabolism, aiding in the discovery of novel compounds and the examination of engineered metabolic pathways (Nguyen et al., 2012). This comprehensive approach underscores the significant role of genome mining in unlocking the potential of microbial secondary metabolites for therapeutic and industrial applications."}, {"papers": [{"metadata": {"year": 2019}, "authors": ["Charlie Kurth"], "summary": "According to psychological constructivism, emotions result from projecting folk emotion concepts onto felt affective episodes. While constructivists acknowledge there is a biological dimension to emotion, they deny that emotions are (or involve) affect programs. So they also deny emotions are natural kinds. However, the essential role that constructivism gives to felt experience and folk concepts leads to an account that is extensionally inadequate and functionally inaccurate. Moreover, biologically oriented proposals that reject these commitments are not similarly encumbered. Recognizing this has two implications: biological mechanisms are more central to emotion than constructivism allows, and the conclusion that emotions are not natural kinds is premature.", "title": "Are Emotions Psychological Constructions?", "claims": ["- According to psychological constructivism, emotions result from projecting folk emotion concepts onto felt affective episodes.", "- Constructivists acknowledge there is a biological dimension to emotion.", "- Constructivists deny that emotions are (or involve) affect programs.", "- Constructivists deny emotions are natural kinds.", "- The essential role that constructivism gives to felt experience and folk concepts leads to an account that is extensionally inadequate and functionally inaccurate.", "- Biologically oriented proposals that reject the commitments of constructivism are not similarly encumbered.", "- Recognizing the limitations of constructivism has two implications: biological mechanisms are more central to emotion than constructivism allows, and the conclusion that emotions are not natural kinds is premature."]}, {"metadata": {"year": 2020}, "authors": ["Iris  Berent", "Lisa  Feldman Barrett", "Melanie  Platt"], "summary": "A large literature debates whether emotions are universal and innate. Here, we ask whether reasoning about such matters is shaped by intuitive Essentialist biases that link innateness to the material body. To gauge the perception of innateness, we asked laypeople to evaluate whether emotion categories will be recognized spontaneously by hunter\u2013gatherers who have had no contact with Westerners. Experiment 1 shows that participants believe that emotions are innate and embodied (facially and internally) and these two properties correlate reliably. Experiment 2 demonstrates that the link is causal. When told that emotions are localized in specific brain areas (i.e., embodied), participants concluded that emotions are innate. Experiment 3 shows that this na\u00efve view persists even when participants are explicitly informed that these emotions are acquired. Our results are the first to suggest that laypeople incorrectly believe that, if emotions are embodied, then they must be innate. We suggest that people\u2019s failure to grasp the workings of their psyche arises from the human psyche itself.", "title": "Essentialist Biases in Reasoning About Emotions", "claims": ["", "A large literature debates whether emotions are universal and innate.", "Reasoning about emotions may be shaped by intuitive Essentialist biases that link innateness to the material body.", "To gauge the perception of innateness, laypeople were asked to evaluate whether emotion categories will be recognized spontaneously by hunter\u2013gatherers who have had no contact with Westerners.", "Experiment 1 shows that participants believe that emotions are innate and embodied (facially and internally).", "In Experiment 1, the belief that emotions are innate and embodied correlates reliably.", "Experiment 2 demonstrates that the link between emotions being embodied and innate is causal.", "In Experiment 2, when participants were told that emotions are localized in specific brain areas (i.e., embodied), they concluded that emotions are innate.", "Experiment 3 shows that the na\u00efve view that emotions are innate persists even when participants are explicitly informed that these emotions are acquired.", "The results are the first to suggest that laypeople incorrectly believe that, if emotions are embodied, then they must be innate.", "The failure of people to grasp the workings of their psyche arises from the human psyche itself."]}, {"metadata": {"year": 2019}, "authors": ["I. Berent", "L. F. Barrett", "Melanie Platt"], "summary": "A large literature debates whether emotions are universal and innate. Here, we ask whether reasoning about such matters is shaped by intuitive Essentialist biases that link innateness to the material body. To gauge the perception of innateness, we asked laypeople to evaluate whether emotion categories will be recognized spontaneously by hunter\u2013gatherers who have had no contact with Westerners. Experiment 1 shows that participants believe that emotions are innate and embodied (facially and internally) and these two properties correlate reliably. Experiment 2 demonstrates that the link is causal. When told that emotions are localized in specific brain areas (i.e., embodied), participants concluded that emotions are innate. Experiment 3 shows that this na\u00efve view persists even when participants are explicitly informed that these emotions are acquired. Our results are the first to suggest that laypeople incorrectly believe that, if emotions are embodied, then they must be innate. We suggest that people\u2019s failure to grasp the workings of their psyche arises from the human psyche itself.", "title": "Essentialist Biases in Reasoning About Emotions", "claims": ["", "A large literature debates whether emotions are universal and innate.", "The document asks whether reasoning about emotions is shaped by intuitive Essentialist biases that link innateness to the material body.", "To gauge the perception of innateness, laypeople were asked to evaluate whether emotion categories will be recognized spontaneously by hunter\u2013gatherers who have had no contact with Westerners.", "Experiment 1 shows that participants believe that emotions are innate and embodied (facially and internally).", "In Experiment 1, the belief that emotions are innate and embodied correlates reliably.", "Experiment 2 demonstrates that the link between emotions being embodied and innate is causal.", "In Experiment 2, when participants were told that emotions are localized in specific brain areas (i.e., embodied), they concluded that emotions are innate.", "Experiment 3 shows that the na\u00efve view that emotions are innate persists even when participants are explicitly informed that these emotions are acquired.", "The results are the first to suggest that laypeople incorrectly believe that, if emotions are embodied, then they must be innate.", "The document suggests that people\u2019s failure to grasp the workings of their psyche arises from the human psyche itself."]}, {"metadata": {"year": 1990}, "authors": ["M. Mascolo", "J. Mancuso"], "summary": "Abstract The theory of emotions outlined in this paper follows a general theory that psychological processes maintain an adaptive equilibrium between one's construction system and sensory input from one's world. Persons build constructions to match any class of sensory data, and also build standards for (construe) varied levels of input which accompany the arousal-related activity associated with standard/input mismatch. Conscious identification of different emotional states reflects the use of constructions assigned to different standard/input relations. A constructivist may regard different emotional states or experiences as idealized configurations of attributes; and these configurations can be treated as prototypes, applying the same analyses which have been developed by cognitive scientists who have offered models for discussions of categorization processes. A model for discussing emotional development is provided, and directions of future constructivist investigations are suggested", "title": "Functioning of Epigenetically Evolved Emotion Systems: A Constructive Analysis", "claims": ["", "- The theory of emotions outlined in this paper follows a general theory that psychological processes maintain an adaptive equilibrium between one's construction system and sensory input from one's world.", "- Persons build constructions to match any class of sensory data.", "- Persons also build standards for (construe) varied levels of input which accompany the arousal-related activity associated with standard/input mismatch.", "- Conscious identification of different emotional states reflects the use of constructions assigned to different standard/input relations.", "- A constructivist may regard different emotional states or experiences as idealized configurations of attributes.", "- These configurations can be treated as prototypes, applying the same analyses which have been developed by cognitive scientists who have offered models for discussions of categorization processes.", "- A model for discussing emotional development is provided.", "- Directions of future constructivist investigations are suggested."]}, {"metadata": {"year": 2020}, "authors": ["I. Berent"], "summary": "Can you tell what a stranger feels just by looking at their face? Could you distinguish fear from anger even in a person from an entirely unfamiliar culture (without having the opportunity to learn about it from experience)? Laypeople assume they can, because they believe that emotions are inborn, and they are universally imprinted on the body, both externally, on the face, and internally (I sense anxiety in the rumbling of my gut). In fact, people believe that emotions are innate precisely because they believe that emotions are \u201cin the body.\u201d So strong is their conviction that they will insist on their belief even when told that the emotions in question are in fact acquired. Our tendency to view \u201cwarm\u201d feelings as embodied and innate is the exact mirror image of our tendency to view \u201ccold\u201d concepts as ephemeral and disembodied. A review of the scientific literature reveals that similar presumptions also plague the debate on universal emotions in affective science. Chapter 10 shows how Essentialism (a principle invoked to explain our aversion to innate ideas) also promotes the promiscuous presumption of innate emotions by laypeople and scientists alike.", "title": "Our Big Hearts", "claims": ["", "Laypeople assume they can distinguish emotions like fear from anger in a person from an entirely unfamiliar culture just by looking at their face.", "Laypeople believe that emotions are inborn and universally imprinted on the body, both externally on the face and internally.", "People believe that emotions are innate because they believe that emotions are \u201cin the body.\u201d", "People will insist on their belief that emotions are innate even when told that the emotions in question are acquired.", "There is a tendency to view \u201cwarm\u201d feelings as embodied and innate.", "There is a tendency to view \u201ccold\u201d concepts as ephemeral and disembodied.", "Similar presumptions about emotions being innate plague the debate on universal emotions in affective science.", "Essentialism is a principle invoked to explain our aversion to innate ideas.", "Essentialism promotes the presumption of innate emotions by laypeople and scientists alike."]}, {"metadata": {"year": 2012}, "authors": ["J. de Rivera"], "summary": "Emotions involve transformations of the relationships that exist in the \u201cnatural\u201d world as well as in social worlds. Thus, the emotions that humans construct are based on affective processes that exist independently from human society and are not necessarily constituted by the interplay of culture and genetic or physiological processes.", "title": "Emotions as Transformational Structures", "claims": ["- Emotions involve transformations of the relationships that exist in the \u201cnatural\u201d world.", "- Emotions involve transformations of the relationships that exist in social worlds.", "- The emotions that humans construct are based on affective processes that exist independently from human society.", "- The emotions that humans construct are not necessarily constituted by the interplay of culture and genetic or physiological processes."]}, {"metadata": {"year": 2012}, "authors": ["J. Rivera"], "summary": "Emotions involve transformations of the relationships that exist in the \u201cnatural\u201d world as well as in social worlds. Thus, the emotions that humans construct are based on affective processes that exist independently from human society and are not necessarily constituted by the interplay of culture and genetic or physiological processes.", "title": "Emotions as Transformational Structures", "claims": ["- Emotions involve transformations of the relationships that exist in the \u201cnatural\u201d world.", "- Emotions involve transformations of the relationships that exist in social worlds.", "- The emotions that humans construct are based on affective processes that exist independently from human society.", "- The emotions that humans construct are not necessarily constituted by the interplay of culture and genetic or physiological processes."]}, {"metadata": {"year": 2016}, "authors": ["L. F. Barrett"], "summary": "Abstract The science of emotion has been using folk psychology categories derived from philosophy to search for the brain basis of emotion. The last two decades of neuroscience research have brought us to the brink of a paradigm shift in understanding the workings of the brain, however, setting the stage to revolutionize our understanding of what emotions are and how they work. In this article, we begin with the structure and function of the brain, and from there deduce what the biological basis of emotions might be. The answer is a brain-based, computational account called the theory of constructed emotion.", "title": "The theory of constructed emotion: an active inference account of interoception and categorization", "claims": ["- The science of emotion has been using folk psychology categories derived from philosophy to search for the brain basis of emotion.", "- The last two decades of neuroscience research have brought us to the brink of a paradigm shift in understanding the workings of the brain.", "- This paradigm shift is setting the stage to revolutionize our understanding of what emotions are and how they work.", "- In the article, the authors begin with the structure and function of the brain to deduce what the biological basis of emotions might be.", "- The answer to the biological basis of emotions is a brain-based, computational account called the theory of constructed emotion."]}], "query": "Are emotions innate or constructed?", "summary_abstract": null, "summary_extract": "The debate on whether emotions are innate or constructed is multifaceted, with significant contributions from various researchers. Charlie Kurth (2019) presents a constructivist perspective, suggesting that emotions are not natural kinds but are constructed through the projection of folk emotion concepts onto felt affective episodes. Kurth acknowledges a biological dimension to emotions but argues that constructivism's reliance on felt experience and folk concepts is inadequate, suggesting that biological mechanisms play a more central role than constructivism allows.\n\nIn contrast, Iris Berent and colleagues (2020) explore the perception of emotions as innate, finding that laypeople often believe emotions are embodied and innate, even when informed otherwise. Their experiments demonstrate a causal link between the belief in emotions being embodied and their perceived innateness, highlighting a persistent na\u00efve view that equates embodiment with innateness.\n\nJ. de Rivera (2012) offers a perspective that emotions, while constructed, are based on affective processes independent of human society, suggesting that they are not solely the result of cultural or genetic interplay. This view aligns with the notion that emotions involve transformations in both natural and social relationships.\n\nFinally, Lisa Feldman Barrett (2016) introduces the theory of constructed emotion, which posits a brain-based, computational account of emotions, suggesting a paradigm shift in understanding emotions' biological basis. This theory challenges traditional views by integrating neuroscience findings to propose that emotions are constructed rather than innate.\n\nCollectively, these claims illustrate a complex interplay between innate and constructed elements in emotions, with ongoing debates and evolving theories contributing to our understanding of their nature."}, {"papers": [{"metadata": {"year": 1997}, "authors": ["P. Wetzels", "C. Pfeiffer"], "summary": "Police crime statistics show a significant increase in the rates of violent crimes committed by children during the last two years. However, since in Germany children under the age of 14 are not accountable for criminal offences, these statistics are highly selective. On the other hand, police crime statistics also show a huge increase of violent crimes committed by juveniles and young adults which cannot be explained by changes of police intervention strategies. It seems reasonable to attribute this mainly to changed living conditions of young people, particularly the increase proportion of children and adolescents living below the thresholds of poverty. To put the issue of violence and children in perspective, the victimization of children should not be overlooked. Criminological as well as psychological research show the devastating consequences of physical and sexual abuse experiences during childhood. Results of a representative german survey concerning the prevalence of violent victimization experiences during childhood are presented. 13.5% of the male and 16.1% of the female respondents had been victims of severe physical or sexual abuse during childhood. If repeatedly witnessing parental violence is additionally taken into consideration, these rates are 18.3% for male and 20.5% for female respondents. A comparison of age groups failed to identify significant differences of victimization rates, except the rates of minor violence committed by parents. Thus it can be assumed tentatively, that the proportion of children subjected to severe violent acts committed by closely related adults as well as the rate of those witnessing parental violence has remained constant over time.", "title": "[Childhood and violence: perpetrator and victim perspectives from the viewpoint of criminology].", "claims": ["", "Police crime statistics show a significant increase in the rates of violent crimes committed by children during the last two years.", "In Germany, children under the age of 14 are not accountable for criminal offences.", "Police crime statistics also show a huge increase of violent crimes committed by juveniles and young adults which cannot be explained by changes of police intervention strategies.", "It seems reasonable to attribute the increase in violent crimes by juveniles and young adults mainly to changed living conditions of young people, particularly the increased proportion of children and adolescents living below the thresholds of poverty.", "The victimization of children should not be overlooked when considering the issue of violence and children.", "Criminological as well as psychological research show the devastating consequences of physical and sexual abuse experiences during childhood.", "Results of a representative German survey concerning the prevalence of violent victimization experiences during childhood are presented.", "13.5% of the male respondents in the German survey had been victims of severe physical or sexual abuse during childhood.", "16.1% of the female respondents in the German survey had been victims of severe physical or sexual abuse during childhood.", "If repeatedly witnessing parental violence is additionally taken into consideration, the rates of victimization are 18.3% for male respondents and 20.5% for female respondents.", "A comparison of age groups failed to identify significant differences in victimization rates, except for the rates of minor violence committed by parents.", "It can be assumed tentatively that the proportion of children subjected to severe violent acts committed by closely related adults, as well as the rate of those witnessing parental violence, has remained constant over time."]}, {"metadata": {"year": 2008}, "authors": ["Chelsea M. Weaver", "J. Borkowski", "T. Whitman"], "summary": "The relationships between childhood exposure to violence and adolescent conduct problems were investigated in a sample of 88 primiparous adolescent mothers and their children. Regression analyses revealed that witnessing violence and victimization prior to age 10 predicted delinquency and violent behaviors, even after controlling for prenatal maternal and early childhood externalizing problems. Social competency and depression during middle childhood moderated the relationship between victimization and violent behaviors for girls, but not boys: Lower levels of social competency and depression served as risk factors for delinquency among teenage girls who experienced victimization during childhood. These findings have important implications for youth violence prevention programs.", "title": "Violence Breeds Violence: Childhood Exposure and Adolescent Conduct Problems.", "claims": ["- The relationships between childhood exposure to violence and adolescent conduct problems were investigated in a sample of 88 primiparous adolescent mothers and their children.", "- Regression analyses revealed that witnessing violence and victimization prior to age 10 predicted delinquency and violent behaviors.", "- Witnessing violence and victimization prior to age 10 predicted delinquency and violent behaviors even after controlling for prenatal maternal and early childhood externalizing problems.", "- Social competency and depression during middle childhood moderated the relationship between victimization and violent behaviors for girls, but not boys.", "- Lower levels of social competency and depression served as risk factors for delinquency among teenage girls who experienced victimization during childhood.", "- These findings have important implications for youth violence prevention programs."]}, {"metadata": {"year": 2005}, "authors": ["Robert A. Murphy", "Robert A. Rosenheck", "Steven J. Berkowitz", "Steven R. Marans"], "summary": "The Child Development Community Policing Program represents a national model of community-based collaboration between police and mental health professionals for violence-exposed and traumatized children. Administrative data from clinical records of a 24-hour consultation service were examined through stepwise multivariate logistic regression to identify child and event characteristics associated with a direct, in-person response at the time of police contact. Of 2361 children, 809 (34.3%) received a direct, in-person response. Relative to Caucasian children, Hispanic youth were more likely to receive this form of response (OR = 1.36). An acute clinical response was more likely for incidents of gang involvement (OR = 8.12), accidents (OR = 5.21), felony assaults (OR = 2.97), property crimes (OR = 2.30), family violence (OR = 1.53) and psychiatric crises (OR = 1.29). Acute response was less likely when juvenile conduct problems (OR = 0.61), fires (OR = 0.59), child maltreatment (OR = 0.57), and domestic violence (OR = 0.44) were involved. Incidents that were more severe or involved a primary mental health component were related to utilization of intensive CDCP resources.", "title": "Acute Service Delivery in a Police-Mental Health Program for Children Exposed to Violence and Trauma", "claims": ["- The Child Development Community Policing Program represents a national model of community-based collaboration between police and mental health professionals for violence-exposed and traumatized children.", "- Administrative data from clinical records of a 24-hour consultation service were examined through stepwise multivariate logistic regression to identify child and event characteristics associated with a direct, in-person response at the time of police contact.", "- Of 2361 children, 809 (34.3%) received a direct, in-person response.", "- Relative to Caucasian children, Hispanic youth were more likely to receive a direct, in-person response (OR = 1.36).", "- An acute clinical response was more likely for incidents of gang involvement (OR = 8.12).", "- An acute clinical response was more likely for incidents of accidents (OR = 5.21).", "- An acute clinical response was more likely for incidents of felony assaults (OR = 2.97).", "- An acute clinical response was more likely for incidents of property crimes (OR = 2.30).", "- An acute clinical response was more likely for incidents of family violence (OR = 1.53).", "- An acute clinical response was more likely for incidents of psychiatric crises (OR = 1.29).", "- Acute response was less likely when juvenile conduct problems were involved (OR = 0.61).", "- Acute response was less likely when fires were involved (OR = 0.59).", "- Acute response was less likely when child maltreatment was involved (OR = 0.57).", "- Acute response was less likely when domestic violence was involved (OR = 0.44).", "- Incidents that were more severe or involved a primary mental health component were related to utilization of intensive CDCP resources."]}, {"metadata": {"year": 2015}, "authors": ["D. Finkelhor", "H. Turner"], "summary": "A National Profile of Children Exposed to Family Violence: Police Response, Family Response and Individual Impact provides the first nationally representative data on youth contact with law enforcement and victim services \u2013 including best practices and help-seeking obstacles \u2013 for cases of family violence involving exposure to children. These data come from a nationally representative sample of 517 family violence incidents drawn from the 4503 respondents to the Second National Survey of Children\u2019s Exposure to Violence (NatSCEV II). The NatSCEV study, conducted in 2011, involved telephone interviews with parents of children age 0-9 and with the youths themselves if they were age 10-17. Between 13%-58% of police contacts and between 34%-97% of advocate contacts following domestic violence incidents involving a child witness included actions from one or more of 10 best practices. Most police best practices were associated with increased likelihood of arrest. Almost half of children witnessed an arrest when one occurred, though only 1 in 4 youth were spoken to by police responding to the scene. Youth exposed to domestic violence, as a group, have high rates of other victimizations and adversities. Although this group reports elevated trauma symptoms, the characteristics of a specific domestic violence incident and the response to that incident by police were generally unrelated to youth's current trauma symptoms after controlling for history of victimization and other adversities. However, child current trauma symptoms were lowest when perpetrators left the house after the incident, followed by when no one moved out, and were highest when the victim moved out. Child witnesses to family violence are a highly victimized group, and it is recommended that they systematically receive assessment and services when any member of their family enters the system due to family violence. This document is a research report submitted to the U.S. Department of Justice. This report has not been published by the Department. Opinions or points of view expressed are those of the author(s) and do not necessarily reflect the official position or policies of the U.S. Department of Justice. NIJ 2010-IJ-CX-0021 Final Report 3", "title": "A National profile of children exposed to family violence: Police response, family response, and individual impact.", "claims": ["- A National Profile of Children Exposed to Family Violence provides the first nationally representative data on youth contact with law enforcement and victim services for cases of family violence involving exposure to children.", "- These data come from a nationally representative sample of 517 family violence incidents drawn from the 4503 respondents to the Second National Survey of Children\u2019s Exposure to Violence (NatSCEV II).", "- The NatSCEV study, conducted in 2011, involved telephone interviews with parents of children age 0-9 and with the youths themselves if they were age 10-17.", "- Between 13%-58% of police contacts following domestic violence incidents involving a child witness included actions from one or more of 10 best practices.", "- Between 34%-97% of advocate contacts following domestic violence incidents involving a child witness included actions from one or more of 10 best practices.", "- Most police best practices were associated with an increased likelihood of arrest.", "- Almost half of children witnessed an arrest when one occurred.", "- Only 1 in 4 youth were spoken to by police responding to the scene of a domestic violence incident.", "- Youth exposed to domestic violence, as a group, have high rates of other victimizations and adversities.", "- Although this group reports elevated trauma symptoms, the characteristics of a specific domestic violence incident and the response to that incident by police were generally unrelated to youth's current trauma symptoms after controlling for history of victimization and other adversities.", "- Child current trauma symptoms were lowest when perpetrators left the house after the incident.", "- Child current trauma symptoms were higher when no one moved out after the incident.", "- Child current trauma symptoms were highest when the victim moved out after the incident.", "- Child witnesses to family violence are a highly victimized group.", "- It is recommended that child witnesses to family violence systematically receive assessment and services when any member of their family enters the system due to family violence.", "- This document is a research report submitted to the U.S. Department of Justice.", "- This report has not been published by the U.S. Department of Justice.", "- Opinions or points of view expressed in the report are those of the author(s) and do not necessarily reflect the official position or policies of the U.S. Department of Justice."]}, {"metadata": {"year": 2012}, "authors": ["H. Richardson-Foster", "N. Stanley", "P. Miller", "G. Thomson"], "summary": "The police represent the front line in the service response to children experiencing domestic violence. This paper examines police intervention in domestic violence incidents involving children, drawing on quantitative and qualitative data from police records and interviews with young people and police officers. The quality of police communication with children and young people emerged as key, and police officers evinced reluctance to engage with children at domestic violence incidents. Providing the police with training and information designed to improve their skills and confidence might promote communication with children in this context. Policy that conceptualised children as victims of domestic violence in policy could focus police attention on the needs of children and young people at such incidents.", "title": "Police intervention in domestic violence incidents where children are present: police and children's perspectives", "claims": ["", "The police represent the front line in the service response to children experiencing domestic violence.", "This paper examines police intervention in domestic violence incidents involving children.", "The examination draws on quantitative and qualitative data from police records and interviews with young people and police officers.", "The quality of police communication with children and young people emerged as key.", "Police officers evinced reluctance to engage with children at domestic violence incidents.", "Providing the police with training and information designed to improve their skills and confidence might promote communication with children in this context.", "Policy that conceptualised children as victims of domestic violence could focus police attention on the needs of children and young people at such incidents."]}, {"metadata": {"year": 1990}, "authors": ["Beverly  Rivera", "Cathy Spatz Widom"], "summary": "The relationship between childhood victimization and violent offending is examined using a prospective cohorts design. Official criminal histories for a large sample of substantiated and validated cases of physical and sexual abuse and neglect (N = 908) from the years 1967 through 1971 were compared to those of a matched control group (N = 667) of individuals with no official record of abuse or neglect. Sex-specific and race-specific effects of childhood victimization and other characteristics of violent offending (chronicity, age of onset, temporal patterns, and continuity) are assessed. Childhood victimization increased overall risk for violent offending and particularly increased risk for males and blacks. In comparison to controls, abused and neglected children began delinquent careers earlier. Temporal patterns of violent offending were examined and childhood victims did not differ in age of arrest for first violent offense, nor were they more likely to continue offending. The findings and their limitations are discussed, as well as directions for future research.", "title": "Childhood Victimization and Violent Offending", "claims": ["- The relationship between childhood victimization and violent offending is examined using a prospective cohorts design.", "- Official criminal histories for a large sample of substantiated and validated cases of physical and sexual abuse and neglect (N = 908) from the years 1967 through 1971 were compared to those of a matched control group (N = 667) of individuals with no official record of abuse or neglect.", "- Sex-specific and race-specific effects of childhood victimization and other characteristics of violent offending (chronicity, age of onset, temporal patterns, and continuity) are assessed.", "- Childhood victimization increased overall risk for violent offending.", "- Childhood victimization particularly increased risk for violent offending in males.", "- Childhood victimization particularly increased risk for violent offending in blacks.", "- In comparison to controls, abused and neglected children began delinquent careers earlier.", "- Temporal patterns of violent offending were examined.", "- Childhood victims did not differ in age of arrest for first violent offense compared to controls.", "- Childhood victims were not more likely to continue offending compared to controls.", "- The findings and their limitations are discussed.", "- Directions for future research are discussed."]}, {"metadata": {"year": 2008}, "authors": ["Jean Dawson", "M. Wells"], "summary": "ABSTRACT This analysis examines child protective service reports made in 494 cases of child victimization known to police. The data were collected from police reports of assaults involving child victims in two rural northeastern towns from 1990 to 1999. Findings suggest that cases reported to child protective services (CPS) were more likely to involve child maltreatment and involve family/caretaker offenders. Cases in which victims were age 13 to 17 years or the perpetrator was male were less likely to be reported to CPS. The data indicate that child protection agencies failed to learn of approximately 35% of the cases involving parent or caretaker offenders. Law enforcement agency policies and mandated reporting guidelines should streamline collaboration between these two types of agencies.", "title": "Crimes Involving Child Victims: Law Enforcement Reporting to Child Protective Services in Rural Communities", "claims": ["- The analysis examines child protective service reports made in 494 cases of child victimization known to police.", "- The data were collected from police reports of assaults involving child victims in two rural northeastern towns from 1990 to 1999.", "- Findings suggest that cases reported to child protective services (CPS) were more likely to involve child maltreatment and involve family/caretaker offenders.", "- Cases in which victims were age 13 to 17 years or the perpetrator was male were less likely to be reported to CPS.", "- The data indicate that child protection agencies failed to learn of approximately 35% of the cases involving parent or caretaker offenders.", "- Law enforcement agency policies and mandated reporting guidelines should streamline collaboration between these two types of agencies."]}, {"metadata": {"year": 2009}, "authors": ["D. Finkelhor", "H. Turner", "Richard K. Ormrod", "S. Hamby"], "summary": "OBJECTIVE: The objective of this research was to obtain national estimates of exposure to the full spectrum of the childhood violence, abuse, and crime victimizations relevant to both clinical practice and public-policy approaches to the problem. METHODS: The study was based on a cross-sectional national telephone survey that involved a target sample of 4549 children aged 0 to 17 years. RESULTS: A clear majority (60.6%) of the children and youth in this nationally representative sample had experienced at least 1 direct or witnessed victimization in the previous year. Almost half (46.3%) had experienced a physical assault in the study year, 1 in 4 (24.6%) had experienced a property offense, 1 in 10 (10.2%) had experienced a form of child maltreatment, 6.1% had experienced a sexual victimization, and more than 1 in 4 (25.3%) had been a witness to violence or experienced another form of indirect victimization in the year, including 9.8% who had witnessed an intrafamily assault. One in 10 (10.2%) had experienced a victimization-related injury. More than one third (38.7%) had been exposed to 2 or more direct victimizations, 10.9% had 5 or more, and 2.4% had 10 or more during the study year. CONCLUSIONS: The scope and diversity of child exposure to victimization is not well recognized. Clinicians and researchers need to inquire about a larger spectrum of victimization types to identify multiply victimized children and tailor prevention and interventions to the full range of threats that children face.", "title": "Violence, Abuse, and Crime Exposure in a National Sample of Children and Youth", "claims": ["", "The objective of this research was to obtain national estimates of exposure to the full spectrum of childhood violence, abuse, and crime victimizations relevant to both clinical practice and public-policy approaches to the problem.", "The study was based on a cross-sectional national telephone survey that involved a target sample of 4549 children aged 0 to 17 years.", "A clear majority (60.6%) of the children and youth in this nationally representative sample had experienced at least 1 direct or witnessed victimization in the previous year.", "Almost half (46.3%) of the children and youth in this nationally representative sample had experienced a physical assault in the study year.", "One in 4 (24.6%) of the children and youth in this nationally representative sample had experienced a property offense in the study year.", "One in 10 (10.2%) of the children and youth in this nationally representative sample had experienced a form of child maltreatment in the study year.", "6.1% of the children and youth in this nationally representative sample had experienced a sexual victimization in the study year.", "More than 1 in 4 (25.3%) of the children and youth in this nationally representative sample had been a witness to violence or experienced another form of indirect victimization in the study year.", "9.8% of the children and youth in this nationally representative sample had witnessed an intrafamily assault in the study year.", "One in 10 (10.2%) of the children and youth in this nationally representative sample had experienced a victimization-related injury in the study year.", "More than one third (38.7%) of the children and youth in this nationally representative sample had been exposed to 2 or more direct victimizations in the study year.", "10.9% of the children and youth in this nationally representative sample had been exposed to 5 or more direct victimizations in the study year.", "2.4% of the children and youth in this nationally representative sample had been exposed to 10 or more direct victimizations in the study year.", "The scope and diversity of child exposure to victimization is not well recognized.", "Clinicians and researchers need to inquire about a larger spectrum of victimization types to identify multiply victimized children.", "Clinicians and researchers need to tailor prevention and interventions to the full range of threats that children face."]}], "query": "police violence and child victimization OR adverse childhood experinces", "summary_abstract": null, "summary_extract": "The research question concerning police violence and child victimization or adverse childhood experiences is addressed through various studies that highlight the profound impact of violence exposure on children. Wetzels and Pfeiffer (1997) emphasize the significant victimization rates among children, with 13.5% of male and 16.1% of female respondents in a German survey reporting severe physical or sexual abuse during childhood. They also note that witnessing parental violence further increases these rates, underscoring the importance of considering child victimization in discussions of violence.\n\nWeaver et al. (2008) found that childhood exposure to violence, particularly witnessing violence and victimization before age 10, predicts delinquency and violent behaviors in adolescence. This relationship persists even after accounting for other factors, highlighting the long-term effects of early adverse experiences.\n\nMurphy et al. (2005) discuss the Child Development Community Policing Program, which exemplifies a collaborative approach between police and mental health professionals to support violence-exposed children. This model underscores the need for acute clinical responses in severe cases, such as gang involvement or family violence, to mitigate the impact on children.\n\nFinkelhor and Turner (2015) provide a national perspective, revealing that children exposed to domestic violence often face multiple victimizations and adversities, which are linked to elevated trauma symptoms. They advocate for systematic assessment and services for child witnesses of family violence to address their complex needs.\n\nRichardson-Foster et al. (2012) highlight the critical role of police as first responders in domestic violence incidents involving children. They suggest that improving police communication and training could enhance the support provided to child victims.\n\nRivera and Widom (1990) demonstrate that childhood victimization increases the risk of violent offending, particularly among males and black individuals, indicating a need for targeted interventions to break the cycle of violence.\n\nCollectively, these studies underscore the pervasive and multifaceted nature of child victimization and the critical role of early intervention and comprehensive support systems in addressing the adverse effects of violence on children."}, {"papers": [{"metadata": {"year": 2004}, "authors": ["L. Valente"], "summary": "The cucurbitacins are highly oxygenated triterpenoid compounds found in several botanical families that show high toxicity and varied biological activities. This review presents the main cucurbitacins so far isolated and their key structural characteristics. It complements and updates the existing reviews on this subject.", "title": "Cucurbitacinas e suas principais caracter\u00edsticas estruturais", "claims": ["- The cucurbitacins are highly oxygenated triterpenoid compounds.", "- The cucurbitacins are found in several botanical families.", "- The cucurbitacins show high toxicity.", "- The cucurbitacins show varied biological activities.", "- This review presents the main cucurbitacins so far isolated.", "- This review presents the key structural characteristics of the main cucurbitacins so far isolated.", "- This review complements and updates the existing reviews on the subject of cucurbitacins."]}, {"metadata": {"year": 2018}, "authors": ["Chao Zhu", "Jieyu Wang", "Zi-hui Meng", "Zhibin Xu"], "summary": "As a new generation of host molecules, Cucurbitins have made remarkable achievements in host-guest chemistry, molecular recognition, molecular assembly, catalysis, separation detection, energy and so on. It has become a hotspot in supramolecular chemistry research. The advance of cucurbit[n]uril analogues, including glycoluril derivatives, hemicucurbit [n] uril, \u201chandle shape\u201d cucurbit[n]uril and heterocucurbit [n] uril is reviewed. Further researches of cucurbit [n] uril analogues are also discussed.", "title": "Research Progress of Cucurbit[n]uril Analogues", "claims": ["", "Cucurbitins have made remarkable achievements in host-guest chemistry, molecular recognition, molecular assembly, catalysis, separation detection, and energy.", "Cucurbitins have become a hotspot in supramolecular chemistry research.", "The advance of cucurbit[n]uril analogues, including glycoluril derivatives, hemicucurbit[n]uril, \u201chandle shape\u201d cucurbit[n]uril, and heterocucurbit[n]uril is reviewed.", "Further researches of cucurbit[n]uril analogues are also discussed."]}, {"metadata": {"year": 1971}, "authors": ["D  Lavie", "E  Glotter"], "summary": "The potent physiological activity of plants belonging to the Cucurbitaceae family has been known since antiquity. They were feared on account of their high toxicity (Elisha\u2019s Miracle)*, and vet valued because of the medicinal properties ascribed to them (40). Greeks and Romans used them, the doctors of the Middle Ages praised their virtues and some were still described in the British Pharmacopoeia of 1914.", "title": "The cucurbitanes, a group of tetracyclic triterpenes.", "claims": ["- The potent physiological activity of plants belonging to the Cucurbitaceae family has been known since antiquity.", "- Plants belonging to the Cucurbitaceae family were feared on account of their high toxicity, as referenced by Elisha\u2019s Miracle.", "- Plants belonging to the Cucurbitaceae family were valued because of the medicinal properties ascribed to them.", "- Greeks and Romans used plants belonging to the Cucurbitaceae family.", "- The doctors of the Middle Ages praised the virtues of plants belonging to the Cucurbitaceae family.", "- Some plants belonging to the Cucurbitaceae family were still described in the British Pharmacopoeia of 1914."]}, {"metadata": {"year": 2005}, "authors": ["Jian Chao Chen", "M. Chiu", "R. Nie", "G. Cordell", "S. Qiu"], "summary": "The natural cucurbitacins constitute a group of triterpenoid substances which are well-known for their bitterness and toxicity. Structurally, they are characterized by the tetracyclic cucurbitane nucleus skeleton, namely, 19-(10-->9beta)-abeo-10alpha-lanost-5-ene (also known as 9beta-methyl-19-norlanosta-5-ene), with a variety of oxygen substitutions at different positions. According to the characteristics of their structures, cucurbitacins are divided into twelve categories. The biological effects of the cucurbitacins are also covered.", "title": "Cucurbitacins and cucurbitane glycosides: structures and biological activities.", "claims": ["- The natural cucurbitacins constitute a group of triterpenoid substances which are well-known for their bitterness and toxicity.", "- Structurally, cucurbitacins are characterized by the tetracyclic cucurbitane nucleus skeleton, namely, 19-(10-->9beta)-abeo-10alpha-lanost-5-ene (also known as 9beta-methyl-19-norlanosta-5-ene), with a variety of oxygen substitutions at different positions.", "- According to the characteristics of their structures, cucurbitacins are divided into twelve categories.", "- The biological effects of the cucurbitacins are also covered."]}, {"metadata": {"year": 1975}, "authors": ["H.  Ripperger", "K.  Seifert"], "summary": "Zusammenfassung Mit Hilfe von Sephadex-LH-20- bzw. Kieselgel-Chromatographie wurden aus Fruchten von Citrullus lanatus var. citroides (Synonym C. colocynthoides) neben Cucurbitacin E (2) zwei Glykoside isoliert, denen die Strukturen 2-o-\u03b2- d -Glucopyranosyl-cucurbitacin I (3) und 2-o-\u03b2- d -Glucopyranosyl-cucurbitacin E (4) zukommen. 3 ist das dritte Cucurbitacin-Glykosid, das kristallin erhalten wurde.", "title": "Die cucurbitacine von Citrullus lanatus var. citroides", "claims": ["- Mit Hilfe von Sephadex-LH-20- bzw. Kieselgel-Chromatographie wurden aus Fruchten von Citrullus lanatus var. citroides (Synonym C. colocynthoides) neben Cucurbitacin E (2) zwei Glykoside isoliert.", "- Den isolierten Glykosiden wurden die Strukturen 2-o-\u03b2- d -Glucopyranosyl-cucurbitacin I (3) und 2-o-\u03b2- d -Glucopyranosyl-cucurbitacin E (4) zugeschrieben.", "- 3 ist das dritte Cucurbitacin-Glykosid, das kristallin erhalten wurde."]}, {"metadata": {"year": 2005}, "authors": ["Jos\u00e9 Luis R\u00edos", "Jos\u00e9 M. Escandell", "M. Carmen Recio"], "summary": "The cucurbitacins are a group of tetracyclic triterpenoids derived from the cucurbitane skeleton and found primarily in the Cucurbitaceae family. These triterpenoids, present in free or glycosidic form, are generally responsible for the bitter taste of the plants that contain them and are probably the principal cause of the antifeedant effects observed for such plants. Several plants used in traditional medicine to treat both inflammatory diseases as well as various types of tumors are rich in cucurbitacins, a fact which has given rise to several studies concerning their potential use as anti-inflammatory and anticancer agents. Nevertheless, since many cucurbitacins are extremely toxic, relatively few papers have dealt with their pharmacological activity. Recently, however, the relationship between the toxicity of a compound and its chemical pattern of substitution has been established, thus allowing for a more in-depth understanding of this class of triterpenes. In the present review, we provide a compilation of all the studies published in the last ten years on the pharmacological and biological effects of cucurbitacins, focusing principally on their pharmacological properties, especially their anti-inflammatory and anticancer effects.", "title": "New insights into the bioactivity of cucurbitacins", "claims": ["", "The cucurbitacins are a group of tetracyclic triterpenoids derived from the cucurbitane skeleton and found primarily in the Cucurbitaceae family.", "These triterpenoids, present in free or glycosidic form, are generally responsible for the bitter taste of the plants that contain them.", "Cucurbitacins are probably the principal cause of the antifeedant effects observed for plants that contain them.", "Several plants used in traditional medicine to treat both inflammatory diseases and various types of tumors are rich in cucurbitacins.", "The richness of cucurbitacins in certain plants used in traditional medicine has given rise to several studies concerning their potential use as anti-inflammatory and anticancer agents.", "Many cucurbitacins are extremely toxic.", "Relatively few papers have dealt with the pharmacological activity of cucurbitacins due to their extreme toxicity.", "Recently, the relationship between the toxicity of a compound and its chemical pattern of substitution has been established.", "The establishment of the relationship between toxicity and chemical pattern of substitution allows for a more in-depth understanding of cucurbitacins.", "The present review provides a compilation of all the studies published in the last ten years on the pharmacological and biological effects of cucurbitacins.", "The present review focuses principally on the pharmacological properties of cucurbitacins, especially their anti-inflammatory and anticancer effects."]}, {"metadata": {"year": 1985}, "authors": ["Sun Cj", "J. Ry", "Kyi Zy"], "summary": "Cucurbitine is a novel amino acid with schistosomicidal activity. In an attempt to enhance its activity by modification of its chemical structure, some related compounds were synthesized. 1,2-Dicarbethoxy-pyrrolidin-4-one was converted into the corresponding ketoxime. Catalytic hydrogenation of the latter compound under atmospheric pressure and subsequent hydrolysis gave racemic 4-allo-hydroxyproline. However, reduction under high pressure, 4-aminopyrrolidine-2-carboxylic acid (\u2162_a) was obtained. A number of derivatives of cucurbitine, including some esters and acylamino compounds (Table 1) were also prepared. Pharmacological examinations revealed that none of the compounds prepared was more active than cucurbitine.", "title": "[Synthesis of some cucurbitine-related compounds].", "claims": ["", "Cucurbitine is a novel amino acid with schistosomicidal activity.", "In an attempt to enhance cucurbitine's activity by modification of its chemical structure, some related compounds were synthesized.", "1,2-Dicarbethoxy-pyrrolidin-4-one was converted into the corresponding ketoxime.", "Catalytic hydrogenation of the ketoxime under atmospheric pressure and subsequent hydrolysis gave racemic 4-allo-hydroxyproline.", "Reduction of the ketoxime under high pressure resulted in the formation of 4-aminopyrrolidine-2-carboxylic acid (\u2162_a).", "A number of derivatives of cucurbitine, including some esters and acylamino compounds, were prepared.", "Pharmacological examinations revealed that none of the compounds prepared was more active than cucurbitine."]}, {"metadata": {"year": 1989}, "authors": ["H. Stuppner1", "H. Wagner2"], "summary": "Picrorhiza kurrooa 4 5 6 7 O O O O", "title": "New Cucurbitacin Glycosides from Picrorhiza kurrooa", "claims": ["the text you provided does not contain enough information for me to extract any claims. Could you please provide more context or a more detailed summary of the document?"]}], "query": "cucurbitins", "summary_abstract": null, "summary_extract": "The research question focuses on cucurbitins, and the claims collectively highlight their significance in various scientific domains. Zhu et al. (2018) emphasize that cucurbitins have achieved remarkable success in fields such as host-guest chemistry, molecular recognition, and catalysis, marking them as a focal point in supramolecular chemistry research. This underscores their versatility and potential for innovation in scientific applications. Meanwhile, Sun et al. (1985) introduce cucurbitine, a novel amino acid with schistosomicidal activity, and discuss efforts to enhance its efficacy through chemical modifications, although these attempts did not surpass the original compound's activity. These claims collectively illustrate the diverse applications and ongoing research interest in cucurbitins, highlighting their potential in both chemical and pharmacological contexts."}, {"papers": [{"metadata": {"year": 2005}, "authors": ["A. Branch"], "summary": "Policy for Flexible Work Practices , Outlines the flexible work practices within the NSW Health System.", "title": "Flexible Work Practices - Policy - NSW Department of Health", "claims": ["- The document outlines the flexible work practices within the NSW Health System.", "- The document is a policy for flexible work practices."]}, {"metadata": {"year": 2012}, "authors": ["M. Grabowska"], "summary": "Flexible employment forms are one of the elements of active labour market policy which is connected with fl exicurity system. Th e new option on labour market in the present times. Results of the global economic crisis and the demographic situation related to ageing societies cause a need to implement solutions on the labour market which shall be both fl exible and protective. Flexible forms of work are forms of work which deviate from the typical form of employment such as a permanent employment contract. Th ese are atypical forms of employment whose characteristics include fl exible working time and place, the form of employment, other relations between the employee and the employer. Th ey are a truly new approach in the labour law as they more and more depart from the classical job under a permanent employment contract.", "title": "Flexible Employment Forms as an Element of Flexicurity", "claims": ["- Flexible employment forms are one of the elements of active labour market policy which is connected with the flexicurity system.", "- Flexible employment forms are a new option on the labour market in the present times.", "- The global economic crisis and the demographic situation related to ageing societies cause a need to implement solutions on the labour market which shall be both flexible and protective.", "- Flexible forms of work deviate from the typical form of employment such as a permanent employment contract.", "- Atypical forms of employment include flexible working time and place, the form of employment, and other relations between the employee and the employer.", "- Flexible forms of work are a truly new approach in the labour law as they more and more depart from the classical job under a permanent employment contract."]}, {"metadata": {"year": 2022}, "authors": ["G. Nazarova", "V. O. Baliasnyi"], "summary": "The article is aimed at studying theoretical approaches to understanding the essence of flexible employment policy in modern enterprises. The article analyzes approaches to understanding the essence of the definition of \u00abemployment of the population\u00bb by domestic and foreign scholars. Modern trends in the field of employment of workers are identified, interpretations of the terms \u00abnon-standard employment\u00bb and \u00abflexible employment\u00bb are studied, their common features and differences are determined. The main trends in the use of labor force are aimed at reducing the costs of structural restructuring of the economy by: the use of various forms of hiring employees and their labor engagement, flexibility in regulating working hours (ensuring a flexible schedule with irregular working hours), flexibility in matters of remuneration (using a differentiated and individual approach), flexibility in the use of forms and methods of social protection of workers. The article analyzes the peculiarities of using the flexibility model in the context of employment problems. Based on the analyzed theoretical approaches, the definition of a flexible employment policy at the State level and the level of individual enterprises is provided. At the State level, flexible employment is defined as a form of labor market regulation, which takes into account and does not oppose the interests of both subjects of social and labor relations, i. e.: employers and hired employees. At the level of individual enterprises, flexible employment policy is the company\u2019s policy towards employees, which gives the latter the opportunity to choose between working and free time \u2013 both in terms of the amount of time and the mode of its use. Thus, the introduction of a flexible employment policy both at the level of individual enterprises and at the State level as a whole will make business more responsible, increase the level of economic activity of the population, make enterprises and organizations more competitive in the labor market in the context of informatization and digitalization of modern society.", "title": "The Theoretical Foundations of Flexible and Non-Standard Employment", "claims": ["- The article is aimed at studying theoretical approaches to understanding the essence of flexible employment policy in modern enterprises.", "- The article analyzes approaches to understanding the essence of the definition of \u00abemployment of the population\u00bb by domestic and foreign scholars.", "- Modern trends in the field of employment of workers are identified.", "- Interpretations of the terms \u00abnon-standard employment\u00bb and \u00abflexible employment\u00bb are studied.", "- The common features and differences between \u00abnon-standard employment\u00bb and \u00abflexible employment\u00bb are determined.", "- The main trends in the use of labor force are aimed at reducing the costs of structural restructuring of the economy.", "- The use of various forms of hiring employees and their labor engagement is a trend aimed at reducing the costs of structural restructuring of the economy.", "- Flexibility in regulating working hours, such as ensuring a flexible schedule with irregular working hours, is a trend aimed at reducing the costs of structural restructuring of the economy.", "- Flexibility in matters of remuneration, using a differentiated and individual approach, is a trend aimed at reducing the costs of structural restructuring of the economy.", "- Flexibility in the use of forms and methods of social protection of workers is a trend aimed at reducing the costs of structural restructuring of the economy.", "- The article analyzes the peculiarities of using the flexibility model in the context of employment problems.", "- Based on the analyzed theoretical approaches, the definition of a flexible employment policy at the State level and the level of individual enterprises is provided.", "- At the State level, flexible employment is defined as a form of labor market regulation, which takes into account and does not oppose the interests of both subjects of social and labor relations, i.e., employers and hired employees.", "- At the level of individual enterprises, flexible employment policy is the company\u2019s policy towards employees, which gives the latter the opportunity to choose between working and free time \u2013 both in terms of the amount of time and the mode of its use.", "- The introduction of a flexible employment policy both at the level of individual enterprises and at the State level as a whole will make business more responsible.", "- The introduction of a flexible employment policy both at the level of individual enterprises and at the State level as a whole will increase the level of economic activity of the population.", "- The introduction of a flexible employment policy both at the level of individual enterprises and at the State level as a whole will make enterprises and organizations more competitive in the labor market in the context of informatization and digitalization of modern society."]}, {"metadata": {"year": 1989}, "authors": ["T. Walsh"], "summary": "Drawing on publicly available statistics and data on employment structures, hours and labour utilisation practices from detailed company case\u2010studies in the retail and catering sectors, this paper considers the implications for labour markets of the rise in part\u2010time, temporary and casual working (variously described as \u2018flexible\u2019 labour). Throughout the paper, emphasis will be given to part\u2010time employment and temporary and casual working in their own right, not simply in relation to full\u2010time work.", "title": "\u2018Flexible\u2019 Labour: Some Policy Perspectives", "claims": ["- Drawing on publicly available statistics and data on employment structures, hours and labour utilisation practices from detailed company case\u2010studies in the retail and catering sectors.", "- This paper considers the implications for labour markets of the rise in part\u2010time, temporary and casual working (variously described as \u2018flexible\u2019 labour).", "- Throughout the paper, emphasis will be given to part\u2010time employment and temporary and casual working in their own right, not simply in relation to full\u2010time work."]}, {"metadata": {"year": 2003}, "authors": ["Li Hui"], "summary": "Flexible employment has been developing rapidly in developed countries and playing an important role in improving labor market and economy since 1970s. There are many reasons for this. An important reason is that governments in the developed countries have made some special policies and measures for the flexible employment, including subsidies for employers and enterprises, assistance to up - starters, support for special groups in poverty as well as increasingly perfect and complete laws and legislations on flexible employment. These policies and measures can definitely give some enlightenment for the flexible employment in Chi-", "title": "Policy of the Flexible Employment in Developed Countries and Its Enlightenment", "claims": ["- Flexible employment has been developing rapidly in developed countries since the 1970s.", "- Flexible employment has been playing an important role in improving the labor market and economy in developed countries since the 1970s.", "- Governments in developed countries have made special policies and measures for flexible employment.", "- These policies and measures include subsidies for employers and enterprises.", "- These policies and measures include assistance to up-starters.", "- These policies and measures include support for special groups in poverty.", "- Developed countries have increasingly perfect and complete laws and legislations on flexible employment.", "- These policies and measures can definitely give some enlightenment for flexible employment in China."]}, {"metadata": {"year": 2001}, "authors": ["S. Ja\u0161arevi\u0107"], "summary": "In today's complex operating conditions, characterized by stricter and stricter competition in the market, there must be a more flexible approach to the organization and continuation of work process, as compared to the years when unemployment and economic crisis did not represent a chronic problem. For our country, with particularly weakened economy and one of the highest rates of actual unemployment in the world, such an approach shall be inevitable. In order to commence more successfully the flexibilization of work, besides reforms leading to originating and open market economy, we shall have to effect significant changes in the area of education (especially expertise), labor legislation and system of social security. However, the experiences of other countries clearly point that amending the regulations shall not be sufficient without reorienting the whole society. especially the state, the unions and employers' associations, towards more active incentive for flexible work in all the operating levels.", "title": "'Flexible work': A necessity of modern economy", "claims": ["- In today's complex operating conditions, there is stricter and stricter competition in the market.", "- There must be a more flexible approach to the organization and continuation of the work process compared to the years when unemployment and economic crisis did not represent a chronic problem.", "- Our country has a particularly weakened economy and one of the highest rates of actual unemployment in the world.", "- For our country, a more flexible approach to work organization shall be inevitable.", "- To commence more successfully the flexibilization of work, significant changes in the area of education (especially expertise), labor legislation, and the system of social security are necessary.", "- The experiences of other countries clearly point out that amending the regulations shall not be sufficient without reorienting the whole society.", "- Reorienting the whole society, especially the state, the unions, and employers' associations, towards more active incentive for flexible work in all the operating levels is necessary."]}, {"metadata": {"year": 2021}, "authors": ["Sla\u0111ana Gligori\u0107", "Sanja \u0160kori\u0107"], "summary": "Global trends in the working world clearly show the changes in the character of labor relations with a significant representation of flexible forms of work. It is an atypical form of work organization that arises as a consequence of strong globalization flows, economic crisis, information and technological revolution, and which stands against the labor law standard of a classical employment, being represented in the form of the employment contract for an indefinite period of time with full time employment. Starting from the concept of flexicurity as the dominant concept in the EU, flexicurity seeks to establish a balance between flexibility in the organization of work in order to preserve stability. Through the flexible organization of work and working hours, there establishes a kind of balance between working hours, the rest time and time for socialization and social activity. However, on the other hand, a flexible organization of work can reduce the rights of the employees and workers outside the employment relationship, especially if this form of work is abused in practice by the contracts concluded contrary to their essence or legal norm. The authors use the historical, comparative-legal and sociological method, as well as the statistical data in the analysis of research subjects with the aim of providing the concrete proposals for the improvement of the existing normative framework.", "title": "Flexible forms of work and work engagement", "claims": ["- Global trends in the working world clearly show the changes in the character of labor relations with a significant representation of flexible forms of work.", "- Flexible forms of work are an atypical form of work organization that arises as a consequence of strong globalization flows, economic crisis, and information and technological revolution.", "- Flexible forms of work stand against the labor law standard of classical employment, which is represented in the form of the employment contract for an indefinite period of time with full-time employment.", "- The concept of flexicurity is the dominant concept in the EU, seeking to establish a balance between flexibility in the organization of work and preserving stability.", "- Through the flexible organization of work and working hours, a balance is established between working hours, rest time, and time for socialization and social activity.", "- A flexible organization of work can reduce the rights of employees and workers outside the employment relationship, especially if this form of work is abused in practice by contracts concluded contrary to their essence or legal norm.", "- The authors use the historical, comparative-legal, and sociological method, as well as statistical data, in the analysis of research subjects.", "- The aim of the authors is to provide concrete proposals for the improvement of the existing normative framework."]}, {"metadata": {"year": 2012}, "authors": ["Elke J. Jahn", "R. Riphahn", "C. Schnabel"], "summary": "In recent decades, economic policy makers across Europe have sought to increase labour market flexibility by promoting the use of temporary employment. The articles in this Feature provide new results on how fixed\u2010term and agency work contracts affect firm productivity and how the segments of two\u2010tier labour markets interact. This article points to a possible trade\u2010off between efficiency and equity when deregulating labour markets. Taken together, the evidence presented in this Feature suggests that flexible forms of employment can be both a boon and a bane for labour markets and for society as a whole.", "title": "Feature: Flexible Forms of Employment: Boon and Bane", "claims": ["- In recent decades, economic policy makers across Europe have sought to increase labour market flexibility by promoting the use of temporary employment.", "- The articles in this Feature provide new results on how fixed\u2010term and agency work contracts affect firm productivity.", "- The articles in this Feature provide new results on how the segments of two\u2010tier labour markets interact.", "- This article points to a possible trade\u2010off between efficiency and equity when deregulating labour markets.", "- The evidence presented in this Feature suggests that flexible forms of employment can be both a boon and a bane for labour markets and for society as a whole."]}], "query": "what is flexible work policy", "summary_abstract": null, "summary_extract": "Flexible work policy is a multifaceted approach to employment that emphasizes adaptability in work arrangements, diverging from traditional, permanent employment contracts. According to Branch (2005), flexible work policies are formalized guidelines that outline adaptable work practices within organizations, such as the NSW Health System. Grabowska (2012) elaborates that flexible employment forms are integral to active labor market policies and are characterized by non-standard employment arrangements, including flexible working hours and locations. This approach is increasingly necessary due to economic and demographic challenges, such as the global economic crisis and aging populations.\n\nNazarova and Baliasnyi (2022) provide a comprehensive definition of flexible employment policy, describing it as a labor market regulation that balances the interests of employers and employees. At the enterprise level, it allows employees to choose their working hours and modes, enhancing both business responsibility and competitiveness. This flexibility is crucial in the context of modern societal changes, including informatization and digitalization.\n\nLi Hui (2003) notes that flexible employment has been pivotal in developed countries since the 1970s, supported by government policies and legislation that promote such work arrangements. These policies often include subsidies and support for specific groups, highlighting the role of flexible employment in economic improvement.\n\nGligori\u0107 and \u0160kori\u0107 (2021) discuss the global trend towards flexible work, driven by globalization, economic crises, and technological advancements. They emphasize the concept of \"flexicurity,\" which seeks to balance work flexibility with job stability. However, they caution that if misused, flexible work arrangements can undermine employee rights.\n\nOverall, flexible work policy is a strategic response to evolving labor market needs, offering a balance between flexibility and security, and is increasingly recognized as essential for economic resilience and competitiveness (Jahn et al., 2012)."}, {"papers": [{"metadata": {"year": 2011}, "authors": ["Eyal Yaniv"], "summary": "Organizational attention is an underdeveloped construct that can account for a variety of organizational phenomena. Attention is the means by which individuals select and process a limited amount of input from the enormous amount of internal and environmental inputs bombarding the senses, memories and other cognitive processes. This article develops a coherent theory of organizational attention, drawing on Cornelissen\u0219s domain-interactive metaphor model. Topics that form the building blocks of individual attention research, including selective and divided attention, automatic versus controlled processes, attention and memory, attention and learning, are examined in terms of their applicability to the organizational context.", "title": "ORGANIZATIONAL ATTENTION: A METAPHOR FOR A CORE COGNITIVE PROCESS", "claims": ["- Organizational attention is an underdeveloped construct that can account for a variety of organizational phenomena.", "- Attention is the means by which individuals select and process a limited amount of input from the enormous amount of internal and environmental inputs bombarding the senses, memories, and other cognitive processes.", "- This article develops a coherent theory of organizational attention, drawing on Cornelissen's domain-interactive metaphor model.", "- Topics that form the building blocks of individual attention research, including selective and divided attention, automatic versus controlled processes, attention and memory, attention and learning, are examined in terms of their applicability to the organizational context."]}, {"metadata": {"year": 2011}, "authors": ["Eyal Yaniv", "D. Schwartz"], "summary": "INTRODUCTION Attention is a term commonly used in education, psychiatry, and psychology. Attention can be defined as an internal cognitive process by which one actively selects environmental information (i.e., sensation) or actively processes information from internal sources (i.e., stored memories and thoughts; Sternberg, 1996). In more general terms, attention can be defined as an ability to focus and maintain interest in a given task or idea, including managing distractions. Attention is selective by its nature. According to Pashler (1998, p. 37), \" The process of selecting from among the many potentially available stimuli is the clearest manifestation of selective attention. \" Why do firms respond to certain events or stimuli in their environment while neglecting others? It seems that organizations, just like individuals , have limited attention capacity. Hence, they must select from among the many potentially available stimuli and respond to these selected stimuli only. Organizational attention is defined as the socially structured pattern of attention by decision makers within the organization (Ocasio, 1997). Organizational attention, like human attention , is a limited resource: \" Attentional limits filter or screen incoming information such that a great deal of data pertinent to strategic decision may never get processed \" (2003) show that the extent to which CEOs (chief executive officers) are selective in their attention to sectors of the environment is a significant predictor of performance. Knowledge management (KM) models and process theories, almost without exception, incorporate a stage or phase in which a given knowledge item is brought to bear on a current decision or action. This stage, referred to alternatively as, is of crucial importance in any knowledge-management cycle. The flow of knowledge in and out of an awareness stage is not merely a function of the universe of available organizational memory or the technological tools available to filter and identify such knowledge. It is influenced to a large degree by organizational attention. The second area in which organizational attention is key is knowledge acquisition and creation as discussed by Ocasio (1997), and Yaniv and Elizur (2003). Successful knowledge management requires attention. Davenport and Volpel (2001) argues that attention is the currency of the information age. Knowledge consumers must pay attention to knowledge and become actively involved in the knowledge-transfer processes. This is particularly important when the knowledge to be received is tacit (Nonaka, 1994). Knowledge can be part of the organization's repository, however, if it does not \u2026", "title": "Organizational Attention", "claims": ["- Attention is a term commonly used in education, psychiatry, and psychology.", "- Attention can be defined as an internal cognitive process by which one actively selects environmental information (i.e., sensation) or actively processes information from internal sources (i.e., stored memories and thoughts; Sternberg, 1996).", "- In more general terms, attention can be defined as an ability to focus and maintain interest in a given task or idea, including managing distractions.", "- Attention is selective by its nature.", "- According to Pashler (1998, p. 37), \"The process of selecting from among the many potentially available stimuli is the clearest manifestation of selective attention.\"", "- Organizations, just like individuals, have limited attention capacity.", "- Organizations must select from among the many potentially available stimuli and respond to these selected stimuli only.", "- Organizational attention is defined as the socially structured pattern of attention by decision makers within the organization (Ocasio, 1997).", "- Organizational attention, like human attention, is a limited resource.", "- \"Attentional limits filter or screen incoming information such that a great deal of data pertinent to strategic decision may never get processed.\"", "- The extent to which CEOs are selective in their attention to sectors of the environment is a significant predictor of performance.", "- Knowledge management (KM) models and process theories, almost without exception, incorporate a stage or phase in which a given knowledge item is brought to bear on a current decision or action.", "- The flow of knowledge in and out of an awareness stage is not merely a function of the universe of available organizational memory or the technological tools available to filter and identify such knowledge.", "- The flow of knowledge is influenced to a large degree by organizational attention.", "- Organizational attention is key in knowledge acquisition and creation as discussed by Ocasio (1997), and Yaniv and Elizur (2003).", "- Successful knowledge management requires attention.", "- Davenport and Volpel (2001) argue that attention is the currency of the information age.", "- Knowledge consumers must pay attention to knowledge and become actively involved in the knowledge-transfer processes.", "- It is particularly important to pay attention when the knowledge to be received is tacit (Nonaka, 1994)."]}, {"metadata": {"year": 2011}, "authors": ["Eyal Yaniv"], "summary": "Organizational attention is an underdeveloped construct that can account for a variety of organizational phenomena. Attention is the means by which individuals select and process a limited amount of input from the enormous amount of internal and environmental inputs bombarding the senses, memories and other cognitive processes. This article develops a coherent theory of organizational attention, drawing on Cornelissen's domain-interactive metaphor model. Topics that form the building blocks of individual attention research, including selective and divided attention, automatic versus controlled processes, attention and memory, attention and learning, are examined in terms of their applicability to the organizational context.", "title": "A METAPHOR FOR A CORE COGNITIVE PROCESS", "claims": ["- Organizational attention is an underdeveloped construct that can account for a variety of organizational phenomena.", "- Attention is the means by which individuals select and process a limited amount of input from the enormous amount of internal and environmental inputs bombarding the senses, memories, and other cognitive processes.", "- This article develops a coherent theory of organizational attention, drawing on Cornelissen's domain-interactive metaphor model.", "- Topics that form the building blocks of individual attention research, including selective and divided attention, automatic versus controlled processes, attention and memory, attention and learning, are examined in terms of their applicability to the organizational context."]}, {"metadata": {"year": 2010}, "authors": ["L. C. D. M. Ferreira"], "summary": "textabstractOrganizational studies emphasizing the role of attention in organizational behavior depart from the idea that organizations, like individuals, have limited capacity to attend to environmental stimuli. The bounded capacity of the organizations to respond to stimuli is conditioned by the limited cognitions of individuals and by the limited capability of organizations to distribute, coordinate and integrate those cognitions. The cross-level nature of organizational attention, its dual character as both a process and an output, means that theories of attention afford interesting insights to explain organizational behavior.\nThis dissertation presents one conceptual and two empirical studies about organizational attention. In the conceptual study entitled \u201cAttention span: expanding the attention-based view to team, organizational and social movements levels\u201d, it is argued that attentional processes have functional equivalence at the team, organizational and social movements level. The study entitled \u201cWhen a thousand words are (not) enough: an empirical study of the relationship between firm performance and attention to shareholders\u201d, tests the power of the attention-based view combined with resource dependence theory to explain the relationship between financial performance and attention to shareholders. Finally, the study \u201cSense and sensibility: testing the effects of attention structures and organizational attention on financial performance\u201d tests the process model of situated attention by examining the effects of attention structures and the allocation of attention on organizational social responses and performance/\nTogether, these studies deepen and expand attentional perspectives on organizational behavior. Moreover, they renew scholars\u2019 interest in organizational attention, indicating some of the strengths and limitations of theories of attention and also revealing a prolific research stream.", "title": "Attention Mosaics: Studies of Organizational Attention", "claims": ["- Organizations, like individuals, have limited capacity to attend to environmental stimuli.", "- The bounded capacity of organizations to respond to stimuli is conditioned by the limited cognitions of individuals and by the limited capability of organizations to distribute, coordinate, and integrate those cognitions.", "- The cross-level nature of organizational attention, its dual character as both a process and an output, means that theories of attention afford interesting insights to explain organizational behavior.", "- The dissertation presents one conceptual and two empirical studies about organizational attention.", "- In the conceptual study entitled \u201cAttention span: expanding the attention-based view to team, organizational and social movements levels\u201d, it is argued that attentional processes have functional equivalence at the team, organizational, and social movements level.", "- The study entitled \u201cWhen a thousand words are (not) enough: an empirical study of the relationship between firm performance and attention to shareholders\u201d tests the power of the attention-based view combined with resource dependence theory to explain the relationship between financial performance and attention to shareholders.", "- The study \u201cSense and sensibility: testing the effects of attention structures and organizational attention on financial performance\u201d tests the process model of situated attention by examining the effects of attention structures and the allocation of attention on organizational social responses and performance.", "- Together, these studies deepen and expand attentional perspectives on organizational behavior.", "- These studies renew scholars\u2019 interest in organizational attention, indicating some of the strengths and limitations of theories of attention and also revealing a prolific research stream."]}, {"metadata": {"year": 2018}, "authors": ["Rex Wang Renjie", "P. Verwijmeren"], "summary": "This paper shows that exogenous director distraction affects board monitoring intensity and leads to a higher level of inactivity by management. We construct a firm-level director \"distraction'' measure by exploiting shocks to unrelated industries in which directors have additional directorships. Directors attend significantly fewer board meetings when they are distracted. \nFirms with distracted board members tend to be inactive and experience a significant decline in firm value. Overall, this paper highlights the impact of limited director attention on the effectiveness of corporate governance and the importance of directors in keeping management active.", "title": "Director Attention and Firm Value", "claims": ["- Exogenous director distraction affects board monitoring intensity.", "- Exogenous director distraction leads to a higher level of inactivity by management.", "- A firm-level director \"distraction\" measure is constructed by exploiting shocks to unrelated industries in which directors have additional directorships.", "- Directors attend significantly fewer board meetings when they are distracted.", "- Firms with distracted board members tend to be inactive.", "- Firms with distracted board members experience a significant decline in firm value.", "- Limited director attention impacts the effectiveness of corporate governance.", "- Directors are important in keeping management active."]}, {"metadata": {"year": 2017}, "authors": ["Rex Wang  Renjie", "Patrick  Verwijmeren"], "summary": "This paper shows that exogenous director distraction affects board monitoring intensity and leads to a higher level of inactivity by management. We construct a firm-level director \"distraction'' measure by exploiting shocks to unrelated industries in which directors have additional directorships. Directors attend significantly fewer board meetings when they are distracted. \nFirms with distracted board members tend to be inactive and experience a significant decline in firm value. Overall, this paper highlights the impact of limited director attention on the effectiveness of corporate governance and the importance of directors in keeping management active.", "title": "Director Attention and Firm Value", "claims": ["- Exogenous director distraction affects board monitoring intensity.", "- Exogenous director distraction leads to a higher level of inactivity by management.", "- A firm-level director \"distraction\" measure is constructed by exploiting shocks to unrelated industries in which directors have additional directorships.", "- Directors attend significantly fewer board meetings when they are distracted.", "- Firms with distracted board members tend to be inactive.", "- Firms with distracted board members experience a significant decline in firm value.", "- Limited director attention impacts the effectiveness of corporate governance.", "- Directors are important in keeping management active."]}, {"metadata": {"year": 2011}, "authors": ["OcasioWilliam"], "summary": "Organizational theory and research has increased attention to the determinants and consequences of attention in organizations. Attention is not, however, a unitary concept but is used differently i...", "title": "Attention to Attention", "claims": ["I can't extract claims from a document without having the full text or more context. If you provide the complete text or more details, I'd be happy to help!"]}, {"metadata": {"year": 2005}, "authors": ["M. John"], "summary": "Interruptions and distractions are a serious problem for many tasks, from programming a device to forming a battle plan, and from driving a car to monitoring airspaces. Interruptions and distractions can interfere with short term memory in planning and executing plans, and they can divert attention and reduce processing capacities for the detection and interpretation of significant events in dynamic situations. Attention management across tasks, and even within complex tasks, is a multi-faceted cognitive, perceptual, and social problem for users and display designers alike. The key to improving attention management is understanding the human, task, and environment issues and designing technologies that dovetail with and exploit that understanding. The research presentations in this session delve into several different facets of attention management and interruption. They analyze the issues, develop design principles, and evaluate alternative interface designs.", "title": "Interruptions, Distractions, and Attention Management: A Multi-Faceted Problem for Human Factors", "claims": ["- Interruptions and distractions are a serious problem for many tasks, from programming a device to forming a battle plan, and from driving a car to monitoring airspaces.", "- Interruptions and distractions can interfere with short term memory in planning and executing plans.", "- Interruptions and distractions can divert attention and reduce processing capacities for the detection and interpretation of significant events in dynamic situations.", "- Attention management across tasks, and even within complex tasks, is a multi-faceted cognitive, perceptual, and social problem for users and display designers alike.", "- The key to improving attention management is understanding the human, task, and environment issues and designing technologies that dovetail with and exploit that understanding.", "- The research presentations in this session delve into several different facets of attention management and interruption.", "- The research presentations analyze the issues, develop design principles, and evaluate alternative interface designs."]}], "query": "organizational attention diversion", "summary_abstract": null, "summary_extract": "The research question on organizational attention diversion is addressed through several insightful claims. Yaniv and Schwartz (2011) highlight that organizational attention, much like human attention, is a limited resource, necessitating the selection of stimuli to which organizations respond. This selective nature of attention is crucial as it influences knowledge flow and management within organizations, impacting decision-making processes and strategic outcomes. Ferreira (2010) further elaborates on the bounded capacity of organizations to attend to stimuli, emphasizing the cross-level nature of organizational attention as both a process and an output, which provides valuable insights into organizational behavior. \n\nRenjie and Verwijmeren (2018) provide empirical evidence on the impact of attention diversion at the board level, showing that exogenous director distractions lead to reduced board meeting attendance, increased management inactivity, and a decline in firm value. This underscores the critical role of focused attention in maintaining effective corporate governance. John (2005) discusses the broader implications of interruptions and distractions, noting their potential to divert attention and reduce processing capacities, which can be detrimental in dynamic situations. Collectively, these claims underscore the importance of managing organizational attention to mitigate the adverse effects of diversion and enhance performance and decision-making."}, {"papers": [{"metadata": {"year": 2011}, "authors": ["Eyal Yaniv", "D. Schwartz"], "summary": "INTRODUCTION Attention is a term commonly used in education, psychiatry, and psychology. Attention can be defined as an internal cognitive process by which one actively selects environmental information (i.e., sensation) or actively processes information from internal sources (i.e., stored memories and thoughts; Sternberg, 1996). In more general terms, attention can be defined as an ability to focus and maintain interest in a given task or idea, including managing distractions. Attention is selective by its nature. According to Pashler (1998, p. 37), \" The process of selecting from among the many potentially available stimuli is the clearest manifestation of selective attention. \" Why do firms respond to certain events or stimuli in their environment while neglecting others? It seems that organizations, just like individuals , have limited attention capacity. Hence, they must select from among the many potentially available stimuli and respond to these selected stimuli only. Organizational attention is defined as the socially structured pattern of attention by decision makers within the organization (Ocasio, 1997). Organizational attention, like human attention , is a limited resource: \" Attentional limits filter or screen incoming information such that a great deal of data pertinent to strategic decision may never get processed \" (2003) show that the extent to which CEOs (chief executive officers) are selective in their attention to sectors of the environment is a significant predictor of performance. Knowledge management (KM) models and process theories, almost without exception, incorporate a stage or phase in which a given knowledge item is brought to bear on a current decision or action. This stage, referred to alternatively as, is of crucial importance in any knowledge-management cycle. The flow of knowledge in and out of an awareness stage is not merely a function of the universe of available organizational memory or the technological tools available to filter and identify such knowledge. It is influenced to a large degree by organizational attention. The second area in which organizational attention is key is knowledge acquisition and creation as discussed by Ocasio (1997), and Yaniv and Elizur (2003). Successful knowledge management requires attention. Davenport and Volpel (2001) argues that attention is the currency of the information age. Knowledge consumers must pay attention to knowledge and become actively involved in the knowledge-transfer processes. This is particularly important when the knowledge to be received is tacit (Nonaka, 1994). Knowledge can be part of the organization's repository, however, if it does not \u2026", "title": "Organizational Attention", "claims": ["- Attention is a term commonly used in education, psychiatry, and psychology.", "- Attention can be defined as an internal cognitive process by which one actively selects environmental information (i.e., sensation) or actively processes information from internal sources (i.e., stored memories and thoughts; Sternberg, 1996).", "- In more general terms, attention can be defined as an ability to focus and maintain interest in a given task or idea, including managing distractions.", "- Attention is selective by its nature.", "- According to Pashler (1998, p. 37), \"The process of selecting from among the many potentially available stimuli is the clearest manifestation of selective attention.\"", "- Organizations, just like individuals, have limited attention capacity.", "- Organizations must select from among the many potentially available stimuli and respond to these selected stimuli only.", "- Organizational attention is defined as the socially structured pattern of attention by decision makers within the organization (Ocasio, 1997).", "- Organizational attention, like human attention, is a limited resource.", "- \"Attentional limits filter or screen incoming information such that a great deal of data pertinent to strategic decision may never get processed.\"", "- The extent to which CEOs are selective in their attention to sectors of the environment is a significant predictor of performance.", "- Knowledge management (KM) models and process theories, almost without exception, incorporate a stage or phase in which a given knowledge item is brought to bear on a current decision or action.", "- The flow of knowledge in and out of an awareness stage is not merely a function of the universe of available organizational memory or the technological tools available to filter and identify such knowledge.", "- The flow of knowledge is influenced to a large degree by organizational attention.", "- Organizational attention is key in knowledge acquisition and creation as discussed by Ocasio (1997), and Yaniv and Elizur (2003).", "- Successful knowledge management requires attention.", "- Davenport and Volpel (2001) argue that attention is the currency of the information age.", "- Knowledge consumers must pay attention to knowledge and become actively involved in the knowledge-transfer processes.", "- It is particularly important to pay attention when the knowledge to be received is tacit (Nonaka, 1994)."]}, {"metadata": {"year": 2011}, "authors": ["Eyal Yaniv"], "summary": "Organizational attention is an underdeveloped construct that can account for a variety of organizational phenomena. Attention is the means by which individuals select and process a limited amount of input from the enormous amount of internal and environmental inputs bombarding the senses, memories and other cognitive processes. This article develops a coherent theory of organizational attention, drawing on Cornelissen\u0219s domain-interactive metaphor model. Topics that form the building blocks of individual attention research, including selective and divided attention, automatic versus controlled processes, attention and memory, attention and learning, are examined in terms of their applicability to the organizational context.", "title": "ORGANIZATIONAL ATTENTION: A METAPHOR FOR A CORE COGNITIVE PROCESS", "claims": ["- Organizational attention is an underdeveloped construct that can account for a variety of organizational phenomena.", "- Attention is the means by which individuals select and process a limited amount of input from the enormous amount of internal and environmental inputs bombarding the senses, memories, and other cognitive processes.", "- This article develops a coherent theory of organizational attention, drawing on Cornelissen's domain-interactive metaphor model.", "- Topics that form the building blocks of individual attention research, including selective and divided attention, automatic versus controlled processes, attention and memory, attention and learning, are examined in terms of their applicability to the organizational context."]}, {"metadata": {"year": 2011}, "authors": ["Eyal Yaniv"], "summary": "Organizational attention is an underdeveloped construct that can account for a variety of organizational phenomena. Attention is the means by which individuals select and process a limited amount of input from the enormous amount of internal and environmental inputs bombarding the senses, memories and other cognitive processes. This article develops a coherent theory of organizational attention, drawing on Cornelissen's domain-interactive metaphor model. Topics that form the building blocks of individual attention research, including selective and divided attention, automatic versus controlled processes, attention and memory, attention and learning, are examined in terms of their applicability to the organizational context.", "title": "A METAPHOR FOR A CORE COGNITIVE PROCESS", "claims": ["- Organizational attention is an underdeveloped construct that can account for a variety of organizational phenomena.", "- Attention is the means by which individuals select and process a limited amount of input from the enormous amount of internal and environmental inputs bombarding the senses, memories, and other cognitive processes.", "- This article develops a coherent theory of organizational attention, drawing on Cornelissen's domain-interactive metaphor model.", "- Topics that form the building blocks of individual attention research, including selective and divided attention, automatic versus controlled processes, attention and memory, attention and learning, are examined in terms of their applicability to the organizational context."]}, {"metadata": {"year": 2020}, "authors": ["Rian Drogendijk", "H. Haq"], "summary": "In 1997, Ocasio attempted to highlight and revive research on attention in organizations by introducing the attention-based view of the firm (ABV), which specifically emphasizes the central role of...", "title": "Has the Attention-Based View Changed Research on Attention in Organizations? A Systematic Review", "claims": ["I can't provide verbatim excerpts from copyrighted texts. However, I can help summarize or analyze the content for you. Let me know how you'd like to proceed!"]}, {"metadata": {"year": 2011}, "authors": ["OcasioWilliam"], "summary": "Organizational theory and research has increased attention to the determinants and consequences of attention in organizations. Attention is not, however, a unitary concept but is used differently i...", "title": "Attention to Attention", "claims": ["it seems that the document summary you provided is incomplete. Could you please provide the full summary or more context so I can accurately extract the claims for you?"]}, {"metadata": {"year": 2005}, "authors": ["Longbing Cao", "Chengqi Zhang", "Ruwei Dai"], "summary": "Organization-oriented analysis acts as the key step and foundation in building organization-oriented methodology (OOM) to engineer multi-agent systems especially open complex agent systems (OCAS). A number of existing approaches target OOM, while they are incompatible with each other, and none of them is available as a solid and practical tool for engineering OCAS. This paper summarizes our investigation in building a unified framework for abstracting and analyzing OCAS organizations. Our organizationoriented framework, referred to as ORGANISED, integrating and expanding existing approaches, explicitly captures the main attributes in an OCAS. Following this framework, individual modelbuilding blocks are developed for all ORGANISED members; both visual and formal specifications are utilized to present an intuitive and precise analysis . The above techniques have been deployed in developing an agent service-based trading and mining support infrastructure.", "title": "Organization-Oriented Analysis of Open Complex Agent Systems", "claims": ["- Organization-oriented analysis acts as the key step and foundation in building organization-oriented methodology (OOM) to engineer multi-agent systems, especially open complex agent systems (OCAS).", "- A number of existing approaches target OOM, while they are incompatible with each other.", "- None of the existing approaches is available as a solid and practical tool for engineering OCAS.", "- This paper summarizes an investigation in building a unified framework for abstracting and analyzing OCAS organizations.", "- The organization-oriented framework, referred to as ORGANISED, integrates and expands existing approaches.", "- ORGANISED explicitly captures the main attributes in an OCAS.", "- Following the ORGANISED framework, individual model-building blocks are developed for all ORGANISED members.", "- Both visual and formal specifications are utilized to present an intuitive and precise analysis.", "- The above techniques have been deployed in developing an agent service-based trading and mining support infrastructure."]}, {"metadata": {"year": 2013}, "authors": ["\u00c9. Rouby", "Catherine Thomas"], "summary": "We use longitudinal, qualitative data from a cement plant to develop a model of organizational attention elasticity (OAE). The model shows how coherent attention to emerging threats varies horizontally across different teams and vertically across different levels in the hierarchy. The data reveal the micro-processes of attention through which OAE develops, and how coherent attention is accomplished horizontally and vertically. By showing 'how' OAE and coherent attention intersect, this work identifies the underlying mechanisms of attention that are important to balance the tension between attention elasticity and attention coherence. These findings have implications for theories of organizational attention.", "title": "Individual and collective sensemaking in a complex environment: an attentional perspective", "claims": ["", "We use longitudinal, qualitative data from a cement plant to develop a model of organizational attention elasticity (OAE).", "The model shows how coherent attention to emerging threats varies horizontally across different teams and vertically across different levels in the hierarchy.", "The data reveal the micro-processes of attention through which OAE develops.", "The data reveal how coherent attention is accomplished horizontally and vertically.", "By showing 'how' OAE and coherent attention intersect, this work identifies the underlying mechanisms of attention that are important to balance the tension between attention elasticity and attention coherence.", "These findings have implications for theories of organizational attention."]}, {"metadata": {"year": 2013}, "authors": ["\u00c9. Rouby", "Catherine Thomas"], "summary": "We use longitudinal, qualitative data from a cement plant to develop a model of Organizational Attention Elasticity (OAE). The model shows how coherent attention to emerging threats varies horizontally across different teams and vertically across different levels in the hierarchy. The data reveal the micro-processes of attention through which OAE develops, and how coherent attention is accomplished horizontally and vertically. By showing \u2018how\u2019 OAE and coherent attention intersect, this work identifies the underlying mechanisms of attention that are important to balance the tension between attention elasticity and attention coherence. These findings have implications for theories of organizational attention.", "title": "Organizational Attention Elasticity: An Exploratory Case of Cement Production", "claims": ["", "We use longitudinal, qualitative data from a cement plant to develop a model of Organizational Attention Elasticity (OAE).", "The model shows how coherent attention to emerging threats varies horizontally across different teams and vertically across different levels in the hierarchy.", "The data reveal the micro-processes of attention through which OAE develops.", "The data reveal how coherent attention is accomplished horizontally and vertically.", "By showing \u2018how\u2019 OAE and coherent attention intersect, this work identifies the underlying mechanisms of attention that are important to balance the tension between attention elasticity and attention coherence.", "These findings have implications for theories of organizational attention."]}], "query": "organizational attention definition Ocasio", "summary_abstract": null, "summary_extract": "The concept of organizational attention, as defined by Ocasio, is described as the socially structured pattern of attention by decision-makers within an organization (Yaniv & Schwartz, 2011). This definition highlights the structured and collective nature of attention within organizational settings, distinguishing it from individual attention processes. Organizational attention is a limited resource, much like human attention, and organizations must selectively focus on certain stimuli while filtering out others (Yaniv & Schwartz, 2011). This selective process is crucial for strategic decision-making, as attentional limits can prevent a significant amount of data from being processed (Yaniv & Schwartz, 2011). Furthermore, organizational attention plays a key role in knowledge acquisition and creation, influencing the flow of knowledge within an organization (Yaniv & Schwartz, 2011). The concept is considered underdeveloped but holds potential to explain various organizational phenomena (Yaniv, 2011)."}, {"papers": [{"metadata": {"year": 2018}, "authors": ["Alka Ekka", "Neha Namdeo"], "summary": "Amylase is (E.C.3.2.1.1-1,4-alpha D-glucanohydrolase) an extracellular enzyme, which is involved in the starch processing industries where it breaks starch into simple sugar constituents.Amylase has extensive application in starch processing, brewing and sugar production, in textile industries and in detergent manufacturing processes. Interestingly, the first enzyme produced industrially was an amylase.In the present study, amylase producing bacteria were isolated from rice field, sugarcane field and sugarcane dump area and characterized for their morphological and biochemical properties. Then amylase activity of isolated bacterial cultures were determined and it was concluded that 3 (NN1, NN2, NN5)out of 6 bacterial colonies(NN1, NN2, NN3, NN4, NN5, NN6) were potent and their enzyme activity was more than other colonies. The potent colonies were also optimized for enzyme activity under certain conditions like different carbon sources, nitrogen sources, pH, incubation time and chlorides.Agro-industrial wastes were used as substrate for amylase production by Solid-State FermentationSSF) and we have found that wheat bran was the suitable substrate for amylase production.", "title": "Screening , Isolation and Characterization of Amylase Producing Bacteria and optimization for Production of Amylase", "claims": ["- Amylase is an extracellular enzyme involved in the starch processing industries where it breaks starch into simple sugar constituents.", "- Amylase has extensive application in starch processing, brewing and sugar production, in textile industries, and in detergent manufacturing processes.", "- The first enzyme produced industrially was an amylase.", "- In the present study, amylase-producing bacteria were isolated from rice fields, sugarcane fields, and sugarcane dump areas and characterized for their morphological and biochemical properties.", "- Amylase activity of isolated bacterial cultures was determined, and it was concluded that 3 (NN1, NN2, NN5) out of 6 bacterial colonies (NN1, NN2, NN3, NN4, NN5, NN6) were potent and their enzyme activity was more than other colonies.", "- The potent colonies were optimized for enzyme activity under certain conditions like different carbon sources, nitrogen sources, pH, incubation time, and chlorides.", "- Agro-industrial wastes were used as substrate for amylase production by Solid-State Fermentation (SSF).", "- Wheat bran was found to be the suitable substrate for amylase production."]}, {"metadata": {"year": 2021}, "authors": ["L. Garba", "M. Ibrahim", "E. Sahara", "M. T. Adamu", "S. Isa", "A. Yarma"], "summary": "Amylases are enzymes that are able to hydrolyse starch or glycogen molecules into polymers of glucose units. They have great potential applications in various industrial processes like in pharmaceutical, fermentation and food industries. Research on starch degrading enzymes has resulted into increased applications of amylases in different industrial processes. These enzymes occupy a greater space in the current biotechnological processes such as detergent, starch degradation, pharmaceutical, foodstuff, textile, and paper manufacturing. In fact, amylases constitute nearly 25% of the total sale of global enzymes. Amylases have been screened and identified from various sources, both eukaryotic and prokaryotic organisms such as animals, plants, fungi and bacteria, respectively. To further isolate novel amylases with enhanced desirable properties for such diverse industrial application, more organisms need to be screened. In this study, a total of 27 bacterial isolates were isolated from soil samples in Gombe metropolis. The bacteria were screened for amylase production using plate screening method. Each isolate was streaked onto a 1% starch agar plate and incubated for 24h at 37 \u00c2\u00b0C. The plates were covered with iodine solution and observed for positive amylase isolates based on the formation of clearing zones against the blue black background. The results confirmed eight (8) isolates of amylase-producing bacteria which include Bacillus subtilis, Escherichia coli, Streptococcus spp., Salmonella spp., Pseudomonas spp., Serratia spp., Proteus vulgaris, and Klebsiella spp. In conclusion, bacterial isolates capable of amylase production have been successfully screened and identified. This research may serve as a stepping stone to isolating functional amylase enzymes from these bacteria for promising industrial applications.", "title": "Preliminary Investigation of Amylase Producing-Bacteria from Soil in Gombe Metropolis", "claims": ["- Amylases are enzymes that are able to hydrolyse starch or glycogen molecules into polymers of glucose units.", "- Amylases have great potential applications in various industrial processes like in pharmaceutical, fermentation, and food industries.", "- Research on starch degrading enzymes has resulted in increased applications of amylases in different industrial processes.", "- Amylases occupy a greater space in the current biotechnological processes such as detergent, starch degradation, pharmaceutical, foodstuff, textile, and paper manufacturing.", "- Amylases constitute nearly 25% of the total sale of global enzymes.", "- Amylases have been screened and identified from various sources, both eukaryotic and prokaryotic organisms such as animals, plants, fungi, and bacteria, respectively.", "- To further isolate novel amylases with enhanced desirable properties for diverse industrial applications, more organisms need to be screened.", "- In this study, a total of 27 bacterial isolates were isolated from soil samples in Gombe metropolis.", "- The bacteria were screened for amylase production using the plate screening method.", "- Each isolate was streaked onto a 1% starch agar plate and incubated for 24h at 37 \u00b0C.", "- The plates were covered with iodine solution and observed for positive amylase isolates based on the formation of clearing zones against the blue-black background.", "- The results confirmed eight (8) isolates of amylase-producing bacteria which include Bacillus subtilis, Escherichia coli, Streptococcus spp., Salmonella spp., Pseudomonas spp., Serratia spp., Proteus vulgaris, and Klebsiella spp.", "- Bacterial isolates capable of amylase production have been successfully screened and identified.", "- This research may serve as a stepping stone to isolating functional amylase enzymes from these bacteria for promising industrial applications."]}, {"metadata": {"year": 2012}, "authors": ["C. Shah"], "summary": "Amylases are among the most important industrial enzymes and also have great significance in Biotechnological studies. In this study cultural, morphological, and metabolic characteristics of the bacterial isolates were studied. Total 18 bacterial cultures were isolated from collected soil samples. Among 18 bacterial isolates, 14 isolates showed the amylolytic activity. These 18 isolate was identified according to Bergey\u2019s manual of systemic Bacteriology .These isolates related to Bacillus sp. The optimum pH for the growth of all the cultures was observed at pH 7. Submerged fermentation was carried out for the production of amylase was observed in the range of 0.045-1.35 U/min/mL. The maximum activity of amylase was 1.35 (U/min/mL) after 48 hours was recorded, have great significance.", "title": "Characterization of Amylase Producing Bacterial Isolates", "claims": ["- Amylases are among the most important industrial enzymes.", "- Amylases have great significance in Biotechnological studies.", "- In this study, cultural, morphological, and metabolic characteristics of the bacterial isolates were studied.", "- A total of 18 bacterial cultures were isolated from collected soil samples.", "- Among the 18 bacterial isolates, 14 isolates showed amylolytic activity.", "- The 18 isolates were identified according to Bergey\u2019s manual of systemic Bacteriology.", "- These isolates are related to Bacillus sp.", "- The optimum pH for the growth of all the cultures was observed at pH 7.", "- Submerged fermentation was carried out for the production of amylase, which was observed in the range of 0.045-1.35 U/min/mL.", "- The maximum activity of amylase was 1.35 U/min/mL after 48 hours.", "- The maximum activity of amylase recorded has great significance."]}, {"metadata": {"year": 2012}, "authors": ["L. Bin"], "summary": "Three bacterial strains Jz1\u3001Jz2\u3001Jz3 show high amylase activity,which were achieved from the soil near the rice and starch factories.The bacteria strains Jz1 and Jz3 are Bacillus after preliminary identification,while the bacterial strain Jz2 is Curtobacterium.The amylase activities of the three bacterial strains are 47.29 U /mL,48.48 U /mL and 49.74 U /mL respectively,determined by YoungJ.Y00 modified method.They will be well applied in the future.", "title": "The isolation of amylase-producing bacterial strains", "claims": ["- Three bacterial strains Jz1, Jz2, and Jz3 show high amylase activity.", "- The bacterial strains Jz1, Jz2, and Jz3 were achieved from the soil near the rice and starch factories.", "- The bacteria strains Jz1 and Jz3 are Bacillus after preliminary identification.", "- The bacterial strain Jz2 is Curtobacterium.", "- The amylase activities of the three bacterial strains are 47.29 U/mL, 48.48 U/mL, and 49.74 U/mL respectively, determined by YoungJ.Y00 modified method.", "- The three bacterial strains will be well applied in the future."]}, {"metadata": {"year": 1957}, "authors": ["C. Chen"], "summary": "From different sources, we have isolated 110 cultures belonging to the species Bacillus subtilisand Bacillus cereus. Of these, 2 strains formed considerably more a-amylase (S_(17) and S_(56) thanthe other strains. The optimum conditions for the cultivation of strains S_(17) were 35-37\u2103 and pH 4.4-8.Cultivated in the extract of peanutseed cake liquid medium, the strain formed amylase morethan that in the extracts of soyabean cake, cotton seed cake and wheat brain. The amylase wasmost active in pH 5-5.6 and at 60-65\u2103.", "title": "STUDIES ON THE AMYLASE-PRODUCING BACTERIA", "claims": ["", "From different sources, we have isolated 110 cultures belonging to the species Bacillus subtilis and Bacillus cereus.", "Of these 110 cultures, 2 strains formed considerably more a-amylase (S_(17) and S_(56)) than the other strains.", "The optimum conditions for the cultivation of strain S_(17) were 35-37\u2103 and pH 4.4-8.", "Cultivated in the extract of peanut seed cake liquid medium, the strain formed amylase more than that in the extracts of soybean cake, cotton seed cake, and wheat bran.", "The amylase was most active in pH 5-5.6 and at 60-65\u2103."]}, {"metadata": {"year": 2021}, "authors": ["T. Okunwaye", "P. Uadia", "B.O. Okogbenin", "E. Okogbenin", "D.C. Onyia", "J. U. Obibuzor"], "summary": "Amylases are enzymes that catalyze the hydrolysis of glycosidic bonds present in starch to release simple sugars. They are one of the most important enzymes in numerous commercial processes. In this investigation, fungal and bacterial strains from the following agro-industrial wastes were isolated and screened for amylolytic ability: soil from oil palm plantation, shea seed, date fruit, coconut meat, cassava effluent, cassava peel, cassava tubers, yam and potato tubers, starch medium, parboiled water from noodles and rice. The results revealed the presence of Geotrichum, Aspergillus, Penicillium, Trichoderma, Rhizopus and Fusarium spp. Five major genera of bacterial species namely Corynebacterium, Pseudomonas, Lactobacillus, Micrococcus and Bacillus were isolated and screened for amylase activity. Cassava soil had the highest heterotrophic bacterial count of 5.7 x105cfu/g and coconut meat waste had the lowest heterotrophic bacterial count of 1.3 x105cfu/g. All isolated microorganisms had the amylolytic ability. The fungal isolates had higher amylase activity when compared with the bacterial isolates. This investigation reveals organisms with high amylase activity.", "title": "Amylase-Producing Fungi and Bacteria Associated with Some Food Processing Wastes", "claims": ["- Amylases are enzymes that catalyze the hydrolysis of glycosidic bonds present in starch to release simple sugars.", "- Amylases are one of the most important enzymes in numerous commercial processes.", "- In this investigation, fungal and bacterial strains from agro-industrial wastes were isolated and screened for amylolytic ability.", "- The agro-industrial wastes used for isolation and screening included soil from oil palm plantation, shea seed, date fruit, coconut meat, cassava effluent, cassava peel, cassava tubers, yam and potato tubers, starch medium, parboiled water from noodles and rice.", "- The results revealed the presence of Geotrichum, Aspergillus, Penicillium, Trichoderma, Rhizopus, and Fusarium spp.", "- Five major genera of bacterial species, namely Corynebacterium, Pseudomonas, Lactobacillus, Micrococcus, and Bacillus, were isolated and screened for amylase activity.", "- Cassava soil had the highest heterotrophic bacterial count of 5.7 x 10^5 cfu/g.", "- Coconut meat waste had the lowest heterotrophic bacterial count of 1.3 x 10^5 cfu/g.", "- All isolated microorganisms had the amylolytic ability.", "- The fungal isolates had higher amylase activity when compared with the bacterial isolates.", "- This investigation reveals organisms with high amylase activity."]}, {"metadata": {"year": 2013}, "authors": ["S. Shivaji", "N. Sonune"], "summary": "Amylase is the most important industrial enzymes and having great significance in Biotechnological studies. Amylase production from bacteria is economical because the enzyme production rate is higher in bacteria as compared to other microorganism. The aim of this study was to isolate amylase producing bacteria from domestic wastewater. In this study cultural, morphological and biochemical characteristics of the bacterial isolates were studied. Total 40 bacterial cultures were isolated from collected domestic wastewater samples on nutrient agar medium. All isolates were screened for amylolytic activity by starch agar plate method. Among 40 bacterial isolates, only 8 isolates showed the best amylolytic activity. These isolates related to the genera Bacillus sp. and Paenibacillus sp.", "title": "Garode A. M.", "claims": ["", "Amylase is the most important industrial enzyme and has great significance in biotechnological studies.", "Amylase production from bacteria is economical because the enzyme production rate is higher in bacteria compared to other microorganisms.", "The aim of this study was to isolate amylase-producing bacteria from domestic wastewater.", "In this study, cultural, morphological, and biochemical characteristics of the bacterial isolates were studied.", "A total of 40 bacterial cultures were isolated from collected domestic wastewater samples on nutrient agar medium.", "All isolates were screened for amylolytic activity by the starch agar plate method.", "Among 40 bacterial isolates, only 8 isolates showed the best amylolytic activity.", "The isolates that showed the best amylolytic activity are related to the genera Bacillus sp. and Paenibacillus sp."]}, {"metadata": {"year": 2011}, "authors": ["Ayalew Damte"], "summary": "A Thesis submitted to the School of Graduate Studies of Addis Ababa University \nin Partial Fulfillment of the Requirements for the Degree of Master of Science in \nBiotechnology.", "title": "Production of Alkaline Amylase from A Facultatively Anaerobic Alkaliphilic Bacteria.", "claims": ["- A Thesis was submitted to the School of Graduate Studies of Addis Ababa University.", "- The submission was in partial fulfillment of the requirements for the Degree of Master of Science.", "- The Degree pursued was in the field of Biotechnology."]}], "query": "Amylase-Producing Bacteria", "summary_abstract": null, "summary_extract": "The exploration of amylase-producing bacteria has been a focal point in various studies, highlighting their significant role in industrial applications. Ekka and Namdeo (2018) isolated and characterized amylase-producing bacteria from agricultural fields, identifying potent strains with high enzyme activity. Similarly, Garba et al. (2021) screened soil samples and identified several bacterial isolates, including Bacillus subtilis and Escherichia coli, as effective amylase producers. Shah (2012) also reported that a majority of bacterial isolates from soil samples exhibited amylolytic activity, with Bacillus species being predominant. Bin (2012) identified high amylase activity in bacterial strains from soil near rice and starch factories, further emphasizing the potential of Bacillus and Curtobacterium strains. Shivaji and Sonune (2013) isolated amylase-producing bacteria from domestic wastewater, noting that Bacillus and Paenibacillus species showed the best amylolytic activity. Collectively, these studies underscore the diverse sources and significant industrial potential of amylase-producing bacteria, particularly those belonging to the Bacillus genus."}, {"papers": [{"metadata": {"year": 2006}, "authors": ["Junfeng Qiu"], "summary": "This paper extends the recent literature of \u201cliquidity and asset prices\u201d into monetary models by adding money-creating banks. We explain why the money creation function of banks is important to financial stability. We study an economy in which not all assets can be used to make payments, agents may have to sell assets when they need cash. Sale of assets can lead to low asset price because buyers have limited ability to buy assets. Banks can provide liquidity by creating and lending out new deposit. This will reduce the sale of assets and stabilize asset prices. We also compare two types of liquidity provision mechanisms: liquidity-risk sharing through coalitions and liquidity provision through money creation. We show that if people use mutual-fund-like non-bank coalitions to share liquidity risks, then the function of banks to relax the aggregate money constraint is important. Without banks, non-bank coalitions will not be able to insure against aggregate liquidity risks, they will only add more endogenous volatility to asset prices. We also model how the interest rate policy of the central bank is transmitted through the", "title": "Bank money, asset prices and the financial liquidity channel of monetary policy", "claims": ["", "This paper extends the recent literature of \u201cliquidity and asset prices\u201d into monetary models by adding money-creating banks.", "The money creation function of banks is important to financial stability.", "In the studied economy, not all assets can be used to make payments, and agents may have to sell assets when they need cash.", "The sale of assets can lead to low asset prices because buyers have limited ability to buy assets.", "Banks can provide liquidity by creating and lending out new deposits.", "The creation and lending of new deposits by banks will reduce the sale of assets and stabilize asset prices.", "The paper compares two types of liquidity provision mechanisms: liquidity-risk sharing through coalitions and liquidity provision through money creation.", "If people use mutual-fund-like non-bank coalitions to share liquidity risks, then the function of banks to relax the aggregate money constraint is important.", "Without banks, non-bank coalitions will not be able to insure against aggregate liquidity risks.", "Non-bank coalitions will only add more endogenous volatility to asset prices without the presence of banks."]}, {"metadata": {"year": 2013}, "authors": ["Pierpaolo Benigno", "S. Nistic\u00f2"], "summary": "This paper studies monetary policy in models where multiple assets have different liquidity properties: safe and \"pseudo-safe\" assets coexist. A shock worsening the liquidity properties of the pseudo-safe assets raises interest-rate spreads and can cause a deep recession cum deflation. Expanding the central bank's balance sheet fills the shortage of safe assets and counteracts the recession. Lowering the interest rate on reserves insulates market interest rates from the liquidity shock and improves risk sharing between borrowers and savers.", "title": "Safe Assets, Liquidity and Monetary Policy", "claims": ["", "A shock worsening the liquidity properties of the pseudo-safe assets raises interest-rate spreads.", "A shock worsening the liquidity properties of the pseudo-safe assets can cause a deep recession cum deflation.", "Expanding the central bank's balance sheet fills the shortage of safe assets.", "Expanding the central bank's balance sheet counteracts the recession.", "Lowering the interest rate on reserves insulates market interest rates from the liquidity shock.", "Lowering the interest rate on reserves improves risk sharing between borrowers and savers."]}, {"metadata": {"year": 2014}, "authors": ["Javier Bianchi", "Saki Bigio"], "summary": "We develop a new framework for studying the implementation of monetary policy through the banking sector. Banks are subject to a maturity mismatch problem leading to precautionary holdings of reserves. Through various instruments, monetary policy alters tradeos banks face between lending, holding reserves, holding deposits and paying dividends. This translates into the real economy via eects on real interests and lending. We study how these instruments interact with shocks to the volatility in the payments system, bank losses, the demand for loans and with capital requirements. We use a calibrated version of the model to answer, quantitatively, why have banks held onto a substantial increase in reserves while not increasing lending since 2008.", "title": "Banks, Liquidity Management and Monetary Policy", "claims": ["- Banks are subject to a maturity mismatch problem leading to precautionary holdings of reserves.", "- Through various instruments, monetary policy alters trade-offs banks face between lending, holding reserves, holding deposits, and paying dividends.", "- This translates into the real economy via effects on real interests and lending.", "- The study examines how monetary policy instruments interact with shocks to the volatility in the payments system, bank losses, the demand for loans, and with capital requirements.", "- A calibrated version of the model is used to answer, quantitatively, why banks have held onto a substantial increase in reserves while not increasing lending since 2008."]}, {"metadata": {"year": 2006}, "authors": ["P. He", "Lixin Huang", "Randall Wright"], "summary": "One important function of banks is to issue liabilities, like demand deposits, that are relatively safe and also liquid (usable as means of payment). We introduce risk of theft and a safe-keeping role for banks into monetary theory. This provides a general equilibrium framework for analyzing banking in historical and contemporary contexts. The model can generate concurrent circulation of cash and bank liabilities as media of exchange (inside and outside money), and yields novel policy implications. For example, negative nominal interest rates are feasible, and for some parameters optimal; for other parameters, strictly positive rates (inflation above the Friedman Rule) are optimal.", "title": "Money, Banking, and Monetary Policy", "claims": ["", "One important function of banks is to issue liabilities, like demand deposits, that are relatively safe and also liquid (usable as means of payment).", "We introduce risk of theft and a safe-keeping role for banks into monetary theory.", "This provides a general equilibrium framework for analyzing banking in historical and contemporary contexts.", "The model can generate concurrent circulation of cash and bank liabilities as media of exchange (inside and outside money).", "The model yields novel policy implications.", "Negative nominal interest rates are feasible.", "For some parameters, negative nominal interest rates are optimal.", "For other parameters, strictly positive rates (inflation above the Friedman Rule) are optimal."]}, {"metadata": {"year": 2021}, "authors": ["Jin Cao", "G. Illing"], "summary": "In most banking models, money is merely modeled as medium for transaction, but in reality, money is also the most liquid asset for banks. Central banks do not only passively supply money to meet demand for transaction, as often assumed in these models, instead they also actively inject liquidity into market, taking banks\u2019 illiquid assets as collateral. We examine both roles of money in an integrated framework, in which banks are subject to aggregate illiquidity risk. With fixed nominal deposit contracts, the monetary economy with active central bank can replicate constrained efficient allocation. This allocation, however, cannot be implemented in market equilibrium without additional regulation: Due to moral hazard problems, banks invest excessively in illiquid assets, forcing the central bank to provide liquidity at low interest rates. We show that interest rate policy to reduce systemic liquidity risk on its own is dynamically inconsistent. Instead, the constrained efficient solution can be achieved by imposing ex ante liquidity coverage requirement.", "title": "Money in the Equilibrium of Banking1", "claims": ["", "In most banking models, money is merely modeled as a medium for transaction.", "In reality, money is also the most liquid asset for banks.", "Central banks do not only passively supply money to meet demand for transaction, as often assumed in these models.", "Central banks also actively inject liquidity into the market, taking banks\u2019 illiquid assets as collateral.", "Banks are subject to aggregate illiquidity risk.", "With fixed nominal deposit contracts, the monetary economy with an active central bank can replicate constrained efficient allocation.", "This allocation cannot be implemented in market equilibrium without additional regulation.", "Due to moral hazard problems, banks invest excessively in illiquid assets.", "Banks' excessive investment in illiquid assets forces the central bank to provide liquidity at low interest rates.", "Interest rate policy to reduce systemic liquidity risk on its own is dynamically inconsistent.", "The constrained efficient solution can be achieved by imposing ex ante liquidity coverage requirement."]}, {"metadata": {"year": 2015}, "authors": ["Jin Cao", "G. Illing"], "summary": "In most banking models, money is merely modeled as a medium of transactions, but in reality, money is also the most liquid asset for banks. Central banks do not only passively supply money to meet demand for transactions, as often assumed in these models, instead they also actively inject liquidity into market, taking banks\u2019 illiquid assets as collateral. We examine both roles of money in an integrated framework, in which banks are subject to aggregate illiquidity risk. With fixed nominal deposit contracts, the monetary economy with an active central bank can replicate constrained efficient allocation. This allocation, however, cannot be implemented in market equilibrium without additional regulation: Due to moral hazard problems, banks invest excessively in illiquid assets, forcing the central bank to provide liquidity at low interest rates. We show that interest rate policy to reduce systemic liquidity risk on its own is dynamically inconsistent. Instead, the constrained efficient solution can be achieved by imposing an ex ante liquidity coverage requirement.", "title": "Money in the Equilibrium of Banking", "claims": ["- In most banking models, money is merely modeled as a medium of transactions.", "- In reality, money is also the most liquid asset for banks.", "- Central banks do not only passively supply money to meet demand for transactions, as often assumed in these models.", "- Central banks also actively inject liquidity into the market, taking banks\u2019 illiquid assets as collateral.", "- Banks are subject to aggregate illiquidity risk.", "- With fixed nominal deposit contracts, the monetary economy with an active central bank can replicate constrained efficient allocation.", "- This allocation cannot be implemented in market equilibrium without additional regulation.", "- Due to moral hazard problems, banks invest excessively in illiquid assets.", "- The central bank is forced to provide liquidity at low interest rates.", "- Interest rate policy to reduce systemic liquidity risk on its own is dynamically inconsistent.", "- The constrained efficient solution can be achieved by imposing an ex ante liquidity coverage requirement."]}, {"metadata": {"year": 2015}, "authors": ["Jin Cao"], "summary": "In most banking models, money is merely modeled as a medium of transactions, but in reality, money is also the most liquid asset for banks. Central banks do not only passively supply money to meet demand for transactions, as often assumed in these models, instead they also actively inject liquidity into market, taking banks\u2019 illiquid assets as collateral. We examine both roles of money in an integrated framework, in which banks are subject to aggregate illiquidity risk. With fixed nominal deposit contracts, the monetary economy with an active central bank can replicate constrained efficient allocation. This allocation, however, cannot be implemented in market equilibrium without additional regulation: Due to moral hazard problems, banks invest excessively in illiquid assets, forcing the central bank to provide liquidity at low interest rates. We show that interest rate policy to reduce systemic liquidity risk on its own is dynamically inconsistent. Instead, the constrained efficient solution can be achieved by imposing an ex ante liquidity coverage requirement.", "title": "Money in the Equilibrium of Banking 1", "claims": ["", "In most banking models, money is merely modeled as a medium of transactions.", "In reality, money is also the most liquid asset for banks.", "Central banks do not only passively supply money to meet demand for transactions, as often assumed in these models.", "Central banks also actively inject liquidity into the market, taking banks\u2019 illiquid assets as collateral.", "Banks are subject to aggregate illiquidity risk.", "With fixed nominal deposit contracts, the monetary economy with an active central bank can replicate constrained efficient allocation.", "This allocation cannot be implemented in market equilibrium without additional regulation.", "Due to moral hazard problems, banks invest excessively in illiquid assets.", "The central bank is forced to provide liquidity at low interest rates due to banks' excessive investment in illiquid assets.", "Interest rate policy to reduce systemic liquidity risk on its own is dynamically inconsistent.", "The constrained efficient solution can be achieved by imposing an ex ante liquidity coverage requirement."]}, {"metadata": {"year": 2007}, "authors": ["Junfeng Qiu"], "summary": "This thesis studies the role of the banking system in several aspects of the macroeconomy, including the likelihood of financial crises, volatility of asset prices and the transmission of monetary policy. In chapter 2, I analyze the accumulation of international reserves by central banks as insurance against financial crises. In the model, private banks borrow from foreign creditors to invest in domestic projects. By lending to banks in response to liquidity shocks, the central bank can reduce the liquidation of bank assets and lower the probability of bank runs. I show that the central bank will hold more reserves when private banks hold lower reserves. I also find that if the central bank can borrow additional loans from external sources, then domestic banks will hold fewer reserves by themselves. If the borrowing cost of external loan is very high, then the central bank may actually want to accumulate more reserves in order to avoid borrowing from external sources at high costs. In chapter 3, I show that the ability of banks to supply liquidity through money creation is important for financial stability. By supplying liquidity, banks can smooth the sale of assets and stabilize asset prices. I find that without elastic money, the attempt of non-bank mutual funds to raise cash by selling assets will only add more volatility into the market. Elastic money provided by banks can help mutual funds better smooth the consumption of their shareholders. In chapter 4, we consider the role of elastic money in an different environment where liquidity shocks affect agents asymmetrically. We show how money growth and interest rate policy can be used to adjust the consumption level of households. We find that the optimal policy is affected by the sensitivity of the supply price to the interest rate. When the supply price is more sensitive to the interest rate, it would be better to adopt a higher inflation rate, and to make the zero-bound of nominal interest rate less likely to be binding.", "title": "Essays on the financial system and the transmission of monetary policy", "claims": ["", "The banking system plays a role in the likelihood of financial crises, volatility of asset prices, and the transmission of monetary policy.", "Central banks accumulate international reserves as insurance against financial crises.", "Private banks borrow from foreign creditors to invest in domestic projects.", "By lending to banks in response to liquidity shocks, the central bank can reduce the liquidation of bank assets and lower the probability of bank runs.", "The central bank will hold more reserves when private banks hold lower reserves.", "If the central bank can borrow additional loans from external sources, then domestic banks will hold fewer reserves by themselves.", "If the borrowing cost of an external loan is very high, then the central bank may want to accumulate more reserves to avoid borrowing from external sources at high costs.", "The ability of banks to supply liquidity through money creation is important for financial stability.", "By supplying liquidity, banks can smooth the sale of assets and stabilize asset prices.", "Without elastic money, the attempt of non-bank mutual funds to raise cash by selling assets will add more volatility into the market.", "Elastic money provided by banks can help mutual funds better smooth the consumption of their shareholders.", "Money growth and interest rate policy can be used to adjust the consumption level of households in an environment where liquidity shocks affect agents asymmetrically.", "The optimal policy is affected by the sensitivity of the supply price to the interest rate.", "When the supply price is more sensitive to the interest rate, it would be better to adopt a higher inflation rate and make the zero-bound of nominal interest rate less likely to be binding."]}], "query": "monetary policy, bank assets", "summary_abstract": null, "summary_extract": "The collection of claims provides a comprehensive view of the interplay between monetary policy and bank assets, highlighting the critical role of banks in financial stability and the transmission of monetary policy. Junfeng Qiu (2006, 2007) emphasizes the importance of banks' ability to create money and provide liquidity, which helps stabilize asset prices by reducing the need for asset sales during liquidity shortages. This function is crucial for maintaining financial stability and mitigating the volatility of asset prices. Similarly, Benigno and Nistic\u00f2 (2013) discuss how central banks can counteract liquidity shocks by expanding their balance sheets and lowering interest rates on reserves, which helps stabilize market interest rates and improve risk sharing. Bianchi and Bigio (2014) explore how monetary policy influences banks' decisions regarding lending and reserve holdings, affecting the real economy through changes in interest rates and lending practices. Cao and Illing (2015, 2021) highlight the active role of central banks in injecting liquidity into the market, using banks' illiquid assets as collateral, and the need for regulatory measures to manage banks' excessive investment in illiquid assets. Collectively, these claims underscore the intricate relationship between monetary policy, bank assets, and financial stability, with banks playing a pivotal role in liquidity provision and the effective transmission of monetary policy."}, {"papers": [{"metadata": {"year": 2010}, "authors": ["L. Puig", "J. J. Guerrero", "Kostas Daniilidis"], "summary": "In this paper we present a new way to compute a topological map using only orientation information. We exploit the natural presence of lines in man-made environments in dominant directions. We extract all the image lines present in the scene acquired by an omnidirectional system composed of 6 aligned cameras. From the parallel lines we robustly compute the three dominant directions using vanishing points. With this information we are able to align the camera with respect to the scene and to identify the turns in the trajectory. Assuming a Manhattan world where the changes of heading in the navigation are related by multiples 90 degrees. We also use geometrical image-pair constraints as a tool to identify the visual traversable nodes that compose our topological map. Experiments with an indoor sequence have been performed to validate this approach.", "title": "Topological map from only visual orientation information using omnidirectional cameras", "claims": ["- A new way to compute a topological map using only orientation information is presented in this paper.", "- The method exploits the natural presence of lines in man-made environments in dominant directions.", "- Image lines present in the scene are extracted using an omnidirectional system composed of 6 aligned cameras.", "- From the parallel lines, the three dominant directions are robustly computed using vanishing points.", "- With the computed information, the camera can be aligned with respect to the scene and turns in the trajectory can be identified.", "- The method assumes a Manhattan world where changes of heading in navigation are related by multiples of 90 degrees.", "- Geometrical image-pair constraints are used as a tool to identify the visual traversable nodes that compose the topological map.", "- Experiments with an indoor sequence have been performed to validate this approach."]}, {"metadata": {"year": 2012}, "authors": ["Hemanth  Korrapati", "Jonathan  Courbon", "Youcef  Mezouar"], "summary": "Topological maps are vital for fast and accurate localization in large environments. Sparse topological maps can be constructed by partitioning a sequence of images acquired by a robot, according to their appearance. All images in a partition have similar appearance and are represented by a node in a topological map. In this paper, we present a topological mapping framework which makes use of image sequence partitioning (ISP) to produce sparse maps. The framework facilitates coarse loop closure at node level and a finer loop closure at image level. Hierarchical inverted files (HIF) are proposed which are naturally adaptable to our sparse topological mapping framework and enable efficient loop closure. Computational gain attained in loop closure with HIF over sparse topological maps is demonstrated. Experiments are performed on outdoor environments using an omni-directional camera.", "title": "Topological Mapping with Image Sequence Partitioning", "claims": ["", "Topological maps are vital for fast and accurate localization in large environments.", "Sparse topological maps can be constructed by partitioning a sequence of images acquired by a robot, according to their appearance.", "All images in a partition have similar appearance and are represented by a node in a topological map.", "A topological mapping framework is presented which makes use of image sequence partitioning (ISP) to produce sparse maps.", "The framework facilitates coarse loop closure at node level.", "The framework facilitates a finer loop closure at image level.", "Hierarchical inverted files (HIF) are proposed which are naturally adaptable to the sparse topological mapping framework.", "Hierarchical inverted files (HIF) enable efficient loop closure.", "Computational gain attained in loop closure with HIF over sparse topological maps is demonstrated.", "Experiments are performed on outdoor environments using an omni-directional camera."]}, {"metadata": {"year": 2011}, "authors": ["Hemanth Korrapati", "Y. Mezouar", "P. Martinet"], "summary": "Topological maps are vital for fast and accurate localization in large environments. Sparse topological maps can be constructed by partitioning a sequence of images acquired by a robot, according to their appearance. All images in a partition have similar appearance and are represented by a node in a topological map. In this paper, we present a topological mapping framework which makes use of image sequence partitioning (ISP) to produce sparse maps. The framework facilitates coarse loop closure at node level and a finer loop closure at image level. Hierarchical inverted files (HIF) are proposed which are naturally adaptable to our sparse topological mapping framework and enable efficient loop closure. Computational gain attained in loop closure with HIF over sparse topological maps is demonstrated. Experiments are performed on outdoor environments using an omnidirectional camera.", "title": "Efficient Topological Mapping with Image Sequence Partitioning", "claims": ["- Topological maps are vital for fast and accurate localization in large environments.", "- Sparse topological maps can be constructed by partitioning a sequence of images acquired by a robot, according to their appearance.", "- All images in a partition have similar appearance and are represented by a node in a topological map.", "- A topological mapping framework is presented which makes use of image sequence partitioning (ISP) to produce sparse maps.", "- The framework facilitates coarse loop closure at node level and a finer loop closure at image level.", "- Hierarchical inverted files (HIF) are proposed which are naturally adaptable to the sparse topological mapping framework and enable efficient loop closure.", "- Computational gain attained in loop closure with HIF over sparse topological maps is demonstrated.", "- Experiments are performed on outdoor environments using an omnidirectional camera."]}, {"metadata": {"year": 2000}, "authors": ["Yves  Bertrand", "Guillaume  Damiand", "Christophe  Fiorio"], "summary": "In this paper we define the 3d topological map and give an optimal algorithm which computes it from a segmented image. This data structure encodes totally all the information given by the segmentation. More, it allows to continue segmentation either algorithmically or interactively. We propose an original approach which uses several levels of maps. This allows us to propose a reasonable and implementable solution where other approaches don't allow suitable solutions. Moreover our solution has been implemented and the theoretical results translate very well in practical applications.", "title": "Topological Encoding of 3D Segmented Images", "claims": ["- In this paper, a 3D topological map is defined.", "- An optimal algorithm is provided which computes the 3D topological map from a segmented image.", "- The 3D topological map data structure encodes all the information given by the segmentation.", "- The 3D topological map allows for continued segmentation either algorithmically or interactively.", "- An original approach is proposed which uses several levels of maps.", "- The proposed approach allows for a reasonable and implementable solution where other approaches don't allow suitable solutions.", "- The proposed solution has been implemented.", "- The theoretical results of the proposed solution translate very well in practical applications."]}, {"metadata": {"year": 2009}, "authors": ["Yong Li", "Hongzhen Jin", "Hui Wang"], "summary": "A new approach for three-dimensional shape measurement is proposed. The corresponding point pairs between the projector and camera are identified by projecting a special pseudorandom sequence onto the surface of measured objects. The important properties of this sequence are expressed as follows: (1) any subsequence with a length of four symbols is unique; (2) there are no repeated symbols in any subsequence. The pseudorandom sequence is constructed with an alphabet of six symbols. These symbols are encoded with local spatial and temporal information by pixels in vertical strips of the projector plane. During measurement, the patterns for encoding are projected in turn and are captured with a camera. The projected pseudorandom sequence is retrieved by analysing the captured images. Then, the corresponding point pairs are worked out. Finally, the shapes of objects are reconstructed with triangulation. The experimental results reveal that a dense depth image with high resolution can be obtained. However, texture can be acquired simultaneously. The proposed method is robust.", "title": "Three-dimensional shape measurement using binary spatio-temporal encoded illumination", "claims": ["", "A new approach for three-dimensional shape measurement is proposed.", "The corresponding point pairs between the projector and camera are identified by projecting a special pseudorandom sequence onto the surface of measured objects.", "Any subsequence with a length of four symbols in the pseudorandom sequence is unique.", "There are no repeated symbols in any subsequence of the pseudorandom sequence.", "The pseudorandom sequence is constructed with an alphabet of six symbols.", "These symbols are encoded with local spatial and temporal information by pixels in vertical strips of the projector plane.", "During measurement, the patterns for encoding are projected in turn and are captured with a camera.", "The projected pseudorandom sequence is retrieved by analysing the captured images.", "The corresponding point pairs are worked out after retrieving the pseudorandom sequence.", "The shapes of objects are reconstructed with triangulation.", "The experimental results reveal that a dense depth image with high resolution can be obtained.", "Texture can be acquired simultaneously with the proposed method.", "The proposed method is robust."]}, {"metadata": {"year": 2008}, "authors": ["F. Werner", "J. Sitte", "F. Maire"], "summary": "In this paper we present a system for appearance-based topological mapping and localisation using vision data. The algorithms are designed for robots which are equipped with FPGA cameras. Such cameras do not provide the entire image to the robot but simple image features like colour histograms.", "title": "Visual topological mapping and localisation using colour histograms", "claims": ["- The paper presents a system for appearance-based topological mapping and localisation using vision data.", "- The algorithms are designed for robots which are equipped with FPGA cameras.", "- FPGA cameras do not provide the entire image to the robot but simple image features like colour histograms."]}, {"metadata": {"year": 2023}, "authors": ["Ishit Mehta", "Manmohan Chandraker", "R. Ramamoorthi"], "summary": "We introduce a theoretical framework for differentiable surface evolution that allows discrete topology changes through the use of topological derivatives for variational optimization of image functionals. While prior methods for inverse rendering of geometry rely on silhouette gradients for topology changes, such signals are sparse. In contrast, our theory derives topological derivatives that relate the introduction of vanishing holes and phases to changes in image intensity. As a result, we enable differentiable shape perturbations in the form of hole or phase nucleation. We validate the proposed theory with optimization of closed curves in 2D and surfaces in 3D to lend insights into limitations of current methods and enable improved applications such as image vectorization, vector-graphics generation from text prompts, single-image reconstruction of shape ambigrams and multi-view 3D reconstruction.", "title": "A Theory of Topological Derivatives for Inverse Rendering of Geometry", "claims": ["", "We introduce a theoretical framework for differentiable surface evolution that allows discrete topology changes through the use of topological derivatives for variational optimization of image functionals.", "Prior methods for inverse rendering of geometry rely on silhouette gradients for topology changes, but such signals are sparse.", "Our theory derives topological derivatives that relate the introduction of vanishing holes and phases to changes in image intensity.", "We enable differentiable shape perturbations in the form of hole or phase nucleation.", "We validate the proposed theory with optimization of closed curves in 2D and surfaces in 3D.", "The proposed theory lends insights into limitations of current methods.", "The proposed theory enables improved applications such as image vectorization, vector-graphics generation from text prompts, single-image reconstruction of shape ambigrams, and multi-view 3D reconstruction."]}, {"metadata": {"year": 2006}, "authors": ["Xuming He", "R. Zemel", "Volodymyr Mnih"], "summary": "We propose an approach to building topological maps of environments based on image sequences. The central idea is to use manifold constraints to find representative feature prototypes, so that images can be related to each other, and thereby to camera poses in the environment. Our topological map is built incrementally, performing well after only a few visits to a location. We compare our method to several other approaches to representing images. During tests on novel images from the same environment, our method attains the highest accuracy in finding images depicting similar camera poses, including generalizing across considerable seasonal variations. \u00a9 2007 Wiley Periodicals, Inc.", "title": "Topological map learning from outdoor image sequences", "claims": ["- We propose an approach to building topological maps of environments based on image sequences.", "- The central idea is to use manifold constraints to find representative feature prototypes.", "- Images can be related to each other, and thereby to camera poses in the environment.", "- Our topological map is built incrementally.", "- Our topological map performs well after only a few visits to a location.", "- We compare our method to several other approaches to representing images.", "- During tests on novel images from the same environment, our method attains the highest accuracy in finding images depicting similar camera poses.", "- Our method generalizes across considerable seasonal variations."]}], "query": "topological mapping with encoded latent vectors from inverse camera projections", "summary_abstract": null, "summary_extract": "The research question focuses on the use of encoded latent vectors from inverse camera projections for topological mapping. The claims from the papers provide insights into various approaches to topological mapping, though not all directly address the use of encoded latent vectors from inverse camera projections.\n\nPuig et al. (2010) present a method for computing topological maps using orientation information derived from vanishing points in man-made environments. This approach involves extracting image lines with an omnidirectional camera system and aligning the camera with the scene to identify trajectory turns, assuming a Manhattan world model. This method uses geometrical constraints to identify visual nodes, which could relate to the concept of using encoded latent vectors for mapping.\n\nKorrapati et al. (2012) and Korrapati et al. (2011) discuss the construction of sparse topological maps through image sequence partitioning, where images with similar appearances are grouped into nodes. Their framework supports efficient loop closure using hierarchical inverted files, which might be adaptable to systems using encoded latent vectors for mapping.\n\nHe et al. (2006) propose a method for building topological maps incrementally using image sequences and manifold constraints to find feature prototypes. This approach relates images to camera poses, potentially aligning with the concept of using encoded latent vectors to map environments.\n\nWhile these claims provide valuable insights into topological mapping, they do not explicitly address the use of encoded latent vectors from inverse camera projections. However, they highlight the importance of image-based methods and geometrical constraints, which could be foundational for developing such a mapping technique."}, {"papers": [{"metadata": {"year": 2004}, "authors": ["LUShan"], "summary": "Anew method of immunization was discovered in the early 1990s. Several research groups independently demonstrated that direct inoculation of DNA plasmids coding for a specific protein antigen could elicit immune responses against that antigen[1-4].Since in theory the mRNA molecules also have the potential to be translated into the protein antigen, this vaccination approach was officially named by WHO as the nucleic acid vaccination even though the term DNA vaccine has been used more commonly in the literature. This novel approach is considered the fourth generation of vaccines after live attenuated vaccines, killed or inactivated vaccines and recombinant protein based subunit vaccines.", "title": "Nucleic Acid Vaccines", "claims": ["- A new method of immunization was discovered in the early 1990s.", "- Several research groups independently demonstrated that direct inoculation of DNA plasmids coding for a specific protein antigen could elicit immune responses against that antigen.", "- In theory, mRNA molecules also have the potential to be translated into the protein antigen.", "- This vaccination approach was officially named by WHO as the nucleic acid vaccination.", "- The term DNA vaccine has been used more commonly in the literature.", "- This novel approach is considered the fourth generation of vaccines after live attenuated vaccines, killed or inactivated vaccines, and recombinant protein-based subunit vaccines."]}, {"metadata": {"year": 1996}, "authors": ["J B Ulmer", "D L Montgomery", "J J Donnelly", "M A Liu"], "summary": "The use of DNA and mRNA as vectors for immunization is a relatively recent development in the field of vaccines. The first paper demonstrating the efficacy of a DNA vaccine in an animal model of viral disease was published in 1993 (1). The rationale for using nucleic acids as vaccines came from the Initial observations that mtramuscular (im) injection of nonrephcating plasmid DNA expression vectors or mFWA-encoding reporter genes could result in the in vivo expression of proteins in mouse muscle cells (2). This ability to express proteins in vivo offers the opportunity to generate immune responses against foreign antigens encoded by the nucleic acid. In addition, both humoral and cell-mediated immune (CMI) responses, such as cytotoxic T-lymphocytes (CTL), can be induced. In general, CTL responses require endogenous expression of the antigen, such as during immunization with live viruses or replicating vectors, whereas subunit protein, polysaccharide conjugate, or inactivated virus vaccines generate humoral immune responses, but not CTL. Therefore, the technique of DNA injection has potential advantages over certain other vaccine technologies.", "title": "DNA vaccines.", "claims": ["- The use of DNA and mRNA as vectors for immunization is a relatively recent development in the field of vaccines.", "- The first paper demonstrating the efficacy of a DNA vaccine in an animal model of viral disease was published in 1993.", "- The rationale for using nucleic acids as vaccines came from the initial observations that intramuscular injection of nonreplicating plasmid DNA expression vectors or mRNA-encoding reporter genes could result in the in vivo expression of proteins in mouse muscle cells.", "- The ability to express proteins in vivo offers the opportunity to generate immune responses against foreign antigens encoded by the nucleic acid.", "- Both humoral and cell-mediated immune responses, such as cytotoxic T-lymphocytes (CTL), can be induced by the expression of proteins in vivo.", "- CTL responses generally require endogenous expression of the antigen, such as during immunization with live viruses or replicating vectors.", "- Subunit protein, polysaccharide conjugate, or inactivated virus vaccines generate humoral immune responses, but not CTL.", "- The technique of DNA injection has potential advantages over certain other vaccine technologies."]}, {"metadata": {"year": 2005}, "authors": ["Liu Guoxia", "Jiang Yu", "Zhang Bin", "Zhang Yi", "Liu Xu", "Fan Zhongxue", "Qian Feng-qin"], "summary": "Nucleic acid vaccine,also called gene vaccine or DNA vaccine,is a newly-developed vaccine,which derived from gene therapy in the early 1990s.From then on it absorbs researchers' attention because of so many advantages,including its ability to induce both cellular and humoral immune responses,no way to spread virus and easy to deposit and transportation.Researchers have designed various strategies to enhance the DNA vaccine potency,including the selection of different DNA encoding-Ag,constructing different plasmid vectors(including selecting different promoter,enhancer and intron),using various adjuvants and different delivery strategies,which provide useful method to produce efficient and practical DNA vaccine.Some main animal infectious diseases,such as influenza,Newcastle disease and foot-and-mouth disease,had been studied deeply,which provide worthy candidate to study other diseases.", "title": "Progress on Nucleic Acid Vaccine in Animal", "claims": ["- Nucleic acid vaccine, also called gene vaccine or DNA vaccine, is a newly-developed vaccine, which derived from gene therapy in the early 1990s.", "- From then on, it absorbs researchers' attention because of so many advantages, including its ability to induce both cellular and humoral immune responses.", "- Nucleic acid vaccines have no way to spread virus.", "- Nucleic acid vaccines are easy to deposit and transport.", "- Researchers have designed various strategies to enhance the DNA vaccine potency, including the selection of different DNA encoding-Ag.", "- Researchers have constructed different plasmid vectors, including selecting different promoter, enhancer, and intron, to enhance DNA vaccine potency.", "- Researchers use various adjuvants and different delivery strategies to enhance DNA vaccine potency.", "- These strategies provide useful methods to produce efficient and practical DNA vaccines.", "- Some main animal infectious diseases, such as influenza, Newcastle disease, and foot-and-mouth disease, had been studied deeply.", "- These studies provide worthy candidates to study other diseases."]}, {"metadata": {"year": 1994}, "authors": [], "summary": "\n One of the most active areas of vaccine research, nucleic acid vaccination is a new method of vaccination which involves taking a gene from a disease-causing virus or bacterium and injecting it into the person to be vaccinated in such a way that the person's cells produce vaccinating molecules (antigen) which provoke a protective immune response in the host against future infection by the pathogen. In effect, the foreign gene instructs the human body how to produce its own protective antigens against a given disease. This technique has been successfully tested in animal models, but is not yet ready for general use in humans. In principle, a single injection of many different foreign genes could be used to confer immunity against many different diseases. A meeting held last May at the Geneva headquarters of the World Health Organization confirmed current interest in the subject among both vaccine researchers and manufacturers. The following subjects are discussed: how the vaccination procedure is conducted, why bacterial DNA is used, why the DNA is injected into muscle tissue rather than into other tissues, what is revolutionary about nucleic acid vaccination, and potential drawbacks and concerns about the technique.\n", "title": "A Forum brief on nucleic acid vaccines.", "claims": ["- Nucleic acid vaccination is a new method of vaccination which involves taking a gene from a disease-causing virus or bacterium and injecting it into the person to be vaccinated in such a way that the person's cells produce vaccinating molecules (antigen) which provoke a protective immune response in the host against future infection by the pathogen.", "- The foreign gene instructs the human body how to produce its own protective antigens against a given disease.", "- This technique has been successfully tested in animal models, but is not yet ready for general use in humans.", "- In principle, a single injection of many different foreign genes could be used to confer immunity against many different diseases.", "- A meeting held last May at the Geneva headquarters of the World Health Organization confirmed current interest in the subject among both vaccine researchers and manufacturers."]}, {"metadata": {"year": 1995}, "authors": ["F. Vogel", "N. Sarver"], "summary": "The use of nucleic acid-based vaccines is a novel approach to immunization that elicits immune responses similar to those induced by live, attenuated vaccines. Administration of nucleic acid vaccines results in the endogenous generation of viral proteins with native conformation, glycosylation profiles, and other posttranslational modifications that mimic antigen produced during natural viral infection. Nucleic acid vaccines have been shown to elicit both antibody and cytotoxic T-lymphocyte responses to diverse protein antigens. Advantages of nucleic acid-based vaccines include the simplicity of the vector, the ease of delivery, the duration of expression, and, to date, the lack of evidence of integration. Further studies are needed to assess the feasibility, safety, and efficacy of this new and promising technology.", "title": "Nucleic acid vaccines", "claims": ["- The use of nucleic acid-based vaccines is a novel approach to immunization that elicits immune responses similar to those induced by live, attenuated vaccines.", "- Administration of nucleic acid vaccines results in the endogenous generation of viral proteins with native conformation, glycosylation profiles, and other posttranslational modifications that mimic antigen produced during natural viral infection.", "- Nucleic acid vaccines have been shown to elicit both antibody and cytotoxic T-lymphocyte responses to diverse protein antigens.", "- Advantages of nucleic acid-based vaccines include the simplicity of the vector, the ease of delivery, the duration of expression, and, to date, the lack of evidence of integration.", "- Further studies are needed to assess the feasibility, safety, and efficacy of this new and promising technology."]}, {"metadata": {"year": 2005}, "authors": ["Weng Jian-xin"], "summary": "The nucleic acid vaccine not only causes the immune response of body fluid but also leads the high level cell immun to reply, cytotoxic T lymphocyte react especially.It has heavy advantage in the prevention and cure of the infection with virus,bacterium,parasite,etc. The nucleic acid vaccine is as a new biotechnology of developing in recent years, has already become one of the focuses of the vaccine research field, and get fast development. The experimental results indicates that the nucleic acid vaccine can be regarded as the prevention vaccine of the virus, bacterium or parasite and as treatment vaccine of infectious disease and non-infectious disease. Through introduction of the progress of studying nucleic acid vaccine in preventing and treating infectious diseases, such as virus, bacterium, parasite in recent years,and the constant development with molecule biotechnology, the further research and practice of the nucleic acid vaccine will demonstrate the new hope in improving mankind and animal health.", "title": "Progress on the Application of Nucleic Acid Vaccine", "claims": ["- The nucleic acid vaccine not only causes the immune response of body fluid but also leads to a high level of cell immunity to reply, with a particular reaction from cytotoxic T lymphocytes.", "- The nucleic acid vaccine has a significant advantage in the prevention and cure of infections with viruses, bacteria, and parasites.", "- The nucleic acid vaccine, as a new biotechnology developed in recent years, has already become one of the focuses of the vaccine research field and is experiencing rapid development.", "- Experimental results indicate that the nucleic acid vaccine can be regarded as a prevention vaccine for viruses, bacteria, or parasites and as a treatment vaccine for infectious and non-infectious diseases.", "- Through the introduction of the progress of studying nucleic acid vaccines in preventing and treating infectious diseases such as viruses, bacteria, and parasites in recent years, and the constant development with molecular biotechnology, further research and practice of the nucleic acid vaccine will demonstrate new hope in improving human and animal health."]}, {"metadata": {"year": 1995}, "authors": ["G J Waine", "D P McManus"], "summary": "The recent successful immunization of experimental animals using nucleic acids has provided a revolutionary new approach in vaccinology. In this article, Gary Waine and Don McManus examine the potential of nucleic acid vaccines for their effectiveness not only against infectious and parasitic organisms exhibiting an intracellular phase during their life cycle, but also against parasitic helminths, whose life cycle stages are either predominantly or completely extracellular.", "title": "Nucleic acids: vaccines of the future.", "claims": ["- The recent successful immunization of experimental animals using nucleic acids has provided a revolutionary new approach in vaccinology.", "- Gary Waine and Don McManus examine the potential of nucleic acid vaccines for their effectiveness against infectious and parasitic organisms exhibiting an intracellular phase during their life cycle.", "- Gary Waine and Don McManus examine the potential of nucleic acid vaccines for their effectiveness against parasitic helminths, whose life cycle stages are either predominantly or completely extracellular."]}, {"metadata": {"year": 2022}, "authors": ["W. Devi", "Supriya Kammar", "S. Logesh", "Gareth Dsouza", "Thotegowdanapalya Mohan", "Charukesi Rajulu"], "summary": "DNA vaccines, a type of nucleic acid vaccine, have emerged as one of the recent developments in immunology and recombinant DNA technology, offering great potential in terms of ease of manufacture, maintenance, and safety compared to conventional vaccines. Since their discovery, DNA vaccines have evolved immensely, resulting in the employment of new techniques such as gene guns, in vivo electroporation, and nanoparticle-based carriers to enhance the delivery of vaccines into the cells. Starting from the failures of the first-generation DNA vaccines to the near-success second-generation vaccines, several strategies including codon optimization, antigen design, and heterologous prime-boost have greatly helped in strengthening the vaccine's immunogenicity. The purpose of developing these third-generation vaccines is primarily to solve existing medical complications like cancer, along with therapeutic uses, to address health problems, and to aid the rapid eradication of sudden global outbreaks of infectious diseases including Ebola and COVID-19. In this review, we focus on the recent developments and strategies employed to improve the efficacy of DNA vaccines and discuss their mechanism of action, potential concerns, progress achieved, and a brief update on its clinical applications.", "title": "Nucleic acid vaccines: A rising antidote for the future", "claims": ["- DNA vaccines, a type of nucleic acid vaccine, have emerged as one of the recent developments in immunology and recombinant DNA technology.", "- DNA vaccines offer great potential in terms of ease of manufacture, maintenance, and safety compared to conventional vaccines.", "- Since their discovery, DNA vaccines have evolved immensely.", "- New techniques such as gene guns, in vivo electroporation, and nanoparticle-based carriers have been employed to enhance the delivery of vaccines into the cells.", "- Starting from the failures of the first-generation DNA vaccines to the near-success second-generation vaccines, several strategies have greatly helped in strengthening the vaccine's immunogenicity.", "- Strategies including codon optimization, antigen design, and heterologous prime-boost have been used to strengthen the vaccine's immunogenicity.", "- The purpose of developing these third-generation vaccines is primarily to solve existing medical complications like cancer.", "- Third-generation vaccines are being developed for therapeutic uses to address health problems.", "- Third-generation vaccines aim to aid the rapid eradication of sudden global outbreaks of infectious diseases including Ebola and COVID-19.", "- The review focuses on the recent developments and strategies employed to improve the efficacy of DNA vaccines.", "- The review discusses the mechanism of action, potential concerns, progress achieved, and provides a brief update on the clinical applications of DNA vaccines."]}], "query": "History of Nucleic Acid Vaccines", "summary_abstract": null, "summary_extract": "The history of nucleic acid vaccines is marked by significant advancements and innovations since their inception in the early 1990s. This novel method of immunization was first demonstrated when researchers showed that direct inoculation of DNA plasmids coding for specific protein antigens could elicit immune responses (LUShan, 2004). The concept was further expanded to include mRNA molecules, which also have the potential to be translated into protein antigens (LUShan, 2004). The World Health Organization officially named this approach \"nucleic acid vaccination,\" although the term \"DNA vaccine\" is more commonly used in literature (LUShan, 2004).\n\nThe first successful demonstration of a DNA vaccine's efficacy in an animal model was published in 1993, highlighting the potential of nucleic acids as vectors for immunization (Ulmer et al., 1996). This approach allows for the in vivo expression of proteins, which can induce both humoral and cell-mediated immune responses, including cytotoxic T-lymphocyte responses (Ulmer et al., 1996; Vogel & Sarver, 1995). The endogenous generation of viral proteins with native conformations and posttranslational modifications mimics natural viral infections, offering a promising alternative to traditional vaccines (Vogel & Sarver, 1995).\n\nNucleic acid vaccines have been recognized for their simplicity, ease of delivery, and the lack of evidence of integration into the host genome (Vogel & Sarver, 1995). They have been shown to elicit immune responses similar to those induced by live, attenuated vaccines, without the risk of spreading the virus (Vogel & Sarver, 1995; Liu et al., 2005). The development of these vaccines has been rapid, with various strategies employed to enhance their potency, such as codon optimization, antigen design, and the use of adjuvants and delivery methods like gene guns and nanoparticles (Devi et al., 2022; Liu et al., 2005).\n\nOverall, nucleic acid vaccines represent a revolutionary approach in vaccinology, with the potential to address both infectious and non-infectious diseases, including cancer and sudden global outbreaks like Ebola and COVID-19 (Devi et al., 2022; Weng, 2005). As research continues, these vaccines are expected to play a crucial role in improving human and animal health (Weng, 2005)."}, {"papers": [{"metadata": {"year": 2004}, "authors": ["Brian  Fynes", "Se\u00e1n de B\u00farca", "Donna  Marshall"], "summary": "Abstract Environmental uncertainty is a fact of life in today's supply chains. In this paper we develop a model of environmental uncertainty, supply chain (SC) relationship quality and SC performance. We use data from the electronics sector in Ireland to test our model. Our results provide mixed support for the model, with the moderating role of both demand and supply uncertainty being supported, but technological uncertainty not supported. We reflect on these findings and suggest a research agenda based on our results.", "title": "Environmental uncertainty, supply chain relationship quality and performance", "claims": ["- Environmental uncertainty is a fact of life in today's supply chains.", "- A model of environmental uncertainty, supply chain (SC) relationship quality, and SC performance is developed in this paper.", "- Data from the electronics sector in Ireland is used to test the model.", "- The results provide mixed support for the model.", "- The moderating role of both demand and supply uncertainty is supported.", "- The moderating role of technological uncertainty is not supported.", "- The authors reflect on the findings and suggest a research agenda based on the results."]}, {"metadata": {"year": 2017}, "authors": ["R.  Sreedevi", "Haritha  Saranga"], "summary": "Abstract In order to remain competitive in the market, firms are forced to expand their product offerings and offer high levels of customization, bringing about high uncertainty in their supply chain. Firms that face high environmental uncertainty are increasingly facing higher risks in terms of supply disruptions, production and delivery delays that ultimately result in poor operational performance. This study aims at understanding the antecedents of supply chain operational risk faced by firms and the conditions under which such risks can be mitigated. Using Indian data from the sixth edition of International Manufacturing Strategy Survey (IMSS) and structural equation modeling, we investigate the relationships between environmental uncertainty and supply chain risk and the moderating effect of supply chain flexibility. We identify appropriate types of flexibility to mitigate the three major aspects of supply chain risk: supply risk, manufacturing process risk and delivery risk. Our empirical investigation reveals that uncertainty in the supply chain leads to high supply chain risk; and in uncertain environments, supply and manufacturing flexibility help in reducing the supply and manufacturing process risks respectively. However, our results also indicate that, in emerging markets such as India where logistic infrastructure is less developed, internal capabilities alone may not be sufficient in reducing supply chain delivery risk. Our findings not only contribute towards filling certain gaps in the supply chain risk management literature, but also provide practicing managers and researchers a better understanding of the types of flexibility that can mitigate supply chain risk in different business environments.", "title": "Uncertainty and supply chain risk: The moderating role of supply chain flexibility in risk mitigation", "claims": ["- Firms are forced to expand their product offerings and offer high levels of customization to remain competitive in the market.", "- High levels of customization bring about high uncertainty in firms' supply chains.", "- Firms facing high environmental uncertainty are increasingly facing higher risks in terms of supply disruptions, production, and delivery delays.", "- Higher risks in supply disruptions, production, and delivery delays ultimately result in poor operational performance for firms.", "- The study aims to understand the antecedents of supply chain operational risk faced by firms and the conditions under which such risks can be mitigated.", "- The study uses Indian data from the sixth edition of the International Manufacturing Strategy Survey (IMSS) and structural equation modeling to investigate relationships between environmental uncertainty and supply chain risk.", "- The study investigates the moderating effect of supply chain flexibility on the relationship between environmental uncertainty and supply chain risk.", "- The study identifies appropriate types of flexibility to mitigate the three major aspects of supply chain risk: supply risk, manufacturing process risk, and delivery risk.", "- The empirical investigation reveals that uncertainty in the supply chain leads to high supply chain risk.", "- In uncertain environments, supply flexibility helps in reducing supply risk.", "- In uncertain environments, manufacturing flexibility helps in reducing manufacturing process risk.", "- In emerging markets such as India, where logistic infrastructure is less developed, internal capabilities alone may not be sufficient in reducing supply chain delivery risk.", "- The findings contribute towards filling certain gaps in the supply chain risk management literature.", "- The findings provide practicing managers and researchers a better understanding of the types of flexibility that can mitigate supply chain risk in different business environments."]}, {"metadata": {"year": 2020}, "authors": ["Nitya P. Singh"], "summary": "ABSTRACT With increasing global exposure, organisations have started to witness supply chain risks that they traditionally were not exposed to. This article therefore attempts to answer the research question of how environmental uncertainty within a firm\u2019s supply chain, impacts firm financial performance. We further evaluate the role of supply chain risk management practices in mitigating the negative impact of such disruption events. To answer the research question, we conduct a literature review and develop the corresponding hypothesis. We test our hypothesis using both primary and secondary data. The results show that environmental uncertainty has a negative impact on firm financial performance, with entrepreneurial managerial capitalism mediating the impact. However, organisations that adopt macro and network supply chain risk management practices are able to improve managerial decision making frame, and mitigate the negative impact of environmental uncertainty on firm financial performance. The article concludes with our findings, along with managerial and practitioner implications of the research.", "title": "Managing environmental uncertainty for improved firm financial performance: the moderating role of supply chain risk management practices on managerial decision making", "claims": ["", "With increasing global exposure, organisations have started to witness supply chain risks that they traditionally were not exposed to.", "Environmental uncertainty within a firm\u2019s supply chain impacts firm financial performance.", "Supply chain risk management practices play a role in mitigating the negative impact of disruption events.", "A literature review and hypothesis development were conducted to answer the research question.", "The hypothesis was tested using both primary and secondary data.", "The results show that environmental uncertainty has a negative impact on firm financial performance.", "Entrepreneurial managerial capitalism mediates the impact of environmental uncertainty on firm financial performance.", "Organisations that adopt macro and network supply chain risk management practices are able to improve managerial decision making frame.", "Organisations that adopt macro and network supply chain risk management practices can mitigate the negative impact of environmental uncertainty on firm financial performance."]}, {"metadata": {"year": 2017}, "authors": ["Odkhishig Ganbold", "Y. Matsui"], "summary": "Today\u2019s ever-changing business environment is often described to be highly competitive, dynamic and complex. Customers are demanding more variability, better quality, higher reliability and faster delivery. Organizations are being faced with more uncertainties from its task environment than before. In order to respond to the uncertainties, organizations are internalizing fewer resources and capabilities, while increasing their integration with partners in the supply chain. Drawing on the resource-dependence theory, this study aims to examine the impact of environmental uncertainty on supply chain integration initiatives. Environmental uncertainty is considered in terms of three types, namely, supply uncertainty, demand or customer uncertainty, and technology uncertainty, based on its sources. Supply chain integration is comprised of internal integration, customer integration, and supplier integration. Based on the empirical study with 108 Japanese manufacturing firms, this study makes significant contributions to the knowledge base and provides theoretical and practical implications.", "title": "IMPACT OF ENVIRONMENTAL UNCERTAINTY ON SUPPLY CHAIN INTEGRATION", "claims": ["- Today\u2019s ever-changing business environment is often described to be highly competitive, dynamic, and complex.", "- Customers are demanding more variability, better quality, higher reliability, and faster delivery.", "- Organizations are being faced with more uncertainties from its task environment than before.", "- In order to respond to the uncertainties, organizations are internalizing fewer resources and capabilities.", "- Organizations are increasing their integration with partners in the supply chain.", "- Drawing on the resource-dependence theory, this study aims to examine the impact of environmental uncertainty on supply chain integration initiatives.", "- Environmental uncertainty is considered in terms of three types, namely, supply uncertainty, demand or customer uncertainty, and technology uncertainty, based on its sources.", "- Supply chain integration is comprised of internal integration, customer integration, and supplier integration.", "- Based on the empirical study with 108 Japanese manufacturing firms, this study makes significant contributions to the knowledge base.", "- The study provides theoretical and practical implications."]}, {"metadata": {"year": 2016}, "authors": ["Stephan  Vachon", "Sara  Hajmohammad"], "summary": "This manuscript examines the impact of supply chain uncertainty on environmental management spending in manufacturing plants. Building on the attention-based view of the firm (ABV), the basic premise is that with increased uncertainty in the supply chain, managers\u2019 attention to environmental management lessens which in turn leads to (i) fewer resources devoted to green issues within the plant and (ii) a bias to use resources toward less disruptive pollution control approaches rather than pollution prevention approaches. Data from a survey of 251 Canadian manufacturing plants was used to test the link between the level of uncertainty in the supply chain and environmental management decisions. The results indicate that supply chain uncertainty does not have a substantial impact on the level of environmental spending in a plant but has a substantial and significant impact on the allocation of the spending between pollution prevention and pollution control. More particularly, as supply chain uncertainty increases, organizations shift their resources away from pollution prevention to favor pollution control approaches.", "title": "Supply chain uncertainty and environmental management", "claims": ["", "This manuscript examines the impact of supply chain uncertainty on environmental management spending in manufacturing plants.", "Building on the attention-based view of the firm (ABV), the basic premise is that with increased uncertainty in the supply chain, managers\u2019 attention to environmental management lessens.", "With increased uncertainty in the supply chain, fewer resources are devoted to green issues within the plant.", "With increased uncertainty in the supply chain, there is a bias to use resources toward less disruptive pollution control approaches rather than pollution prevention approaches.", "Data from a survey of 251 Canadian manufacturing plants was used to test the link between the level of uncertainty in the supply chain and environmental management decisions.", "The results indicate that supply chain uncertainty does not have a substantial impact on the level of environmental spending in a plant.", "Supply chain uncertainty has a substantial and significant impact on the allocation of the spending between pollution prevention and pollution control.", "As supply chain uncertainty increases, organizations shift their resources away from pollution prevention to favor pollution control approaches."]}, {"metadata": {"year": 2021}, "authors": ["R. A. Inman", "K. Green"], "summary": "PurposeToday's businesses are facing a world that is more complex, turbulent and unpredictable than in the past with increasing levels of environmental complexity. Rather than proposing environmental uncertainty as a mediator/moderator of the relationship between agility and performance as others have done, the authors offer an alternative view where supply chain agility is seen as mediating the relationship between environmental uncertainty and supply chain performance.Design/methodology/approachThe authors propose that supply chain agility is a response to the effects of environmental uncertainty and, as such, environmental uncertainty should be seen as a driver of supply chain agility. Few studies test the direct relationship between uncertainty and supply chain performance, and none simultaneously test for agility's mediation and moderation effect between environmental uncertainty and agility.FindingsThe model was statistically assessed using partial-least-squares structural equation modeling (PLS/SEM) by analyzing survey data from manufacturing managers in 136 US firms. The study results did not indicate a significant relationship between environmental uncertainty and supply chain performance. However, the authors did find a significant positive relationship between agile manufacturing and supply chain performance using measures that were primarily operations-centered rather than financial. Additionally, the authors found that agile manufacturing fully mediates the relationship between environmental uncertainty and supply chain performance.Originality/valueThe authors\u2019 model, though simple, provides a base for future research for them and other researchers who can incorporate other impacting variables into the model. The study results show that uncertainty can be a force for good and that utilizing agile manufacturing can be a new source of opportunity.", "title": "Environmental uncertainty and supply chain performance: the effect of agility", "claims": ["- Today's businesses are facing a world that is more complex, turbulent, and unpredictable than in the past with increasing levels of environmental complexity.", "- The authors offer an alternative view where supply chain agility is seen as mediating the relationship between environmental uncertainty and supply chain performance.", "- The authors propose that supply chain agility is a response to the effects of environmental uncertainty.", "- Environmental uncertainty should be seen as a driver of supply chain agility.", "- Few studies test the direct relationship between uncertainty and supply chain performance, and none simultaneously test for agility's mediation and moderation effect between environmental uncertainty and agility.", "- The model was statistically assessed using partial-least-squares structural equation modeling (PLS/SEM) by analyzing survey data from manufacturing managers in 136 US firms.", "- The study results did not indicate a significant relationship between environmental uncertainty and supply chain performance.", "- The authors found a significant positive relationship between agile manufacturing and supply chain performance using measures that were primarily operations-centered rather than financial.", "- Agile manufacturing fully mediates the relationship between environmental uncertainty and supply chain performance.", "- The authors\u2019 model, though simple, provides a base for future research for them and other researchers who can incorporate other impacting variables into the model.", "- The study results show that uncertainty can be a force for good and that utilizing agile manufacturing can be a new source of opportunity."]}, {"metadata": {"year": 2022}, "authors": ["Erdin\u00e7 Ko\u00e7", "Muhammet Burak Deliba\u015f", "Yaprak Anadol"], "summary": "In this study, the direct effect of environmental uncertainty on competitive advantage and its indirect effect through the sequential mediator variables of supply chain integration and supply chain agility were investigated. The sample of the study consists of company managers operating in the manufacturing sector in Turkey. An online survey was sent to company managers through connections established on LinkedIn and an analysis was carried out with the data collected from 414 participants. As a result of the analysis, it has been determined that environmental uncertainty has a direct, significant and positive effect on competitive advantage. In addition, the results of the research show that supply chain integration and supply chain agility have a partial mediating role in the relationship between environmental uncertainty and competitive advantage. According to the results of this study, in conditions of high environmental uncertainty, companies can increase their supply chain agility capabilities by establishing a more integrated structure with their supply chain partners, and thus gain a unique competitive advantage over their competitors. It has been observed that the relationships between the concepts, which are the subject of the study, have been investigated separately in different studies in the literature. This study will contribute to the literature by investigating the relationships between concepts in a holistic way.", "title": "Environmental Uncertainties and Competitive Advantage: A Sequential Mediation Model of Supply Chain Integration and Supply Chain Agility", "claims": ["", "The direct effect of environmental uncertainty on competitive advantage was investigated in this study.", "The indirect effect of environmental uncertainty on competitive advantage through the sequential mediator variables of supply chain integration and supply chain agility was investigated in this study.", "The sample of the study consists of company managers operating in the manufacturing sector in Turkey.", "An online survey was sent to company managers through connections established on LinkedIn.", "An analysis was carried out with the data collected from 414 participants.", "It has been determined that environmental uncertainty has a direct, significant, and positive effect on competitive advantage.", "The results of the research show that supply chain integration and supply chain agility have a partial mediating role in the relationship between environmental uncertainty and competitive advantage.", "In conditions of high environmental uncertainty, companies can increase their supply chain agility capabilities by establishing a more integrated structure with their supply chain partners.", "By increasing their supply chain agility capabilities, companies can gain a unique competitive advantage over their competitors.", "The relationships between the concepts, which are the subject of the study, have been investigated separately in different studies in the literature.", "This study will contribute to the literature by investigating the relationships between concepts in a holistic way."]}, {"metadata": {"year": 2010}, "authors": ["Dehui Xu", "Li Zhao", "Gang Li", "Linyan Sun"], "summary": "Supply chain integration nowadays is considered as an important approach to building and sustaining advantages. Many previous empirical researches focus on the effect of supply chain integration on the firms' performance, yet, the antecedence of supply chain integration is still largely unknown. This paper investigates the relationship between environmental uncertainty (including demand uncertainty, supply uncertainty and technology uncertainty) and supply chain integration (including customer integration, supplier integration and internal integration) with 139 samples from Chinese manufacturing industry. The results reveal both supply uncertainty and technology uncertainty significantly influence supply chain integration; the effect of supply uncertainty is negative, while that of technology uncertainty is positive. However, demand uncertainty just has a significant effect on internal integration. The relationship between demand uncertainty and external integration (including customer integration and supplier integration) is mediated by the internal integration.", "title": "The effect of environmental uncertainty on supply chain integration in Chinese manufacturing industry", "claims": ["- Supply chain integration is considered an important approach to building and sustaining advantages.", "- Many previous empirical researches focus on the effect of supply chain integration on firms' performance.", "- The antecedence of supply chain integration is still largely unknown.", "- This paper investigates the relationship between environmental uncertainty (including demand uncertainty, supply uncertainty, and technology uncertainty) and supply chain integration (including customer integration, supplier integration, and internal integration) with 139 samples from the Chinese manufacturing industry.", "- The results reveal that supply uncertainty significantly influences supply chain integration.", "- The effect of supply uncertainty on supply chain integration is negative.", "- Technology uncertainty significantly influences supply chain integration.", "- The effect of technology uncertainty on supply chain integration is positive.", "- Demand uncertainty has a significant effect on internal integration.", "- The relationship between demand uncertainty and external integration (including customer integration and supplier integration) is mediated by internal integration."]}], "query": "\"Environmental uncertainty would moderate the relationship between demand risk and supply chain disruption impact such that the relationship would become stronger when environmental uncertainty is high.\"", "summary_abstract": null, "summary_extract": "The research question explores whether environmental uncertainty intensifies the relationship between demand risk and the impact of supply chain disruptions. Several studies provide insights into this dynamic. Fynes et al. (2004) support the moderating role of demand and supply uncertainty, suggesting that these uncertainties can indeed influence the impact of supply chain disruptions. Sreedevi and Saranga (2017) further elaborate that high environmental uncertainty exacerbates supply chain risks, including disruptions, which in turn negatively affect operational performance. They also highlight that supply chain flexibility can mitigate these risks, indicating that the relationship between demand risk and disruption impact is indeed stronger under high uncertainty. Singh (2020) corroborates these findings by showing that environmental uncertainty negatively impacts firm financial performance, but effective supply chain risk management can mitigate these effects. Collectively, these studies suggest that environmental uncertainty does strengthen the relationship between demand risk and supply chain disruption impact, particularly when firms lack adaptive strategies like flexibility and risk management practices."}, {"papers": [{"metadata": {"year": 2022}, "authors": ["Karolina A. Serhan", "Tamara L. Kemp"], "summary": "Summary: Phyllodes tumors are rare fibroepithelial breast tumors representing less than 1% of all breast malignancies, with an extremely uncommon presence in the pediatric population.1 Although prognosis is favorable following excision given their indolent course, they often grow rapidly and frequently recur. As such, they can present unique oncologic and reconstructive challenges. Herein we present a case of a malignant phyllodes tumor in an 11-year-old girl treated with total skin-sparing mastectomy and adjustable saline implant, and explore the reconstructive challenges of this unique case.", "title": "Immediate Breast Reconstruction in an 11-year-old Girl with a Large Malignant Phyllodes Tumor", "claims": ["- Phyllodes tumors are rare fibroepithelial breast tumors representing less than 1% of all breast malignancies.", "- Phyllodes tumors have an extremely uncommon presence in the pediatric population.", "- Prognosis is favorable following excision of phyllodes tumors given their indolent course.", "- Phyllodes tumors often grow rapidly and frequently recur.", "- Phyllodes tumors can present unique oncologic and reconstructive challenges.", "- A case of a malignant phyllodes tumor in an 11-year-old girl was treated with total skin-sparing mastectomy and adjustable saline implant.", "- The document explores the reconstructive challenges of the unique case of a malignant phyllodes tumor in an 11-year-old girl."]}, {"metadata": {"year": 2014}, "authors": ["E. Houseman", "T. Ince"], "summary": "Historically, breast cancer classification has relied on prognostic subtypes. Thus, unlike hematopoietic cancers, breast tumor classification lacks phylogenetic rationale. The feasibility of phylogenetic classification of breast tumors has recently been demonstrated based on estrogen receptor (ER), androgen receptor (AR), vitamin D receptor (VDR) and Keratin 5 expression. Four hormonal states (HR0\u20133) comprising 11 cellular subtypes of breast cells have been proposed. This classification scheme has been shown to have relevance to clinical prognosis. We examine the implications of such phylogenetic classification on DNA methylation of both breast tumors and normal breast tissues by applying recently developed deconvolution algorithms to three DNA methylation data sets archived on Gene Expression Omnibus. We propose that breast tumors arising from a particular cell-of-origin essentially magnify the epigenetic state of their original cell type. We demonstrate that DNA methylation of tumors manifests patterns consistent with cell-specific epigenetic states, that these states correspond roughly to previously posited normal breast cell types, and that estimates of proportions of the underlying cell types are predictive of tumor phenotypes. Taken together, these findings suggest that the epigenetics of breast tumors is ultimately based on the underlying phylogeny of normal breast tissue.", "title": "Normal Cell-Type Epigenetics and Breast Cancer Classification: A Case Study of Cell Mixture\u2013Adjusted Analysis of DNA Methylation Data from Tumors", "claims": ["- Historically, breast cancer classification has relied on prognostic subtypes.", "- Unlike hematopoietic cancers, breast tumor classification lacks phylogenetic rationale.", "- The feasibility of phylogenetic classification of breast tumors has recently been demonstrated based on estrogen receptor (ER), androgen receptor (AR), vitamin D receptor (VDR), and Keratin 5 expression.", "- Four hormonal states (HR0\u20133) comprising 11 cellular subtypes of breast cells have been proposed.", "- This classification scheme has been shown to have relevance to clinical prognosis.", "- The implications of phylogenetic classification on DNA methylation of both breast tumors and normal breast tissues are examined by applying recently developed deconvolution algorithms to three DNA methylation data sets archived on Gene Expression Omnibus.", "- It is proposed that breast tumors arising from a particular cell-of-origin essentially magnify the epigenetic state of their original cell type.", "- DNA methylation of tumors manifests patterns consistent with cell-specific epigenetic states.", "- These epigenetic states correspond roughly to previously posited normal breast cell types.", "- Estimates of proportions of the underlying cell types are predictive of tumor phenotypes.", "- The findings suggest that the epigenetics of breast tumors is ultimately based on the underlying phylogeny of normal breast tissue."]}, {"metadata": {"year": 2021}, "authors": ["Meher Charfi", "S. Ka", "A. Dem"], "summary": "No abstract.", "title": "Breast reconstruction after breast cancer", "claims": ["I need the content of the document to extract the claims. Could you please provide the text or more details from the document?"]}, {"metadata": {"year": 2020}, "authors": ["Benjamin Yongcheng Tan", "Nur Diyana Md Nasir", "Huan Ying Chang", "Cedric Chuan Young Ng", "Peiyong  Guan", "Sanjanaa  Nagarajan", "Vikneswari  Rajasegaran", "Jing Yi Lee", "Jing Quan Lim", "Aye Aye Thike", "Bin Tean Teh", "Puay Hoon Tan"], "summary": "Breast fibroepithelial lesions (FELs) encompass the common fibroadenoma (FA) and relatively rare phyllodes tumour (PT); the latter entity is usually classified as benign, borderline or malignant. Intratumoural heterogeneity is frequently present in these tumours, making accurate histologic evaluation challenging. Despite their rarity, PTs are an important clinical problem due to their propensity for recurrence and, in the case of malignant PT, metastasis. Surgical excision is the mainstay of management. Recent work has uncovered myriad genetic alterations in breast FELs. In this study, exome sequencing was performed on seven cases of morphologically heterogeneous breast FELs, including FAs, PTs of all grades, and a case of metaplastic spindle cell carcinoma arising in PT, in order to elucidate their intratumoural genetic repertoire. Gene mutations identified encompassed cell signalling, tumour suppressor, DNA repair and cell cycle regulating pathways. Mutations common to multiple tumour regions generally showed higher variant allele frequency. Frequent mutations included MED12 , TP53 , RARA and PIK3CA . Histological observations of increased cellular density and pleomorphism correlated with mutational burden. Phylogenetic analyses revealed disparate pathways of possible tumour progression. In summary, histological heterogeneity correlated with genetic changes in breast FELs.", "title": "Morphologic and genetic heterogeneity in breast fibroepithelial lesions\u2014a comprehensive mapping study", "claims": ["- Breast fibroepithelial lesions (FELs) encompass the common fibroadenoma (FA) and relatively rare phyllodes tumour (PT).", "- Phyllodes tumours (PTs) are usually classified as benign, borderline, or malignant.", "- Intratumoural heterogeneity is frequently present in breast fibroepithelial lesions, making accurate histologic evaluation challenging.", "- Despite their rarity, phyllodes tumours (PTs) are an important clinical problem due to their propensity for recurrence and, in the case of malignant PT, metastasis.", "- Surgical excision is the mainstay of management for breast fibroepithelial lesions.", "- Recent work has uncovered myriad genetic alterations in breast fibroepithelial lesions.", "- In this study, exome sequencing was performed on seven cases of morphologically heterogeneous breast fibroepithelial lesions, including fibroadenomas, phyllodes tumours of all grades, and a case of metaplastic spindle cell carcinoma arising in a phyllodes tumour, in order to elucidate their intratumoural genetic repertoire.", "- Gene mutations identified in breast fibroepithelial lesions encompassed cell signalling, tumour suppressor, DNA repair, and cell cycle regulating pathways.", "- Mutations common to multiple tumour regions generally showed higher variant allele frequency.", "- Frequent mutations in breast fibroepithelial lesions included MED12, TP53, RARA, and PIK3CA.", "- Histological observations of increased cellular density and pleomorphism correlated with mutational burden in breast fibroepithelial lesions.", "- Phylogenetic analyses revealed disparate pathways of possible tumour progression in breast fibroepithelial lesions.", "- In summary, histological heterogeneity correlated with genetic changes in breast fibroepithelial lesions."]}, {"metadata": {"year": 2020}, "authors": ["J. Kutasovic", "A. M. McCart Reed", "A. Sokolova", "S. Lakhani", "P. Simpson"], "summary": "Breast cancer is a remarkably complex and diverse disease. Subtyping based on morphology, genomics, biomarkers and/or clinical parameters seeks to stratify optimal approaches for management, but it is clear that every breast cancer is fundamentally unique. Intra-tumour heterogeneity adds further complexity and impacts a patient\u2019s response to neoadjuvant or adjuvant therapy. Here, we review some established and more recent evidence related to the complex nature of breast cancer evolution. We describe morphologic and genomic diversity as it arises spontaneously during the early stages of tumour evolution, and also in the context of treatment where the changing subclonal architecture of a tumour is driven by the inherent adaptability of tumour cells to evolve and resist the selective pressures of therapy.", "title": "Morphologic and Genomic Heterogeneity in the Evolution and Progression of Breast Cancer", "claims": ["- Breast cancer is a remarkably complex and diverse disease.", "- Subtyping based on morphology, genomics, biomarkers, and/or clinical parameters seeks to stratify optimal approaches for management.", "- It is clear that every breast cancer is fundamentally unique.", "- Intra-tumour heterogeneity adds further complexity and impacts a patient\u2019s response to neoadjuvant or adjuvant therapy.", "- Morphologic and genomic diversity arises spontaneously during the early stages of tumour evolution.", "- In the context of treatment, the changing subclonal architecture of a tumour is driven by the inherent adaptability of tumour cells to evolve and resist the selective pressures of therapy."]}, {"metadata": {"year": 2020}, "authors": ["Kathleen  Sprouffske", "Grainne  Kerr", "Cheng  Li", "Anirudh  Prahallad", "Ramona  Rebmann", "Verena  Waehle", "Ulrike  Naumann", "Hans  Bitter", "Michael R Jensen", "Francesco  Hofmann", "Saskia M Brachmann", "St\u00e9phane  Ferretti", "Audrey  Kauffmann"], "summary": "Graphical abstract", "title": "Genetic heterogeneity and clonal evolution during metastasis in breast cancer patient-derived tumor xenograft models", "claims": ["I can't extract claims from a document based solely on the term \"Graphical abstract.\" If you provide more details or a summary of the document, I can help identify and extract the claims for you."]}, {"metadata": {"year": 2005}, "authors": ["Agla Jael Rubner Fridriksdottir", "Ren\u00e9  Villadsen", "Thorarinn  Gudjonsson", "Ole William Petersen"], "summary": "Recent genome-wide expression analysis of breast cancer has brought new life to the classical idea of tumors as caricatures of the process of tissue renewal as envisioned by Pierce and Speers (Cancer Res 1988;48:1996\u20132004) more than a decade ago. The search for a cancer founder cell or different cancer founder cells is only possible if a hierarchy of differentiation has been established for the particular tissue in question. In the human breast, the luminal epithelial and myoepithelial lineages have been characterized extensively in situ by increasingly elaborate panel of markers, and methods to isolate, culture, and clone different subpopulations have improved dramatically. Comparisons have been made with the mouse mammary gland in physiological three-dimensional culture assays of morphogenesis, and the plasticity of breast epithelial cells has been challenged by immortalization and transformation. As a result of these efforts, several candidate progenitor cells have been proposed independently of each other, and some of their features have been compared. This research has all been done to better understand breast tissue homeostasis, cell-type diversification in general and breast cancer evolution in particular. The present review discusses the current approaches to address these issues and the measures taken to unravel and maintain cell type diversification for further investigation.", "title": "Maintenance of Cell Type Diversification in the Human Breast", "claims": ["- Recent genome-wide expression analysis of breast cancer has brought new life to the classical idea of tumors as caricatures of the process of tissue renewal as envisioned by Pierce and Speers more than a decade ago.", "- The search for a cancer founder cell or different cancer founder cells is only possible if a hierarchy of differentiation has been established for the particular tissue in question.", "- In the human breast, the luminal epithelial and myoepithelial lineages have been characterized extensively in situ by an increasingly elaborate panel of markers.", "- Methods to isolate, culture, and clone different subpopulations of breast cells have improved dramatically.", "- Comparisons have been made with the mouse mammary gland in physiological three-dimensional culture assays of morphogenesis.", "- The plasticity of breast epithelial cells has been challenged by immortalization and transformation.", "- As a result of these efforts, several candidate progenitor cells have been proposed independently of each other.", "- Some features of the proposed candidate progenitor cells have been compared.", "- This research has been conducted to better understand breast tissue homeostasis, cell-type diversification in general, and breast cancer evolution in particular.", "- The present review discusses the current approaches to address these issues and the measures taken to unravel and maintain cell type diversification for further investigation."]}, {"metadata": {"year": 2018}, "authors": ["M. Ejjiyar", "M. Elgueouatri", "Mehdi Sahibi", "Abdelkoddous Bhihi", "I. Yafi", "M. Mahrouch", "Moulay", "D. Elamrani", "Y. Benchamkha"], "summary": "Article History Received: 19.11.2018 Accepted: 28.11.2018 Published: 30.12.2018 Abstract: Phyllodes tumors of the breast are rare fibroepithelial tumors in their malignant form, the gravity lies in high risk of local recurrence. We report two observations of patients admitted for the management of local recurrence of phyllode breast tumor. The average age of our patients was 39 years old. The size of the tumor ranged from 10 cm to 30 cm in diameter, with a localization exclusively on the right. Surgical management consisted of a enlarged tumor resection, followed by radiotherapeutic complement. Histologically, it was a phyllode tumor initially benign with slowly progressive evolution, to a phyllode sarcoma at one patient, and to a liposarcoma in the other. The evolution towards a malignant transformation can be explained in both cases by incomplete previous excisional gestures. This underlines the importance of early diagnosis and surgical management responding to oncological rules.", "title": "Phyllode Tumors: Breast Tumors with a High Potential for Recurrence- About Two Cases", "claims": ["", "Phyllodes tumors of the breast are rare fibroepithelial tumors in their malignant form.", "Phyllodes tumors of the breast have a high risk of local recurrence.", "Two patients were admitted for the management of local recurrence of phyllode breast tumor.", "The average age of the patients was 39 years old.", "The size of the tumors ranged from 10 cm to 30 cm in diameter.", "The tumors were localized exclusively on the right side.", "Surgical management consisted of an enlarged tumor resection followed by radiotherapeutic complement.", "Histologically, one patient had a phyllode tumor that evolved into a phyllode sarcoma.", "Histologically, the other patient had a phyllode tumor that evolved into a liposarcoma.", "The evolution towards a malignant transformation in both cases can be explained by incomplete previous excisional gestures.", "Early diagnosis and surgical management responding to oncological rules are important."]}], "query": "phylogeny reconstruction in breast cancer", "summary_abstract": null, "summary_extract": "The exploration of phylogeny reconstruction in breast cancer has been significantly advanced by recent studies. Houseman and Ince (2014) have demonstrated the feasibility of a phylogenetic classification of breast tumors, which is based on the expression of estrogen receptor (ER), androgen receptor (AR), vitamin D receptor (VDR), and Keratin 5. This classification scheme, which includes four hormonal states and 11 cellular subtypes, has shown relevance to clinical prognosis and suggests that the epigenetics of breast tumors is rooted in the phylogeny of normal breast tissue. This approach highlights the potential for phylogenetic rationale in breast cancer classification, contrasting with the traditional reliance on prognostic subtypes.\n\nFurther supporting this, Tan et al. (2020) conducted phylogenetic analyses on breast fibroepithelial lesions, revealing diverse pathways of tumor progression. Their study underscores the genetic heterogeneity within these lesions, which correlates with histological diversity and suggests complex evolutionary trajectories. This research aligns with the notion that understanding the phylogenetic relationships and genetic alterations in breast cancer can provide insights into tumor behavior and potential therapeutic targets.\n\nCollectively, these studies underscore the importance of integrating phylogenetic perspectives into breast cancer research, offering a more nuanced understanding of tumor classification and progression."}, {"papers": [{"metadata": {"year": 2019}, "authors": ["Tarmo  Tuisk", "Gunnar  Prause"], "summary": "Since the 1st of January 2013 the public transport is free for residents of the City of Tallinn. People registered outside Tallinn who want to use the public transport have to pay for their trips. Parallel, Tallinn City Governance raised the parking tariffs in the city centre which caused an increase of using of the public transport by 10% and a decrease of car traffic in the city centre by 6%. Currently, the greening of urban transport enjoys a high rank on the political agenda in a lot of European and even some cities are thinking to follow the example of Tallinn. Literature review reveals that scientific papers are focussing mainly on ecological aspects whereas socio-economic studies are neglected. The paper will present insights in social, economic and political aspects which are related to the experience of free public transport in Tallinn. Furthermore, the paper will highlight the role of digitalisation in public transport and discuss the influence of the Estonian e-governance system for the success of the Tallinn case.", "title": "Socio-Economic Aspects of Free Public Transport", "claims": ["", "Since the 1st of January 2013, the public transport is free for residents of the City of Tallinn.", "People registered outside Tallinn who want to use the public transport have to pay for their trips.", "Tallinn City Governance raised the parking tariffs in the city centre.", "The increase in parking tariffs caused an increase of using of the public transport by 10%.", "The increase in parking tariffs caused a decrease of car traffic in the city centre by 6%.", "The greening of urban transport enjoys a high rank on the political agenda in a lot of European cities.", "Some cities are thinking to follow the example of Tallinn regarding free public transport.", "Literature review reveals that scientific papers are focusing mainly on ecological aspects of free public transport.", "Socio-economic studies related to free public transport are neglected in scientific papers.", "The paper will present insights into social, economic, and political aspects related to the experience of free public transport in Tallinn.", "The paper will highlight the role of digitalisation in public transport.", "The paper will discuss the influence of the Estonian e-governance system for the success of the Tallinn case."]}, {"metadata": {"year": 2016}, "authors": ["D. Gabald\u00f3n-Estevan"], "summary": "Urban areas are of increasing relevance when it comes to sustainability. \u2022\u00a0\u00a0\u00a0\u00a0\u00a0 First, about half of the world\u2019s population now lives in cities (increasing to 60% by 2030). \u2022\u00a0\u00a0\u00a0\u00a0\u00a0 Second, cities are nowadays responsible for levels of resource consumption and waste generation that are higher beyond their share on world population. \u2022\u00a0\u00a0\u00a0\u00a0\u00a0 Third, cities are more vulnerable to disruptive events that can lead to restrictions on the provision of resources and to changes on the environment caused by climate change. \u2022\u00a0\u00a0\u00a0\u00a0\u00a0 And fourth, because they concentrate key resources (political, social, cultural\u2026), cities are seen as strategic scenarios where to experiment and develop solutions to cope with the prevailing sustainability challenges driven by the major social and environmental transformations. Urban agglomerations can be seen as complex innovation systems where human activities are shaped in order to transform societies towards sustainable development. For this paper, we focus on the case of an environmental innovation regarding transport policy, the implementation of the fare-free policy on public transport for all inhabitants of Tallinn, Estonia. Tallinn, with 414,000 inhabitants in 2015, is the capital of Estonia and the largest city in the country. Over the last two decades the share of public transport trips decreased dramatically. After a public opinion poll in 2012, in which over 75% of the participants voted for a fare-free public transportation system (FFPTS) in Tallinn, the new policy was implemented on 1st January 2013. From that date on inhabitants of Tallinn could use all public transport services (busses, trams, trolly-busses) operated by city-run operators for free. Later the fare-free system was implemented also on trains within Tallinn. In this paper we analyze the context, in which this policy was implemented, the main characteristics of its implementation and its actual situation. DOI: http://dx.doi.org/10.4995/CIT2016.2016.3532", "title": "Environmental innovation through transport policy. The implementation of the free fare policy on public transport in Tallinn, Estonia", "claims": ["- About half of the world\u2019s population now lives in cities, increasing to 60% by 2030.", "- Cities are responsible for levels of resource consumption and waste generation that are higher than their share of the world population.", "- Cities are more vulnerable to disruptive events that can lead to restrictions on the provision of resources and to changes in the environment caused by climate change.", "- Cities concentrate key resources (political, social, cultural) and are seen as strategic scenarios to experiment and develop solutions to cope with sustainability challenges driven by major social and environmental transformations.", "- Urban agglomerations can be seen as complex innovation systems where human activities are shaped to transform societies towards sustainable development.", "- The paper focuses on an environmental innovation regarding transport policy, specifically the implementation of the fare-free policy on public transport for all inhabitants of Tallinn, Estonia.", "- Tallinn, with 414,000 inhabitants in 2015, is the capital of Estonia and the largest city in the country.", "- Over the last two decades, the share of public transport trips in Tallinn decreased dramatically.", "- After a public opinion poll in 2012, over 75% of the participants voted for a fare-free public transportation system (FFPTS) in Tallinn.", "- The fare-free public transportation policy was implemented in Tallinn on 1st January 2013.", "- From 1st January 2013, inhabitants of Tallinn could use all public transport services (buses, trams, trolley-buses) operated by city-run operators for free.", "- Later, the fare-free system was also implemented on trains within Tallinn."]}, {"metadata": {"year": 2017}, "authors": ["Daniel Baldwin Hess"], "summary": "Abstract Among many possible interventions in public transport finance and policy designed to enhance the attractiveness of riding public transport, one of the most extreme, which is seldom implemented, is the elimination of passenger fares, effectively making public transport \u201cfree\u201d for riders (with operating costs paid from other funding sources). This article describes a fare-free public transport program in Tallinn, Estonia, launched in 2013, which has exhibited lower-than-expected increases in ridership. Evaluations of Tallinn\u2019s fare-free public transport program are presented and synthesized, with a focus on program goals and how goals are met through program performance. Findings suggest certain flaws limit the program\u2019s potential success since the program design is misaligned with its primary stated goals, and several program goals relating to external effects of fare reform cannot be evaluated. Although it would be valuable for transport managers in other cities to learn about this experience, the Tallinn fare-free public transport program provides scant transferable evidence about how such a program can operate outside of a politicized context, which was crucial to its implementation in Estonia.", "title": "Decrypting fare-free public transport in Tallinn, Estonia", "claims": ["- Among many possible interventions in public transport finance and policy designed to enhance the attractiveness of riding public transport, one of the most extreme, which is seldom implemented, is the elimination of passenger fares, effectively making public transport \u201cfree\u201d for riders (with operating costs paid from other funding sources).", "- This article describes a fare-free public transport program in Tallinn, Estonia, launched in 2013, which has exhibited lower-than-expected increases in ridership.", "- Evaluations of Tallinn\u2019s fare-free public transport program are presented and synthesized, with a focus on program goals and how goals are met through program performance.", "- Findings suggest certain flaws limit the program\u2019s potential success since the program design is misaligned with its primary stated goals.", "- Several program goals relating to external effects of fare reform cannot be evaluated.", "- Although it would be valuable for transport managers in other cities to learn about this experience, the Tallinn fare-free public transport program provides scant transferable evidence about how such a program can operate outside of a politicized context, which was crucial to its implementation in Estonia."]}, {"metadata": {"year": 2014}, "authors": ["Derek Galey"], "summary": "The City of Tallinn, capital of Estonia, with a population of 420,000, recently became the world's largest municipality offering free public transportation. Tourists still have to pay to ride the city's bus, trolley, and tram network, but registered residents\u2014including a large population of Russian-speaking non-citizens\u2014only have to tap their municipal transit cards once onboard. Tallinn's leadership has justi\ufffd\u8000ed the policy on environmental and social grounds\u2014namely, reducing carbon dioxide emissions and providing equal rights to freedom of movement. Although only 26% of trips in Tallinn utilize private cars, private transportation accounts for 60% of the city's carbon dioxide emissions. Public transportation, which provides 40% of trips in Tallinn, accounts for only 6-7% of the city's total emissions. On an annual municipal public transport satisfaction survey from 2010, 49% of the respondents were most unsatis- \ufffd\u8000ed with fares, followed by crowding (29%) and frequency (21%). (Cats, Susilo, and Eliasson 2012, 3-4) The city's government responded by calling a March 2012 referendum, in which 75% of voters supported free public transportation. In contrast with past experiences with free public transportation in other cities, preliminary results indicate a \"relatively small increase in passenger demand\" of only 3% citywide in the three-month period after implementation (Cats, Susilo, and Reimal 2014, 5). Notably, however, passenger counts increased 10% in Lasnamae, a populous and dense housing district with a price-sensitive population and many Russian-speaking residents.", "title": "Free Public Transportation for Residents of Tallinn", "claims": ["- The City of Tallinn, capital of Estonia, has a population of 420,000.", "- Tallinn recently became the world's largest municipality offering free public transportation.", "- Tourists still have to pay to ride the city's bus, trolley, and tram network.", "- Registered residents, including a large population of Russian-speaking non-citizens, only have to tap their municipal transit cards once onboard.", "- Tallinn's leadership has justified the free public transportation policy on environmental and social grounds, specifically reducing carbon dioxide emissions and providing equal rights to freedom of movement.", "- Only 26% of trips in Tallinn utilize private cars.", "- Private transportation accounts for 60% of the city's carbon dioxide emissions.", "- Public transportation provides 40% of trips in Tallinn.", "- Public transportation accounts for only 6-7% of the city's total emissions.", "- In an annual municipal public transport satisfaction survey from 2010, 49% of respondents were most unsatisfied with fares.", "- In the same survey, 29% of respondents were unsatisfied with crowding.", "- In the same survey, 21% of respondents were unsatisfied with frequency.", "- The city's government called a March 2012 referendum in which 75% of voters supported free public transportation.", "- Preliminary results indicate a \"relatively small increase in passenger demand\" of only 3% citywide in the three-month period after the implementation of free public transportation.", "- Passenger counts increased 10% in Lasnamae, a populous and dense housing district with a price-sensitive population and many Russian-speaking residents."]}, {"metadata": {"year": 2014}, "authors": ["Derek Galey"], "summary": "The City of Tallinn, capital of Estonia, with a population of 420,000, recently became the world\u2019s largest municipality offering free public transportation. Tourists still have to pay to ride the city\u2019s bus, trolley, and tram network, but registered residents\u2014including a large population of Russian-speaking non-citizens\u2014only have to tap their municipal transit cards once onboard. This article presents a qualitative account of the world\u2019s largest free public transporta- tion experiment to date. The results challenge and inform the conventional measures and objectives of transportation experts. The analysis is meant to complement the existing literature surveying free public transportation experiments and evaluating transportation pricing schemes.", "title": "License to Ride: Free Public Transportation for Residents of Tallinn", "claims": ["- The City of Tallinn, capital of Estonia, has a population of 420,000.", "- Tallinn recently became the world\u2019s largest municipality offering free public transportation.", "- Tourists still have to pay to ride Tallinn's bus, trolley, and tram network.", "- Registered residents of Tallinn, including a large population of Russian-speaking non-citizens, only have to tap their municipal transit cards once onboard to use public transportation for free.", "- The article presents a qualitative account of the world\u2019s largest free public transportation experiment to date.", "- The results of the experiment challenge and inform the conventional measures and objectives of transportation experts.", "- The analysis in the article is meant to complement the existing literature surveying free public transportation experiments and evaluating transportation pricing schemes."]}, {"metadata": {"year": 2019}, "authors": ["D. Gabald\u00f3n-Estevan", "K. Orru", "C. Kaufmann", "H. Orru"], "summary": "ABSTRACT In this paper, we focus on the rationale for implementing the fare-free public transportation system (FFPTS) in Tallinn, Estonia, that took place on 1 January 2013. Through a series of interviews with relevant informants, we identify the main enablers and the FFPTS in Tallinn faced and the potential of such a system to contribute to the sustainable city development. Our analysis shows that the interlinking between local and national politics determines not only the type of initiatives implemented and the support they receive but also the degree of their success and their stability. We conclude that to be even more effective, it should be extended to the all potential users, not just to local registered residents as it has been recently applied in state-run bus travels in rural municipalities in Estonia. Finally, more restrictive private car policies should be considered to fuel a sustainable mobility transition and increase cities life quality.", "title": "Broader impacts of the fare-free public transportation system in Tallinn", "claims": ["", "The fare-free public transportation system (FFPTS) was implemented in Tallinn, Estonia, on 1 January 2013.", "The FFPTS in Tallinn has the potential to contribute to sustainable city development.", "The interlinking between local and national politics determines the type of initiatives implemented, the support they receive, their success, and their stability.", "The FFPTS should be extended to all potential users, not just local registered residents, as it has been recently applied in state-run bus travels in rural municipalities in Estonia.", "More restrictive private car policies should be considered to fuel a sustainable mobility transition and increase cities' life quality."]}, {"metadata": {"year": 2019}, "authors": ["Wojciech K\u0119b\u0142owski", "T. Tuvikene", "T. Pikner", "J. Jauhiainen"], "summary": "In this article, we study the largest existing fare-free public transport (FFPT) programme, launched in 2013 in Tallinn, Estonia. Instead of focusing solely on the rationale and impact of fare-free public transport in terms of finances and travel patterns, we propose to analyse FFPT from the perspective of urban political geography, and to inquire into its political and scalar dynamics. We analyse how Tallinn\u2019s fare-free programme was developed, and demonstrate the politics of its conception and implementation. We observe who has access to free travel and we reveal how FFPT is embedded in Estonia\u2019s place-of-residence-based taxation system. Finally, we identify where lies the impact of territorial competition exacerbated by FFPT. Therefore, we argue that transport policies \u2013 of which FFPT is but an example \u2013 should be understood as much more than strategies dealing with transport issues per se. Instead, we propose to approach them as political and spatial projects, whose processual, cross-sectorial and scalar dimensions help to reveal the embeddedness of transport in inherently urban questions of metropolitan governance, electoral strategies, territorial competition and socio-spatial inequalities.", "title": "Towards an urban political geography of transport: Unpacking the political and scalar dynamics of fare-free public transport in Tallinn, Estonia", "claims": ["- The largest existing fare-free public transport (FFPT) programme was launched in 2013 in Tallinn, Estonia.", "- The article proposes to analyse FFPT from the perspective of urban political geography, rather than focusing solely on the rationale and impact of fare-free public transport in terms of finances and travel patterns.", "- The article analyses how Tallinn\u2019s fare-free programme was developed and demonstrates the politics of its conception and implementation.", "- The article observes who has access to free travel and reveals how FFPT is embedded in Estonia\u2019s place-of-residence-based taxation system.", "- The article identifies the impact of territorial competition exacerbated by FFPT.", "- The article argues that transport policies, including FFPT, should be understood as more than strategies dealing with transport issues per se.", "- The article proposes to approach transport policies as political and spatial projects, whose processual, cross-sectorial, and scalar dimensions help to reveal the embeddedness of transport in urban questions of metropolitan governance, electoral strategies, territorial competition, and socio-spatial inequalities."]}, {"metadata": {"year": 2020}, "authors": ["Gunnar  Prause", "Tarmo  Tuisk"], "summary": "Abstract Tallinn's fare-free public transportation (FFPT) for the residents of the city has been vital for over 6\u00a0years, and there is no evidence of major setbacks. While expectations about political impact were high, the implementation if FFPT still did not demonstrate any significant change in this respect. The usage of public transport rose from 55% to 63%. Within Estonia's developed e-governance framework, the optimization of transport lines and costs has been taken place effectively. Pollution and emission levels in the city have not increased due to the stricter environmental requirements for vehicles and fuels, although the number of cars is continuously rising. As the satisfaction with FFPT transport services in Tallinn is rather high, also other municipalities of Estonia have started to implement the same concept in their transportation.", "title": "Case study", "claims": ["- Tallinn's fare-free public transportation (FFPT) for the residents of the city has been vital for over 6 years.", "- There is no evidence of major setbacks in Tallinn's fare-free public transportation (FFPT) for the residents of the city.", "- Expectations about the political impact of FFPT were high.", "- The implementation of FFPT did not demonstrate any significant change in political impact.", "- The usage of public transport in Tallinn rose from 55% to 63%.", "- Within Estonia's developed e-governance framework, the optimization of transport lines and costs has taken place effectively.", "- Pollution and emission levels in Tallinn have not increased due to stricter environmental requirements for vehicles and fuels.", "- The number of cars in Tallinn is continuously rising.", "- Satisfaction with FFPT transport services in Tallinn is rather high.", "- Other municipalities of Estonia have started to implement the FFPT concept in their transportation."]}], "query": "Tallinn emerged as a pioneer by introducing free public transport in 2013.", "summary_abstract": null, "summary_extract": "Tallinn emerged as a pioneer in public transport by implementing a fare-free public transportation system (FFPTS) for its residents on January 1, 2013. This initiative was driven by a public referendum in 2012, where over 75% of participants supported the idea (Gabald\u00f3n-Estevan, 2016; Galey, 2014). The policy allows registered residents to use all city-operated public transport services, including buses, trams, and trolley-buses, without charge (Gabald\u00f3n-Estevan, 2016; Galey, 2014). However, tourists and non-residents still need to pay for these services (Galey, 2014; Tuisk & Prause, 2019).\n\nThe introduction of free public transport in Tallinn was justified on environmental and social grounds, aiming to reduce carbon dioxide emissions and promote equal access to mobility (Galey, 2014). Despite these intentions, the increase in public transport usage was lower than expected, with only a modest rise in ridership (Hess, 2017; Galey, 2014). Nevertheless, the policy has been considered successful in maintaining high satisfaction levels among users and has not led to increased pollution, thanks to stricter environmental regulations (Prause & Tuisk, 2020).\n\nThe initiative has sparked interest in other cities considering similar policies, highlighting Tallinn's role as a trailblazer in urban transport innovation (Tuisk & Prause, 2019). However, the program's success is closely tied to Estonia's unique political and governance context, which may limit its applicability elsewhere (Hess, 2017; K\u0119b\u0142owski et al., 2019). Overall, Tallinn's experience with free public transport underscores the complex interplay of political, social, and environmental factors in urban policy-making."}, {"papers": [{"metadata": {"year": 1993}, "authors": ["Markus  See\u03b2elberg", "Francesco  Petruccione"], "summary": "Abstract The solution of stochastic partial differential equations generally relies on numerical tools. However, conventional numerical procedures are not appropriate to solve such problems. In this paper an algorithm is proposed which allows the numerical treatment of a large class of stochastic partial differential equations. To this end we reduce stochastic partial differential equations to a system of stochastic ordinary differential equations which can be solved numerically by a well-known stochastic Euler-procedure. We apply our algorithm to two stochastic partial differential equations which are special examples because their stationary two-point correlation functions can be determined analytically. Our algorithm proves to work out very well when numerical results are compared with the analytic correlation function.", "title": "Numerical integration of stochastic partial differential equations", "claims": ["- The solution of stochastic partial differential equations generally relies on numerical tools.", "- Conventional numerical procedures are not appropriate to solve stochastic partial differential equations.", "- An algorithm is proposed in the paper which allows the numerical treatment of a large class of stochastic partial differential equations.", "- The proposed algorithm reduces stochastic partial differential equations to a system of stochastic ordinary differential equations.", "- The system of stochastic ordinary differential equations can be solved numerically by a well-known stochastic Euler-procedure.", "- The algorithm is applied to two stochastic partial differential equations which are special examples because their stationary two-point correlation functions can be determined analytically.", "- The algorithm proves to work out very well when numerical results are compared with the analytic correlation function."]}, {"metadata": {"year": 1992}, "authors": ["Tadahisa  Funaki"], "summary": "Abstract We investigate a certain stochastic partial differential equation which is defined on the unit interval with periodic boundary condition and takes values in a manifold. Such equation has particularly two different applications. Namely, it determines the evolution law of an interacting constrained system of continuum distributed over the unit circle, while it defines a diffusive motion of loops on a manifold. We establish the existence and uniqueness results and then show the smoothness property of the solutions. Some examples are given in the final section.", "title": "A stochastic partial differential equation with values in a manifold", "claims": ["- A certain stochastic partial differential equation is defined on the unit interval with periodic boundary condition and takes values in a manifold.", "- The stochastic partial differential equation has two different applications.", "- The equation determines the evolution law of an interacting constrained system of continuum distributed over the unit circle.", "- The equation defines a diffusive motion of loops on a manifold.", "- The existence and uniqueness results for the solutions of the equation are established.", "- The smoothness property of the solutions is shown.", "- Some examples are given in the final section."]}, {"metadata": {"year": 1987}, "authors": ["G. Prato", "L. Tubaro"], "summary": "Existence and uniqueness results for a non linear stochastic partial differential equation.- Continuity in non linear filtering some different approacees.- Expectation functionals associated with some stochastic evolution equations.- Dirichlet boundary value problem and optimal control for a stochastic distributed parameter system.- Stochastic product integration and stochastic equations.- Some remarks on a problem in stochastic optimal control.- Passage from two-parameters to infinite dimension.- The heat equation and fourier transforms of generalized brownian functionals.- The separation principle for stochastic differential equations with unbounded coefficients.- Weak convergence of measure valued processes using sobolev-imbedding techniques.- Probability distributions of solutions to some stochastic partial differential equations.- Two-sided stochastic calculus for spdes.- Convergence of implicit discretization schemes for linear differential equations with application to filtering.- Some applications of the Malliavin calculus to stochastic analysis.- Exit problem for infinite dimensional systems.", "title": "Stochastic partial differential equations and applications : proceedings of a conference held in Trento, Italy, Sept. 30-Oct. 5, 1985", "claims": ["", "Existence and uniqueness results are established for a nonlinear stochastic partial differential equation.", "Continuity is explored in nonlinear filtering through some different approaches.", "Expectation functionals are associated with some stochastic evolution equations.", "The Dirichlet boundary value problem and optimal control are addressed for a stochastic distributed parameter system.", "Stochastic product integration is applied to stochastic equations.", "Some remarks are made on a problem in stochastic optimal control.", "There is a passage from two-parameters to infinite dimension.", "The heat equation and Fourier transforms are applied to generalized Brownian functionals.", "The separation principle is applied to stochastic differential equations with unbounded coefficients.", "Weak convergence of measure-valued processes is studied using Sobolev-imbedding techniques.", "Probability distributions of solutions are determined for some stochastic partial differential equations.", "Two-sided stochastic calculus is applied to stochastic partial differential equations (SPDEs).", "Convergence of implicit discretization schemes is analyzed for linear differential equations with application to filtering.", "Some applications of the Malliavin calculus are made to stochastic analysis.", "The exit problem is addressed for infinite dimensional systems."]}, {"metadata": {"year": 2021}, "authors": ["Yijun Li", "Guanggan Chen", "Ting Lei"], "summary": "This work is concerned with a class of stochastic partial differential equations with a fast random dynamical boundary condition. In the limit of fast diffusion, it derives an effective stochastic partial differential equation to describe the evolution of the dominant pattern. Using the multiscale analysis and the averaging principle, it then establishes deviation estimates of the original stochastic system towards the effective approximating system. A concrete example further illustrates the result on a large time scale.", "title": "Approximate dynamics of stochastic partial differential equations under fast dynamical boundary conditions", "claims": ["- This work is concerned with a class of stochastic partial differential equations with a fast random dynamical boundary condition.", "- In the limit of fast diffusion, it derives an effective stochastic partial differential equation to describe the evolution of the dominant pattern.", "- Using the multiscale analysis and the averaging principle, it establishes deviation estimates of the original stochastic system towards the effective approximating system.", "- A concrete example further illustrates the result on a large time scale."]}, {"metadata": {"year": 2013}, "authors": ["N. Hema", "A. Jeyalakshmi"], "summary": "In this paper, we propose a stochastic differential equation model where the underlying stochastic process is a jumpdiffusion process.The stochastic differential equation is represented as a Partial Integro Differential Equation(PIDE) using the Fokker Planck equation. The solution of the PIDE is obtained by the method of finite differences. The consistency, the convergence of the solution and the stability of the finite difference scheme are discussed. The model is applied to forecast the daily price changes in a commodity derivative. The observed values are compared graphically with the values expected from the proposed model.", "title": "A Stochastic Differential Equation Model", "claims": ["", "The paper proposes a stochastic differential equation model where the underlying stochastic process is a jump-diffusion process.", "The stochastic differential equation is represented as a Partial Integro Differential Equation (PIDE) using the Fokker Planck equation.", "The solution of the PIDE is obtained by the method of finite differences.", "The consistency of the finite difference scheme is discussed.", "The convergence of the solution of the finite difference scheme is discussed.", "The stability of the finite difference scheme is discussed.", "The model is applied to forecast the daily price changes in a commodity derivative.", "The observed values are compared graphically with the values expected from the proposed model."]}, {"metadata": {"year": 1996}, "authors": ["H. Holden", "B. \u00d8ksendal", "J. Ub\u00f8e", "Tusheng Zhang"], "summary": "Framework.- Applications to Stochastic Ordinary Differential Equations.- Stochastic Partial Differential Equations Driven by Brownian White Noise.- Stochastic Partial Differential Equations Driven by L#x00E9 vy Processes.", "title": "Stochastic Partial Differential Equations: A Modeling, White Noise Functional Approach", "claims": ["- The document includes a framework for applications to stochastic ordinary differential equations.", "- The document discusses stochastic partial differential equations driven by Brownian white noise.", "- The document covers stochastic partial differential equations driven by L\u00e9vy processes."]}, {"metadata": {"year": 2020}, "authors": ["Chi Hong Wong", "X. Yang", "Jing Zhang"], "summary": "We study a class of stochastic partial integral-differential equations with an asymmetrical non-local operator 1 2 \u2206+a\u2206 \u03b1 2 +b \u00b7\u2207 and a distribution expressed as divergence of a measurable field. For 0 < \u03b1 < 2, the existence and uniqueness of solution is proved by analytical method, and a probabilistic interpretation, similar to the Feynman-Kac formula, is presented for 0 < \u03b1 < 1. The method of backward doubly stochastic differential equations is also extended in this work.", "title": "Stochastic partial integral-differential equations with divergence terms", "claims": ["- We study a class of stochastic partial integral-differential equations with an asymmetrical non-local operator \\( \\frac{1}{2} \\Delta + a \\Delta^{\\frac{\\alpha}{2}} + b \\cdot \\nabla \\).", "- The distribution is expressed as divergence of a measurable field.", "- For \\( 0 < \\alpha < 2 \\), the existence and uniqueness of solution is proved by analytical method.", "- A probabilistic interpretation, similar to the Feynman-Kac formula, is presented for \\( 0 < \\alpha < 1 \\).", "- The method of backward doubly stochastic differential equations is also extended in this work."]}, {"metadata": {"year": 2007}, "authors": ["Wei Wang", "Jinqiao Duan"], "summary": "Abstract In order to understand the impact of random influences at physical boundary on the evolution of multiscale systems, a stochastic partial differential equation model under a fast random dynamical boundary condition is investigated. The noises in the model and in the boundary condition are both additive. An effective equation is derived and justified by reducing the random dynamical boundary condition to a simpler one. The effective system is still a stochastic partial differential equation. Furthermore, the quantitative comparison between the solution of the original stochastic system and the effective solution is provided by establishing normal deviations and large deviations principles. Namely, the normal deviations are asymptotically characterized, while the rate and speed of the large deviations are estimated.", "title": "Reductions and Deviations for Stochastic Partial Differential Equations Under Fast Dynamical Boundary Conditions", "claims": ["- In order to understand the impact of random influences at physical boundary on the evolution of multiscale systems, a stochastic partial differential equation model under a fast random dynamical boundary condition is investigated.", "- The noises in the model and in the boundary condition are both additive.", "- An effective equation is derived and justified by reducing the random dynamical boundary condition to a simpler one.", "- The effective system is still a stochastic partial differential equation.", "- A quantitative comparison between the solution of the original stochastic system and the effective solution is provided by establishing normal deviations and large deviations principles.", "- The normal deviations are asymptotically characterized.", "- The rate and speed of the large deviations are estimated."]}], "query": "application of algebraic analysis for stochastic partial differential equation", "summary_abstract": null, "summary_extract": "The application of algebraic analysis to stochastic partial differential equations (SPDEs) is a multifaceted area of research, with various approaches and methodologies being explored. See\u03b2elberg and Petruccione (1993) propose an innovative algorithm that transforms SPDEs into a system of stochastic ordinary differential equations, which can then be solved using a stochastic Euler-procedure. This approach is particularly effective for certain SPDEs where analytical solutions for stationary two-point correlation functions are available, demonstrating strong agreement between numerical and analytical results.\n\nFunaki (1992) explores SPDEs in the context of systems with periodic boundary conditions, focusing on the evolution of interacting constrained systems and the diffusive motion of loops on manifolds. This work emphasizes the existence, uniqueness, and smoothness of solutions, providing a solid theoretical foundation for the application of algebraic analysis to SPDEs.\n\nPrato and Tubaro (1987) contribute to the field by establishing existence and uniqueness results for nonlinear SPDEs and applying stochastic product integration. Their work also delves into the probability distributions of solutions and the application of two-sided stochastic calculus, highlighting the versatility of algebraic methods in addressing complex SPDEs.\n\nLi, Chen, and Lei (2021) and Wang and Duan (2007) both investigate SPDEs with fast random dynamical boundary conditions, employing multiscale analysis and averaging principles to derive effective equations. These studies provide insights into the behavior of SPDEs under varying conditions and demonstrate the utility of algebraic analysis in simplifying and understanding complex stochastic systems.\n\nOverall, the collective research underscores the importance of algebraic analysis in solving and understanding SPDEs, offering a range of techniques from numerical algorithms to theoretical frameworks that enhance the study and application of these equations in various scientific fields."}, {"papers": [{"metadata": {"year": 2010}, "authors": ["Alexandros  Flamos", "Katherine  Begg"], "summary": "The purpose of technology transfer under the UNFCCC Article 4.5 is to \u201c\u2026promote, facilitate, and finance as appropriate the transfer of, or access to, environmentally sound technologies and know how to other Parties particularly Developing Country parties to enable them to implement the provisions of the Convention.\u201d The key challenge in this respect is that low-carbon sustainable technologies need to be adopted both by developed as well as developing countries. However, this paper focuses on the process of technology transfer to developing countries to allow them to move quickly to environmentally sound and sustainable practices, institutions and technologies. In the above framework, this paper reviews key aspects of technology transfer from a range of perspectives in the literature and discusses insights from this literature for the transfer and innovation process needed to reduce global vulnerability to climate change in the context of current international activities based on the research undertaken by the EU sponsored ENTTRANS project.", "title": "Technology transfer insights for new climate regime", "claims": ["", "The purpose of technology transfer under the UNFCCC Article 4.5 is to promote, facilitate, and finance as appropriate the transfer of, or access to, environmentally sound technologies and know-how to other Parties, particularly Developing Country parties, to enable them to implement the provisions of the Convention.", "Low-carbon sustainable technologies need to be adopted both by developed as well as developing countries.", "The paper focuses on the process of technology transfer to developing countries to allow them to move quickly to environmentally sound and sustainable practices, institutions, and technologies.", "The paper reviews key aspects of technology transfer from a range of perspectives in the literature.", "The paper discusses insights from the literature for the transfer and innovation process needed to reduce global vulnerability to climate change.", "The context of the paper is based on current international activities and research undertaken by the EU sponsored ENTTRANS project."]}, {"metadata": {"year": 1979}, "authors": ["K. H. Veldhuis"], "summary": "It is said nowadays that commercial companies, and particularly multinational ones, are one of the most important routes via which technology is transferred to developing countries. What is often called into question, however, is how appropriate is a particular technology to the country concerned. What, in fact, is meant by \u2018appropriate\u2019 in this context?", "title": "Transfer and Adaptation of Technology: Unilever as a Case Study", "claims": ["- Commercial companies, and particularly multinational ones, are one of the most important routes via which technology is transferred to developing countries.", "- It is often called into question how appropriate a particular technology is to the country concerned."]}, {"metadata": {"year": 2010}, "authors": ["Charikleia  Karakosta", "Haris  Doukas", "John  Psarras"], "summary": "Climate change mitigation is considered as a high priority internationally and is placed in the top of the agenda for most politicians and decision makers. The key challenge is that low-carbon sustainable technologies need to be adopted both by developed as well as developing countries, in an effort to avoid past unsustainable practices and being locked into old, less sustainable technologies. Technology transfer (TT), as an important feature of both the United Nations Framework Convention on Climate Change (UNFCCC) and its Kyoto Protocol can play a key role. TT can allow countries to move quickly to environmentally sound and sustainable practices, institutions and technologies. Indeed, the transfer or innovation process must be fast enough, to reduce global vulnerability to climate change. The aim of this paper is to analyse the TT challenges and emerging opportunities under the new climate regime, in terms of the process of innovation into an existing energy system, the related barriers and the supporting diffusion mechanisms. Good practices for renewable energy are also presented and discussed by both the developed and the developing countries in this respect.", "title": "Technology transfer through climate change: Setting a sustainable energy pattern", "claims": ["", "Climate change mitigation is considered as a high priority internationally.", "Climate change mitigation is placed at the top of the agenda for most politicians and decision makers.", "Low-carbon sustainable technologies need to be adopted by both developed and developing countries.", "The adoption of low-carbon sustainable technologies is an effort to avoid past unsustainable practices.", "The adoption of low-carbon sustainable technologies is an effort to avoid being locked into old, less sustainable technologies.", "Technology transfer (TT) is an important feature of both the United Nations Framework Convention on Climate Change (UNFCCC) and its Kyoto Protocol.", "Technology transfer (TT) can play a key role in climate change mitigation.", "Technology transfer (TT) can allow countries to move quickly to environmentally sound and sustainable practices, institutions, and technologies.", "The transfer or innovation process must be fast enough to reduce global vulnerability to climate change.", "The aim of the paper is to analyze the TT challenges and emerging opportunities under the new climate regime.", "The paper analyzes the process of innovation into an existing energy system.", "The paper analyzes the related barriers to technology transfer.", "The paper analyzes the supporting diffusion mechanisms for technology transfer.", "Good practices for renewable energy are presented and discussed by both developed and developing countries."]}, {"metadata": {"year": 2022}, "authors": ["Nicol\u00e1s M. Perrone"], "summary": "The role of technology transfer in climate change negotiations is vital. If technology is to help us mitigate and adapt to climate change, the international community needs to ensure sufficient innovation and technology transfer. One of the main challenges of the technology transfer regime for environmentally sound technologies is that a private and market-led model may not meet global technology transfer needs. This policy brief suggests that governments should explore market, hybrid and non-market approaches to accelerate the transfer of environmentally sound technologies. Developing countries\u2019 governments should also explore cooperative approaches to improve their bargaining power, reduce costs and ensure adaptation and innovation capacity in the developing world", "title": "Technology Transfer and Climate Change: A developing country perspective", "claims": ["- The role of technology transfer in climate change negotiations is vital.", "- If technology is to help us mitigate and adapt to climate change, the international community needs to ensure sufficient innovation and technology transfer.", "- One of the main challenges of the technology transfer regime for environmentally sound technologies is that a private and market-led model may not meet global technology transfer needs.", "- This policy brief suggests that governments should explore market, hybrid, and non-market approaches to accelerate the transfer of environmentally sound technologies.", "- Developing countries\u2019 governments should also explore cooperative approaches to improve their bargaining power, reduce costs, and ensure adaptation and innovation capacity in the developing world."]}, {"metadata": {"year": 2019}, "authors": ["Chen Zhou"], "summary": "Climate friendly technologies contribute to tackling global climate crisis and the dynamic transfer of these technologies is important to achieve universal climate actions. The UNFCCC, and its recent Paris Agreement, have introduced international assistance to promote climate related-technology transfer. They call for collaborative actions from both technology supplier and demander sides in order to enable environments for a meaningful and effective technology transfer. According to the UNFCCC, the international technology assistance is unlikely to work in a desired way with the absence of indigenous enabling environments. Therefore, it is crucial to identify, assess and overcome potential barriers potentially confronted by host countries in their acquisition of climate technologies, which helps prepare these countries for climate resilience economy and sustainable development. This paper attempts to provide a deep and comprehensive analysis on enabling policy/law environments in host countries and uses Asian countries as examples in most occasions.", "title": "Enabling Law and Policy Environment for Climate Technology Transfer: From Perspectives of Host Countries", "claims": ["", "Climate friendly technologies contribute to tackling the global climate crisis.", "The dynamic transfer of climate friendly technologies is important to achieve universal climate actions.", "The UNFCCC and its recent Paris Agreement have introduced international assistance to promote climate-related technology transfer.", "The UNFCCC and its recent Paris Agreement call for collaborative actions from both technology supplier and demander sides to enable environments for meaningful and effective technology transfer.", "According to the UNFCCC, international technology assistance is unlikely to work in a desired way without indigenous enabling environments.", "It is crucial to identify, assess, and overcome potential barriers confronted by host countries in their acquisition of climate technologies.", "Overcoming potential barriers helps prepare host countries for a climate-resilient economy and sustainable development.", "The paper attempts to provide a deep and comprehensive analysis of enabling policy/law environments in host countries.", "The paper uses Asian countries as examples in most occasions."]}, {"metadata": {"year": 2012}, "authors": ["May  Elsayyad", "Florian  Morath"], "summary": "This paper considers investments in cost-reducing technology in the context of contributions to climate protection. Contributions to mitigating climate change are analyzed in a two-period public goods framework where later contributions can be based on better information, but delaying the contribution to the public good is costly because of irreversible damages. We show that, when all countries have access to the new technology, countries have an incentive to invest in technology because this can lead to an earlier contribution of other countries and therefore reduce a country's burden of contributing to the public good. Our results provide a rationale for the support of technology sharing initiatives.", "title": "Technology Transfers for Climate Change", "claims": ["", "This paper considers investments in cost-reducing technology in the context of contributions to climate protection.", "Contributions to mitigating climate change are analyzed in a two-period public goods framework.", "Later contributions to climate change mitigation can be based on better information.", "Delaying the contribution to the public good is costly because of irreversible damages.", "When all countries have access to the new technology, countries have an incentive to invest in technology.", "Investing in technology can lead to an earlier contribution of other countries.", "An earlier contribution of other countries can reduce a country's burden of contributing to the public good.", "The results of the paper provide a rationale for the support of technology sharing initiatives."]}, {"metadata": {"year": 2012}, "authors": ["J. Lovett", "P. Hofman", "K. Morsink", "J. Clancy"], "summary": "A key element of climate change mitigation and adaptation is the transfer of more effective and efficient low-carbon technologies between developed and developing countries. Although several policy mechanisms for technology transfer are in place, most observers agree that these have not been very effective in accelerating the rate of diffusion of energy-efficient and renewable-based technologies. There is a need for market-oriented approaches in order to diffuse efficient technologies more rapidly and to reduce high transaction costs, which are a major factor explaining the low effectiveness of existing mechanisms (Michaelowa and Jotzo, 2005; Jung, 2006; Hofman et al, 2008; Lovett et al, 2009; Byigero et al, 2010; Timilsina et al, 2010). At the 2007 G8 Summit in Heiligendamm, it was recognized that an \u2018expanded approach to collaboratively accelerate the widespread adoption of clean energy and climate friendly technology\u2019 was needed (G8, 2007). In successive outputs from the United Nations Framework Convention on Climate Change (UNFCCC) negotiations, such as the 2007 Bali Action Plan, the 2008 Poznan Strategic Programme on Technology Transfer, the 2009 Copenhagen Accord and the 2010 Cancun Technology Mechanism, the requirement for scaling up technology transfer features prominently. The problem is that project-based funding mechanisms, such as those under the Global Environment Facility (GEF) and Clean Development Mechanism (CDM), can never do more than provide a fraction of the resources needed to transfer sufficient environmentally sound technologies to permit economic advancement of developing countries while minimizing greenhouse gas emissions;", "title": "Technology Transfer and Global Markets", "claims": ["- A key element of climate change mitigation and adaptation is the transfer of more effective and efficient low-carbon technologies between developed and developing countries.", "- Although several policy mechanisms for technology transfer are in place, most observers agree that these have not been very effective in accelerating the rate of diffusion of energy-efficient and renewable-based technologies.", "- There is a need for market-oriented approaches in order to diffuse efficient technologies more rapidly and to reduce high transaction costs, which are a major factor explaining the low effectiveness of existing mechanisms.", "- At the 2007 G8 Summit in Heiligendamm, it was recognized that an \u2018expanded approach to collaboratively accelerate the widespread adoption of clean energy and climate friendly technology\u2019 was needed.", "- In successive outputs from the United Nations Framework Convention on Climate Change (UNFCCC) negotiations, such as the 2007 Bali Action Plan, the 2008 Poznan Strategic Programme on Technology Transfer, the 2009 Copenhagen Accord and the 2010 Cancun Technology Mechanism, the requirement for scaling up technology transfer features prominently.", "- The problem is that project-based funding mechanisms, such as those under the Global Environment Facility (GEF) and Clean Development Mechanism (CDM), can never do more than provide a fraction of the resources needed to transfer sufficient environmentally sound technologies to permit economic advancement of developing countries while minimizing greenhouse gas emissions."]}, {"metadata": {"year": 2011}, "authors": ["D. Popp"], "summary": "As the developed world begins efforts to limit its emissions of greenhouse gases, economic growth in developing countries is causing increased emissions from the developing world. Reducing these emissions while still enabling developing countries to grow requires the use of climate-friendly technologies in these countries. In most cases, these technologies are first created in high-income countries. Thus, the challenge for climate policy is to encourage the transfer of these climate-friendly technologies to the developing world. This article reviews the economic literature on environmental technology transfer and discusses the implications of this literature for climate policy, focusing on the Clean Development Mechanism (CDM). A key point is that technology diffusion is gradual. Early adoption of policy by developed countries leads to the development of new technologies that make it easier for developing countries to reduce pollution as well. Since clean technologies are first developed in the world's leading economies, international trade and foreign investments provide access to these technologies. Moreover, evidence suggests that some technologies, such as those enhancing energy efficiency, will diffuse to developing countries even without the aid of policy prescriptions, such as the CDM. This is important for assessing the potential emissions reductions of proposed CDM projects.", "title": "International Technology Transfer, Climate Change, and the Clean Development Mechanism", "claims": ["- As the developed world begins efforts to limit its emissions of greenhouse gases, economic growth in developing countries is causing increased emissions from the developing world.", "- Reducing these emissions while still enabling developing countries to grow requires the use of climate-friendly technologies in these countries.", "- In most cases, these climate-friendly technologies are first created in high-income countries.", "- The challenge for climate policy is to encourage the transfer of these climate-friendly technologies to the developing world.", "- Technology diffusion is gradual.", "- Early adoption of policy by developed countries leads to the development of new technologies that make it easier for developing countries to reduce pollution as well.", "- Since clean technologies are first developed in the world's leading economies, international trade and foreign investments provide access to these technologies.", "- Evidence suggests that some technologies, such as those enhancing energy efficiency, will diffuse to developing countries even without the aid of policy prescriptions, such as the Clean Development Mechanism (CDM).", "- The diffusion of technologies without policy aid is important for assessing the potential emissions reductions of proposed CDM projects."]}], "query": "Technology Transfer: COP26 emphasized the importance of technology transfer from developed to developing countries to foster climate adaptation and mitigation. This entails sharing and facilitating access to clean and sustainable technologies that can support low-carbon pathways for development. Unilever, as a global player in the consumer goods industry, has made significant contributions through technology transfer. For instance, the company's Sustainable Living Plan includes initiatives such as sharing renewable energy solutions, water-saving technologies, and sustainable packaging innovations with suppliers and partners across its value chain. Unilever's commitment to technology transfer supports the agenda set at COP26, promoting the equitable distribution of climate-friendly technologies for a more sustainable future.", "summary_abstract": null, "summary_extract": "The collective claims emphasize the critical role of technology transfer in addressing climate change, particularly in the context of COP26's goals for fostering climate adaptation and mitigation through the sharing of clean and sustainable technologies. Flamos and Begg (2010) highlight the importance of technology transfer under the UNFCCC to enable developing countries to adopt environmentally sound technologies, aligning with the objectives set at COP26. Veldhuis (1979) underscores the significance of multinational companies as key conduits for technology transfer to developing nations, which is pertinent to Unilever's role in this process. Karakosta et al. (2010) and Perrone (2022) both stress that technology transfer is essential for climate change mitigation and that it must be expedited to reduce global vulnerability. Zhou (2019) further supports this by noting the necessity of overcoming barriers to technology transfer to prepare host countries for sustainable development. Lovett et al. (2012) and Popp (2011) discuss the challenges and gradual nature of technology diffusion, emphasizing the need for effective mechanisms to accelerate the transfer of low-carbon technologies. Collectively, these claims illustrate the multifaceted approach required to ensure the successful transfer of climate-friendly technologies, as advocated by COP26 and exemplified by Unilever's initiatives."}, {"papers": [{"metadata": {"year": 2016}, "authors": ["Steven Arnocky"], "summary": "Men, more than women, prefer physically attractive and sexually faithful mates. Women and girls who are high on these desired traits might also be more popular within their same-sex peer networks. Accordingly, women, more than men, are motivated to display and accentuate these matevalue and peer-valued characteristics, which are, in part, signals of reproductively and socially relevant information. Social-cognitive mechanisms such as social comparison, as well as emotions such as envy, appear to underlie some behaviors associated with women\u2019s desire to be considered among desirable women. Across diverse human cultures, men\u2019s and women\u2019s mate preferences have been shown to diverge in reproductively important ways. One of the most consistent sex differences is men\u2019s greater expressed preference for physically attractive partners. For instance, Buss (1989) found that in each of 37 cultures studied, men more than women desired partners who were youthful and physically attractive. Moreover, men are remarkably consistent in the specific features that they find attractive in a mate. These features typically include lustrous hair, clear skin, full breasts, feminine and symmetrical facial features, and a low waist-to-hip ratio (i.e., an hourglass figure) (Buss 1989; see Arnocky et al. 2014 for review). A growing body of evidence suggests that such physical features may have evolved, in part, as relatively honest cues to reproductively important aspects of women\u2019s phenotypic condition, including youth (i.e., being of reproductive age), underlying health, and/or fertility (Arnocky et al. 2014). Ancestral men who happened to be attracted to these features would therefore have out-reproduced those who did not share their preferences (Arnocky et al. 2014). To the extent that mate preferences for condition-linked physical features are heritable, such preferences would proliferate and become prevalent in the population.", "title": "D Desire to Be Included Among Desirable Women", "claims": ["- Men, more than women, prefer physically attractive and sexually faithful mates.", "- Women and girls who are high on desired traits of physical attractiveness and sexual faithfulness might also be more popular within their same-sex peer networks.", "- Women, more than men, are motivated to display and accentuate mate-value and peer-valued characteristics, which are signals of reproductively and socially relevant information.", "- Social-cognitive mechanisms such as social comparison, as well as emotions such as envy, appear to underlie some behaviors associated with women\u2019s desire to be considered among desirable women.", "- Across diverse human cultures, men\u2019s and women\u2019s mate preferences have been shown to diverge in reproductively important ways.", "- One of the most consistent sex differences is men\u2019s greater expressed preference for physically attractive partners.", "- Buss (1989) found that in each of 37 cultures studied, men more than women desired partners who were youthful and physically attractive.", "- Men are remarkably consistent in the specific features that they find attractive in a mate, which typically include lustrous hair, clear skin, full breasts, feminine and symmetrical facial features, and a low waist-to-hip ratio (i.e., an hourglass figure).", "- A growing body of evidence suggests that physical features such as lustrous hair, clear skin, full breasts, feminine and symmetrical facial features, and a low waist-to-hip ratio may have evolved, in part, as relatively honest cues to reproductively important aspects of women\u2019s phenotypic condition, including youth, underlying health, and/or fertility.", "- Ancestral men who happened to be attracted to features like lustrous hair, clear skin, full breasts, feminine and symmetrical facial features, and a low waist-to-hip ratio would have out-reproduced those who did not share their preferences.", "- To the extent that mate preferences for condition-linked physical features are heritable, such preferences would proliferate and become prevalent in the population."]}, {"metadata": {"year": 2013}, "authors": ["A. Little", "B. Jones", "D. Feinberg", "D. Perrett"], "summary": "Several evolutionarily relevant sources of individual differences in face preference have been documented for women. Here, we examine three such sources of individual variationinmen\u2019spreferenceforfemalefacialfemininity:termofrelationship,partnership status and self-perceived attractiveness. We show that men prefer more feminine female faces when rating for a short-term relationship and when they have a partner (Study 1). These variables were found to interact in a follow-up study (Study 2). Men who thought themselves attractive also preferred more feminized female faces for short-term relationships than men who thought themselves less attractive (Study 1 and Study 2). In women, similar findings for masculine preferences in male faces have been interpreted as adaptive. In men, such preferences potentially reflect that attractive males are able to compete for high-quality female partners in short-term contexts. When a man has secured a mate, the potential cost of being discovered may increase his choosiness regardingshort-termpartnersrelativetounpartneredmen,whocanbetterincreasetheir short-term mating success by relaxing their standards. Such potentially strategic preferences imply that men also face trade-offs when choosing relatively masculine or feminine faced partners. In line with a trade-off, women with feminine faces were seen as more likely to be unfaithful and more likely to pursue short-term relationships (Study 3), suggesting that risk of cuckoldry is one factor that may limit men\u2019s preferences for femininity in women and could additionally lead to preferences for femininity in short-term mates. Mature features in adult human faces reflect the masculinization or feminization of secondary sexual characteristics that occurs at puberty. These face shape differences in part arise because of the action of hormones such as testosterone. For example, smaller jawbones and fatter cheeks are features of female faces that differentiate them from male faces (e.g., Enlow, 1982). In terms of women\u2019s attraction to masculinity in male faces, the direction of relationship varies across studies and researchers have documented differences in the attractiveness of masculinity according to short-term versus long-term matingcontextsandvarioussourcesofindividualdifferencesinpreferences(Little,Jones,", "title": "Men'sstrategicpreferencesforfemininityinfemale faces", "claims": ["- Several evolutionarily relevant sources of individual differences in face preference have been documented for women.", "- Men prefer more feminine female faces when rating for a short-term relationship and when they have a partner (Study 1).", "- These variables (term of relationship, partnership status, and self-perceived attractiveness) were found to interact in a follow-up study (Study 2).", "- Men who thought themselves attractive also preferred more feminized female faces for short-term relationships than men who thought themselves less attractive (Study 1 and Study 2).", "- In women, similar findings for masculine preferences in male faces have been interpreted as adaptive.", "- In men, such preferences potentially reflect that attractive males are able to compete for high-quality female partners in short-term contexts.", "- When a man has secured a mate, the potential cost of being discovered may increase his choosiness regarding short-term partners relative to unpartnered men, who can better increase their short-term mating success by relaxing their standards.", "- Such potentially strategic preferences imply that men also face trade-offs when choosing relatively masculine or feminine faced partners.", "- Women with feminine faces were seen as more likely to be unfaithful and more likely to pursue short-term relationships (Study 3).", "- Risk of cuckoldry is one factor that may limit men\u2019s preferences for femininity in women and could additionally lead to preferences for femininity in short-term mates.", "- Mature features in adult human faces reflect the masculinization or feminization of secondary sexual characteristics that occurs at puberty.", "- These face shape differences in part arise because of the action of hormones such as testosterone.", "- Smaller jawbones and fatter cheeks are features of female faces that differentiate them from male faces (e.g., Enlow, 1982).", "- In terms of women\u2019s attraction to masculinity in male faces, the direction of relationship varies across studies.", "- Researchers have documented differences in the attractiveness of masculinity according to short-term versus long-term mating contexts and various sources of individual differences in preferences (Little, Jones)."]}, {"metadata": {"year": 2020}, "authors": ["L. Lamy"], "summary": "When asked to state their ideal romantic-partner preferences, men tend to overestimate women\u2019s physical attractiveness, whereas women tend to overestimate men\u2019s earning prospects [1,2]. Beyond this gender-related difference, however, both men and women prefer attractive, as compared to non-attractive partners. Attractive individuals are more popular, at least among members of the opposite gender, and they are more successful in dating relationships [3]. In line with these findings, it could be expected that feelings of love and affection would be more readily directed towards attractive individuals. But it is striking that this hypothesis was not supported by empirical studies. Among dating partners, neither independent observer, self, nor partner ratings of attractiveness are linked with the level of love an individual receives from his/her partner [4]. For men and women alike, beauty has no advantage in terms of love received, or given. Attractive women are more desired as romantic partners. Attractive men have more cross-gender interactions. Thus, it could be stated that physical attractiveness creates attraction, but it is not enough to create love.", "title": "Physical Attractiveness and Romantic Relationships: A Review", "claims": ["- When asked to state their ideal romantic-partner preferences, men tend to overestimate women\u2019s physical attractiveness.", "- When asked to state their ideal romantic-partner preferences, women tend to overestimate men\u2019s earning prospects.", "- Beyond this gender-related difference, both men and women prefer attractive, as compared to non-attractive partners.", "- Attractive individuals are more popular, at least among members of the opposite gender.", "- Attractive individuals are more successful in dating relationships.", "- Among dating partners, neither independent observer, self, nor partner ratings of attractiveness are linked with the level of love an individual receives from his/her partner.", "- For men and women alike, beauty has no advantage in terms of love received, or given.", "- Attractive women are more desired as romantic partners.", "- Attractive men have more cross-gender interactions.", "- Physical attractiveness creates attraction, but it is not enough to create love."]}, {"metadata": {"year": 1994}, "authors": ["D. Kenrick", "S. Neuberg", "Kristin L. Zierk", "J. Krones"], "summary": "Previous research indicates that males, compared with females, evaluate their relationships less favorably after exposure to physically attractive members of the other sex. An evolutionary model predicts a converse effect after exposure to opposite-sex individuals high in dominance, which should lead females to evaluate their current relationships less favorably than males. Women and men rated their current relationships after being exposed to opposite-sex targets varying in both dominance and physical attractiveness. Consistent with earlier research, males exposed to physically attractive, as compared with average, targets rated their current relationships less favorably. Males' relationship evaluations were not directly influenced by the targets' dominance, although the effect of physical attractiveness was significant only for men exposed to women low in dominance. However; females' evaluations of their relationships were unaffected by exposure to physically attractive males but were lower after exposure to targets high in dominance. These data support predictions derived from an evolutionary model and suggest that such models can be used to generate testable hypotheses about ongoing social cognition.", "title": "Evolution and Social Cognition: Contrast Effects as a Function of Sex, Dominance, and Physical Attractiveness", "claims": ["", "Previous research indicates that males, compared with females, evaluate their relationships less favorably after exposure to physically attractive members of the other sex.", "An evolutionary model predicts a converse effect after exposure to opposite-sex individuals high in dominance, which should lead females to evaluate their current relationships less favorably than males.", "Women and men rated their current relationships after being exposed to opposite-sex targets varying in both dominance and physical attractiveness.", "Consistent with earlier research, males exposed to physically attractive, as compared with average, targets rated their current relationships less favorably.", "Males' relationship evaluations were not directly influenced by the targets' dominance.", "The effect of physical attractiveness was significant only for men exposed to women low in dominance.", "Females' evaluations of their relationships were unaffected by exposure to physically attractive males.", "Females' evaluations of their relationships were lower after exposure to targets high in dominance.", "These data support predictions derived from an evolutionary model.", "Such models can be used to generate testable hypotheses about ongoing social cognition."]}, {"metadata": {"year": 2021}, "authors": ["S. Whyte", "R. Brooks", "H. F. Chan", "B. Torgler"], "summary": "Because sexual attraction is a key driver of human mate choice and reproduction, we descriptively assess relative sex differences in the level of attraction individuals expect in the aesthetic, resource, and personality characteristics of potential mates. As a novelty we explore how male and female sexual attractiveness preference changes across age, using a dataset comprising online survey data for over 7,000 respondents across a broad age distribution of individuals between 18 and 65 years. In general, we find that both males and females show similar distribution patterns in their preference responses, with statistically significant sex differences within most of the traits. On average, females rate age, education, intelligence, income, trust, and emotional connection around 9 to 14 points higher than males on our 0\u2013100 scale range. Our relative importance analysis shows greater male priority for attractiveness and physical build, compared to females, relative to all other traits. Using multiple regression analysis, we find a consistent statistical sex difference (males relative to females) that decreases linearly with age for aesthetics, while the opposite is true for resources and personality, with females exhibiting a stronger relative preference, particularly in the younger aged cohort. Exploring non-linearity in sex difference with contour plots for intelligence and attractiveness across age (mediated by age) indicates that sex differences in attractiveness preferences are driven by the male cohort (particularly age 30 to 40) for those who care about the importance of age, while intelligence is driven by females caring relatively more about intelligence for those who see age as very important (age cohort 40 to 55). Overall, many of our results indicate distinct variations within sex at key life stages, which is consistent with theories of selection pressure. Moreover, results also align with theories of parental investment, the gender similarities hypothesis, and mutual mate choice\u2013which speaks to the fact that the broader discipline of evolutionary mate choice research in humans still contains considerable scope for further inquiry towards a unified theory, particularly when exploring sex-difference across age.", "title": "Sex differences in sexual attraction for aesthetics, resources and personality across age", "claims": ["- Sexual attraction is a key driver of human mate choice and reproduction.", "- The study descriptively assesses relative sex differences in the level of attraction individuals expect in the aesthetic, resource, and personality characteristics of potential mates.", "- The study explores how male and female sexual attractiveness preference changes across age using a dataset comprising online survey data for over 7,000 respondents across a broad age distribution of individuals between 18 and 65 years.", "- Both males and females show similar distribution patterns in their preference responses, with statistically significant sex differences within most of the traits.", "- On average, females rate age, education, intelligence, income, trust, and emotional connection around 9 to 14 points higher than males on a 0\u2013100 scale range.", "- The relative importance analysis shows greater male priority for attractiveness and physical build compared to females, relative to all other traits.", "- Multiple regression analysis finds a consistent statistical sex difference (males relative to females) that decreases linearly with age for aesthetics.", "- The opposite trend is true for resources and personality, with females exhibiting a stronger relative preference, particularly in the younger aged cohort.", "- Exploring non-linearity in sex difference with contour plots for intelligence and attractiveness across age indicates that sex differences in attractiveness preferences are driven by the male cohort (particularly age 30 to 40) for those who care about the importance of age.", "- Intelligence is driven by females caring relatively more about intelligence for those who see age as very important (age cohort 40 to 55).", "- Many results indicate distinct variations within sex at key life stages, which is consistent with theories of selection pressure.", "- Results align with theories of parental investment, the gender similarities hypothesis, and mutual mate choice.", "- The broader discipline of evolutionary mate choice research in humans still contains considerable scope for further inquiry towards a unified theory, particularly when exploring sex-difference across age."]}, {"metadata": {"year": 2017}, "authors": ["Guanlin  Wang", "Minxuan  Cao", "Justina  Sauciuvenaite", "Ruth  Bissland", "Megan  Hacker", "Catherine  Hambly", "Lobke M. Vaanholt", "Chaoqun  Niu", "Mark D. Faries", "John R. Speakman"], "summary": "Abstract Parental investment hypotheses regarding mate selection suggest that human males should seek partners featured by youth and high fertility. However, females should be more sensitive to resources that can be invested on themselves and their offspring. Previous studies indicate that economic status is indeed important in male attractiveness. However, no previous study has quantified and compared the impact of equivalent resources on male and female attractiveness. Annual salary is a direct way to evaluate economic status. Here, we combined images of male and female body shape with information on annual salary to elucidate the influence of economic status on the attractiveness ratings by opposite sex raters in American, Chinese and European populations. We found that ratings of attractiveness were around 1000 times more sensitive to salary for females rating males, compared to males rating females. These results indicate that higher economic status can offset lower physical attractiveness in men much more easily than in women. Neither raters' BMI nor age influenced this effect for females rating male attractiveness. This difference explains many features of human mating behavior and may pose a barrier for male engagement in low-consumption lifestyles.", "title": "Different impacts of resources on opposite sex ratings of physical attractiveness by males and females", "claims": ["", "Parental investment hypotheses regarding mate selection suggest that human males should seek partners featured by youth and high fertility.", "Females should be more sensitive to resources that can be invested in themselves and their offspring.", "Previous studies indicate that economic status is indeed important in male attractiveness.", "No previous study has quantified and compared the impact of equivalent resources on male and female attractiveness.", "Annual salary is a direct way to evaluate economic status.", "The study combined images of male and female body shape with information on annual salary to elucidate the influence of economic status on attractiveness ratings by opposite sex raters in American, Chinese, and European populations.", "Ratings of attractiveness were around 1000 times more sensitive to salary for females rating males, compared to males rating females.", "Higher economic status can offset lower physical attractiveness in men much more easily than in women.", "Neither raters' BMI nor age influenced the effect of economic status on attractiveness for females rating male attractiveness.", "The difference in sensitivity to economic status explains many features of human mating behavior.", "The difference in sensitivity to economic status may pose a barrier for male engagement in low-consumption lifestyles."]}, {"metadata": {"year": 2022}, "authors": ["M. Kowal", "P. Sorokowski"], "summary": "Background: Public opinion on who performs more beauty-enhancing behaviors (men or women) seems unanimous. Women are often depicted as primarily interested in how they look, opposed to men, who are presumably less focused on their appearance. However, previous studies might have overlooked how masculinity relates to self-modification among men. Methods: We explored this issue in depth by conducting a qualitative Study 1 aimed to establish how men and women enhance their attractiveness (N = 121) and a quantitative Study 2 aimed to test time spent on activities that increase one\u2019s attractiveness in a longitudinal design (with seven repeated measures from 62 participants; N(total) = 367). Results: We observed no sex differences in beauty investments. Although women spent more time on make-up and cosmetics usage, men caught up with women in exercising and bodybuilding. Conclusion: Our study provides evidence that there may not be such wide sex differences in the intensity of enhancing one\u2019s appearance as has been previously thought. We hypothesize that this might partly stem from changes in gender roles regarding masculinity.", "title": "Sex Differences in Physical Attractiveness Investments: Overlooked Side of Masculinity", "claims": ["- Public opinion seems unanimous that women perform more beauty-enhancing behaviors than men.", "- Women are often depicted as primarily interested in how they look, as opposed to men, who are presumably less focused on their appearance.", "- Previous studies might have overlooked how masculinity relates to self-modification among men.", "- Study 1 was a qualitative study aimed to establish how men and women enhance their attractiveness, with a sample size of 121 participants.", "- Study 2 was a quantitative study aimed to test time spent on activities that increase one\u2019s attractiveness in a longitudinal design, with seven repeated measures from 62 participants and a total sample size of 367.", "- The study observed no sex differences in beauty investments.", "- Women spent more time on make-up and cosmetics usage.", "- Men caught up with women in exercising and bodybuilding.", "- The study provides evidence that there may not be such wide sex differences in the intensity of enhancing one\u2019s appearance as has been previously thought.", "- The study hypothesizes that the lack of wide sex differences in beauty-enhancing behaviors might partly stem from changes in gender roles regarding masculinity."]}, {"metadata": {"year": 1995}, "authors": ["Nigel  Barber"], "summary": "Abstract Psychological evidence suggests that sex differences in morphology have been modified by sexual selection so as to attract mates (intersexual selection) or intimidate rivals (intrasexual selection). Women compete with each other for high quality husbands by advertising reproductive value in terms of the distribution of fat reserves and by exaggerating morphological indicators of youthfulness such as a small nose and small feet and pale, hairless skin. Men's physical appearance tends to communicate social dominance, which has the combined effects of intimidating reproductive rivals and attracting mates. In addition to their attractiveness and intimidatory effects, human secondary sexual characters also provide cues to hormonal status and phenotypic quality consistent with the good genes model of sexual selection (which includes parasite resistance). Low waist-hip ratio is sexually attractive in women and indicates a high estrogen/testosterone ratio (which favors reproductive function). Facial attractiveness provides honest cues to health and mate value. The permanently enlarged female breast appears to have evolved under the influence of both the good genes and the runaway selection mechanisms. The male beard is not obviously related to phenotypic quality and may have evolved through a process of runaway intersexual selection.", "title": "The evolutionary psychology of physical attractiveness: Sexual selection and human morphology", "claims": ["- Psychological evidence suggests that sex differences in morphology have been modified by sexual selection to attract mates (intersexual selection) or intimidate rivals (intrasexual selection).", "- Women compete with each other for high-quality husbands by advertising reproductive value in terms of the distribution of fat reserves.", "- Women compete by exaggerating morphological indicators of youthfulness such as a small nose, small feet, and pale, hairless skin.", "- Men's physical appearance tends to communicate social dominance, which has the combined effects of intimidating reproductive rivals and attracting mates.", "- Human secondary sexual characters provide cues to hormonal status and phenotypic quality consistent with the good genes model of sexual selection, which includes parasite resistance.", "- Low waist-hip ratio is sexually attractive in women and indicates a high estrogen/testosterone ratio, which favors reproductive function.", "- Facial attractiveness provides honest cues to health and mate value.", "- The permanently enlarged female breast appears to have evolved under the influence of both the good genes and the runaway selection mechanisms.", "- The male beard is not obviously related to phenotypic quality and may have evolved through a process of runaway intersexual selection."]}], "query": "Female attractiveness evolves compared to male attractiveness because men are more interested in attractiveness?", "summary_abstract": null, "summary_extract": "The research question explores whether female attractiveness evolves differently from male attractiveness due to men's heightened interest in physical appeal. The claims collectively suggest that men indeed place a greater emphasis on physical attractiveness when selecting mates, which has influenced the evolution of female attractiveness traits. Arnocky (2016) highlights that men consistently prefer physically attractive partners, with specific features such as lustrous hair, clear skin, and a low waist-to-hip ratio being particularly appealing. This preference is thought to be linked to cues of youth, health, and fertility, which are important for reproductive success. Little et al. (2013) further support this by noting that men prefer more feminine female faces, especially in short-term relationships, indicating a strategic preference based on perceived reproductive value.\n\nMoreover, Whyte et al. (2021) confirm that men prioritize attractiveness and physical build more than women, who tend to value resources and personality traits. This aligns with the parental investment theory, which suggests that men seek partners with high fertility, while women are more attuned to resource availability (Wang et al., 2017). Lamy (2020) also notes that attractive women are more desired as romantic partners, reinforcing the idea that physical attractiveness is a significant factor in male mate choice.\n\nIn contrast, women are depicted as engaging more in beauty-enhancing behaviors, possibly to meet these male preferences (Kowal & Sorokowski, 2022). Barber (1995) adds that women compete for high-quality mates by emphasizing morphological indicators of youthfulness, such as a low waist-hip ratio, which is sexually attractive and indicative of reproductive health.\n\nOverall, the claims suggest that male preferences for physical attractiveness have indeed played a role in shaping the evolution of female attractiveness, as men are more consistently driven by visual cues linked to reproductive potential."}, {"papers": [{"metadata": {"year": 2021}, "authors": ["P. Robertson"], "summary": ": Misinformation related to climate change has been around for decades, mostly in the form of denying the existence of global warming. Today, misinformation is manifesting in different ways, but it still has the same outcome: undermining science and delaying climate action.", "title": "Introduction and context", "claims": ["- Misinformation related to climate change has been around for decades.", "- Misinformation mostly took the form of denying the existence of global warming.", "- Today, misinformation is manifesting in different ways.", "- Misinformation still has the same outcome: undermining science and delaying climate action."]}, {"metadata": {"year": 2015}, "authors": ["LaRue Allen", "Bridget B. Kelly", "Youth Board on Children", "Families."], "summary": ": Misinformation related to climate change has been around for decades, mostly in the form of denying the existence of global warming. Today, misinformation is manifesting in different ways, but it still has the same outcome: undermining science and delaying climate action. Social can undermine and have", "title": "Introduction and Context", "claims": ["- Misinformation related to climate change has been around for decades.", "- Misinformation mostly takes the form of denying the existence of global warming.", "- Today, misinformation is manifesting in different ways.", "- Misinformation still has the same outcome: undermining science and delaying climate action."]}, {"metadata": {"year": 2023}, "authors": ["Tiffany E. Sill", "Jaime R Ayala", "Julianne Rolf", "Spencer Smith", "Shelby Dye"], "summary": "Despite the existence of a substantial amount of climate-related scientific data, misconceptions about climate change are still prevalent within public opinion. Dissemination of misinformation to the public through subjective media sources is a major challenge that climate scientists face. Implementation of climate policy is crucial for mitigation and adaptation measures required to curtail anthropogenic rooted climate change. This paper will discuss student perspectives on the 2022 United Nations climate summit in Egypt (COP27) related to climate literacy and public opinion as the driving forces behind the enactment and execution of important climate-based policy.", "title": "How Climate Literacy and Public Opinion Are the Driving Forces Behind Climate-Based Policy: A Student Perspective on COP27", "claims": ["- Despite the existence of a substantial amount of climate-related scientific data, misconceptions about climate change are still prevalent within public opinion.", "- Dissemination of misinformation to the public through subjective media sources is a major challenge that climate scientists face.", "- Implementation of climate policy is crucial for mitigation and adaptation measures required to curtail anthropogenic rooted climate change.", "- This paper will discuss student perspectives on the 2022 United Nations climate summit in Egypt (COP27) related to climate literacy and public opinion as the driving forces behind the enactment and execution of important climate-based policy."]}, {"metadata": {"year": 2019}, "authors": ["J. Cook"], "summary": "While there is overwhelming scientific agreement on climate change, the public has become polarized over fundamental questions such as human-caused global warming. Communication strategies to reduce polarization rarely address the underlying cause: ideologically-driven misinformation. In order to effectively counter misinformation campaigns, scientists, communicators, and educators need to understand the arguments and techniques in climate science denial, as well as adopt evidence-based approaches to neutralizing misinforming content. This chapter reviews analyses of climate misinformation, outlining a range of denialist arguments and fallacies. Identifying and deconstructing these different types of arguments is necessary to design appropriate interventions that effectively neutralize the misinformation. This chapter also reviews research into how to counter misinformation using communication interventions such as inoculation, educational approaches such as misconception-based learning, and the interdisciplinary combination of technology and psychology known as technocognition.", "title": "Understanding and Countering Misinformation About Climate Change", "claims": ["", "There is overwhelming scientific agreement on climate change.", "The public has become polarized over fundamental questions such as human-caused global warming.", "Communication strategies to reduce polarization rarely address the underlying cause: ideologically-driven misinformation.", "In order to effectively counter misinformation campaigns, scientists, communicators, and educators need to understand the arguments and techniques in climate science denial.", "Scientists, communicators, and educators need to adopt evidence-based approaches to neutralizing misinforming content.", "This chapter reviews analyses of climate misinformation, outlining a range of denialist arguments and fallacies.", "Identifying and deconstructing different types of arguments is necessary to design appropriate interventions that effectively neutralize the misinformation.", "This chapter reviews research into how to counter misinformation using communication interventions such as inoculation.", "This chapter reviews research into how to counter misinformation using educational approaches such as misconception-based learning.", "This chapter reviews research into how to counter misinformation using the interdisciplinary combination of technology and psychology known as technocognition."]}, {"metadata": {"year": 2022}, "authors": ["John  Cook"], "summary": "While there is overwhelming scientific agreement on climate change, the public has become polarized over fundamental questions such as human-caused global warming. Communication strategies to reduce polarization rarely address the underlying cause: ideologically-driven misinformation. In order to effectively counter misinformation campaigns, scientists, communicators, and educators need to understand the arguments and techniques in climate science denial, as well as adopt evidence-based approaches to neutralizing misinforming content. This chapter reviews analyses of climate misinformation, outlining a range of denialist arguments and fallacies. Identifying and deconstructing these different types of arguments is necessary to design appropriate interventions that effectively neutralize the misinformation. This chapter also reviews research into how to counter misinformation using communication interventions such as inoculation, educational approaches such as misconception-based learning, and the interdisciplinary combination of technology and psychology known as technocognition.", "title": "Understanding and Countering Misinformation About Climate Change", "claims": ["- There is overwhelming scientific agreement on climate change.", "- The public has become polarized over fundamental questions such as human-caused global warming.", "- Communication strategies to reduce polarization rarely address the underlying cause: ideologically-driven misinformation.", "- In order to effectively counter misinformation campaigns, scientists, communicators, and educators need to understand the arguments and techniques in climate science denial.", "- Scientists, communicators, and educators need to adopt evidence-based approaches to neutralizing misinforming content.", "- This chapter reviews analyses of climate misinformation, outlining a range of denialist arguments and fallacies.", "- Identifying and deconstructing different types of arguments is necessary to design appropriate interventions that effectively neutralize the misinformation.", "- This chapter reviews research into how to counter misinformation using communication interventions such as inoculation.", "- This chapter reviews research into how to counter misinformation using educational approaches such as misconception-based learning.", "- This chapter reviews research into how to counter misinformation using the interdisciplinary combination of technology and psychology known as technocognition."]}, {"metadata": {"year": 2019}, "authors": ["Justin  Farrell", "Kathryn  McConnell", "Robert  Brulle"], "summary": "Nowhere has the impact of scientific misinformation been more profound than on the issue of climate change in the United States. Effective responses to this multifaceted problem have been slow to develop, in large part because many experts have not only underestimated its impact, but have also overlooked the underlying institutional structure, organizational power and financial roots of misinformation. Fortunately, a growing body of sophisticated research has emerged that can help us to better understand these dynamics and provide the basis for developing a coordinated set of strategies across four related areas (public inoculation, legal strategies, political mechanisms and financial transparency) to thwart large-scale misinformation campaigns before they begin, or after they have taken root.This Perspective synthesizes research on the origins and impacts of scientific misinformation campaigns, pointing to public inoculation, legal, political and financial strategies for countering climate change misinformation and limiting its dissemination.", "title": "Evidence-based strategies to combat scientific misinformation", "claims": ["- Nowhere has the impact of scientific misinformation been more profound than on the issue of climate change in the United States.", "- Effective responses to the multifaceted problem of climate change misinformation have been slow to develop.", "- Many experts have underestimated the impact of climate change misinformation.", "- Many experts have overlooked the underlying institutional structure, organizational power, and financial roots of misinformation.", "- A growing body of sophisticated research has emerged that can help us better understand the dynamics of misinformation.", "- This research provides the basis for developing a coordinated set of strategies across four related areas to thwart large-scale misinformation campaigns.", "- The four related areas for developing strategies are public inoculation, legal strategies, political mechanisms, and financial transparency.", "- The Perspective synthesizes research on the origins and impacts of scientific misinformation campaigns.", "- The Perspective points to public inoculation, legal, political, and financial strategies for countering climate change misinformation and limiting its dissemination."]}, {"metadata": {"year": 2017}, "authors": ["J. Cook", "S. Lewandowsky", "Ullrich K. H. Ecker"], "summary": "Misinformation can undermine a well-functioning democracy. For example, public misconceptions about climate change can lead to lowered acceptance of the reality of climate change and lowered support for mitigation policies. This study experimentally explored the impact of misinformation about climate change and tested several pre-emptive interventions designed to reduce the influence of misinformation. We found that false-balance media coverage (giving contrarian views equal voice with climate scientists) lowered perceived consensus overall, although the effect was greater among free-market supporters. Likewise, misinformation that confuses people about the level of scientific agreement regarding anthropogenic global warming (AGW) had a polarizing effect, with free-market supporters reducing their acceptance of AGW and those with low free-market support increasing their acceptance of AGW. However, we found that inoculating messages that (1) explain the flawed argumentation technique used in the misinformation or that (2) highlight the scientific consensus on climate change were effective in neutralizing those adverse effects of misinformation. We recommend that climate communication messages should take into account ways in which scientific content can be distorted, and include pre-emptive inoculation messages.", "title": "Neutralizing misinformation through inoculation: Exposing misleading argumentation techniques reduces their influence", "claims": ["", "Misinformation can undermine a well-functioning democracy.", "Public misconceptions about climate change can lead to lowered acceptance of the reality of climate change.", "Public misconceptions about climate change can lead to lowered support for mitigation policies.", "This study experimentally explored the impact of misinformation about climate change.", "This study tested several pre-emptive interventions designed to reduce the influence of misinformation.", "False-balance media coverage, which gives contrarian views equal voice with climate scientists, lowered perceived consensus overall.", "The effect of false-balance media coverage was greater among free-market supporters.", "Misinformation that confuses people about the level of scientific agreement regarding anthropogenic global warming (AGW) had a polarizing effect.", "Free-market supporters reduced their acceptance of AGW when exposed to misinformation about scientific agreement.", "Those with low free-market support increased their acceptance of AGW when exposed to misinformation about scientific agreement.", "Inoculating messages that explain the flawed argumentation technique used in the misinformation were effective in neutralizing the adverse effects of misinformation.", "Inoculating messages that highlight the scientific consensus on climate change were effective in neutralizing the adverse effects of misinformation.", "Climate communication messages should take into account ways in which scientific content can be distorted.", "Climate communication messages should include pre-emptive inoculation messages."]}, {"metadata": {"year": 2023}, "authors": ["Isyaku Hassan", "R. Musa", "Mohd Nazri Latiff Azmi", "Mohamad Razali Abdullah", "Siti Zanariah Yusoff"], "summary": "Disinformation represents one of the major obstacles to meaningful actions against climate change skepticism. This study, therefore, aimed to investigate climate change disinformation across types, agents, and media platforms as reported in selected online newspapers. A total of 124 news articles gathered from Malaysia's The Star and New Straits Times were subjected to content analysis. The articles were collected from the newspapers\u2019 digital archives between August 2015 and October 2021 using \u201cclimate change\u201d and \u201cdisinformation\u201d as keywords. Subsequently, data were analyzed using the Chi-square test and descriptive statistics. The study found that disinformation about climate change is more likely to be spread by politicians, organizations, and anonymous agencies compared with business tycoons, celebrities, and academics. Also, misleading and fabricated contents represent the most common types of disinformation spread by politicians. The findings suggest that politics and social media represent the most critical factors influencing climate change. The study, therefore, calls for the joint efforts of activists, media practitioners, and governments to mitigate disinformation about climate change.", "title": "Analysis of climate change disinformation across types, agents and media platforms", "claims": ["- Disinformation represents one of the major obstacles to meaningful actions against climate change skepticism.", "- This study aimed to investigate climate change disinformation across types, agents, and media platforms as reported in selected online newspapers.", "- A total of 124 news articles gathered from Malaysia's The Star and New Straits Times were subjected to content analysis.", "- The articles were collected from the newspapers\u2019 digital archives between August 2015 and October 2021 using \u201cclimate change\u201d and \u201cdisinformation\u201d as keywords.", "- Data were analyzed using the Chi-square test and descriptive statistics.", "- The study found that disinformation about climate change is more likely to be spread by politicians, organizations, and anonymous agencies compared with business tycoons, celebrities, and academics.", "- Misleading and fabricated contents represent the most common types of disinformation spread by politicians.", "- The findings suggest that politics and social media represent the most critical factors influencing climate change.", "- The study calls for the joint efforts of activists, media practitioners, and governments to mitigate disinformation about climate change."]}], "query": "laws and policies governing climate change disinformation or misinformation", "summary_abstract": null, "summary_extract": "The collection of claims highlights the significant challenges posed by climate change misinformation and disinformation, as well as the need for effective laws and policies to address these issues. Farrell et al. (2019) emphasize the profound impact of scientific misinformation on climate change in the United States and suggest that effective responses have been slow to develop. They propose a coordinated strategy involving public inoculation, legal strategies, political mechanisms, and financial transparency to counter misinformation campaigns. Similarly, Cook (2019, 2022) underscores the importance of understanding and deconstructing denialist arguments to design interventions that neutralize misinformation. He advocates for evidence-based approaches and communication strategies, such as inoculation and misconception-based learning, to counteract ideologically-driven misinformation. Hassan et al. (2023) identify politicians, organizations, and anonymous agencies as primary spreaders of climate change disinformation, highlighting the role of politics and social media in influencing public perception. They call for collaborative efforts among activists, media practitioners, and governments to mitigate disinformation. Collectively, these claims suggest that a multifaceted approach involving legal, educational, and communicative strategies is essential to combat climate change misinformation effectively."}, {"papers": [{"metadata": {"year": 1993}, "authors": ["Anjali  Kumar"], "summary": "Concerns about public enterprise management, especially since the 1980s, have been closely associated with more generalized concerns about the role of the state in processes of production. Whether in specific enterprises or industries in the context of a mixed market economy, or across the entire economy, in a system of centralized planning, state owned and operated production units have been associated with economic inefficiencies leading to lower relative levels of output, a diversion of resources from their most productive uses and internal economic inefficiencies in management and motivation within the productive unit.1 A major cause of the economic inefficiencies of public enterprises is the difficulty of reconciling the multiple political, social and ideological aims of governments and government-appointed managers guiding the operations of these enterprises, with the achievement of economic efficiency. These concerns have led to the adoption of a wide spectrum of mechanisms to modify or alter the controls and obligations between governments and state owned enterprises to better achieve these multiple and sometimes conflicting objectives.", "title": "Public Enterprise Management Through State Holding Companies", "claims": ["", "Concerns about public enterprise management have been closely associated with more generalized concerns about the role of the state in processes of production, especially since the 1980s.", "State owned and operated production units have been associated with economic inefficiencies leading to lower relative levels of output.", "State owned and operated production units have been associated with a diversion of resources from their most productive uses.", "State owned and operated production units have been associated with internal economic inefficiencies in management and motivation within the productive unit.", "A major cause of the economic inefficiencies of public enterprises is the difficulty of reconciling the multiple political, social, and ideological aims of governments and government-appointed managers with the achievement of economic efficiency.", "Concerns about the economic inefficiencies of public enterprises have led to the adoption of a wide spectrum of mechanisms to modify or alter the controls and obligations between governments and state owned enterprises.", "The adoption of mechanisms to modify or alter the controls and obligations between governments and state owned enterprises aims to better achieve multiple and sometimes conflicting objectives."]}, {"metadata": {"year": 2002}, "authors": ["Suthathip  Yaisawarng"], "summary": "A number of studies have documented that public and private sector organisations do not use their limited resources efficiently. A possible implication is that reallocation of resources from the provision of goods and services that have relatively low marginal social benefits to those that have relatively high marginal social benefits would enhance overall social welfare. Another implication is that resources have not been used by the most productive means; ie, it is possible to produce more goods and services without additional resources. Suggested remedies range from industry reforms such as restructuring and deregulation to promote competition, to institutional changes such as adoption of efficient management practices.", "title": "Performance Measurement and Resource Allocation", "claims": ["- A number of studies have documented that public and private sector organisations do not use their limited resources efficiently.", "- A possible implication is that reallocation of resources from the provision of goods and services that have relatively low marginal social benefits to those that have relatively high marginal social benefits would enhance overall social welfare.", "- Another implication is that resources have not been used by the most productive means; ie, it is possible to produce more goods and services without additional resources.", "- Suggested remedies range from industry reforms such as restructuring and deregulation to promote competition, to institutional changes such as adoption of efficient management practices."]}, {"metadata": {"year": 2002}, "authors": ["Go  Yano", "Maho  Shiraishi"], "summary": "In this paper we attempt to investigate empirically the cause of inefficiency of Chinese state-owned enterprises in 1989\u201395, in the contract relation between Chinese government and state-owned enterprises. It is found that several moral hazards arose, in 1989\u201395 Chinese state-owned enterprises, in textile industry. To put it another way, the enterprises chose less private effort and risk than the first-best levels, because of the incentive structure designed by the government. Especially, concave payoff function to the enterprises designed by the government made them institutional risk averters and choose too little risks.", "title": "State-Owned Enterprises and Their Contract with Government in China: An Econometric Analysis", "claims": ["- In this paper, the authors attempt to investigate empirically the cause of inefficiency of Chinese state-owned enterprises in 1989\u201395, in the contract relation between the Chinese government and state-owned enterprises.", "- It is found that several moral hazards arose in 1989\u201395 in Chinese state-owned enterprises, specifically in the textile industry.", "- The enterprises chose less private effort and risk than the first-best levels because of the incentive structure designed by the government.", "- The concave payoff function to the enterprises, designed by the government, made them institutional risk averters and choose too little risks."]}, {"metadata": {"year": 2005}, "authors": ["Xiong Qing-guo"], "summary": "The state-owned enterprises almost have no room to make their own decision in changing their own fate and have always played a relatively passive role and been in a submissive position. That is the key reason why the state-owned enterprises are confronted with difficulty in the reform. As a result , effective measures should been taken to eliminate the government\u2032s substitution for the state-owned enterprises in making decision, and return the right to conduct self-reform , thus these enterprises can decide their own future.", "title": "The Consequence of Government\u2032s Substitution in Decision-making and its Rectification \u2014\u2014Reflections on the reform of the state-owned enterprises", "claims": ["", "- The state-owned enterprises almost have no room to make their own decision in changing their own fate.", "- State-owned enterprises have always played a relatively passive role.", "- State-owned enterprises have been in a submissive position.", "- The lack of decision-making power is the key reason why the state-owned enterprises are confronted with difficulty in the reform.", "- Effective measures should be taken to eliminate the government\u2032s substitution for the state-owned enterprises in making decisions.", "- Returning the right to conduct self-reform to state-owned enterprises will allow them to decide their own future."]}, {"metadata": {"year": 1974}, "authors": ["Mancur  Olson"], "summary": "Many of those who write about the corporation and the role of government take it for granted that the fundamental problem is the prevalence of monopoly in the corporate sector and that one of the crucial functions of government is to deal with this problem through anti-trust laws, or regulation of uncompetitive industries, or public ownership of firms with monopoly power. Though there is some merit in this commonplace perspective, this paper will attempt to show that there is another way of looking at the corporate and public sectors that is both better balanced and more likely to bring progress in dealing with the major problems modern societies face. More specifically, the first section of this paper will contend that the problem of monopoly, as that term is characteristically understood in economic theory, is of only modest importance, at least in the United States, both in terms of economic efficiency and distributive justice; the second section will argue that the concepts of collective goods and externalities provide a more relevant insight into the major economic problems of the time; the third will conclude that because of the problems involved in dealing with externalities and producing collective goods, and the existing mechanisms in the public sector for dealing with these problems, inefficiencies in this area are probably of extraordinary importance, and in the aggregate presumably dwarf all of those resulting from monopoly; and the fourth will suggest that social efficiency could be substantially increased through certain changes in existing mechanisms in the public sector.", "title": "On the Priority of Public Problems", "claims": ["- Many of those who write about the corporation and the role of government take it for granted that the fundamental problem is the prevalence of monopoly in the corporate sector.", "- One of the crucial functions of government is to deal with the problem of monopoly through anti-trust laws, regulation of uncompetitive industries, or public ownership of firms with monopoly power.", "- There is some merit in the commonplace perspective that monopoly is a fundamental problem in the corporate sector.", "- The paper will attempt to show that there is another way of looking at the corporate and public sectors that is both better balanced and more likely to bring progress in dealing with the major problems modern societies face.", "- The first section of the paper will contend that the problem of monopoly, as that term is characteristically understood in economic theory, is of only modest importance in the United States, both in terms of economic efficiency and distributive justice.", "- The second section will argue that the concepts of collective goods and externalities provide a more relevant insight into the major economic problems of the time.", "- The third section will conclude that because of the problems involved in dealing with externalities and producing collective goods, and the existing mechanisms in the public sector for dealing with these problems, inefficiencies in this area are probably of extraordinary importance.", "- Inefficiencies in dealing with externalities and producing collective goods presumably dwarf all of those resulting from monopoly.", "- The fourth section will suggest that social efficiency could be substantially increased through certain changes in existing mechanisms in the public sector."]}, {"metadata": {"year": 2017}, "authors": ["A. Tatuev", "Murat A. Kerefov", "N. I. Ovcharova", "Maria L. Vilisova", "Renata A. Shibzuhova"], "summary": "Nowadays, the implementation of state's social policies becomes critically urgent in the context of social development for all countries of the world. For a number of objective reasons, the state is forced to reduce its obligations to a certain extent in the social sphere in such a way as to avoid hampering the markets development. The objective of the current study is to identify the priorities of modern public administration. The structure of budget expenditures demonstrates shifting to national defense, social policy and national economy with lower health-care and education spending. At the same time, the use of tax system as a resource for meeting the State's social obligations is increasingly constrained.", "title": "Budget Constraints and Expanding of Non-Governmental Organizations Participation in the Implementation of State's Social Policies", "claims": ["- Nowadays, the implementation of state's social policies becomes critically urgent in the context of social development for all countries of the world.", "- For a number of objective reasons, the state is forced to reduce its obligations to a certain extent in the social sphere.", "- The state reduces its obligations in the social sphere in such a way as to avoid hampering the markets development.", "- The objective of the current study is to identify the priorities of modern public administration.", "- The structure of budget expenditures demonstrates shifting to national defense, social policy, and national economy.", "- There is lower health-care and education spending in the structure of budget expenditures.", "- The use of the tax system as a resource for meeting the State's social obligations is increasingly constrained."]}, {"metadata": {"year": 1985}, "authors": ["T. Goodale"], "summary": "Limited resources and growing needs continue to challenge providers of local government services. Equitable distribution of resources is both more important and more difficult when the local economy is growing slowly if at all. The need to increase revenue and reduce costs leads us to focus on efficiency rather than effectiveness, and market equity rather than equal opportunity. This can lead to a distortion of mandate and objectives. Public purpose and philosophy should join the dialogue of business and finance.", "title": "The Political Economics of Local Leisure Services", "claims": ["- Limited resources and growing needs continue to challenge providers of local government services.", "- Equitable distribution of resources is both more important and more difficult when the local economy is growing slowly if at all.", "- The need to increase revenue and reduce costs leads us to focus on efficiency rather than effectiveness.", "- The need to increase revenue and reduce costs leads us to focus on market equity rather than equal opportunity.", "- Focusing on efficiency and market equity can lead to a distortion of mandate and objectives.", "- Public purpose and philosophy should join the dialogue of business and finance."]}, {"metadata": {"year": 2011}, "authors": ["E. Apriatni"], "summary": "Abstract : The role of private enterprise in poverty reduction is still questionable because the company's concern toward social problems is still half-heartedly. Coverage in the media, associated with forest destruction, pollution of river water, as well as other forms of injustice felt by the community is still often heard. This proves the corporate social responsibility in upholding justice in the world of business is still low. Injustices in the economic and social development create a gap, especially in public access to utilize existing resources. On the other hand, companies show their existence in the business world, with their ability to utilize existing resources in the country. Embodiment of business ethics within the context of corporate social responsibility should be accommodated in company policies with the aim to achieve corporate objectives, but do not ignore the social interests of surrounding communities. With good relationship, through the CSR labeled activity, will eventually be able to maintain the existence of the company in the business world.\u00a0 Key words: Social Responsibility: Business Ethics; justice permalink :\u00a0 http://ejournal.undip.ac.id/index.php/forum/article/view/3150", "title": "TANGGUNG JAWAB SOSIAL PERUSAHAAN DALAM MEWUJUDKAN KEADILAN DALAM BISNIS", "claims": ["- The role of private enterprise in poverty reduction is still questionable because the company's concern toward social problems is still half-heartedly.", "- Coverage in the media, associated with forest destruction, pollution of river water, as well as other forms of injustice felt by the community is still often heard.", "- This proves the corporate social responsibility in upholding justice in the world of business is still low.", "- Injustices in the economic and social development create a gap, especially in public access to utilize existing resources.", "- Companies show their existence in the business world, with their ability to utilize existing resources in the country.", "- Embodiment of business ethics within the context of corporate social responsibility should be accommodated in company policies with the aim to achieve corporate objectives, but do not ignore the social interests of surrounding communities.", "- With good relationship, through the CSR labeled activity, will eventually be able to maintain the existence of the company in the business world."]}], "query": "Curry (2005) and Seip (2013) highlight that government-owned businesses often prioritize meeting social obligations over commercial objectives, leading to inefficient resource allocation and financial struggles for these enterprises.", "summary_abstract": null, "summary_extract": "The claims collectively underscore the challenges faced by government-owned businesses in balancing social obligations with commercial objectives, often leading to inefficiencies and financial difficulties. Anjali Kumar (1993) highlights that state-owned enterprises are plagued by economic inefficiencies due to the complex reconciliation of political, social, and ideological aims with economic efficiency. This misalignment results in resource diversion from their most productive uses and internal management inefficiencies. Similarly, Suthathip Yaisawarng (2002) notes that both public and private sector organizations struggle with resource efficiency, suggesting that reallocating resources to areas with higher marginal social benefits could enhance social welfare. Go Yano and Maho Shiraishi (2002) provide an empirical perspective, illustrating how the incentive structures designed by governments lead to risk aversion and suboptimal effort levels in Chinese state-owned enterprises. Xiong Qing-guo (2005) emphasizes the lack of decision-making power in state-owned enterprises, which hinders their ability to reform and adapt, suggesting that granting them autonomy could improve their performance. Collectively, these claims highlight the tension between fulfilling social mandates and achieving economic efficiency, a theme central to the research question posed by Curry (2005) and Seip (2013)."}, {"papers": [{"metadata": {"year": 2013}, "authors": ["Bj\u00f6rn Bartling", "F. Engl", "Roberto A. Weber"], "summary": "This paper studies whether people can avoid punishment by remaining willfully ignorant about possible negative consequences of their actions for others. We employ a laboratory experiment, using modified dictator games in which a dictator can remain willfully ignorant about the payoff consequences of his decision for a receiver. A third party can punish the dictator after observing the dictator\u2019s decision and the resulting payoffs. On the one hand, willfully ignorant dictators are punished less if their actions lead to unfair outcomes than dictators who reveal the consequences before implementing the same outcome. On the other hand, willfully ignorant dictators are punished more than revealing dictators if their actions do not lead to unfair outcomes. We conclude that willful ignorance can circumvent blame when unfair outcomes result, but that the act of remaining willfully ignorant is itself punished, regardless of the outcome.", "title": "Does Willful Ignorance Deflect Punishment? - An Experimental Study", "claims": ["- This paper studies whether people can avoid punishment by remaining willfully ignorant about possible negative consequences of their actions for others.", "- We employ a laboratory experiment, using modified dictator games in which a dictator can remain willfully ignorant about the payoff consequences of his decision for a receiver.", "- A third party can punish the dictator after observing the dictator\u2019s decision and the resulting payoffs.", "- Willfully ignorant dictators are punished less if their actions lead to unfair outcomes than dictators who reveal the consequences before implementing the same outcome.", "- Willfully ignorant dictators are punished more than revealing dictators if their actions do not lead to unfair outcomes.", "- We conclude that willful ignorance can circumvent blame when unfair outcomes result.", "- The act of remaining willfully ignorant is itself punished, regardless of the outcome."]}, {"metadata": {"year": 2019}, "authors": ["Robert  St\u00fcber"], "summary": "Altruistic punishment is often thought to be a major enforcement mechanism of social norms. I present experimental results from a modified version of the dictator game with third-party punishment, in which third parties can remain ignorant about the choice of the dictator. I find that a substantial fraction of subjects choose not to reveal the dictator\u2019s choice and not to punish the dictator. I show that this behavior is in line with the social norms that prevail in a situation of initial ignorance. Remaining ignorant and choosing not to punish is not inappropriate. As a result, altruistic punishment is significantly lower when the dictator\u2019s choice is initially hidden. The decrease in altruistic punishment leads to more selfish dictator behavior only if dictators are explicitly informed about the effect of willful ignorance on punishment rates. Hence, in scenarios in which third parties can ignore information and dictators know what this implies, third-party punishment may only ineffectively enforce social norms.", "title": "The benefit of the doubt: willful ignorance and altruistic punishment", "claims": ["", "Altruistic punishment is often thought to be a major enforcement mechanism of social norms.", "A modified version of the dictator game with third-party punishment was used in the experiment.", "In the modified dictator game, third parties can remain ignorant about the choice of the dictator.", "A substantial fraction of subjects choose not to reveal the dictator\u2019s choice and not to punish the dictator.", "The behavior of remaining ignorant and choosing not to punish is in line with the social norms that prevail in a situation of initial ignorance.", "Remaining ignorant and choosing not to punish is not inappropriate.", "Altruistic punishment is significantly lower when the dictator\u2019s choice is initially hidden.", "The decrease in altruistic punishment leads to more selfish dictator behavior only if dictators are explicitly informed about the effect of willful ignorance on punishment rates.", "In scenarios in which third parties can ignore information and dictators know what this implies, third-party punishment may only ineffectively enforce social norms."]}, {"metadata": {"year": 2017}, "authors": ["Rainer Michael Rilke"], "summary": "Organizations aim to influence\u2014via their internal guidelines and corporate culture\u2014how unfair treatment of other stakeholders is perceived and condemned by employees. To understand how different frames and forms of publicity influence moralistic punishment, that is, the willingness of employees to take costs in order to foster norm compliance, we employ a modified version of a dictator game. In our dictator game, a bystander observes a dictator\u2019s behavior towards a recipient and can punish the dictator. We vary how the dictator\u2019s action is framed (either as giving money to the recipient or taking money from the recipient) and whether or not the recipient, as a victim of unfair behavior, is informed about the punishment. Our results suggest that bystanders are more likely to punish dictators when their action is framed as giving rather than taking, although both lead to the same consequences. When bystanders cannot inform recipients about their punishment, less punishment can be observed. On average, dictators partially anticipate this effect and behave more generously when recipients are informed about the bystanders\u2019 punishment.", "title": "On the duty to give (and not to take): An experiment on moralistic punishment", "claims": ["", "Organizations aim to influence how unfair treatment of other stakeholders is perceived and condemned by employees via their internal guidelines and corporate culture.", "To understand how different frames and forms of publicity influence moralistic punishment, a modified version of a dictator game is employed.", "In the dictator game, a bystander observes a dictator\u2019s behavior towards a recipient and can punish the dictator.", "The dictator\u2019s action is varied in framing, either as giving money to the recipient or taking money from the recipient.", "The recipient, as a victim of unfair behavior, may or may not be informed about the punishment.", "Results suggest that bystanders are more likely to punish dictators when their action is framed as giving rather than taking, although both lead to the same consequences.", "When bystanders cannot inform recipients about their punishment, less punishment can be observed.", "On average, dictators partially anticipate the effect of whether recipients are informed about the bystanders\u2019 punishment and behave more generously when recipients are informed."]}, {"metadata": {"year": 2008}, "authors": ["Stefania Ottone", "Ferruccio Ponzano", "L. Zarri"], "summary": "Social norms are ubiquitous in human life. Their role is essential in allowing cooperation to prevail, despite the presence of incentives to free ride. As far as norm enforcement devices are concerned, it would be impossible to have widespread social norms if second parties only enforced them. However, both the quantitative relevance and the motivations underlying altruistic punishment on the part of \u2018unaffected\u2019 third parties are still largely unexplored. This paper contributes to shed light on the issue, by means of an experimental design consisting of three treatments: a Dictator Game Treatment, a Third-Party Punishment Game Treatment (Fehr and Fischbacher, 2004) and a Metanorm Treatment, that is a variant of the Third-party Punishment Game where the Recipient can punish the third party. We find that third parties are willing to punish dictators (Fehr and Fischbacher, 2004; Ottone, 2008) and, in doing so, they are affected by \u2018reference-dependent fairness\u2019, rather than by the \u2018egalitarian distribution norm\u2019. By eliciting players\u2019 normative expectations, it turns out that all of them expect a Dictator to transfer something \u2013 not half of the endowment. Consequently, the Observers\u2019 levels of punishment are sensitive to their subjective sense of fairness. A positive relation between the level of punishment and the degree of negative subjective unfairness emerges. Subjective unfairness also affects Dictators\u2019 behaviour: their actual transfers and their ideal transfer are not significantly different. Finally, we interestingly find that third parties are also sensitive to the receivers\u2019 (credible) threat to punish them: as the Dictator\u2019s transfer becomes lower and lower than the Observer\u2019s ideal transfer, the Observer\u2019s reaction is \u2013 other things being equal \u2013 significantly stronger in the Metanorm Treatment than in the Third-Party Punishment Game Treatment. Hence, despite their being to some extent genuinely nonstrategically motivated, also third parties \u2013 like second parties \u2013 are sensitive to the costs of punishing.", "title": "Moral Sentiments and Material Interests behind Altruistic Third-Party Punishment", "claims": ["- Social norms are ubiquitous in human life.", "- The role of social norms is essential in allowing cooperation to prevail, despite the presence of incentives to free ride.", "- It would be impossible to have widespread social norms if second parties only enforced them.", "- Both the quantitative relevance and the motivations underlying altruistic punishment on the part of \u2018unaffected\u2019 third parties are still largely unexplored.", "- This paper contributes to shedding light on the issue of altruistic punishment by means of an experimental design consisting of three treatments: a Dictator Game Treatment, a Third-Party Punishment Game Treatment, and a Metanorm Treatment.", "- Third parties are willing to punish dictators.", "- Third parties are affected by \u2018reference-dependent fairness\u2019, rather than by the \u2018egalitarian distribution norm\u2019.", "- By eliciting players\u2019 normative expectations, it turns out that all of them expect a Dictator to transfer something \u2013 not half of the endowment.", "- Observers\u2019 levels of punishment are sensitive to their subjective sense of fairness.", "- A positive relation between the level of punishment and the degree of negative subjective unfairness emerges.", "- Subjective unfairness also affects Dictators\u2019 behaviour: their actual transfers and their ideal transfer are not significantly different.", "- Third parties are sensitive to the receivers\u2019 (credible) threat to punish them.", "- As the Dictator\u2019s transfer becomes lower and lower than the Observer\u2019s ideal transfer, the Observer\u2019s reaction is significantly stronger in the Metanorm Treatment than in the Third-Party Punishment Game Treatment.", "- Despite their being to some extent genuinely nonstrategically motivated, third parties \u2013 like second parties \u2013 are sensitive to the costs of punishing."]}, {"metadata": {"year": 2019}, "authors": ["R\u00e9ka  Heim", "J\u00fcrgen  Huber"], "summary": "Abstract In this paper we explore how decisions in a sequential three-person game are influenced by either dynamics of roles or group composition. In the game a dictator decides how much of his endowment to transfer to the recipient. The supervisor can punish the dictator and/or transfer to the recipient after learning about the dictator\u2019s decision. We find that transfers by a dictator are highest and stable when the group of three is fixed, no matter whether roles change or not. There is limited support of a leading-by-example effect, that is, only when both role and group composition of subjects are fixed, supervisors give more the more dictators gave, and dictators transfer more in the next period the more supervisors gave in a period. Punishment partially has a disciplining effect on dictators. Finally, we observe that subjects\u2019 actual actions are consistent with their beliefs and expectations.", "title": "Leading-by-example and third-party punishment: Experimental evidence", "claims": ["", "In the game, a dictator decides how much of his endowment to transfer to the recipient.", "The supervisor can punish the dictator and/or transfer to the recipient after learning about the dictator\u2019s decision.", "Transfers by a dictator are highest and stable when the group of three is fixed, no matter whether roles change or not.", "There is limited support of a leading-by-example effect, meaning only when both role and group composition of subjects are fixed, supervisors give more the more dictators gave.", "Dictators transfer more in the next period the more supervisors gave in a period.", "Punishment partially has a disciplining effect on dictators.", "Subjects\u2019 actual actions are consistent with their beliefs and expectations."]}, {"metadata": {"year": 2014}, "authors": ["E. Winschel", "Philipp Zahn"], "summary": "In most laboratory experiments concerning prosocial behavior subjects are fully informed how their decision influences the payoff of other players. Outside the laboratory, however, individuals typically have to decide without such detailed knowledge. To assess the effect of information asymmetries on prosocial behavior, we conduct a laboratory experiment with a simple non-strategic interaction. A dictator has only limited knowledge about the benefits his prosocial action generates for a recipient. We observe subjects with heterogenous social preferences. While under symmetric information only individuals with the same type of preferences transfer, under asymmetric information different types transfer at the same time. As a consequence and the main finding of our experiment, uninformed dictators behave more prosocially than informed dictators.", "title": "When Ignorance is Bliss - Information Asymmetries Enhance Prosocial Behavior in Dictator Games", "claims": ["", "In most laboratory experiments concerning prosocial behavior, subjects are fully informed about how their decision influences the payoff of other players.", "Outside the laboratory, individuals typically have to decide without such detailed knowledge.", "To assess the effect of information asymmetries on prosocial behavior, a laboratory experiment is conducted with a simple non-strategic interaction.", "In the experiment, a dictator has only limited knowledge about the benefits his prosocial action generates for a recipient.", "Subjects in the experiment exhibit heterogeneous social preferences.", "Under symmetric information, only individuals with the same type of preferences transfer.", "Under asymmetric information, different types transfer at the same time.", "The main finding of the experiment is that uninformed dictators behave more prosocially than informed dictators."]}, {"metadata": {"year": 2016}, "authors": ["A. Murata"], "summary": "The aim of this study was to demonstrate that indirect mediation in behaviors leads to insensitivity to unethical behavior through a dictator game and to give some implications for safety management. The indirect involvement in the unethical behavior such as the violation of regulation is believed to lessen the responsibility and the criticism from others for the unethical behavior as compared to the direct involvement in it. The instruction condition for the evaluator of behavior in a dictator game was taken up as an experimental variable. Instruction condition 1 was to pay attention to the behavior of only a dictator. In instruction condition 2, the participant (evaluator) was required to review all players\u2019 behavior and evaluate a dictator. It has been investigated whether allowing indirect actions (mediations) leads to reduced punishment as a function of the instruction condition. While the punishment to the indirectness did not get smaller for instruction condition 2, the punishment to the indirectness tended to get smaller only for instruction condition 1.", "title": "Insensitivity to Unethical Behavior in Dictator Game When Indirectly Intermediated-Implications of Indirect Blindness for Safety Management", "claims": ["- The aim of this study was to demonstrate that indirect mediation in behaviors leads to insensitivity to unethical behavior through a dictator game.", "- The study aimed to give some implications for safety management.", "- Indirect involvement in unethical behavior, such as the violation of regulation, is believed to lessen the responsibility and the criticism from others for the unethical behavior as compared to direct involvement in it.", "- The instruction condition for the evaluator of behavior in a dictator game was taken up as an experimental variable.", "- Instruction condition 1 was to pay attention to the behavior of only a dictator.", "- In instruction condition 2, the participant (evaluator) was required to review all players\u2019 behavior and evaluate a dictator.", "- It has been investigated whether allowing indirect actions (mediations) leads to reduced punishment as a function of the instruction condition.", "- The punishment to the indirectness did not get smaller for instruction condition 2.", "- The punishment to the indirectness tended to get smaller only for instruction condition 1."]}, {"metadata": {"year": 2019}, "authors": ["Jo Thori Lind", "Karine  Nyborg", "Anna  Pauls"], "summary": "Our lab experiment tests for strategic ignorance about the environmental consequences of one\u2019s actions. In a binary dictator situation based on the design by Dana, Weber, and Kuang (2007), we test whether the option to remain ignorant about the receiver\u2019s payoffs reduces generosity. Our receiver is a charity that engages in carbon offset. Contrary to previous \ufb01ndings by Dana, Weber, and Kuang (2007) and replications, the option to remain ignorant does not decrease generosity. Only 22% of dictators choose ignorance. We test social interaction by allowing another subject to force the dictator to learn the receiver\u2019s payoff, and by allowing the dictator to sanction that subject. When information can be imposed by another subject, almost all dictators choose information themselves, but this does not increase generosity. The possibility of sanctions does not discourage subjects from providing information to dictators.", "title": "Save the planet or close your eyes? Testing strategic ignorance in a charity context", "claims": ["- Our lab experiment tests for strategic ignorance about the environmental consequences of one\u2019s actions.", "- In a binary dictator situation based on the design by Dana, Weber, and Kuang (2007), we test whether the option to remain ignorant about the receiver\u2019s payoffs reduces generosity.", "- Our receiver is a charity that engages in carbon offset.", "- Contrary to previous findings by Dana, Weber, and Kuang (2007) and replications, the option to remain ignorant does not decrease generosity.", "- Only 22% of dictators choose ignorance.", "- We test social interaction by allowing another subject to force the dictator to learn the receiver\u2019s payoff, and by allowing the dictator to sanction that subject.", "- When information can be imposed by another subject, almost all dictators choose information themselves, but this does not increase generosity.", "- The possibility of sanctions does not discourage subjects from providing information to dictators."]}], "query": "how does deliberate ignorance affect punishment in the dictator game?", "summary_abstract": null, "summary_extract": "The research question explores the impact of deliberate ignorance on punishment within the context of the dictator game. Bartling et al. (2013) provide a comprehensive examination, revealing that dictators who choose to remain willfully ignorant about the consequences of their actions tend to receive less punishment when their decisions result in unfair outcomes compared to those who are fully informed. This suggests that willful ignorance can serve as a mechanism to avoid blame. However, they also note that willfully ignorant dictators are punished more than informed ones when their actions do not lead to unfair outcomes, indicating that the act of remaining ignorant is itself subject to punishment, regardless of the outcome.\n\nSt\u00fcber (2019) further supports this by showing that altruistic punishment decreases when the dictator's choice is hidden, which can lead to more selfish behavior by dictators if they are aware of this effect. This suggests that deliberate ignorance can undermine the enforcement of social norms through punishment. Additionally, St\u00fcber highlights that a significant number of third parties choose to remain ignorant and refrain from punishing, aligning with prevailing social norms in situations of initial ignorance.\n\nCollectively, these findings suggest that deliberate ignorance can strategically influence the level of punishment in the dictator game, potentially reducing accountability for unfair actions while also being a punishable offense in itself. This dynamic complicates the role of punishment as a tool for enforcing fairness and social norms."}, {"papers": [{"metadata": {"year": 2018}, "authors": ["K. Ram", "Raj Kumar", "Sun Ta", "R. Munjal"], "summary": "Carbon requirements for grain filling in wheat are mainly from current assimilation by photosynthesis and remobilization of reserves from the stems (Yang et al., 2000). Remobilization of assimilates is an active process that involves translocation of stored reserves from stems and sheaths to grains (Gupta et al., 2015). Stem reserves contribute 20 to 40% weight of the grain in non-stressed condition (Vignjevic et al., 2015) and this can be up to 70% under stressed conditions during grain filling (Rebetzke et al., 2008). Drought and high temperature induced earlier mobilization of non-structural reserve carbohydrates from stem and leaf sheaths, which provided a greater proportion of grain International Journal of Current Microbiology and Applied Sciences ISSN: 2319-7706 Volume 7 Number 04 (2018) Journal homepage: http://www.ijcmas.com", "title": "Stem Reserve Mobilization in Relation to Yield under Different Drought and High Temperature Stress Conditions in Wheat (Triticum aestivum L.) Genotypes", "claims": ["- Carbon requirements for grain filling in wheat are mainly from current assimilation by photosynthesis and remobilization of reserves from the stems (Yang et al., 2000).", "- Remobilization of assimilates is an active process that involves translocation of stored reserves from stems and sheaths to grains (Gupta et al., 2015).", "- Stem reserves contribute 20 to 40% weight of the grain in non-stressed condition (Vignjevic et al., 2015).", "- Stem reserves can contribute up to 70% of the grain weight under stressed conditions during grain filling (Rebetzke et al., 2008).", "- Drought and high temperature induce earlier mobilization of non-structural reserve carbohydrates from stem and leaf sheaths.", "- Earlier mobilization of non-structural reserve carbohydrates from stem and leaf sheaths provides a greater proportion of grain."]}, {"metadata": {"year": 2004}, "authors": ["A.  Blum"], "summary": "Stem reserves from pre-anthesis plant assimilation are being increasingly recognised as an important source of carbon for grain filling when current photosynthesis is inhibited by drought, heat or disease stress during this stage. Genotypic and environmental factors affecting reserve accumulation and utilisation for grain filling are reviewed. The genetic improvement of stem reserve storage and utilisation as a potent mechanism for grain filling under stress is discussed, and practical guidelines for selection work are provided.", "title": "Improving wheat grain filling under stress by stem reserve mobilisation", "claims": ["- Stem reserves from pre-anthesis plant assimilation are being increasingly recognised as an important source of carbon for grain filling when current photosynthesis is inhibited by drought, heat, or disease stress during this stage.", "- Genotypic and environmental factors affecting reserve accumulation and utilisation for grain filling are reviewed.", "- The genetic improvement of stem reserve storage and utilisation as a potent mechanism for grain filling under stress is discussed.", "- Practical guidelines for selection work are provided."]}, {"metadata": {"year": 1997}, "authors": ["Abraham  Blum"], "summary": "Stem reserves from pre-anthesis plant assimilation are being increasingly recognised as an important source of carbon for grain filling when current photosynthesis is inhibited by drought, heat or disease stress during this stage. Genotypic and environmental factors affecting reserve accumulation and utilisation for grain filling are reviewed. The genetic improvement of stem reserve storage and utilisation as a potent mechanism for grain filling under stress is discussed, and practical guidelines for selection work are provided.", "title": "Improving wheat grain filling under stress by stem reserve mobilisation", "claims": ["- Stem reserves from pre-anthesis plant assimilation are being increasingly recognised as an important source of carbon for grain filling when current photosynthesis is inhibited by drought, heat, or disease stress during this stage.", "- Genotypic and environmental factors affecting reserve accumulation and utilisation for grain filling are reviewed.", "- The genetic improvement of stem reserve storage and utilisation as a potent mechanism for grain filling under stress is discussed.", "- Practical guidelines for selection work are provided."]}, {"metadata": {"year": 2011}, "authors": ["A. Gupta", "K. Kaur", "N. Kaur"], "summary": "The effect of water deficit on stem reserve mobilization and sink activity in wheat (Triticum aestivum L.) cultivars, viz., C306 (drought tolerant) and PBW343 (drought sensitive) was studied. Drought was maintained in pot raised plants by withholding irrigation at 95 days after sowing (DAS), i.e. just five days before the initiation of anthesis. Drought induced a significant reduction in mean biomass of all the internodes of sensitive cultivar as compared to those of tolerant one. Mobilized dry matter and mobilization efficiency were observed to be higher in the internodes of tolerant cultivar, both under control and stress conditions, which resulted in enhanced translocation of stem reserves to the grains. Water soluble carbohydrates (WSC), which mainly occur as fructans, were observed to be higher in the internodes of tolerant cultivar than those of sensitive one. When drought was applied, fructans were mobilized more effectively from the internodes of tolerant cultivar. A significantly higher sucrose synthase activity in the grains of tolerant cultivar, under drought conditions, increased the sink strength by unloading the assimilates in the sink, thereby increasing further mobilization of assimilates to the grains. Grains of sensitive cultivar attained maturity much earlier as compared to the tolerant one, both under control and stress conditions. The longer duration of grain maturation in tolerant cultivar supported enhanced mobilization of stem reserves, thus restricting heavy decrease in grain yield, under stress conditions, as compared to the sensitive cultivar. It may, therefore, be concluded that certain characteristics viz., enhanced capability of fructan storage, higher mobilization efficiency, stronger sink activity and longer duration of grain maturation might help the drought tolerant cultivar in coping the stress conditions", "title": "Stem Reserve Mobilization and Sink Activity in Wheat under Drought Conditions", "claims": ["", "Drought was maintained in pot raised plants by withholding irrigation at 95 days after sowing (DAS), i.e. just five days before the initiation of anthesis.", "Drought induced a significant reduction in mean biomass of all the internodes of the sensitive cultivar as compared to those of the tolerant one.", "Mobilized dry matter and mobilization efficiency were observed to be higher in the internodes of the tolerant cultivar, both under control and stress conditions.", "Higher mobilization efficiency in the tolerant cultivar resulted in enhanced translocation of stem reserves to the grains.", "Water soluble carbohydrates (WSC), which mainly occur as fructans, were observed to be higher in the internodes of the tolerant cultivar than those of the sensitive one.", "When drought was applied, fructans were mobilized more effectively from the internodes of the tolerant cultivar.", "A significantly higher sucrose synthase activity in the grains of the tolerant cultivar, under drought conditions, increased the sink strength by unloading the assimilates in the sink.", "Increased sink strength in the tolerant cultivar led to further mobilization of assimilates to the grains.", "Grains of the sensitive cultivar attained maturity much earlier as compared to the tolerant one, both under control and stress conditions.", "The longer duration of grain maturation in the tolerant cultivar supported enhanced mobilization of stem reserves.", "Enhanced mobilization of stem reserves in the tolerant cultivar restricted heavy decrease in grain yield under stress conditions, as compared to the sensitive cultivar.", "Certain characteristics, viz., enhanced capability of fructan storage, higher mobilization efficiency, stronger sink activity, and longer duration of grain maturation, might help the drought tolerant cultivar in coping with stress conditions."]}, {"metadata": {"year": 2018}, "authors": ["S. Gare", "R. Wagh", "A. Ingle", "N. Soni"], "summary": "Wheat (Triticum aestivum) is the first important and strategic cereal crop for the majority of world\u2019s populations. In 100 grams, wheat provides 327 calories and is an excellent source of multiple essential nutrients, such as protein, dietary fiber, manganese, phosphorus and niacin. Several B vitamins and other dietary minerals are in significant content. High temperature (>30\u00b0C) at the time of grain filling is one of the major constraints in increasing productivity of wheat in tropical countries like India (Zhao 2007). This survey/review may likewise help in interdisciplinary study regards to influence of temperature stress on stem reserve mobilization when wheat plants suffer from arrested photosynthesis during stress", "title": "Effect of temperature on stem reserve mobilization for grain development in wheat", "claims": ["- Wheat (Triticum aestivum) is the first important and strategic cereal crop for the majority of the world\u2019s populations.", "- In 100 grams, wheat provides 327 calories.", "- Wheat is an excellent source of multiple essential nutrients, such as protein, dietary fiber, manganese, phosphorus, and niacin.", "- Several B vitamins and other dietary minerals are in significant content in wheat.", "- High temperature (>30\u00b0C) at the time of grain filling is one of the major constraints in increasing the productivity of wheat in tropical countries like India (Zhao 2007).", "- This survey/review may help in interdisciplinary study regarding the influence of temperature stress on stem reserve mobilization when wheat plants suffer from arrested photosynthesis during stress."]}, {"metadata": {"year": 2008}, "authors": ["Pireivatlou As", "Aliyev Rt"], "summary": "Two experiments were conducted on 11 diverse wheat genotypes, under both well watered, and drought stress field experiments. Drought decreased vegetative organs (above ground dry matter) weight at anthesis and maturity, grain yield per spike, grains per spike and 1000 grain weight by 5.7, 24.5, 21.2, 15.7 and 6.4 %, respectively. Translocation of dry matter from vegetative organs (above ground dry matter) to developing kernels and mobilization efficiency were considerably increased under drought stress condition, by 60.1 and 74 %, respectively. The contribution of pre anthesis assimilate was also highly increased under the drought stress condition. Translocation of dry matter from the peduncle, penultimate, and the lower internodes ranged from 51.2 to 76.9, 106.8 to 182.3 and from 100 to 208.6 mg under well watered and drought stress conditions, respectively. Mobilization of dry matter was higher under the drought stress condition than in well watered for peduncle by 50.2 %, penultimate internode 70.7 and for lower internodes 111.6 % respectively. Drought increased the contribution of pre-anthesis assimilates to grain yield by 81.5 % in peduncle, 108.1 % in penultimate internode and by 153.8 % in lowerinternodes respectively. Drought was also increased the translocation efficiency by 84, 91.3 and 111.6 % for peduncle, penultimate internode and lower internodes, respectively. Vegetative organ (above ground dry matter) at anthesis was correlated with grain weight per spike (r = 0.68*), translocation of dry matter (r = 0.34) under drought stress condition. Translocation of dry matter was correlated with lower internodes, penultimate and peduncle maximum weight under drought stress condition by r = 0.55, 0.56 and 0.34, respectively.", "title": "Stem reserve and its contribution to grain yield of wheat (Triticum aestivum L.) genotypes under drought stress conditions", "claims": ["", "Two experiments were conducted on 11 diverse wheat genotypes under both well-watered and drought stress field experiments.", "Drought decreased vegetative organs (above ground dry matter) weight at anthesis and maturity by 5.7%.", "Drought decreased grain yield per spike by 24.5%.", "Drought decreased grains per spike by 21.2%.", "Drought decreased 1000 grain weight by 15.7%.", "Drought decreased vegetative organs (above ground dry matter) weight by 6.4%.", "Translocation of dry matter from vegetative organs (above ground dry matter) to developing kernels was considerably increased under drought stress condition by 60.1%.", "Mobilization efficiency was considerably increased under drought stress condition by 74%.", "The contribution of pre-anthesis assimilate was highly increased under the drought stress condition.", "Translocation of dry matter from the peduncle ranged from 51.2 to 76.9 mg under well-watered and drought stress conditions, respectively.", "Translocation of dry matter from the penultimate internode ranged from 106.8 to 182.3 mg under well-watered and drought stress conditions, respectively.", "Translocation of dry matter from the lower internodes ranged from 100 to 208.6 mg under well-watered and drought stress conditions, respectively.", "Mobilization of dry matter was higher under the drought stress condition than in well-watered for peduncle by 50.2%.", "Mobilization of dry matter was higher under the drought stress condition than in well-watered for penultimate internode by 70.7%.", "Mobilization of dry matter was higher under the drought stress condition than in well-watered for lower internodes by 111.6%.", "Drought increased the contribution of pre-anthesis assimilates to grain yield by 81.5% in peduncle.", "Drought increased the contribution of pre-anthesis assimilates to grain yield by 108.1% in penultimate internode.", "Drought increased the contribution of pre-anthesis assimilates to grain yield by 153.8% in lower internodes.", "Drought increased the translocation efficiency by 84% for peduncle.", "Drought increased the translocation efficiency by 91.3% for penultimate internode.", "Drought increased the translocation efficiency by 111.6% for lower internodes.", "Vegetative organ (above ground dry matter) at anthesis was correlated with grain weight per spike with a correlation coefficient of r = 0.68* under drought stress condition.", "Vegetative organ (above ground dry matter) at anthesis was correlated with translocation of dry matter with a correlation coefficient of r = 0.34 under drought stress condition.", "Translocation of dry matter was correlated with lower internodes maximum weight under drought stress condition with a correlation coefficient of r = 0.55.", "Translocation of dry matter was correlated with penultimate internode maximum weight under drought stress condition with a correlation coefficient of r = 0.56.", "Translocation of dry matter was correlated with peduncle maximum weight under drought stress condition with a correlation coefficient of r = 0.34."]}, {"metadata": {"year": 2019}, "authors": ["Samuel C\u00f3rdova S\u00e1nchez", "Iris Amairani Garc\u00eda Alejandro", "C. Ruiz", "S. Garc\u00eda", "Ra\u00fal Casta\u00f1eda Ceja", "S. Vel\u00e1zquez", "M. Villegas", "L. D. C. L. Espinoza", "Cintya Valerio C\u00e1rdenas", "Rosa Graciela Santos Arguelles"], "summary": "For the replanting of the sugarcane crop, plants produced from buds of different reserve sizes and from different positions on the stem are used, without up to now an optimum reserve and position size has been determined to obtain a quality plant. Therefore, five treatments were evaluated for nutritional reserve: T1 (short reserve), T2 (without reserve), T3 (half reserve), T4 (long basal reserve) and T5 (long reserve superior) and for the position a design was used 2x3 factorial (two cultivars: MEX69-290 and COLPOSCTMEX05-223 and three yolk positions: basal, middle and apical), the treatments were distributed in a completely randomized arrangement. The buds were sown in unicel vessels with a liter capacity and sifted sand was used as substrate. It was evaluated; emergency percentage, root length and plant height. The results indicate that the use of buds with different positions in the stem is possible to produce seedlings of good quality, since more than 50% of sprouting was obtained in both cultivars. The results on nutrient reserves showed that T3 had the longest root length (36.2 cm) and T1 had the highest plant height (61.4 cm), showing that there is no direct relationship between plant height and root length. To obtain a quality plant it is enough to use short buds or half reserve and any position. For the commercial production of plants, it is recommended to plant in substrates rich in nutrients.", "title": "EFFECT OF NUTRITIONAL RESERVES AND POSITION OF THE YEMAS IN THE STEM IN THE QUALITY OF SUGAR CANE PLANTS", "claims": ["- For the replanting of the sugarcane crop, plants produced from buds of different reserve sizes and from different positions on the stem are used, without up to now an optimum reserve and position size has been determined to obtain a quality plant.", "- Five treatments were evaluated for nutritional reserve: T1 (short reserve), T2 (without reserve), T3 (half reserve), T4 (long basal reserve), and T5 (long reserve superior).", "- For the position, a design was used 2x3 factorial (two cultivars: MEX69-290 and COLPOSCTMEX05-223 and three yolk positions: basal, middle, and apical).", "- The treatments were distributed in a completely randomized arrangement.", "- The buds were sown in unicel vessels with a liter capacity and sifted sand was used as substrate.", "- It was evaluated; emergency percentage, root length, and plant height.", "- The results indicate that the use of buds with different positions in the stem is possible to produce seedlings of good quality, since more than 50% of sprouting was obtained in both cultivars.", "- The results on nutrient reserves showed that T3 had the longest root length (36.2 cm).", "- T1 had the highest plant height (61.4 cm).", "- There is no direct relationship between plant height and root length.", "- To obtain a quality plant it is enough to use short buds or half reserve and any position.", "- For the commercial production of plants, it is recommended to plant in substrates rich in nutrients."]}, {"metadata": {"year": 1982}, "authors": ["R. W. Daniels", "M. Alcock", "D. Scarisbrick"], "summary": "SUMMARY Pre-anthesis stem reserve contribution to grain yield was assessed in two spring barley cultivars of contrasting height. It was greatest in the taller, but final grain yields were similar. Partitioning of total reserve capacity to various plant parts showed that the leaf and sheath below the peduncle were most important, followed by stem internodes which had increasing reserve capacity up to internode 4. It is suggested that stem reserves are valuable for yields commonly achieved in U.K. commercial practice. High grain yields were associated with large positive increases in stem dry weight after anthesis. This would indicate that the source capacity to boost yield is more than proportional to that required to fill the grain alone.", "title": "A reappraisal of stem reserve contribution to grain yield in spring barley (Hordeum vulgare L.)", "claims": ["- Pre-anthesis stem reserve contribution to grain yield was assessed in two spring barley cultivars of contrasting height.", "- The pre-anthesis stem reserve contribution to grain yield was greatest in the taller cultivar.", "- Final grain yields were similar between the two spring barley cultivars.", "- Partitioning of total reserve capacity to various plant parts showed that the leaf and sheath below the peduncle were most important.", "- Stem internodes had increasing reserve capacity up to internode 4.", "- It is suggested that stem reserves are valuable for yields commonly achieved in U.K. commercial practice.", "- High grain yields were associated with large positive increases in stem dry weight after anthesis.", "- The source capacity to boost yield is more than proportional to that required to fill the grain alone."]}], "query": "wheat stem sugar reserve mobilization", "summary_abstract": null, "summary_extract": "The mobilization of sugar reserves from wheat stems plays a crucial role in grain filling, particularly under stress conditions. Ram et al. (2018) highlight that stem reserves can contribute significantly to grain weight, accounting for 20 to 40% under non-stressed conditions and up to 70% when the plant is stressed. This process involves the active translocation of stored reserves from stems and sheaths to grains (Ram et al., 2018). Drought and high temperatures can trigger earlier mobilization of these non-structural carbohydrates, enhancing their contribution to grain development (Ram et al., 2018).\n\nBlum (2004) and Blum (1997) emphasize the importance of stem reserves as a carbon source for grain filling when photosynthesis is compromised by environmental stresses such as drought, heat, or disease. The genetic improvement of stem reserve storage and utilization is suggested as a strategy to enhance grain filling under such conditions.\n\nGupta et al. (2011) further support this by demonstrating that drought-tolerant wheat cultivars exhibit higher mobilization efficiency and enhanced translocation of stem reserves to grains, which helps mitigate yield losses under stress. This is achieved through characteristics like increased fructan storage, stronger sink activity, and longer grain maturation periods.\n\nPireivatlou and Aliyev (2008) provide quantitative evidence of increased mobilization and translocation efficiency of dry matter from vegetative organs to grains under drought stress, highlighting the significant role of pre-anthesis assimilates in supporting grain yield during such conditions. Collectively, these studies underscore the critical function of stem sugar reserve mobilization in sustaining wheat productivity, especially in the face of environmental challenges."}, {"papers": [{"metadata": {"year": 2004}, "authors": ["M. Brettingham"], "summary": "The Labour government's systematic investment in the health service is delivering concrete results, Nigel Crisp, chief executive of the NHS, said last week in his end of year report.\n\nThe financial expansion, which started in 1998 and has seen the NHS receive several large cash injections, is now resulting in shorter waiting times and falling numbers of premature deaths.\n\nThe reduction in waiting times, which the government has been under particular pressure to deliver, gives the report a focus. The number of inpatients on waiting lists has fallen by 35% since it peaked in 1998, falling from more than a million then to 850 000 today.\n\nThe report shows that about 70 000 outpatients are now waiting \u2026", "title": "NHS waiting list has fallen by 35% since 1998", "claims": ["- The Labour government's systematic investment in the health service is delivering concrete results.", "- Nigel Crisp, chief executive of the NHS, said last week in his end of year report that the Labour government's investment is delivering results.", "- The financial expansion started in 1998.", "- The NHS has received several large cash injections since 1998.", "- The financial expansion is resulting in shorter waiting times.", "- The financial expansion is resulting in falling numbers of premature deaths.", "- The government has been under particular pressure to deliver a reduction in waiting times.", "- The number of inpatients on waiting lists has fallen by 35% since it peaked in 1998.", "- The number of inpatients on waiting lists has fallen from more than a million in 1998 to 850,000 today."]}, {"metadata": {"year": 2022}, "authors": ["A. O'dowd"], "summary": "\u201cOur research highlights hope and opportunities to reduce waiting times in the present day: by addressing shortages of healthcare staff andphysical resources urgently; by working with integrated care systems in the spirit of prevention, collaboration, inclusion, and community based models of care; and in aligning a vision for the health service with a plan that brings staff, patients, and the public along on the journey to get there.\u201d", "title": "Multipronged efforts are needed to reduce NHS waiting times, says review", "claims": ["- Our research highlights hope and opportunities to reduce waiting times in the present day.", "- Reducing waiting times can be achieved by addressing shortages of healthcare staff and physical resources urgently.", "- Working with integrated care systems in the spirit of prevention, collaboration, inclusion, and community-based models of care can help reduce waiting times.", "- Aligning a vision for the health service with a plan that brings staff, patients, and the public along on the journey can help reduce waiting times."]}, {"metadata": {"year": 2010}, "authors": ["A. Harrison", "J. Appleby"], "summary": "Abstract Recent authors have proposed that waiting times for elective treatment should be reduced to the point where the costs of doing so exceed the benefits. This paper considers how this criterion could be put into effect. Taking benefits first it argues that these could be estimated in three different ways \u2013 social cost benefit, clinical and user valuation \u2013 that would not necessarily produce consistent results and hence a choice has to be made between them. It then considers the costs of reducing waits and argues, citing relevant evidence, that these may range widely according to whether or not reductions can be achieved through simple management measures or whether more long-term capacity is required. It concludes therefore that the apparently simple criterion proposed for defining the point where waiting times are optimal is hard to establish. Choice of criterion must be made in the light of the overall values that a given health care system is intended to promote.", "title": "Optimising waiting: a view from the English National Health Service", "claims": ["- Recent authors have proposed that waiting times for elective treatment should be reduced to the point where the costs of doing so exceed the benefits.", "- The paper considers how the criterion of reducing waiting times to the point where costs exceed benefits could be put into effect.", "- Benefits of reducing waiting times could be estimated in three different ways: social cost benefit, clinical, and user valuation.", "- The three different ways of estimating benefits (social cost benefit, clinical, and user valuation) would not necessarily produce consistent results.", "- A choice has to be made between the different ways of estimating benefits because they may not produce consistent results.", "- The paper considers the costs of reducing waits and argues that these may range widely.", "- The range of costs for reducing waits depends on whether reductions can be achieved through simple management measures or whether more long-term capacity is required.", "- The paper concludes that the apparently simple criterion proposed for defining the point where waiting times are optimal is hard to establish.", "- Choice of criterion for reducing waiting times must be made in the light of the overall values that a given health care system is intended to promote."]}, {"metadata": {"year": 2009}, "authors": ["A. Harrison", "J. Appleby"], "summary": "In recent years, the English NHS has achieved substantial reductions in waiting times for hospital treatment. This paper considers first whether the data used by the Government provide an accurate description of changes in waiting times and identifies some of the limitations of the measures used. It then attempts to identify how reductions have been achieved. It argues that some features of central government policy have been important - such as the use of targets - others, such as the introduction of new private sector capacity have not. It also shows that changes at local level have been critical to achieving the recorded improvements, but the precise impact of these is hard to identify.", "title": "Reducing Waiting Times for Hospital Treatment: Lessons from the English NHS", "claims": ["- In recent years, the English NHS has achieved substantial reductions in waiting times for hospital treatment.", "- The paper considers whether the data used by the Government provide an accurate description of changes in waiting times.", "- The paper identifies some of the limitations of the measures used to describe changes in waiting times.", "- The paper attempts to identify how reductions in waiting times have been achieved.", "- The paper argues that some features of central government policy, such as the use of targets, have been important in achieving reductions in waiting times.", "- The paper argues that the introduction of new private sector capacity has not been important in achieving reductions in waiting times.", "- The paper shows that changes at the local level have been critical to achieving the recorded improvements in waiting times.", "- The precise impact of changes at the local level on achieving recorded improvements in waiting times is hard to identify."]}, {"metadata": {"year": 1996}, "authors": ["C. Gray"], "summary": "Reforms involving the National Health Service (NHS) have greatly reduced the length of waiting lists in the United Kingdom. The key to the reductions was additional funding from the government, the chief executive of the NHS said during a recent visit to Ottawa. Decreasing the size of the waiting lists created intense stress for NHS personnel, who had to work longer hours, and it also lowered demand for private-sector care.", "title": "NHS reforms reduce length of waiting lists but create widespread unease.", "claims": ["- Reforms involving the National Health Service (NHS) have greatly reduced the length of waiting lists in the United Kingdom.", "- The key to the reductions in the length of waiting lists was additional funding from the government.", "- The chief executive of the NHS said during a recent visit to Ottawa that additional funding from the government was key to the reductions in waiting lists.", "- Decreasing the size of the waiting lists created intense stress for NHS personnel.", "- NHS personnel had to work longer hours due to the decrease in the size of the waiting lists.", "- Decreasing the size of the waiting lists lowered demand for private-sector care."]}, {"metadata": {"year": 2008}, "authors": ["C. Propper", "M. Sutton", "C. Whitnall", "F. Windmeijer"], "summary": "Abstract Waiting times have been a central concern in the English NHS, where care is provided free at the point of delivery and is rationed by waiting time. Pro-market reforms introduced in the NHS in the 1990s were not accompanied by large drops in waiting times. As a result, the English government in 2000 adopted the use of an aggressive policy of targets coupled with the publication of waiting times data at the hospital level and strong sanctions for poor performing hospital managers. This regime has been dubbed \u0091targets and terror\u0092. We estimate the effect of the English target regime for waiting times for hospital care after 2001 by a comparative analysis with Scotland, a neighbouring country with the same healthcare system that did not adopt the target regime. We estimate difference-in-differences models of the proportion of people on the waiting list who waited over 6, 9 and 12 months. Comparisons between England and Scotland are sensitive to whether published or unpublished data are used but, regardless of the data source, the \u0091targets and terror\u0092 regime in England lowered the proportion of people waiting for elective treatment relative to Scotland.", "title": "Did 'Targets and Terror' Reduce Waiting Times in England for Hospital Care?", "claims": ["", "Waiting times have been a central concern in the English NHS, where care is provided free at the point of delivery and is rationed by waiting time.", "Pro-market reforms introduced in the NHS in the 1990s were not accompanied by large drops in waiting times.", "In 2000, the English government adopted an aggressive policy of targets coupled with the publication of waiting times data at the hospital level and strong sanctions for poor performing hospital managers.", "The regime adopted by the English government in 2000 has been dubbed 'targets and terror'.", "The effect of the English target regime for waiting times for hospital care after 2001 was estimated by a comparative analysis with Scotland, a neighbouring country with the same healthcare system that did not adopt the target regime.", "Difference-in-differences models were used to estimate the proportion of people on the waiting list who waited over 6, 9, and 12 months.", "Comparisons between England and Scotland are sensitive to whether published or unpublished data are used.", "Regardless of the data source, the 'targets and terror' regime in England lowered the proportion of people waiting for elective treatment relative to Scotland."]}, {"metadata": {"year": 1981}, "authors": ["R. Feldman", "D. Ballard"], "summary": "This paper estimates a model of demand for the services of general practitioner physicians (GPs) in the British National Health Service (NHS). A wide range of services is available from the NHS to any person free of charge at the time of use. Money prices have been replaced, except for nominal charges for prescriptions and appliances, b^ nonprice rationing methods such as queuing for hospital admissions and waiting for physicians' office visits. Nonprice rationing has been cited as a major difficulty of the NHS [1, p. 219]. While this problem has not surfaced in the United States to the same degree as in England, it is nevertheless instructive to study the British experience. About 40 percent of U.S. health expenditures in 1980 were paid by public sources [2] and, if national health insurance legislation is enacted here, the public share could rise toward the level observed in the nationalized British system. In addition, some private health insurance plans in the U.S. have features that resemble the NHS, e.g., free care at the time of use. The NHS may thus provide a model for the analysis of these U.S. plans. We examine the effect of office waiting time on the demand for GPs' services. Using a utility-maximizing model of physicians' behavior, we predict that waiting time should be directly related to exogenous demand pressures on the physician's practice. Longer waiting time, in turn, should reduce both the number of visits per person and the number of patients in the physician's practice (which the British call the physician's \"listsize\"). We specify and estimate an empirical version of the model with three equations: waiting time, visits per patient, and listsize. A key finding is that the elasticity of demand for GPs' services with respect to waiting time is between -.48 and -.92, depending on our definition of variables and functional form. This result has important implications for national health insurance for outpatient visits (if such legislation is passed in the U.S.). If insurance were to reduce money prices to zero, demand would become relatively more sensitive to differences in time prices. In turn, as Acton has noted [3], this would permit persons with a lower opportunity cost of time to bid services away from those with a higher opportunity cost of time. National health insurance might, therefore, have important distributional effects, as well as the intended reduction of money price barriers to access. Even without national health insurance, policy-makers in the U.S. might want to study the British National Health Service. Increas-", "title": "The Role of Waiting Time in a Prepaid Health Care System: Evidence from the British National Health Service", "claims": ["- A wide range of services is available from the NHS to any person free of charge at the time of use.", "- Money prices have been replaced, except for nominal charges for prescriptions and appliances, by nonprice rationing methods such as queuing for hospital admissions and waiting for physicians' office visits.", "- Nonprice rationing has been cited as a major difficulty of the NHS.", "- About 40 percent of U.S. health expenditures in 1980 were paid by public sources.", "- If national health insurance legislation is enacted in the U.S., the public share of health expenditures could rise toward the level observed in the nationalized British system.", "- Some private health insurance plans in the U.S. have features that resemble the NHS, e.g., free care at the time of use.", "- The NHS may provide a model for the analysis of these U.S. plans.", "- Longer waiting time should reduce both the number of visits per person and the number of patients in the physician's practice (which the British call the physician's \"listsize\").", "- The elasticity of demand for GPs' services with respect to waiting time is between -.48 and -.92, depending on the definition of variables and functional form.", "- If insurance were to reduce money prices to zero, demand would become relatively more sensitive to differences in time prices.", "- National health insurance might have important distributional effects, as well as the intended reduction of money price barriers to access.", "- Even without national health insurance, policy-makers in the U.S. might want to study the British National Health Service."]}, {"metadata": {"year": 1986}, "authors": ["E. Scrivens", "G. Hart"], "summary": "Ministers are anxious to see shorter hospital waiting lists. Instead of buying services from the private sector, health authorities may do better by trading with each other. But, if the full potential of trading is to be realised, the financing and management of the NHS will have to alter.", "title": "How to reduce waiting lists: A case for trading within the NHS", "claims": ["- Ministers are anxious to see shorter hospital waiting lists.", "- Health authorities may do better by trading with each other instead of buying services from the private sector.", "- If the full potential of trading is to be realised, the financing and management of the NHS will have to alter."]}], "query": "Health economic benefits of reducing NHS waiting times", "summary_abstract": null, "summary_extract": "The collection of claims highlights several health economic benefits associated with reducing NHS waiting times. Brettingham (2004) notes that financial investments in the NHS since 1998 have led to shorter waiting times and a significant reduction in inpatient waiting lists, which fell by 35% from their peak. This reduction in waiting times is also linked to a decrease in premature deaths, indicating substantial health benefits. Harrison and Appleby (2009) emphasize that central government policies, particularly the use of targets, have been instrumental in achieving these reductions. They also suggest that local-level changes have played a critical role, although the precise impact is challenging to quantify.\n\nO'Dowd (2022) suggests that addressing shortages in healthcare staff and resources, along with fostering integrated care systems, can further reduce waiting times. This approach aligns with a vision that includes prevention, collaboration, and community-based care models. Harrison and Appleby (2010) propose that the benefits of reducing waiting times can be assessed through social cost-benefit analysis, clinical outcomes, and user valuation, although these methods may yield inconsistent results. They argue that the costs of reducing waiting times should be weighed against these benefits, considering the values promoted by the healthcare system.\n\nGray (1996) highlights that additional government funding has been crucial in reducing waiting lists, which in turn has decreased the demand for private-sector care. Propper et al. (2008) discuss the 'targets and terror' regime implemented in England, which effectively lowered the proportion of people waiting for elective treatment compared to Scotland, demonstrating the economic impact of policy-driven reductions in waiting times. Collectively, these claims underscore the multifaceted economic benefits of reducing NHS waiting times, including improved health outcomes, reduced reliance on private care, and the efficient allocation of healthcare resources."}, {"papers": [{"metadata": {"year": 1999}, "authors": ["Raymond Papp"], "summary": "Last Fall, my university began an initiative to offer courses online in what many call a \"distance learning\" environment. Being an early adopter of the Internet and WWW in my traditional on-campus courses, I jumped at the chance to offer a course in an on-line environment. This paper will briefly explore the differences between on-campus and on-line education, discuss my approach for implementing the course (including a comparison/contrast of student perceptions and performance in both on-campus and on-line sections of the same course), and conclude with some implications for educators endeavoring to teach in a distance learning environment.", "title": "\"On-campus\" vs. \"On-line\": Student Perceptions & Performance", "claims": ["- Last Fall, my university began an initiative to offer courses online in what many call a \"distance learning\" environment.", "- I was an early adopter of the Internet and WWW in my traditional on-campus courses.", "- I jumped at the chance to offer a course in an on-line environment.", "- This paper will briefly explore the differences between on-campus and on-line education.", "- The paper will discuss my approach for implementing the course, including a comparison/contrast of student perceptions and performance in both on-campus and on-line sections of the same course.", "- The paper will conclude with some implications for educators endeavoring to teach in a distance learning environment."]}, {"metadata": {"year": 2001}, "authors": ["Xiaoyan Xie", "Fuzong Lin", "Zhang Tao"], "summary": "More and more universities and colleges are providing online courses not only for on-campus students but also for off-campus students. Tutors have to consider the differences between on- and off-campus students in order to improve effective instruction. Comparisons are made in this paper between on- and off-campus performances in online learning from four areas: learning time, path of browsing courseware, intercommunication and adaptability towards online learning. The last two areas are emphasized. Multiple approaches were adopted to collect data, which include questionnaires, posted documents, online logs, interviews and observations. This study shows that the rush time of online learning, paths of browsing courseware and favourite intercommunication means of on- and off-campus students are similar. But there are also some differences between these two groups such as competence of self-learning, enthusiasm of interpersonal exchange, dependence on tutors, feeling of learning stress, etc.", "title": "Comparison between on- and off-campus behaviour and adaptability in online learning: A case from China", "claims": ["- More and more universities and colleges are providing online courses not only for on-campus students but also for off-campus students.", "- Tutors have to consider the differences between on- and off-campus students in order to improve effective instruction.", "- Comparisons are made in this paper between on- and off-campus performances in online learning from four areas: learning time, path of browsing courseware, intercommunication, and adaptability towards online learning.", "- The last two areas, intercommunication and adaptability towards online learning, are emphasized.", "- Multiple approaches were adopted to collect data, which include questionnaires, posted documents, online logs, interviews, and observations.", "- This study shows that the rush time of online learning, paths of browsing courseware, and favorite intercommunication means of on- and off-campus students are similar.", "- There are also some differences between on- and off-campus students such as competence of self-learning, enthusiasm of interpersonal exchange, dependence on tutors, and feeling of learning stress."]}, {"metadata": {"year": 2005}, "authors": ["G. Ury", "M. McDonald", "G. McDonald", "Brian Dorn"], "summary": "In previous papers, the authors reported results of smaller-scale studies. The purpose of this study is to combine and expand those individual smaller scaled studies, to determine if significant differences exist between student performance in online and traditional classroom environments. The study includes more than 1300 observations spread across seven courses that are part of the computer science and information systems curriculum at Northwest Missouri State University. Student performance was compared by grade point average, ACT composite scores, number of credit hours completed, instructor, and delivery method. The only significant difference found was between student performance and delivery method in three high volume courses that serve multiple majors and minors. Online students in these three courses obtained a significantly lower average grade than onground students. In four other courses that service upper-level computer science majors no significant differences in performance were found. The varied results of the study could be a simple statement of fact. Different courses in different programs might have different performance results. It could be concluded that online students are simply satisfied with a little lower grade in particular courses or that traditional students perform better because of the availability of added resources planned and implemented for online curriculum. It could be concluded that faculty continue to deal with problems in effectively transferring traditional classroom learning to the online environment. It could also be speculated that the difference is any combination of the above conclusions.", "title": "Student Performance Online vs Onground: A Statistical Analysis of IS Courses", "claims": ["- In previous papers, the authors reported results of smaller-scale studies.", "- The purpose of this study is to combine and expand those individual smaller scaled studies to determine if significant differences exist between student performance in online and traditional classroom environments.", "- The study includes more than 1300 observations spread across seven courses that are part of the computer science and information systems curriculum at Northwest Missouri State University.", "- Student performance was compared by grade point average, ACT composite scores, number of credit hours completed, instructor, and delivery method.", "- The only significant difference found was between student performance and delivery method in three high volume courses that serve multiple majors and minors.", "- Online students in these three courses obtained a significantly lower average grade than onground students.", "- In four other courses that service upper-level computer science majors, no significant differences in performance were found.", "- The varied results of the study could be a simple statement of fact.", "- Different courses in different programs might have different performance results.", "- It could be concluded that online students are simply satisfied with a little lower grade in particular courses.", "- It could be concluded that traditional students perform better because of the availability of added resources planned and implemented for online curriculum.", "- It could be concluded that faculty continue to deal with problems in effectively transferring traditional classroom learning to the online environment.", "- It could also be speculated that the difference is any combination of the above conclusions."]}, {"metadata": {"year": 2014}, "authors": ["Di  Xu", "Shanna S. Jaggars"], "summary": "Using a dataset containing nearly 500,000 courses taken by over 40,000 community and technical college students in Washington State, this study examines the performance gap between online and face-to-face courses and how the size of that gap differs across student subgroups and academic subject areas. While all types of students in the study suffered decrements in performance in online courses, those with the strongest declines were males, younger students, Black students, and students with lower grade point averages. Online performance gaps were also wider in some academic subject areas than others. After controlling for individual and peer effects, the social sciences and the applied professions (e.g., business, law, and nursing) showed the strongest online performance gaps.", "title": "Performance Gaps Between Online and Face-to-Face Courses: Differences Across Types of Students and Academic Subject Areas", "claims": ["- The study uses a dataset containing nearly 500,000 courses taken by over 40,000 community and technical college students in Washington State.", "- The study examines the performance gap between online and face-to-face courses.", "- The study investigates how the size of the performance gap differs across student subgroups and academic subject areas.", "- All types of students in the study suffered decrements in performance in online courses.", "- Males, younger students, Black students, and students with lower grade point averages experienced the strongest declines in online course performance.", "- Online performance gaps were wider in some academic subject areas than others.", "- After controlling for individual and peer effects, the social sciences and the applied professions (e.g., business, law, and nursing) showed the strongest online performance gaps."]}, {"metadata": {"year": 2014}, "authors": ["Di Xu", "S. Jaggars"], "summary": "Using a dataset containing nearly 500,000 courses taken by over 40,000 community and technical college students in Washington State, this study examines the performance gap between online and face-to-face courses and how the size of that gap differs across student subgroups and academic subject areas. While all types of students in the study suffered decrements in performance in online courses, those with the strongest declines were males, younger students, Black students, and students with lower grade point averages. Online performance gaps were also wider in some academic subject areas than others. After controlling for individual and peer effects, the social sciences and the applied professions (e.g., business, law, and nursing) showed the strongest online performance gaps.", "title": "Performance Gaps between Online and Face-to-Face Courses: Differences across Types of Students and Academic Subject Areas", "claims": ["- The study uses a dataset containing nearly 500,000 courses taken by over 40,000 community and technical college students in Washington State.", "- The study examines the performance gap between online and face-to-face courses.", "- The study investigates how the size of the performance gap differs across student subgroups and academic subject areas.", "- All types of students in the study suffered decrements in performance in online courses.", "- Males, younger students, Black students, and students with lower grade point averages experienced the strongest declines in online course performance.", "- Online performance gaps were wider in some academic subject areas than others.", "- After controlling for individual and peer effects, the social sciences and the applied professions (e.g., business, law, and nursing) showed the strongest online performance gaps."]}, {"metadata": {"year": 2016}, "authors": ["C. B. Gregory", "J. Lampley"], "summary": "As part of a nationwide effort to increase the postsecondary educational attainment levels of citizens, community colleges have expanded offerings of courses and programs to more effectively meet the needs of students. Online courses offer convenience and flexibility that traditional face-to-face classes do not. These features appeal to students with family and work responsibilities that typically make attending classes on campus difficult. However, many of the students who tend to take courses in this instructional format have characteristics that place them at high-risk for academic failure. Because of the traditional mission of community colleges, they generally serve more students who fit this high-risk profile. Despite the promise and potential of online delivery systems, studies have associated distance with higher student withdrawal rates. In addition, research has indicated that online students tend to earn lower grades than students in comparable face-to-face classes. The existence of contrasting findings in the literature exposes the need for additional empirical research relative to the overall success of students in online courses, as well as on factors associated with success in distance education. This is especially true for community college students. The purpose of this study was to determine if significant differences existed in student success at the community college level in online courses as compared to face-to-face courses. In addition, the researchers investigated the relationship between selected demographic, academic, enrollment, and external environmental factors and student success in online courses. The study involved secondary data analysis of quantitative data relevant to students enrolled in course sections taught by instructors who taught both online and face-to-face sections of the same course within the same semester from fall 2012 through spring 2015. The target population included 4,604 students enrolled at a public 2-year community college located in Tennessee. Results indicated there was a significant difference in success between students taking a course online and students taking a course face-to-face. Also, there was a significant difference in success based on instructional method when the following factors were considered: age group, gender, student academic classification, and Pell Grant eligibility status. There was no significant difference in success based on instructional method when first-generation college student status was considered.", "title": "Community College Student Success in Online Versus Equivalent Face-to-Face Courses", "claims": ["- As part of a nationwide effort to increase the postsecondary educational attainment levels of citizens, community colleges have expanded offerings of courses and programs to more effectively meet the needs of students.", "- Online courses offer convenience and flexibility that traditional face-to-face classes do not.", "- These features appeal to students with family and work responsibilities that typically make attending classes on campus difficult.", "- Many of the students who tend to take courses in this instructional format have characteristics that place them at high-risk for academic failure.", "- Because of the traditional mission of community colleges, they generally serve more students who fit this high-risk profile.", "- Despite the promise and potential of online delivery systems, studies have associated distance with higher student withdrawal rates.", "- Research has indicated that online students tend to earn lower grades than students in comparable face-to-face classes.", "- The existence of contrasting findings in the literature exposes the need for additional empirical research relative to the overall success of students in online courses, as well as on factors associated with success in distance education.", "- This need for additional empirical research is especially true for community college students.", "- The purpose of this study was to determine if significant differences existed in student success at the community college level in online courses as compared to face-to-face courses.", "- The researchers investigated the relationship between selected demographic, academic, enrollment, and external environmental factors and student success in online courses.", "- The study involved secondary data analysis of quantitative data relevant to students enrolled in course sections taught by instructors who taught both online and face-to-face sections of the same course within the same semester from fall 2012 through spring 2015.", "- The target population included 4,604 students enrolled at a public 2-year community college located in Tennessee.", "- Results indicated there was a significant difference in success between students taking a course online and students taking a course face-to-face.", "- There was a significant difference in success based on instructional method when the following factors were considered: age group, gender, student academic classification, and Pell Grant eligibility status.", "- There was no significant difference in success based on instructional method when first-generation college student status was considered."]}, {"metadata": {"year": 2013}, "authors": ["Di  Xu", "Shanna Smith Jaggars"], "summary": "Using a large administrative dataset from a statewide system including 34 community and technical colleges, the authors employed an instrumental variable technique to estimate the impact of online versus face-to-face course delivery on student course performance. The travel distance between each student's home and college campus served as an instrument for the likelihood of enrolling in an online section of a given course. In addition, college-by-course fixed effects controlled for within- and between-course selection bias. Analyses yield robust negative estimates for online learning in terms of both course persistence and course grade, contradicting the notion that there is no significant difference between online and face-to-face student outcomes\u2014at least within the community college setting. Accordingly, both two-year and four-year colleges may wish to focus on evaluating and improving the quality of online coursework before engaging in further expansions of online learning.", "title": "The impact of online learning on students\u2019 course outcomes: Evidence from a large community and technical college system", "claims": ["- The authors used a large administrative dataset from a statewide system including 34 community and technical colleges.", "- The authors employed an instrumental variable technique to estimate the impact of online versus face-to-face course delivery on student course performance.", "- The travel distance between each student's home and college campus served as an instrument for the likelihood of enrolling in an online section of a given course.", "- College-by-course fixed effects controlled for within- and between-course selection bias.", "- Analyses yield robust negative estimates for online learning in terms of both course persistence and course grade.", "- The findings contradict the notion that there is no significant difference between online and face-to-face student outcomes, at least within the community college setting.", "- Both two-year and four-year colleges may wish to focus on evaluating and improving the quality of online coursework before engaging in further expansions of online learning."]}, {"metadata": {"year": 1999}, "authors": ["R. Sims", "Allan H. Schuman"], "summary": "The past five years have borne witness to a revolution in education with an acceleration in the use of online technologies to assist or, in many cases, supplant traditional modes of instruction (Bjorner 1993; Velsmid 1997). Peterson's Guide reports that nearly 400 accredited colleges and universities in North America currently employ online instruction of some sort (Velsmid). In addition, Herther (1997) noted that over 150 accredited institutions offer entire bachelor's degree programs to students who rarely, if ever, visit campus. The asynchronous nature of many online programs together with their accessibility from home, office, or hotel room are obvious advantages to students (see Bjorner). Additionally, as the cost of traditional education increases, market pressures are forcing more and more institutions to consider online offerings (see Gubernick and Ebeling 1997) that do not incur the costs of dormitories, athletic programs, etc. The Florida State University system expects online programs to save about 40% of the cost of in-class programs (\"Caught\" 1998). It should be noted, however, that Duke University charges a premium for its online MBA ($82,500 vs. $50,000 for its on-campus equivalent). As more and more online courses and programs proliferate, the questions of quality and comparability of such instruction with traditional methods naturally arise. Gubernick & Ebeling report a study conducted by the University of Phoenix (a private, for-profit institution) that demonstrated standardized achievement test scores of its online graduates were 5% to 10% higher than graduates of competing on-campus programs at three Arizona public universities. While one may legitimately question the degree of comparability of the subject populations, these results are similar to those summarized by Vasarhelyi and Graham (1997) in which investigators at the University of Michigan concluded that computer-based instruction yielded higher average scores than traditional instruction. To date, the most methodologically sound investigation to evaluate the effectiveness of online instruction was conducted by Gerald Schutte at Cal State, Northridge (as cited by McCollum 1997). \"Schutte randomly divided his statistics class into two groups. One attended class as usual, listening to lectures, handing in homework assignments, and taking examinations. The other took an online version of the course, completing assignments on a World Wide Web site, posting questions and comments to an electronic discussion list, and meeting with their professor in an Internet chat room. After an orientation session, students in the virtual class went to Dr. Schutte's classroom only for their midterm and final exams. On both tests, Dr. Schutte found, the wired students outscored their traditional counterparts by an average of 20 percent.\" The present study extends Schutte's paradigm by looking at pre and posttest scores of students enrolled in online and inclass versions of the same class taught by the same instructors over a variety of disciplines. Methodology Students enrolled in five different undergraduate online courses during the Fall semester 1997 participated in a test-retest study designed to measure their learning of the course material. These students were compared with students enrolled in traditional inclass courses taught by the same instructors. The course titles were Organization Behavior, Personal Finance, Managerial Accounting, Sociological Foundations of Education, and Environmental Studies. Student participation was voluntary; names were only used to ensure a matching of the pre / posttest results. Subjects In total, 40 undergraduate students were enrolled in the online courses and 59 undergraduate students were enrolled in the inclass courses during the testing period. Pretests Instructors designed pretests to measure the level of knowledge students had of the course content prior to the start of the course. \u2026", "title": "Learning in an Online Format versus an In-Class Format: An Experimental Study", "claims": ["- The past five years have seen a revolution in education with an acceleration in the use of online technologies to assist or supplant traditional modes of instruction.", "- Nearly 400 accredited colleges and universities in North America currently employ online instruction of some sort.", "- Over 150 accredited institutions offer entire bachelor's degree programs to students who rarely, if ever, visit campus.", "- The asynchronous nature of many online programs together with their accessibility from home, office, or hotel room are obvious advantages to students.", "- As the cost of traditional education increases, market pressures are forcing more institutions to consider online offerings that do not incur the costs of dormitories, athletic programs, etc.", "- The Florida State University system expects online programs to save about 40% of the cost of in-class programs.", "- Duke University charges a premium for its online MBA ($82,500 vs. $50,000 for its on-campus equivalent).", "- As more online courses and programs proliferate, questions of quality and comparability of such instruction with traditional methods naturally arise.", "- A study conducted by the University of Phoenix demonstrated standardized achievement test scores of its online graduates were 5% to 10% higher than graduates of competing on-campus programs at three Arizona public universities.", "- Investigators at the University of Michigan concluded that computer-based instruction yielded higher average scores than traditional instruction.", "- The most methodologically sound investigation to evaluate the effectiveness of online instruction was conducted by Gerald Schutte at Cal State, Northridge.", "- Schutte randomly divided his statistics class into two groups, one attending class as usual and the other taking an online version, and found that the wired students outscored their traditional counterparts by an average of 20 percent on both midterm and final exams.", "- The present study extends Schutte's paradigm by looking at pre and posttest scores of students enrolled in online and in-class versions of the same class taught by the same instructors over a variety of disciplines.", "- Students enrolled in five different undergraduate online courses during the Fall semester 1997 participated in a test-retest study designed to measure their learning of the course material.", "- These students were compared with students enrolled in traditional in-class courses taught by the same instructors.", "- In total, 40 undergraduate students were enrolled in the online courses and 59 undergraduate students were enrolled in the in-class courses during the testing period.", "- Instructors designed pretests to measure the level of knowledge students had of the course content prior to the start of the course."]}], "query": "Online university versus on campus and academic performance differences", "summary_abstract": null, "summary_extract": "The research question regarding the differences in academic performance between online and on-campus university education is addressed through various studies, each offering unique insights. Ury et al. (2005) found that online students in certain high-volume courses achieved significantly lower average grades compared to their on-campus counterparts, suggesting that the delivery method can impact performance. Similarly, Xu and Jaggars (2013, 2014) reported that students generally performed worse in online courses, with specific subgroups such as males, younger students, and Black students experiencing the most significant declines. They also noted that performance gaps were more pronounced in certain subject areas like social sciences and applied professions.\n\nGregory and Lampley (2016) echoed these findings, indicating a significant difference in success rates favoring face-to-face courses, particularly when considering factors like age, gender, and academic classification. They highlighted the higher withdrawal rates and lower grades associated with online courses, especially among high-risk students typically served by community colleges.\n\nContrastingly, Sims and Schuman (1999) presented evidence from studies where online students outperformed their on-campus peers, such as the University of Phoenix study and Schutte's experiment at Cal State, Northridge. These findings suggest that under certain conditions, online education can be as effective, if not more so, than traditional methods.\n\nOverall, while some studies suggest that online education may lead to lower academic performance, particularly for certain student demographics and subject areas, others highlight scenarios where online learning can be equally or more effective. This indicates a complex landscape where the effectiveness of online versus on-campus education may depend on various factors, including course design, student characteristics, and institutional support."}, {"papers": [{"metadata": {"year": 1999}, "authors": ["Hui Chen", "Yan-jun Fang", "Li Yuan", "T. An"], "summary": "An on-line determination of chlorine dioxide (ClO2) in potable water using chlorophenol red (CPR) by gas diffusion flow-injection analysis (FIA) was investigated in the presence of various chlorinated species that can occur under normal water-treatment conditions. A gas diffusion membrane is used to separate the donor (sample) stream from the acceptor (detecting) stream (the donor stream transports the sample stream to the membrane separate device, and the acceptor stream collects all of the penetrated analytes and transports quantitatively to the detector) and makes it possible for this method to eliminate interference from metal ions, as well as other oxychlorinated compounds such as chlorite and chlorate. The system is more selective for chlorine dioxide than chlorine. The linear range of ClO2 concentration is 0\u20130.5 mg\u00b7mL\u22121 with a detection limit of 0.02 \u03bcg\u00b7mL\u22121 (S/N = 3) and a sampling frequency of 50 h\u22121. \u00a9 1999 John Wiley & Sons, Inc. Lab Robotics and Automation 11: 157\u2013161, 1999", "title": "An on\u2010line determination of chlorine dioxide using chlorophenol red by gas diffusion flow\u2010injection analysis", "claims": ["- An on-line determination of chlorine dioxide (ClO2) in potable water using chlorophenol red (CPR) by gas diffusion flow-injection analysis (FIA) was investigated in the presence of various chlorinated species that can occur under normal water-treatment conditions.", "- A gas diffusion membrane is used to separate the donor (sample) stream from the acceptor (detecting) stream.", "- The donor stream transports the sample stream to the membrane separate device, and the acceptor stream collects all of the penetrated analytes and transports quantitatively to the detector.", "- This method makes it possible to eliminate interference from metal ions, as well as other oxychlorinated compounds such as chlorite and chlorate.", "- The system is more selective for chlorine dioxide than chlorine.", "- The linear range of ClO2 concentration is 0\u20130.5 mg\u00b7mL\u22121.", "- The detection limit of ClO2 is 0.02 \u03bcg\u00b7mL\u22121 (S/N = 3).", "- The sampling frequency is 50 h\u22121."]}, {"metadata": {"year": 2007}, "authors": ["F. Tran", "D. Rouleau", "D. Couillard"], "summary": "A new model for mixtures (two and more solutes) of aqueous electrolyte solutions was found to be as accurate as other models, or more accurate, in prediction of new experimental results of the ternary systems HClO4\u2013NaClO3\u2013H2O and HClO4\u2013NaCl\u2013H2O. The water activity values are then used to study the mechanism of the chloride\u2013chlorate reaction, generating chlorine dioxide: \n \n \n \n2H+ + ClO\u22123 + Cl\u2212 ClO2 + 1/2Cl2 + H2O \n \n \n \nSpectrophotometric measurements of the production rate of ClO2 have confirmed that the intermediary species in the proposed equilibrium \n \n \n \nH+(mH2O) H+(m-n)H2O + nH2O \n \n \n \nIs actually H(H20)+m-n. The final kinetic expression for the reaction rate of chlorine dioxide generation, used in pulp bleaching, is then derived to explain the high order with respect to acid concentration.", "title": "Study of ClO2 generation reaction via experimental data of aqueous mixed electrolyte solutions: HClO4\u2013NaCLO3\u2013H2O and HCLO4\u2013NaCl\u2013H2O", "claims": ["- A new model for mixtures of aqueous electrolyte solutions was found to be as accurate as other models, or more accurate, in predicting new experimental results of the ternary systems HClO4\u2013NaClO3\u2013H2O and HClO4\u2013NaCl\u2013H2O.", "- The water activity values are used to study the mechanism of the chloride\u2013chlorate reaction, which generates chlorine dioxide.", "- Spectrophotometric measurements of the production rate of ClO2 have confirmed that the intermediary species in the proposed equilibrium is actually H(H2O)+m-n.", "- The final kinetic expression for the reaction rate of chlorine dioxide generation, used in pulp bleaching, is derived to explain the high order with respect to acid concentration."]}, {"metadata": {"year": 2011}, "authors": ["Liu Xiao-geng"], "summary": "A new spectrophotometric method for the determination of chlorine dioxide(ClO2) in tap water was developed based on methyl red(MR) oxidation and discoloration.Wavelength scanning showed that MR had maximal absorption at 518 nm.Under the experiment conditions of c(MR)/c(ClO2) = 6.4,pH 4.0-4.5,25 \u2103 and reaction time of 40 min,a linear equation was obtained as \u0394A518 =-1.7845c(ClO2) +1.5228(r = 0.992) in the range of 0.0004-0.80 mg/L,the apparent molar absorptivitye = 1.2 \u00d7 105 L/(mol\u00b7cm),and the detection of limit 0.0036 mg/L.MR discoloration by ClO2 oxidation was a first-order reaction.The dynamic equation at 25 \u2103 was ln[c\u221e/(c\u221e-c)] =-0.000689t + 2.263669 with the activation energy Ea = 87.3 kJ/mol and the half-time t1/2 = 16.8 min.The average recoveries for ClO2 in tap water and ClO2 disinfectant were 98.2%-103.2%(n = 5) with a relative standard deviation of 2.43%-3.83%.This method and the recommended standard N,N-diethyl-p-phenylendiamin(DPD) method showed no significant difference(P = 0.05) according to F-test and t-test.Furthermore,satisfying determination results were obtained from this method.", "title": "Spectrophotometric Determination of Chlorine Dioxide in Tap Water Using Methyl Red", "claims": ["", "A new spectrophotometric method for the determination of chlorine dioxide (ClO2) in tap water was developed based on methyl red (MR) oxidation and discoloration.", "Wavelength scanning showed that MR had maximal absorption at 518 nm.", "Under the experiment conditions of c(MR)/c(ClO2) = 6.4, pH 4.0-4.5, 25 \u2103 and reaction time of 40 min, a linear equation was obtained as \u0394A518 = -1.7845c(ClO2) + 1.5228 (r = 0.992) in the range of 0.0004-0.80 mg/L.", "The apparent molar absorptivity e = 1.2 \u00d7 10^5 L/(mol\u00b7cm).", "The detection limit is 0.0036 mg/L.", "MR discoloration by ClO2 oxidation was a first-order reaction.", "The dynamic equation at 25 \u2103 was ln[c\u221e/(c\u221e-c)] = -0.000689t + 2.263669.", "The activation energy Ea = 87.3 kJ/mol.", "The half-time t1/2 = 16.8 min.", "The average recoveries for ClO2 in tap water and ClO2 disinfectant were 98.2%-103.2% (n = 5) with a relative standard deviation of 2.43%-3.83%.", "This method and the recommended standard N,N-diethyl-p-phenylendiamin (DPD) method showed no significant difference (P = 0.05) according to F-test and t-test.", "Satisfying determination results were obtained from this method."]}, {"metadata": {"year": 2005}, "authors": ["L. Zhong-bin"], "summary": "The optimum reaction conditions of ClO_2-Fe \u2161 -luminal chemiluminescence CL system were studied by flow injection technique in detail . A new method of CL for the determination of chlorine dioxide is proposed . The detection limit of the method is 4.0 \u03bcg/L ClO_2 and the linear range is 4.0\uff5e680 \u03bcg/L. The method is highly selective , simple , sensitive and has been applied to the determination of ClO_2 in tap water with satisfactory results .", "title": "ClO_2-Fe(II)-Luminal Flow Injection Chemiluminescence System and Its Analytical Application", "claims": ["", "The optimum reaction conditions of the ClO_2-Fe \u2161 -luminal chemiluminescence CL system were studied by flow injection technique in detail.", "A new method of chemiluminescence (CL) for the determination of chlorine dioxide is proposed.", "The detection limit of the proposed method is 4.0 \u03bcg/L ClO_2.", "The linear range of the proposed method is 4.0 to 680 \u03bcg/L.", "The proposed method is highly selective.", "The proposed method is simple.", "The proposed method is sensitive.", "The proposed method has been applied to the determination of ClO_2 in tap water with satisfactory results."]}, {"metadata": {"year": 2001}, "authors": ["Z. Ying", "S. Yao"], "summary": "A method was described for determination of chlorine dioxide in water samples by using porosity polytetrafluoroethylene membrane to separate ClO 2 from ClO -,ClO - 2,ClO - 3 et al and UV absorption spectroscopy. The linear range is 0.24 mg/L\uff5e11.81 mg/L for ClO 2 with detection limit of 5.2 mg/L. The recovery was 96.8\uff5e102 8% with the standard addition method.", "title": "Continuous Determination of Chlorine Dioxide in Water Samples by Membrane Seperation and UV Spectroscopy", "claims": ["- A method was described for determination of chlorine dioxide in water samples by using porosity polytetrafluoroethylene membrane to separate ClO2 from ClO-, ClO-2, ClO-3 et al and UV absorption spectroscopy.", "- The linear range is 0.24 mg/L\uff5e11.81 mg/L for ClO2.", "- The detection limit for ClO2 is 5.2 mg/L.", "- The recovery was 96.8\uff5e102.8% with the standard addition method."]}, {"metadata": {"year": 2001}, "authors": ["Z. Ying"], "summary": "A method is described for the determination of chlorine dioxide by using porosity polytetrafluoroethylene membrane In this paper, the method is studied according to analytical application in a drinking water plant The conclusion is come to that there is no obvious difference between the method and another method which is commended by Vulan company(USA)if the concentration of ClO 2 in water is more than or equal to 0 08mg/L", "title": "The application of continuous determination of chlorine dioxide by UV-Vis and using membrane to separate gas from water", "claims": ["- A method is described for the determination of chlorine dioxide by using a porosity polytetrafluoroethylene membrane.", "- The method is studied according to analytical application in a drinking water plant.", "- There is no obvious difference between the described method and another method commended by Vulan company (USA) if the concentration of ClO2 in water is more than or equal to 0.08 mg/L."]}, {"metadata": {"year": 2010}, "authors": ["Sun Da-hu"], "summary": "Objective To establish differential spectrophotometry method to determine chlorine dioxide(ClO2) in drinking water.Methods The differential spectrophotometry method was conducted to scan in wave length of 574 nm.Results The experiment demonstrated that linear correlation coefficient was high when the ranges were 0.10-0.50 mg/L,0.26-1.31 mg/L,and 0.50-2.70 mg/L,the linearity was good.Conclusion The method has good accuracy and precision,it is suitable for determination of low concentration chlorine dioxide.", "title": "Determination of Chlorine Dioxide in Water by Chlorophenol Red Differential Spectrophotometry", "claims": ["- The objective was to establish a differential spectrophotometry method to determine chlorine dioxide (ClO2) in drinking water.", "- The differential spectrophotometry method was conducted to scan in a wavelength of 574 nm.", "- The experiment demonstrated that the linear correlation coefficient was high when the ranges were 0.10-0.50 mg/L, 0.26-1.31 mg/L, and 0.50-2.70 mg/L.", "- The linearity was good in the specified ranges.", "- The method has good accuracy and precision.", "- The method is suitable for the determination of low concentration chlorine dioxide."]}, {"metadata": {"year": 2005}, "authors": ["Zhao Chang-jun"], "summary": "A reverse flow injection spectrophometric method for the determination of chlorine dioxide was developed with leucomethylene blue as the coloration reagent. By this method low concentration chlorine dioxide in water was determined in the presence of Cl_2 and anion species such as ClO~-, ClO~-_2 and ClO~-_3. The linear range of ClO_2 measurement is 0~1.91 mg/L with a detection limit of 0.028 mg/L. The presence of chlorine and hypochlorite ion can be masked by using oxalic acid. Chlorate does not interfere with the measurement. The permissible maximum concentration of ClO~-_2 is 3.0 mg/L.", "title": "New method for the flow injection spectrophotometric deternination of low concentration chlorine dioxide in water using methylene blue", "claims": ["- A reverse flow injection spectrophotometric method for the determination of chlorine dioxide was developed with leucomethylene blue as the coloration reagent.", "- By this method, low concentration chlorine dioxide in water was determined in the presence of Cl_2 and anion species such as ClO~-, ClO~-_2, and ClO~-_3.", "- The linear range of ClO_2 measurement is 0~1.91 mg/L.", "- The detection limit of ClO_2 measurement is 0.028 mg/L.", "- The presence of chlorine and hypochlorite ion can be masked by using oxalic acid.", "- Chlorate does not interfere with the measurement.", "- The permissible maximum concentration of ClO~-_2 is 3.0 mg/L."]}], "query": "ClO/ClO2 data in water analysis", "summary_abstract": null, "summary_extract": "The research question focuses on the analysis of ClO/ClO2 data in water, and several studies have explored various methods for determining chlorine dioxide (ClO2) concentrations in water samples. Hui Chen et al. (1999) developed an on-line determination method using gas diffusion flow-injection analysis, which effectively separates ClO2 from other chlorinated species and eliminates interference from metal ions and oxychlorinated compounds. This method is particularly selective for ClO2 over chlorine, with a detection limit of 0.02 \u03bcg/mL and a linear range of 0\u20130.5 mg/mL.\n\nLiu Xiao-geng (2011) introduced a spectrophotometric method based on methyl red oxidation, achieving a detection limit of 0.0036 mg/L and demonstrating high accuracy and precision, with average recoveries of 98.2%-103.2% in tap water. This method showed no significant difference compared to the standard DPD method.\n\nZ. Ying and S. Yao (2001) described a method using a porosity polytetrafluoroethylene membrane and UV absorption spectroscopy, with a linear range of 0.24\u201311.81 mg/L and a detection limit of 5.2 mg/L. This method was validated for use in drinking water plants.\n\nSun Da-hu (2010) established a differential spectrophotometry method with good accuracy and precision, suitable for low concentration ClO2 determination, with high linear correlation coefficients in specified ranges.\n\nZhao Chang-jun (2005) developed a reverse flow injection spectrophotometric method using leucomethylene blue, with a linear range of 0\u20131.91 mg/L and a detection limit of 0.028 mg/L. This method effectively masks the presence of chlorine and hypochlorite ions using oxalic acid, ensuring accurate ClO2 measurement.\n\nCollectively, these studies highlight a range of analytical techniques for ClO2 determination in water, each with specific advantages in terms of sensitivity, selectivity, and applicability to different water treatment contexts."}, {"papers": [{"metadata": {"year": 2022}, "authors": ["S. Veretenenko"], "summary": "The stratospheric polar vortex is a large-scale cyclonic circulation that forms in a cold air mass in the polar region and extends from the middle troposphere to the stratosphere. The polar vortex is implicated in a variety of atmospheric processes, such as the formation of ozone holes, the North Atlantic and the Arctic Oscillations, variations in extratropical cyclone tracks, etc. The results presented in this work show that the vortex plays an important part in the mechanism of solar activity influence on lower atmosphere circulation, with variations in the vortex intensity being responsible for temporal variability in the correlation links observed between atmospheric characteristics and solar activity phenomena. In turn, the location of the vortex is favorable for the influence of ionization changes associated with charged particle fluxes (cosmic rays, auroral and radiation belt electrons) that affect the chemical composition and temperature regime of the polar atmosphere as well as its electric properties and cloudiness state. In this work, recent results concerning solar activity effects on the state of the stratospheric polar vortex as well as its role in solar\u2013atmospheric links are discussed.", "title": "Stratospheric Polar Vortex as an Important Link between the Lower Atmosphere Circulation and Solar Activity", "claims": ["- The stratospheric polar vortex is a large-scale cyclonic circulation that forms in a cold air mass in the polar region and extends from the middle troposphere to the stratosphere.", "- The polar vortex is implicated in a variety of atmospheric processes, such as the formation of ozone holes.", "- The polar vortex is implicated in the North Atlantic and the Arctic Oscillations.", "- The polar vortex is implicated in variations in extratropical cyclone tracks.", "- The vortex plays an important part in the mechanism of solar activity influence on lower atmosphere circulation.", "- Variations in the vortex intensity are responsible for temporal variability in the correlation links observed between atmospheric characteristics and solar activity phenomena.", "- The location of the vortex is favorable for the influence of ionization changes associated with charged particle fluxes (cosmic rays, auroral and radiation belt electrons).", "- Ionization changes associated with charged particle fluxes affect the chemical composition and temperature regime of the polar atmosphere.", "- Ionization changes associated with charged particle fluxes affect the electric properties and cloudiness state of the polar atmosphere.", "- Recent results concerning solar activity effects on the state of the stratospheric polar vortex as well as its role in solar\u2013atmospheric links are discussed in this work."]}, {"metadata": {"year": 1959}, "authors": ["C. E. Palmer"], "summary": "In winter the polar stratospheric air within the earth's shadow forms the core of an intense \u2018cold low\u2019 which extends from about 10 km to at least 50 km and possibly to the base of the ionosphere. Compared with the tropospheric general circulation, this vortex seems to be remarkably stable, particularly in the Southern Hemisphere. \n \nRecent research work in Canada and the United States on the characteristics of the vortex is reviewed. The chief conclusions are that the vortex is more stable in the Southern than in the Northern Hemisphere, that \u2018explosive warmings\u2019 in the lower stratosphere of the Northern Hemisphere follow the breakdown of the vortex at high levels close to the pole, and that the breakdown extends from above downward over a period of several days. It is suggested that the high-level breakdown is correlated with solar activity.", "title": "The stratospheric polar vortex in winter", "claims": ["- In winter, the polar stratospheric air within the earth's shadow forms the core of an intense \u2018cold low\u2019 which extends from about 10 km to at least 50 km and possibly to the base of the ionosphere.", "- Compared with the tropospheric general circulation, the polar stratospheric vortex seems to be remarkably stable, particularly in the Southern Hemisphere.", "- Recent research work in Canada and the United States on the characteristics of the vortex is reviewed.", "- The chief conclusions from the research are that the vortex is more stable in the Southern Hemisphere than in the Northern Hemisphere.", "- \u2018Explosive warmings\u2019 in the lower stratosphere of the Northern Hemisphere follow the breakdown of the vortex at high levels close to the pole.", "- The breakdown of the vortex extends from above downward over a period of several days.", "- It is suggested that the high-level breakdown of the vortex is correlated with solar activity."]}, {"metadata": {"year": 2019}, "authors": ["S. Lee", "A. Butler"], "summary": "The stratospheric polar vortex is a westerly circulation that forms over the winter pole around 10-50 km above the surface, which is known to influence mid-latitude weather patterns. During 2018-19, the Arctic polar vortex demonstrated an unusually large amount of variability,\r\nincluding a strong and persistent sudden stratospheric warming (SSW) event, a strong vortex event, and a dynamic final stratospheric warming (FSW). In this article we discuss the evolution of the vortex, placing it in the context of wider observed climatology, and comment on its apparent impacts on tropospheric weather patterns \u2013 notably, the lack of a surface climate response to the SSW of similar magnitude to the February-March 2018 \u201cBeast from the East\u201d cold-wave.", "title": "The 2018\u20132019 Arctic stratospheric polar vortex", "claims": ["- The stratospheric polar vortex is a westerly circulation that forms over the winter pole around 10-50 km above the surface.", "- The stratospheric polar vortex is known to influence mid-latitude weather patterns.", "- During 2018-19, the Arctic polar vortex demonstrated an unusually large amount of variability.", "- The 2018-19 Arctic polar vortex variability included a strong and persistent sudden stratospheric warming (SSW) event.", "- The 2018-19 Arctic polar vortex variability included a strong vortex event.", "- The 2018-19 Arctic polar vortex variability included a dynamic final stratospheric warming (FSW).", "- The article discusses the evolution of the vortex, placing it in the context of wider observed climatology.", "- The article comments on the apparent impacts of the vortex on tropospheric weather patterns.", "- There was a lack of a surface climate response to the SSW of similar magnitude to the February-March 2018 \u201cBeast from the East\u201d cold-wave."]}, {"metadata": {"year": 2000}, "authors": ["G. Manney", "J. L. Sabutis"], "summary": "The 1999\u20132000 Arctic stratospheric vortex was unusually cold, especially in the early winter lower stratosphere, with a larger area near polar stratospheric cloud formation temperatures in Dec and Jan, and much lower temperatures averaged over Nov\u2013Jan, than any previously observed Arctic winter. In Nov and early Dec, there was a double jet in the upper stratosphere, with the anticyclone cutoff in a region of cyclonic material. By late Dec, there was a discontinuous vortex, large in the upper stratosphere, small in the lower stratosphere; evolving to a strong, continuous, relatively upright vortex by mid\u2010Jan. This vortex evolution in 1999\u20132000 is typical of that in other cold early winters. Despite unusually low temperatures, the lower stratospheric vortex developed more slowly than in previous unusually cold early winters, and was weaker than average until late Dec.", "title": "Development of the polar vortex in the 1999\u20132000 Arctic winter stratosphere", "claims": ["- The 1999\u20132000 Arctic stratospheric vortex was unusually cold, especially in the early winter lower stratosphere.", "- There was a larger area near polar stratospheric cloud formation temperatures in December and January during the 1999\u20132000 Arctic stratospheric vortex.", "- The temperatures averaged over November to January during the 1999\u20132000 Arctic stratospheric vortex were much lower than any previously observed Arctic winter.", "- In November and early December of the 1999\u20132000 Arctic stratospheric vortex, there was a double jet in the upper stratosphere.", "- During the 1999\u20132000 Arctic stratospheric vortex, the anticyclone was cutoff in a region of cyclonic material in November and early December.", "- By late December of the 1999\u20132000 Arctic stratospheric vortex, there was a discontinuous vortex, large in the upper stratosphere and small in the lower stratosphere.", "- The vortex evolved to a strong, continuous, relatively upright vortex by mid-January during the 1999\u20132000 Arctic stratospheric vortex.", "- The vortex evolution in 1999\u20132000 is typical of that in other cold early winters.", "- Despite unusually low temperatures, the lower stratospheric vortex in 1999\u20132000 developed more slowly than in previous unusually cold early winters.", "- The lower stratospheric vortex in 1999\u20132000 was weaker than average until late December."]}, {"metadata": {"year": 2013}, "authors": ["D. Waugh", "L. Polvani"], "summary": "The Stratosphere: Geophysical Mon Copyright 2010 b 10.1029/2009GM The intense cyclonic vortices that form over the winter pole are one of the most prominent features of the stratospheric circulation. The structure and dynamics of these \u201cpolar vortices\u201d play a dominant role in the winter and spring stratospheric circulation and are key to determining distribution of trace gases, in particular ozone, and the couplings between the stratosphere and troposphere. In this chapter, we review the observed structure, dynamical theories, and modeling of these polar vortices. We consider both the zonal mean and three-dimensional potential vorticity perspective and examine the occurrence of extreme events and long-term trends.", "title": "Stratospheric Polar Vortices", "claims": ["", "The intense cyclonic vortices that form over the winter pole are one of the most prominent features of the stratospheric circulation.", "The structure and dynamics of these \u201cpolar vortices\u201d play a dominant role in the winter and spring stratospheric circulation.", "The structure and dynamics of these \u201cpolar vortices\u201d are key to determining the distribution of trace gases, in particular ozone.", "The structure and dynamics of these \u201cpolar vortices\u201d are key to determining the couplings between the stratosphere and troposphere.", "The chapter reviews the observed structure, dynamical theories, and modeling of these polar vortices.", "The chapter considers both the zonal mean and three-dimensional potential vorticity perspective.", "The chapter examines the occurrence of extreme events and long-term trends related to polar vortices."]}, {"metadata": {"year": 2020}, "authors": ["S. Lee"], "summary": "The polar vortex is the dominant feature of the wintertime stratosphere. Sometimes, it is unusually strong, while at others it is very weak or destroyed in an event known as a sudden stratospheric warming (SSW). Both can play an important role in driving the type and predictability of the weather we experience at the surface.", "title": "The stratospheric polar vortex and sudden stratospheric warmings", "claims": ["- The polar vortex is the dominant feature of the wintertime stratosphere.", "- Sometimes, the polar vortex is unusually strong.", "- At other times, the polar vortex is very weak or destroyed in an event known as a sudden stratospheric warming (SSW).", "- Both a strong polar vortex and a sudden stratospheric warming can play an important role in driving the type and predictability of the weather we experience at the surface."]}, {"metadata": {"year": 2018}, "authors": ["V. Harvey", "C. Randall", "L. Goncharenko", "E. Becker", "J. France"], "summary": "The polar vortices play a central role in vertically coupling the atmosphere from the ground to geospace by shaping the background wind field through which atmospheric waves propagate. This work extends the vertical range of previous polar vortex climatologies into the upper mesosphere. The mesospheric polar vortices are defined using the CO gradient method with Microwave Limb Sounder satellite data; the stratospheric polar vortices are defined using a stream function\u2010based algorithm with data from meteorological reanalyses. Strengths and weaknesses of the two vortex definitions are given, as well as recommendations for when, where, and why to use each definition. Midwinter mean vortex geometry in the mesosphere is funnel shaped in the Arctic, with a wide top and narrow bottom. The Antarctic mesospheric vortex tapers with height in early winter and broadens with height in late winter. The seasonal evolution of mesospheric vortex frequency of occurrence, size, and zonal symmetry in both hemispheres is presented. Unexpected behavior above 60 km includes late season vortex broadening in both hemispheres, especially following winters without sudden stratospheric warmings. Following extreme stratospheric disturbances the polar night jet in the mesosphere strengthens and shifts poleward, resulting in a mesospheric vortex that contracts. Overall, the mesospheric polar vortices are more similar between the two hemispheres than their stratospheric counterparts. The vortex climatology presented here serves as an observational benchmark to which the mesospheric polar vortices in high\u2010top climate models can be evaluated.", "title": "On the Upward Extension of the Polar Vortices Into the Mesosphere", "claims": ["- The polar vortices play a central role in vertically coupling the atmosphere from the ground to geospace by shaping the background wind field through which atmospheric waves propagate.", "- This work extends the vertical range of previous polar vortex climatologies into the upper mesosphere.", "- The mesospheric polar vortices are defined using the CO gradient method with Microwave Limb Sounder satellite data.", "- The stratospheric polar vortices are defined using a stream function\u2010based algorithm with data from meteorological reanalyses.", "- Strengths and weaknesses of the two vortex definitions are given, as well as recommendations for when, where, and why to use each definition.", "- Midwinter mean vortex geometry in the mesosphere is funnel shaped in the Arctic, with a wide top and narrow bottom.", "- The Antarctic mesospheric vortex tapers with height in early winter and broadens with height in late winter.", "- The seasonal evolution of mesospheric vortex frequency of occurrence, size, and zonal symmetry in both hemispheres is presented.", "- Unexpected behavior above 60 km includes late season vortex broadening in both hemispheres, especially following winters without sudden stratospheric warmings.", "- Following extreme stratospheric disturbances, the polar night jet in the mesosphere strengthens and shifts poleward, resulting in a mesospheric vortex that contracts.", "- Overall, the mesospheric polar vortices are more similar between the two hemispheres than their stratospheric counterparts.", "- The vortex climatology presented here serves as an observational benchmark to which the mesospheric polar vortices in high\u2010top climate models can be evaluated."]}, {"metadata": {"year": 2010}, "authors": ["Alvaro de la C\u00e1mara", "Carlos R. Mechoso", "Kayo  Ide", "Richard L. Walterscheid", "Gerald  Schubert"], "summary": "The present paper examines the vortex breakdown and large-scale stirring during the final warming of the Southern Hemisphere stratosphere during the spring of 2005. A unique set of in situ observations collected by 27 superpressure balloons (SPBs) is used. The balloons, which were launched from McMurdo, Antarctica, by the Strat\u00e9ole/VORCORE project, drifted for several weeks on two different isopycnic levels in the lower stratosphere. We describe balloon trajectories and compare them with simulations obtained on the basis of the velocity field from the GEOS-5 and NCEP/NCAR reanalyses performed with and without VORCORE data. To gain insight on the mechanisms responsible for the horizontal transport of air inside and outside the well-isolated vortex we examine the balloon trajectories in the framework of the Lagrangian properties of the stratospheric flow. Coherent structures of the flow are visualized by computing finite-time Lyapunov exponents (FTLE). A combination of isentropic analysis and FTLE distributions reveals that air is stripped away from the vortex\u2019s interior as stable manifolds eventually cross the vortex\u2019s edge. It is shown that two SPBs escaped from the vortex within high potential vorticity tongues that developed in association with wave breaking at locations along the vortex\u2019s edge where forward and backward FTLE maxima approximately intersect. The trajectories of three SPBs flying as a group at the same isopycnic level are examined and their behavior is interpreted in reference to the FTLE field. These results support the concept of stable and unstable manifolds governing transport of air masses across the periphery of the stratospheric polar vortex.", "title": "Polar night vortex breakdown and large-scale stirring in the southern stratosphere", "claims": ["- The present paper examines the vortex breakdown and large-scale stirring during the final warming of the Southern Hemisphere stratosphere during the spring of 2005.", "- A unique set of in situ observations was collected by 27 superpressure balloons (SPBs).", "- The balloons were launched from McMurdo, Antarctica, by the Strat\u00e9ole/VORCORE project.", "- The balloons drifted for several weeks on two different isopycnic levels in the lower stratosphere.", "- Balloon trajectories are described and compared with simulations obtained on the basis of the velocity field from the GEOS-5 and NCEP/NCAR reanalyses performed with and without VORCORE data.", "- To gain insight on the mechanisms responsible for the horizontal transport of air inside and outside the well-isolated vortex, the balloon trajectories are examined in the framework of the Lagrangian properties of the stratospheric flow.", "- Coherent structures of the flow are visualized by computing finite-time Lyapunov exponents (FTLE).", "- A combination of isentropic analysis and FTLE distributions reveals that air is stripped away from the vortex\u2019s interior as stable manifolds eventually cross the vortex\u2019s edge.", "- It is shown that two SPBs escaped from the vortex within high potential vorticity tongues that developed in association with wave breaking at locations along the vortex\u2019s edge where forward and backward FTLE maxima approximately intersect.", "- The trajectories of three SPBs flying as a group at the same isopycnic level are examined and their behavior is interpreted in reference to the FTLE field.", "- These results support the concept of stable and unstable manifolds governing transport of air masses across the periphery of the stratospheric polar vortex."]}], "query": "polar vortex stretching stratosphere", "summary_abstract": null, "summary_extract": "The research question regarding the stretching of the polar vortex in the stratosphere is addressed through various studies that highlight the dynamics and implications of the polar vortex. Palmer (1959) notes that the polar vortex is a stable feature, particularly in the Southern Hemisphere, but can experience breakdowns in the Northern Hemisphere, which are associated with \"explosive warmings\" in the lower stratosphere. This breakdown process is suggested to be linked with solar activity. Lee and Butler (2019) discuss the variability of the Arctic polar vortex, particularly during the 2018-19 winter, which included significant events such as sudden stratospheric warming (SSW) and final stratospheric warming (FSW), indicating the dynamic nature of the vortex. Manney and Sabutis (2000) describe the evolution of the Arctic stratospheric vortex during the 1999-2000 winter, noting its unusual coldness and the development of a strong, continuous vortex by mid-January. This evolution is typical of cold early winters, suggesting a pattern in the vortex's behavior. Harvey et al. (2018) emphasize the role of polar vortices in vertically coupling the atmosphere, affecting the propagation of atmospheric waves and the overall wind field. This coupling is crucial for understanding the broader atmospheric dynamics influenced by the polar vortex. Collectively, these studies underscore the complex and variable nature of the polar vortex, its interactions with solar activity, and its significant impact on atmospheric processes and weather patterns."}, {"papers": [{"metadata": {"year": 2018}, "authors": ["W. Young", "R. Gearry", "Paul Cotter", "K. Fraser", "W. McNabb", "N. Roy"], "summary": "Irritable Bowel Syndrome (IBS) is a functional gastrointestinal (GI) disorder featuring chronic or recurrent abdominal discomfort, usually with changes in GI habit. However, the mechanisms responsible for IBS are poorly understood. Although alterations in the GI microbiome has been implicated in IBS, there is a lack of consensus on what the exact role of the microbiome is, and how it changes, in IBS. To gain a better understanding of the link between the microbiome and IBS, we undertook shotgun metagenomic sequencing of faecal samples from a case\u2010control study. The overall aim of the study was to identify microbial and metabolomic factors that provide mechanistic insights into functional GI disorders and increase the predictability of phenotypes for use in nutrition intervention studies. Faecal samples from 112 individuals with functional GI symptoms (cases) or those that were asymptomatic (controls) were shotgun sequenced using the Illumina NextSeq platform. Taxonomic classifications were determined using Metaxa2 and the SILVA 128 database. Gene functions were assigned with the MG\u2010RAST pipeline. Bacterial genera that discriminated case\u2010controls from IBS groups included Faecalibacterium, Blautia, Roseburia, Bilophila, and Streptococcus, which were relatively more abundant in certain IBS subtypes. For example, Faecalibacterium was relatively more abundant in individuals presenting with constipation associated IBS (IBS\u2010C; P<0.001), while Blautia was more prominent in those with the diarrhea form of IBS (IBS\u2010D; P=0.015). Gene functions that best separated groups included those related to carbohydrate metabolism (higher in IBS compared to case\u2010controls), protein metabolism, and virulence factors. Our results suggest that carbohydrate fermentation by the microbiome may be an important factor in IBS. This work shows that efforts to understand the role of the microbiome in IBS need to include consideration of microbial function rather than just microbial composition.", "title": "Exploring the link between Irritable Bowel Syndrome and the microbiome", "claims": ["- Irritable Bowel Syndrome (IBS) is a functional gastrointestinal (GI) disorder featuring chronic or recurrent abdominal discomfort, usually with changes in GI habit.", "- The mechanisms responsible for IBS are poorly understood.", "- Alterations in the GI microbiome have been implicated in IBS.", "- There is a lack of consensus on what the exact role of the microbiome is, and how it changes, in IBS.", "- A case-control study was conducted to gain a better understanding of the link between the microbiome and IBS.", "- Shotgun metagenomic sequencing of faecal samples was undertaken in the study.", "- The overall aim of the study was to identify microbial and metabolomic factors that provide mechanistic insights into functional GI disorders.", "- The study aimed to increase the predictability of phenotypes for use in nutrition intervention studies.", "- Faecal samples from 112 individuals with functional GI symptoms (cases) or those that were asymptomatic (controls) were shotgun sequenced using the Illumina NextSeq platform.", "- Taxonomic classifications were determined using Metaxa2 and the SILVA 128 database.", "- Gene functions were assigned with the MG-RAST pipeline.", "- Bacterial genera that discriminated case-controls from IBS groups included Faecalibacterium, Blautia, Roseburia, Bilophila, and Streptococcus.", "- Faecalibacterium was relatively more abundant in individuals presenting with constipation associated IBS (IBS-C; P<0.001).", "- Blautia was more prominent in those with the diarrhea form of IBS (IBS-D; P=0.015).", "- Gene functions that best separated groups included those related to carbohydrate metabolism, protein metabolism, and virulence factors.", "- Carbohydrate metabolism was higher in IBS compared to case-controls.", "- The results suggest that carbohydrate fermentation by the microbiome may be an important factor in IBS.", "- The work shows that efforts to understand the role of the microbiome in IBS need to include consideration of microbial function rather than just microbial composition."]}, {"metadata": {"year": 2018}, "authors": ["Sampan  Attri", "Ravinder  Nagpal", "Gunjan  Goel"], "summary": "Abstract The present study characterized the colonization and development of gut microbial communities in healthy Indian infants from North-Western Himalayan region in the province Himachal Pradesh. The diversity and transitions of core genera was assessed targeting the 16S rRNA V3-V4 hypervariable region on an Illumina platform. Analysis of more than 17,000 filtered high quality reads indicated that the diversity was lowest in the month 2 followed by gradual increase towards month 4 (1.24 folds increase in Shannon index). The microbial population in month 1 was dominated by Firmicutes and Proteobacteria followed by dominance of Actinobacteria and Firmicutes in the month 4. The analysis of aggregate microbiota at class level indicated relatively higher abundance of Clostridia, Bacteroides and Actinobacteria in month 1, 3 and 4, respectively. The global comparison of dominance of different phyla with the similar subjects indicated that the Indian microbiome is more similar with studies conducted with Swedish infants, although the differences in DNA extraction protocols, geographical location and sequencing platforms as confounding factors cannot be neglected. The findings in this small cohort study could facilitate future studies exploring various aspects of the human gut microbiome in Indian subcontinent.", "title": "High throughput sequence profiling of gut microbiome in Northern Indian infants during the first four months and its global comparison", "claims": ["- The present study characterized the colonization and development of gut microbial communities in healthy Indian infants from North-Western Himalayan region in the province Himachal Pradesh.", "- The diversity and transitions of core genera were assessed targeting the 16S rRNA V3-V4 hypervariable region on an Illumina platform.", "- Analysis of more than 17,000 filtered high quality reads indicated that the diversity was lowest in the month 2 followed by gradual increase towards month 4 (1.24 folds increase in Shannon index).", "- The microbial population in month 1 was dominated by Firmicutes and Proteobacteria.", "- The microbial population in month 4 was dominated by Actinobacteria and Firmicutes.", "- The analysis of aggregate microbiota at class level indicated relatively higher abundance of Clostridia in month 1.", "- The analysis of aggregate microbiota at class level indicated relatively higher abundance of Bacteroides in month 3.", "- The analysis of aggregate microbiota at class level indicated relatively higher abundance of Actinobacteria in month 4.", "- The global comparison of dominance of different phyla with the similar subjects indicated that the Indian microbiome is more similar with studies conducted with Swedish infants.", "- Differences in DNA extraction protocols, geographical location, and sequencing platforms are confounding factors that cannot be neglected.", "- The findings in this small cohort study could facilitate future studies exploring various aspects of the human gut microbiome in Indian subcontinent."]}, {"metadata": {"year": 2021}, "authors": ["Yuxia Liu", "Wenhui Li", "Hongxia Yang", "Xiaoying Zhang", "Wenxiu Wang", "Sitong Jia", "Beibei Xiang", "Yi Wang", "Lin Miao", "Han Zhang", "Lin Wang", "Yujing Wang", "Jixiang Song", "Yingjie Sun", "Lijuan Chai", "Xiaoxuan Tian"], "summary": "Irritable bowel syndrome (IBS) is a chronic gastrointestinal disorder characterized by abdominal pain or discomfort. Previous studies have illustrated that the gut microbiota might play a critical role in IBS, but the conclusions of these studies, based on various methods, were almost impossible to compare, and reproducible microorganism signatures were still in question. To cope with this problem, previously published 16S rRNA gene sequencing data from 439 fecal samples, including 253 IBS samples and 186 control samples, were collected and processed with a uniform bioinformatic pipeline. Although we found no significant differences in community structures between IBS and healthy controls at the amplicon sequence variants (ASV) level, machine learning (ML) approaches enabled us to discriminate IBS from healthy controls at genus level. Linear discriminant analysis effect size (LEfSe) analysis was subsequently used to seek out 97 biomarkers across all studies. Then, we quantified the standardized mean difference (SMDs) for all significant genera identified by LEfSe and ML approaches. Pooled results showed that the SMDs of nine genera had statistical significance, in which the abundance of Lachnoclostridium, Dorea, Erysipelatoclostridium, Prevotella 9, and Clostridium sensu stricto 1 in IBS were higher, while the dominant abundance genera of healthy controls were Ruminococcaceae UCG-005, Holdemanella, Coprococcus 2, and Eubacterium coprostanoligenes group. In summary, based on six published studies, this study identified nine new microbiome biomarkers of IBS, which might be a basis for understanding the key gut microbes associated with IBS, and could be used as potential targets for microbiome-based diagnostics and therapeutics.", "title": "Leveraging 16S rRNA Microbiome Sequencing Data to Identify Bacterial Signatures for Irritable Bowel Syndrome", "claims": ["", "Irritable bowel syndrome (IBS) is a chronic gastrointestinal disorder characterized by abdominal pain or discomfort.", "Previous studies have illustrated that the gut microbiota might play a critical role in IBS.", "The conclusions of previous studies on the gut microbiota's role in IBS, based on various methods, were almost impossible to compare.", "Reproducible microorganism signatures in studies on the gut microbiota's role in IBS were still in question.", "Previously published 16S rRNA gene sequencing data from 439 fecal samples, including 253 IBS samples and 186 control samples, were collected and processed with a uniform bioinformatic pipeline.", "No significant differences in community structures between IBS and healthy controls were found at the amplicon sequence variants (ASV) level.", "Machine learning (ML) approaches enabled discrimination between IBS and healthy controls at the genus level.", "Linear discriminant analysis effect size (LEfSe) analysis was used to seek out 97 biomarkers across all studies.", "The standardized mean difference (SMDs) for all significant genera identified by LEfSe and ML approaches was quantified.", "Pooled results showed that the SMDs of nine genera had statistical significance.", "The abundance of Lachnoclostridium, Dorea, Erysipelatoclostridium, Prevotella 9, and Clostridium sensu stricto 1 in IBS were higher.", "The dominant abundance genera of healthy controls were Ruminococcaceae UCG-005, Holdemanella, Coprococcus 2, and Eubacterium coprostanoligenes group.", "Based on six published studies, this study identified nine new microbiome biomarkers of IBS.", "The identified microbiome biomarkers might be a basis for understanding the key gut microbes associated with IBS.", "The identified microbiome biomarkers could be used as potential targets for microbiome-based diagnostics and therapeutics."]}, {"metadata": {"year": 2019}, "authors": ["R. Pittayanon", "Jennifer T. Lau", "Yuhong Yuan", "G. Leontiadis", "F. Tse", "M. Surette", "P. Moayyedi"], "summary": "BACKGROUND & AIMS\nIrritable bowel syndrome (IBS) is common but difficult to treat. Altering the gut microbiota has been proposed as a strategy for treatment of IBS, but the association between the gut microbiome and IBS symptoms has not been well established. We performed a systematic review to explore evidence for this association.\n\n\nMETHODS\nWe searched databases, including MEDLINE, EMBASE, Cochrane CDSR, and CENTRAL, through April 2, 2018 for case-control studies comparing the fecal or colon microbiomes of adult or pediatric patients with IBS with microbiomes of healthy individuals (controls). The primary outcome was differences in specific gut microbes between patients with IBS and controls.\n\n\nRESULTS\nThe search identified 2631 citations; 24 studies from 22 articles were included. Most studies evaluated adults presenting with various IBS subtypes. Family Enterobacteriaceae (phylum Proteobacteria), family Lactobacillaceae, and genus Bacteroides were increased in patients with IBS compared with controls, whereas uncultured Clostridiales I, genus Faecalibacterium (including Faecalibacterium prausnitzii), and genus Bifidobacterium were decreased in patients with IBS. The diversity of the microbiota was either decreased or not different in IBS patients compared with controls. More than 40% of included studies did not state whether cases and controls were comparable (did not describe sex and/or age characteristics).\n\n\nCONCLUSIONS\nIn a systematic review, we identified specific bacteria associated with microbiomes of patients with IBS vs controls. Studies are needed to determine whether these microbes are a product or cause of IBS.", "title": "Gut Microbiota in Patients With Irritable Bowel Syndrome-A Systematic Review.", "claims": ["- Irritable bowel syndrome (IBS) is common but difficult to treat.", "- Altering the gut microbiota has been proposed as a strategy for treatment of IBS.", "- The association between the gut microbiome and IBS symptoms has not been well established.", "- A systematic review was performed to explore evidence for the association between the gut microbiome and IBS symptoms.", "- Databases including MEDLINE, EMBASE, Cochrane CDSR, and CENTRAL were searched through April 2, 2018, for case-control studies comparing the fecal or colon microbiomes of adult or pediatric patients with IBS with microbiomes of healthy individuals (controls).", "- The primary outcome of the systematic review was differences in specific gut microbes between patients with IBS and controls.", "- The search identified 2631 citations, and 24 studies from 22 articles were included in the review.", "- Most studies evaluated adults presenting with various IBS subtypes.", "- Family Enterobacteriaceae (phylum Proteobacteria), family Lactobacillaceae, and genus Bacteroides were increased in patients with IBS compared with controls.", "- Uncultured Clostridiales I, genus Faecalibacterium (including Faecalibacterium prausnitzii), and genus Bifidobacterium were decreased in patients with IBS compared with controls.", "- The diversity of the microbiota was either decreased or not different in IBS patients compared with controls.", "- More than 40% of included studies did not state whether cases and controls were comparable in terms of sex and/or age characteristics.", "- In a systematic review, specific bacteria associated with microbiomes of patients with IBS vs controls were identified.", "- Studies are needed to determine whether these microbes are a product or cause of IBS."]}, {"metadata": {"year": 2021}, "authors": ["L. Aldars-Garc\u00eda", "M. Chaparro", "J. Gisbert"], "summary": "Inflammatory bowel disease (IBD) is a chronic relapsing\u2013remitting systemic disease of the gastrointestinal tract. It is well established that the gut microbiome has a profound impact on IBD pathogenesis. Our aim was to systematically review the literature on the IBD gut microbiome and its usefulness to provide microbiome-based biomarkers. A systematic search of the online bibliographic database PubMed from inception to August 2020 with screening in accordance with the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines was conducted. One-hundred and forty-four papers were eligible for inclusion. There was a wide heterogeneity in microbiome analysis methods or experimental design. The IBD intestinal microbiome was generally characterized by reduced species richness and diversity, and lower temporal stability, while changes in the gut microbiome seemed to play a pivotal role in determining the onset of IBD. Multiple studies have identified certain microbial taxa that are enriched or depleted in IBD, including bacteria, fungi, viruses, and archaea. The two main features in this sense are the decrease in beneficial bacteria and the increase in pathogenic bacteria. Significant differences were also present between remission and relapse IBD status. Shifts in gut microbial community composition and abundance have proven to be valuable as diagnostic biomarkers. The gut microbiome plays a major role in IBD, yet studies need to go from casualty to causality. Longitudinal designs including newly diagnosed treatment-na\u00efve patients are needed to provide insights into the role of microbes in the onset of intestinal inflammation. A better understanding of the human gut microbiome could provide innovative targets for diagnosis, prognosis, treatment and even cure of this relevant disease.", "title": "Systematic Review: The Gut Microbiome and Its Potential Clinical Application in Inflammatory Bowel Disease", "claims": ["- Inflammatory bowel disease (IBD) is a chronic relapsing\u2013remitting systemic disease of the gastrointestinal tract.", "- It is well established that the gut microbiome has a profound impact on IBD pathogenesis.", "- A systematic search of the online bibliographic database PubMed from inception to August 2020 with screening in accordance with the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines was conducted.", "- One-hundred and forty-four papers were eligible for inclusion in the systematic review.", "- There was a wide heterogeneity in microbiome analysis methods or experimental design in the reviewed studies.", "- The IBD intestinal microbiome was generally characterized by reduced species richness and diversity, and lower temporal stability.", "- Changes in the gut microbiome seemed to play a pivotal role in determining the onset of IBD.", "- Multiple studies have identified certain microbial taxa that are enriched or depleted in IBD, including bacteria, fungi, viruses, and archaea.", "- The two main features of the IBD gut microbiome are the decrease in beneficial bacteria and the increase in pathogenic bacteria.", "- Significant differences were present between remission and relapse IBD status in terms of gut microbiome composition.", "- Shifts in gut microbial community composition and abundance have proven to be valuable as diagnostic biomarkers for IBD.", "- The gut microbiome plays a major role in IBD.", "- Studies need to go from casualty to causality to better understand the role of the gut microbiome in IBD.", "- Longitudinal designs including newly diagnosed treatment-na\u00efve patients are needed to provide insights into the role of microbes in the onset of intestinal inflammation.", "- A better understanding of the human gut microbiome could provide innovative targets for diagnosis, prognosis, treatment, and even cure of IBD."]}, {"metadata": {"year": 2020}, "authors": ["M. Agnello", "L. Carroll", "N. Imam", "R. Pino", "C. Palmer", "Ignacio Varas", "C. Greene", "Maureen Hitschfeld", "Sarah Gupta", "D. Almonacid", "M. Hoaglin"], "summary": "Objective Irritable bowel syndrome (IBS) is a common gastrointestinal disorder that is difficult to diagnose and treat due to its inherent heterogeneity and unclear aetiology. Although there is evidence suggesting the importance of the microbiome in IBS, this association remains poorly defined. In the current study, we aimed to characterise a large cross-sectional cohort of patients with self-reported IBS in terms of microbiome composition, demographics, and risk factors. Design Individuals who had previously submitted a stool sample for 16S microbiome sequencing were sent a comprehensive survey regarding IBS diagnosis, demographics, health history, comorbidities, family history, and symptoms. Log ratio-transformed abundances of microbial taxa were compared between individuals reporting a diagnosis of IBS without any comorbidities and individuals reporting no health conditions. Univariable testing was followed by a multivariable logistic regression model controlling for relevant confounders. Results Out of 6386 respondents, 1692 reported a diagnosis of IBS without comorbidities and 1124 reported no health conditions. We identified 3 phyla, 15 genera, and 19 species as significantly associated with IBS after adjustment for confounding factors. Demographic risk factors include a family history of gut disorders and reported use of antibiotics in the last year. Conclusion The results of this study confirm important IBS risk factors in a large cohort and support a connection for microbiome compositional changes in IBS pathogenesis. The results also suggest clinical relevance in monitoring and investigating the microbiome in patients with IBS. Further, the exploratory models described here provide a foundation for future studies.", "title": "Gut microbiome composition and risk factors in a large cross-sectional IBS cohort", "claims": ["- Irritable bowel syndrome (IBS) is a common gastrointestinal disorder that is difficult to diagnose and treat due to its inherent heterogeneity and unclear aetiology.", "- There is evidence suggesting the importance of the microbiome in IBS, but this association remains poorly defined.", "- The current study aimed to characterise a large cross-sectional cohort of patients with self-reported IBS in terms of microbiome composition, demographics, and risk factors.", "- Individuals who had previously submitted a stool sample for 16S microbiome sequencing were sent a comprehensive survey regarding IBS diagnosis, demographics, health history, comorbidities, family history, and symptoms.", "- Log ratio-transformed abundances of microbial taxa were compared between individuals reporting a diagnosis of IBS without any comorbidities and individuals reporting no health conditions.", "- Out of 6386 respondents, 1692 reported a diagnosis of IBS without comorbidities.", "- Out of 6386 respondents, 1124 reported no health conditions.", "- The study identified 3 phyla, 15 genera, and 19 species as significantly associated with IBS after adjustment for confounding factors.", "- Demographic risk factors for IBS include a family history of gut disorders and reported use of antibiotics in the last year.", "- The results of this study confirm important IBS risk factors in a large cohort.", "- The results support a connection for microbiome compositional changes in IBS pathogenesis.", "- The results suggest clinical relevance in monitoring and investigating the microbiome in patients with IBS.", "- The exploratory models described in the study provide a foundation for future studies."]}, {"metadata": {"year": 2011}, "authors": ["Nuttachat Wisittipanit", "H. Rangwala", "P. Gillevet"], "summary": "The interaction and inter-play of microbes with human host cells is responsible for several disease conditions and of criticality to human health. In this study we analyze the microbial communities within the human gut and their roles in Inflammatory Bowel Disease (IBD). These microbial communities can be profiled using either Length Heterogeneity PCR (LH-PCR) or small subunit (SSU) rRNA sequences. Classification methods based on support vector machines (SVM) and k-nearest neighbor (KNN) were developed to differentiate between healthy controls and IBD patients at various intestinal locations using those profiles. The results show that there exist significant operational taxonomic units (OTUs) or microbial species that are differentially abundant between IBD and healthy control state at specific intestinal locations. Moreover, the classification performances of the sequence data outperform those of LH-PCR profiles and the lowest taxonomic level (Genus-Species) is more likely to have superior classification performances than the higher taxonomic levels.", "title": "Analysis of Microbiome Data across Inflammatory Bowel Disease Patients", "claims": ["- The interaction and inter-play of microbes with human host cells is responsible for several disease conditions and is of criticality to human health.", "- The study analyzes the microbial communities within the human gut and their roles in Inflammatory Bowel Disease (IBD).", "- Microbial communities can be profiled using either Length Heterogeneity PCR (LH-PCR) or small subunit (SSU) rRNA sequences.", "- Classification methods based on support vector machines (SVM) and k-nearest neighbor (KNN) were developed to differentiate between healthy controls and IBD patients at various intestinal locations using microbial profiles.", "- There exist significant operational taxonomic units (OTUs) or microbial species that are differentially abundant between IBD and healthy control states at specific intestinal locations.", "- The classification performances of the sequence data outperform those of LH-PCR profiles.", "- The lowest taxonomic level (Genus-Species) is more likely to have superior classification performances than the higher taxonomic levels."]}, {"metadata": {"year": 2014}, "authors": ["Valentina Taverniti", "S. Guglielmetti"], "summary": "Irritable bowel syndrome (IBS) is an intestinal functional disorder with the highest prevalence in the industrialized world. The intestinal microbiota (IM) plays a role in the pathogenesis of IBS and is not merely a consequence of this disorder. Previous research efforts have not revealed unequivocal microbiological signatures of IBS, and the experimental results are contradictory. The experimental methodologies adopted to investigate the complex intestinal ecosystem drastically impact the quality and significance of the results. Therefore, to consider the methodological aspects of the research on IM in IBS, we reviewed 29 relevant original research articles identified through a PubMed search using three combinations of keywords: \"irritable bowel syndrome + microflora\", \"irritable bowel syndrome + microbiota\" and \"irritable bowel syndrome + microbiome\". For each study, we reviewed the quality and significance of the scientific evidence obtained with respect to the experimental method adopted. The data obtained from each study were compared with all considered publications to identify potential inconsistencies and explain contradictory results. The analytical revision of the studies referenced in the present review has contributed to the identification of microbial groups whose relative abundance significantly alters IBS, suggesting that these microbial groups could be IM signatures for this syndrome. The identification of microbial biomarkers in the IM can be advantageous for the development of new diagnostic tools and novel therapeutic strategies for the treatment of different subtypes of IBS.", "title": "Methodological issues in the study of intestinal microbiota in irritable bowel syndrome.", "claims": ["- Irritable bowel syndrome (IBS) is an intestinal functional disorder with the highest prevalence in the industrialized world.", "- The intestinal microbiota (IM) plays a role in the pathogenesis of IBS and is not merely a consequence of this disorder.", "- Previous research efforts have not revealed unequivocal microbiological signatures of IBS, and the experimental results are contradictory.", "- The experimental methodologies adopted to investigate the complex intestinal ecosystem drastically impact the quality and significance of the results.", "- To consider the methodological aspects of the research on IM in IBS, 29 relevant original research articles were reviewed, identified through a PubMed search using three combinations of keywords: \"irritable bowel syndrome + microflora\", \"irritable bowel syndrome + microbiota\" and \"irritable bowel syndrome + microbiome\".", "- For each study, the quality and significance of the scientific evidence obtained with respect to the experimental method adopted were reviewed.", "- The data obtained from each study were compared with all considered publications to identify potential inconsistencies and explain contradictory results.", "- The analytical revision of the studies referenced in the present review has contributed to the identification of microbial groups whose relative abundance significantly alters IBS.", "- These microbial groups could be IM signatures for this syndrome.", "- The identification of microbial biomarkers in the IM can be advantageous for the development of new diagnostic tools and novel therapeutic strategies for the treatment of different subtypes of IBS."]}], "query": "I need all research papers which used Shotgun sequencing to study gut microbiome of IBS patients in India", "summary_abstract": null, "summary_extract": "The research question seeks studies that utilized shotgun sequencing to investigate the gut microbiome of IBS patients in India. Among the claims provided, only the study by Young et al. (2018) directly addresses this question. This study employed shotgun metagenomic sequencing of fecal samples to explore the gut microbiome in individuals with functional gastrointestinal symptoms, including IBS. The research aimed to identify microbial and metabolomic factors that could provide insights into functional GI disorders. The study involved sequencing fecal samples from 112 individuals using the Illumina NextSeq platform, and it identified specific bacterial genera that differentiated IBS cases from controls, such as Faecalibacterium and Blautia. This work highlights the importance of considering microbial function alongside composition in understanding IBS (Young et al., 2018). No other claims specifically mention the use of shotgun sequencing in the context of IBS patients in India."}, {"papers": [{"metadata": {"year": 2023}, "authors": ["Yue-Ming Zhang", "Ru-Meng Wei", "Ming Ni", "Qi-Tao Wu", "Yun Li", "Y. Ge", "X. Kong", "Xue-Yan Li", "Guiping Chen"], "summary": "Growing evidence clearly demonstrates that maternal rodents exposure to sleep deprivation (SD) during late pregnancy impairs learning and memory in their offspring. Epigenetic mechanisms, particularly histone acetylation, are known to be involved in synaptic plasticity, learning, and memory. We hypothesize that the cognitive decline induced by SD during late pregnancy is associated with histone acetylation dysfunction, and this effect could be reversed by an enriched environment (EE).", "title": "An enriched environment improves maternal sleep deprivation\u2010induced cognitive deficits and synaptic plasticity via hippocampal histone acetylation", "claims": ["- Growing evidence clearly demonstrates that maternal rodents' exposure to sleep deprivation (SD) during late pregnancy impairs learning and memory in their offspring.", "- Epigenetic mechanisms, particularly histone acetylation, are known to be involved in synaptic plasticity, learning, and memory.", "- The cognitive decline induced by SD during late pregnancy is hypothesized to be associated with histone acetylation dysfunction.", "- The effect of cognitive decline induced by SD during late pregnancy could be reversed by an enriched environment (EE)."]}, {"metadata": {"year": 2016}, "authors": ["Yan  Peng", "Wei  Wang", "Tao  Tan", "Wenting  He", "Zhifang  Dong", "Yu Tian Wang", "Huili  Han"], "summary": "BackgroundSleep deprivation during pregnancy is a serious public health problem as it can affect the health of pregnant women and newborns. However, it is not well studied whether sleep deprivation at different stages of pregnancy has similar effects on emotional and cognitive functions of the offspring, and if so, the potential cellular mechanisms also remain poorly understood.MethodsIn the present study, the pregnant rats were subjected to sleep deprivation for 6\u00a0h per day by gentle handling during the first (gestational days 1\u20137), second (gestational days 8\u201314) and third trimester (gestational days 15\u201321) of pregnancy, respectively. The emotional and cognitive functions as well as hippocampal long-term potentiation (LTP) were tested in the offspring rats (postnatal days 42-56).ResultsThe offspring displayed impaired hippocampal-dependent spatial learning and memory, and increased depressive- and anxiety-like behaviors. Quantification of BrdU-positive cells revealed that adult hippocampal neurogenesis was significantly reduced compared to control. Electrophysiological recording showed that maternal sleep deprivation impaired hippocampal CA1 LTP and reduced basal synaptic transmission, as reflected by a decrease in the frequency and amplitude of miniature excitatory postsynaptic current in the hippocampal CA1 pyramidal neurons.ConclusionsTaken together, these results suggest that maternal sleep deprivation at different stages of pregnancy disrupts the emotional and cognitive functions of the offspring that might be attributable to the suppression of hippocampal LTP and basal synaptic transmission.", "title": "Maternal sleep deprivation at different stages of pregnancy impairs the emotional and cognitive functions, and suppresses hippocampal long-term potentiation in the offspring rats", "claims": ["", "Sleep deprivation during pregnancy is a serious public health problem as it can affect the health of pregnant women and newborns.", "It is not well studied whether sleep deprivation at different stages of pregnancy has similar effects on emotional and cognitive functions of the offspring.", "The potential cellular mechanisms of how sleep deprivation affects emotional and cognitive functions of the offspring remain poorly understood.", "In the present study, pregnant rats were subjected to sleep deprivation for 6 hours per day by gentle handling during the first, second, and third trimesters of pregnancy.", "The emotional and cognitive functions as well as hippocampal long-term potentiation (LTP) were tested in the offspring rats on postnatal days 42-56.", "The offspring displayed impaired hippocampal-dependent spatial learning and memory.", "The offspring displayed increased depressive- and anxiety-like behaviors.", "Quantification of BrdU-positive cells revealed that adult hippocampal neurogenesis was significantly reduced compared to control.", "Electrophysiological recording showed that maternal sleep deprivation impaired hippocampal CA1 LTP.", "Maternal sleep deprivation reduced basal synaptic transmission, as reflected by a decrease in the frequency and amplitude of miniature excitatory postsynaptic current in the hippocampal CA1 pyramidal neurons.", "Maternal sleep deprivation at different stages of pregnancy disrupts the emotional and cognitive functions of the offspring.", "The disruption of emotional and cognitive functions in the offspring might be attributable to the suppression of hippocampal LTP and basal synaptic transmission."]}, {"metadata": {"year": 2016}, "authors": ["Grace Violeta Espinoza Pardo", "J\u00e9ferson Ferraz Goularte", "Ana L\u00facia Hoefel", "Alexandre Luz de Castro", "Luiz Carlos Kucharski", "Alex Sander da Rosa Araujo", "Aldo Bolten Lucion"], "summary": "The present study aimed to analyze the effects of sleep restriction (SR) during pregnancy in rats. The following three groups were studied: home cage (HC pregnant females remained in their home cage), Sham (females were placed in tanks similar to the SR group but with sawdust) and SR (females were submitted to the multiple platform method for 20 h per day from gestational days (GD) 14 to 20). Plasma corticosterone after 6 days of SR was not different among the groups. However, the relative adrenal weight was higher in the SR group compared with the HC group, which suggests possible stress impact. SR during pregnancy reduces the body weight of the female but no changes in liver glycogen, cholesterol and triglycerides, and muscle glycogen were detected. On GD 20, the fetuses of the females submitted to SR exhibited increased brain derived neurotrophic factor (BDNF) in the hippocampus, which indicates that sleep restriction of mothers during the final week of gestation may affect neuronal growth factors in a fetal brain structure, in which active neurogenesis occurs during the deprivation period. However, no changes in the total reactive oxygen species (ROS) in the cortex, hippocampus, or cerebellum of the fetuses were detected. SR females showed no major change in the maternal behavior, and the pups' preference for the mother's odor on postpartum day (PPD) 7 was not altered. On GD 20, the SR females exhibited increased plasma prolactin (PRL) and oxytocin (OT) compared with the HC and Sham groups. The negative outcomes of sleep restriction during delivery could be related, in part, to this hormonal imbalance. Sleep restriction during pregnancy induces different changes compared with the changes described in males and affects both the mother and offspring.", "title": "Effects of sleep restriction during pregnancy on the mother and fetuses in rats", "claims": ["- The present study aimed to analyze the effects of sleep restriction (SR) during pregnancy in rats.", "- The study included three groups: home cage (HC), Sham, and SR.", "- HC pregnant females remained in their home cage.", "- Sham females were placed in tanks similar to the SR group but with sawdust.", "- SR females were submitted to the multiple platform method for 20 hours per day from gestational days (GD) 14 to 20.", "- Plasma corticosterone after 6 days of SR was not different among the groups.", "- The relative adrenal weight was higher in the SR group compared with the HC group, suggesting possible stress impact.", "- SR during pregnancy reduces the body weight of the female.", "- No changes in liver glycogen, cholesterol, triglycerides, and muscle glycogen were detected in SR females.", "- On GD 20, fetuses of SR females exhibited increased brain-derived neurotrophic factor (BDNF) in the hippocampus.", "- Increased BDNF in the hippocampus indicates that sleep restriction of mothers during the final week of gestation may affect neuronal growth factors in a fetal brain structure where active neurogenesis occurs during the deprivation period.", "- No changes in the total reactive oxygen species (ROS) in the cortex, hippocampus, or cerebellum of the fetuses were detected.", "- SR females showed no major change in maternal behavior.", "- The pups' preference for the mother's odor on postpartum day (PPD) 7 was not altered.", "- On GD 20, SR females exhibited increased plasma prolactin (PRL) and oxytocin (OT) compared with the HC and Sham groups.", "- The negative outcomes of sleep restriction during delivery could be related, in part, to hormonal imbalance.", "- Sleep restriction during pregnancy induces different changes compared with the changes described in males.", "- Sleep restriction during pregnancy affects both the mother and offspring."]}, {"metadata": {"year": 2023}, "authors": ["K. Gulia"], "summary": "Abstract We spend one-third of our lives in sleep, yet the core function of it still remains an enigma due to underlying complex neural processing in this altered state of consciousness. Sleep requirement varies with phase of development. Neonates spent about 85% of their time in sleep, which is polyphasic in nature. Gradually, this pattern takes the shape of a monophasic sleep in adolescents and adults, with changing micro- and macroarchitecture in every phase. Deprivation of sleep in adults impairs learning and memory, and reduces theta coherence among hippocampus and amygdale during sleep. However, sleep loss during pregnancy can affect the ontogenetic development of networks for sleep\u2013wakefulness and the cognitive development of offspring. Even in normal pregnancy, poor sleep quality, reduced rapid eye movement (REM) sleep, and sleep fragmentation are common observation during the last trimester of pregnancy. Delta power, a marker for the homeostatic drive for sleep, in the NREM sleep during the last trimester of pregnancy and postpartum is increased. However, further sleep loss during late pregnancy is a growing concern. Neonates that are born to the total sleep-restricted dams present significant alterations in their emotional development (symptoms of hyperactivity, increased risk-taking behavior during periadolescence) and immature sleep\u2013wakefulness patterns. The REM sleep restriction during late pregnancy elicits depressionlike traits in neonates, which persist until middle age. For a healthy development of brain and body, thorough understanding of the dynamic nature of sleep in relation to age and state (pregnancy) is instrumental in preventing the above-mentioned conditions of prenatal origin. Although sleep is essential for an active brain (for work during day), it remains an underestimated phenomenon. This review highlights the importance of sleep during pregnancy for a healthy brain network programming in offspring.", "title": "Effect of Sleep Restriction during Pregnancy on Fetal Brain Programming and Neurocognitive Development of Offspring: A Review", "claims": ["", "We spend one-third of our lives in sleep.", "The core function of sleep still remains an enigma due to underlying complex neural processing in this altered state of consciousness.", "Sleep requirement varies with phase of development.", "Neonates spend about 85% of their time in sleep, which is polyphasic in nature.", "The sleep pattern gradually takes the shape of a monophasic sleep in adolescents and adults, with changing micro- and macroarchitecture in every phase.", "Deprivation of sleep in adults impairs learning and memory.", "Deprivation of sleep in adults reduces theta coherence among hippocampus and amygdala during sleep.", "Sleep loss during pregnancy can affect the ontogenetic development of networks for sleep\u2013wakefulness and the cognitive development of offspring.", "Even in normal pregnancy, poor sleep quality, reduced rapid eye movement (REM) sleep, and sleep fragmentation are common observations during the last trimester of pregnancy.", "Delta power, a marker for the homeostatic drive for sleep, in the NREM sleep during the last trimester of pregnancy and postpartum is increased.", "Further sleep loss during late pregnancy is a growing concern.", "Neonates that are born to the total sleep-restricted dams present significant alterations in their emotional development, such as symptoms of hyperactivity and increased risk-taking behavior during periadolescence.", "Neonates that are born to the total sleep-restricted dams present immature sleep\u2013wakefulness patterns.", "The REM sleep restriction during late pregnancy elicits depression-like traits in neonates, which persist until middle age.", "For a healthy development of brain and body, thorough understanding of the dynamic nature of sleep in relation to age and state (pregnancy) is instrumental in preventing the above-mentioned conditions of prenatal origin.", "Although sleep is essential for an active brain (for work during day), it remains an underestimated phenomenon.", "The review highlights the importance of sleep during pregnancy for a healthy brain network programming in offspring."]}, {"metadata": {"year": 2016}, "authors": ["E. Hoekzema", "E. Barba-M\u00fcller", "C. Pozzobon", "M. Picado", "F. Lucco", "D. Garc\u00eda\u2010Garc\u00eda", "J. Soliva", "A. Tobe\u00f1a", "M. Desco", "E. Crone", "A. Ballesteros", "Susanna Carmona", "\u00d3. Vilarroya"], "summary": "\uf0b7 Abstract\u2022 \uf0b7 Introduction\u2022 \uf0b7 Results\u2022 \uf0b7 Discussion\u2022 \uf0b7 Methods\u2022 \uf0b7 References\u2022 \uf0b7 Acknowledgments\u2022 \uf0b7 Author information\u2022 \uf0b7 Supplementary information Pregnancy involves radical hormone surges and biological adaptations. However, the effects of pregnancy on the human brain are virtually unknown. Here we show, using a prospective ('pre''post' pregnancy) study involving first-time mothers and fathers and nulliparous control groups, that pregnancy renders substantial changes in brain structure, primarily reductions in gray matter (GM) volume in regions subserving social cognition. The changes were selective for the mothers and highly consistent, correctly classifying all women as having undergone pregnancy or not inbetween sessions. Interestingly, the volume reductions showed a substantial overlap with brain regions responding to the women's babies postpartum. Furthermore, the GM volume changes of pregnancy predicted measures of postpartum maternal attachment, suggestive of an adaptive process serving the transition into motherhood. Another follow-up session showed that the GM reductions endured for at least 2 years post-pregnancy. Our data provide the first evidence that pregnancy confers long-lasting changes in a woman's brain. Woman\u2019s Brain change to prepare for Baby 4 Subject terms: \uf0b7 Brain \uf0b7 Cognitive neuroscience \uf0b7 Neuroscience \uf0b7 Social neuroscience", "title": "Woman\u2019s Brain change to prepare for Baby", "claims": ["- Pregnancy involves radical hormone surges and biological adaptations.", "- The effects of pregnancy on the human brain are virtually unknown.", "- A prospective ('pre''post' pregnancy) study was conducted involving first-time mothers and fathers and nulliparous control groups.", "- Pregnancy renders substantial changes in brain structure, primarily reductions in gray matter (GM) volume in regions subserving social cognition.", "- The changes in brain structure were selective for the mothers and highly consistent, correctly classifying all women as having undergone pregnancy or not between sessions.", "- The volume reductions in gray matter showed a substantial overlap with brain regions responding to the women's babies postpartum.", "- The GM volume changes of pregnancy predicted measures of postpartum maternal attachment, suggestive of an adaptive process serving the transition into motherhood.", "- Another follow-up session showed that the GM reductions endured for at least 2 years post-pregnancy.", "- The data provide the first evidence that pregnancy confers long-lasting changes in a woman's brain."]}, {"metadata": {"year": 2015}, "authors": ["A. Wilkerson"], "summary": "New mothers often complain of impaired cognitive functioning, and it is well documented that women experience a significant increase in sleep disturbance after the birth of a child. Sleep disturbance has been linked to impaired cognitive performance in several populations, including commercial truck drivers, airline pilots, and medical residents, though this relationship has rarely been studied in postpartum women. In the present study 13 pregnant women and a group of 22 non-pregnant controls completed one week of actigraphy followed by a battery of neuropsychological tests and questionnaires in the last month of pregnancy (Time 1) and again at four weeks postpartum (Time 2). Pregnant women experienced significantly more objective and subjective sleep disturbance than the control group at both time points. They also demonstrated more impairment in objective, but not subjective cognitive functioning. Preliminary analyses indicated increased objective sleep fragmentation from Time 1 to Time 2 predicted decreased objective cognitive performance from Time 1 to Time 2, though small sample size limited the power of these findings. Implications for perinatal women and need for future research were discussed.", "title": "Cognitive Performance as a Function of Sleep Disturbance in the Postpartum Period", "claims": ["- New mothers often complain of impaired cognitive functioning.", "- It is well documented that women experience a significant increase in sleep disturbance after the birth of a child.", "- Sleep disturbance has been linked to impaired cognitive performance in several populations, including commercial truck drivers, airline pilots, and medical residents.", "- The relationship between sleep disturbance and impaired cognitive performance has rarely been studied in postpartum women.", "- In the present study, 13 pregnant women and a group of 22 non-pregnant controls completed one week of actigraphy followed by a battery of neuropsychological tests and questionnaires in the last month of pregnancy (Time 1) and again at four weeks postpartum (Time 2).", "- Pregnant women experienced significantly more objective and subjective sleep disturbance than the control group at both time points.", "- Pregnant women demonstrated more impairment in objective, but not subjective cognitive functioning compared to the control group.", "- Preliminary analyses indicated increased objective sleep fragmentation from Time 1 to Time 2 predicted decreased objective cognitive performance from Time 1 to Time 2.", "- The small sample size limited the power of the findings regarding the prediction of decreased objective cognitive performance from increased objective sleep fragmentation.", "- Implications for perinatal women and the need for future research were discussed."]}, {"metadata": {"year": 2010}, "authors": ["Gabriel Natan Pires", "Monica Levy Andersen", "M\u00e1rcia  Giovenardi", "Sergio  Tufik"], "summary": "The modern living standard has imposed upon society a situation of chronic sleep deprivation. This chronic loss of sleep affects women more than it does men. As a result, the postponement of pregnancy has become a common choice due to the priority given to social and domestic activities. For women, pregnancy represents a condition of intense physical and physiological changes that subject the pregnant woman to a number of potentially stressful situations, ultimately interfering with their quality of sleep. Chronic sleep deprivation, along with the changes imposed on women through pregnancy, can lead to several harmful consequences for the pregnant woman and the child, and can potentially undermine the mother-infant relationship. This article discusses circumstances under which sleep deprivation and poor sleep quality during pregnancy could result in damage to the mother-infant relationship, specifically through maternal fatigue, postpartum depression and changes in pregnancy-related hormonal secretions and activity.", "title": "Sleep impairment during pregnancy: possible implications on mother-infant relationship.", "claims": ["- The modern living standard has imposed upon society a situation of chronic sleep deprivation.", "- This chronic loss of sleep affects women more than it does men.", "- The postponement of pregnancy has become a common choice due to the priority given to social and domestic activities.", "- For women, pregnancy represents a condition of intense physical and physiological changes that subject the pregnant woman to a number of potentially stressful situations.", "- These stressful situations during pregnancy ultimately interfere with women's quality of sleep.", "- Chronic sleep deprivation, along with the changes imposed on women through pregnancy, can lead to several harmful consequences for the pregnant woman and the child.", "- Chronic sleep deprivation and changes during pregnancy can potentially undermine the mother-infant relationship.", "- Sleep deprivation and poor sleep quality during pregnancy could result in damage to the mother-infant relationship through maternal fatigue.", "- Sleep deprivation and poor sleep quality during pregnancy could result in damage to the mother-infant relationship through postpartum depression.", "- Sleep deprivation and poor sleep quality during pregnancy could result in damage to the mother-infant relationship through changes in pregnancy-related hormonal secretions and activity."]}, {"metadata": {"year": 2010}, "authors": ["Jen Jen Chang", "Grace W Pien", "Stephen P Duntley", "George A Macones"], "summary": "Sleep duration in the population has been declining. Women occupy an increasingly prominent place in the work force without reducing most of their responsibilities at home. Consequently, sleep needs are often pushed to the bottom of women's daily priority list. Prior research has indicated that sleep deprivation is associated with higher levels of pro-inflammatory serum cytokines. This is important because higher plasma concentrations of pro-inflammatory serum cytokine levels are associated with postpartum depression and adverse birth outcomes such as preterm delivery. However, little research has directly examined how sleep deprivation may affect maternal and fetal outcomes. This review summarizes the existing data on the effect of sleep deprivation during pregnancy on maternal and fetal outcomes. We review supporting evidence for the hypotheses that sleep deprivation during pregnancy increases the risk of preterm delivery and postpartum depression, and that systemic inflammation is the causal mechanism in the association. Prior research on sleep in pregnancy has been limited by varying data collection methods, subjective self-reported sleep measures, small and non-representative samples, cross-sectional designs; descriptive or non-hypothesis driven studies. Future research with longitudinal study designs is needed to allow examination of the effect of sleep deprivation on adverse maternal and fetal outcomes.", "title": "Sleep deprivation during pregnancy and maternal and fetal outcomes: is there a relationship?", "claims": ["", "Sleep duration in the population has been declining.", "Women occupy an increasingly prominent place in the workforce without reducing most of their responsibilities at home.", "Sleep needs are often pushed to the bottom of women's daily priority list.", "Prior research has indicated that sleep deprivation is associated with higher levels of pro-inflammatory serum cytokines.", "Higher plasma concentrations of pro-inflammatory serum cytokine levels are associated with postpartum depression.", "Higher plasma concentrations of pro-inflammatory serum cytokine levels are associated with adverse birth outcomes such as preterm delivery.", "Little research has directly examined how sleep deprivation may affect maternal and fetal outcomes.", "This review summarizes the existing data on the effect of sleep deprivation during pregnancy on maternal and fetal outcomes.", "The review supports the hypothesis that sleep deprivation during pregnancy increases the risk of preterm delivery.", "The review supports the hypothesis that sleep deprivation during pregnancy increases the risk of postpartum depression.", "The review supports the hypothesis that systemic inflammation is the causal mechanism in the association between sleep deprivation and adverse outcomes.", "Prior research on sleep in pregnancy has been limited by varying data collection methods.", "Prior research on sleep in pregnancy has been limited by subjective self-reported sleep measures.", "Prior research on sleep in pregnancy has been limited by small and non-representative samples.", "Prior research on sleep in pregnancy has been limited by cross-sectional designs.", "Prior research on sleep in pregnancy has been limited by descriptive or non-hypothesis driven studies.", "Future research with longitudinal study designs is needed to allow examination of the effect of sleep deprivation on adverse maternal and fetal outcomes."]}], "query": "how pregnancy reshape the mother brain to cope with sleep deprivation", "summary_abstract": null, "summary_extract": "The research question explores how pregnancy reshapes the mother's brain to cope with sleep deprivation. Several studies provide insights into this complex interaction. Hoekzema et al. (2016) highlight that pregnancy induces significant changes in brain structure, particularly reductions in gray matter volume in areas related to social cognition. These changes are thought to be adaptive, aiding the transition into motherhood and potentially helping mothers manage the cognitive demands of sleep deprivation. Gulia (2023) notes that sleep loss during pregnancy can affect the development of networks for sleep-wakefulness and cognitive functions in offspring, suggesting that the maternal brain may undergo adaptations to mitigate these effects. Wilkerson (2015) reports that pregnant women experience more sleep disturbances and objective cognitive impairments compared to non-pregnant controls, indicating that the brain may adapt to manage these challenges. Collectively, these studies suggest that pregnancy involves both structural and functional brain adaptations that may help mothers cope with the cognitive and emotional demands of sleep deprivation."}, {"papers": [{"metadata": {"year": 2014}, "authors": ["Daniel C. Moos", "D. Pitton"], "summary": "Cognitive load theory (CLT) can explain the challenges faced by student teachers. This study, guided by the CLT, included 26 pre-service teachers. Participants completed a cognitive load self-report questionnaire and were interviewed at two points during their student teaching. Results revealed that student teachers decreased mental effort related to monitoring their students\u2019 level of attention, meeting needs of diverse learners, and managing internal and external distractions. Qualitative analysis revealed: (1) student teachers became aware of limited cognitive resources; (2) lesson planning imposes cognitive load during student teaching; and (3) cognitive overload limits the ability to make modifications during teaching.", "title": "Student teacher challenges: using the cognitive load theory as an explanatory lens", "claims": ["- Cognitive load theory (CLT) can explain the challenges faced by student teachers.", "- This study, guided by the CLT, included 26 pre-service teachers.", "- Participants completed a cognitive load self-report questionnaire.", "- Participants were interviewed at two points during their student teaching.", "- Results revealed that student teachers decreased mental effort related to monitoring their students\u2019 level of attention.", "- Results revealed that student teachers decreased mental effort related to meeting needs of diverse learners.", "- Results revealed that student teachers decreased mental effort related to managing internal and external distractions.", "- Qualitative analysis revealed that student teachers became aware of limited cognitive resources.", "- Qualitative analysis revealed that lesson planning imposes cognitive load during student teaching.", "- Qualitative analysis revealed that cognitive overload limits the ability to make modifications during teaching."]}, {"metadata": {"year": 2010}, "authors": ["\u00d6. Springer"], "summary": "Cognitive load is a theoretical notion with an increasingly central role in the educational research literature. The basic idea of cognitive load theory is that cognitive capacity in working memory is limited, so that if a learning task requires too much capacity, learning will be hampered. The recommended remedy is to design instructional systems that optimize the use of working memory capacity and avoid cognitive overload. Cognitive load theory has advanced educational research considerably and has been used to explain a large set of experimental findings. This article sets out to explore the open questions and the boundaries of cognitive load theory by identifying a number of prob lematic conceptual, methodological and application-related issues. It concludes by pre senting a research agenda for future studies of cognitive load.", "title": "Cognitive load theory, educational research, and instructional design: some food for thought", "claims": ["- Cognitive load is a theoretical notion with an increasingly central role in the educational research literature.", "- The basic idea of cognitive load theory is that cognitive capacity in working memory is limited.", "- If a learning task requires too much capacity, learning will be hampered.", "- The recommended remedy is to design instructional systems that optimize the use of working memory capacity and avoid cognitive overload.", "- Cognitive load theory has advanced educational research considerably.", "- Cognitive load theory has been used to explain a large set of experimental findings.", "- This article sets out to explore the open questions and the boundaries of cognitive load theory by identifying a number of problematic conceptual, methodological, and application-related issues.", "- The article concludes by presenting a research agenda for future studies of cognitive load."]}, {"metadata": {"year": 2010}, "authors": ["Ton de Jong"], "summary": "Cognitive load is a theoretical notion with an increasingly central role in the educational research literature. The basic idea of cognitive load theory is that cognitive capacity in working memory is limited, so that if a learning task requires too much capacity, learning will be hampered. The recommended remedy is to design instructional systems that optimize the use of working memory capacity and avoid cognitive overload. Cognitive load theory has advanced educational research considerably and has been used to explain a large set of experimental findings. This article sets out to explore the open questions and the boundaries of cognitive load theory by identifying a number of problematic conceptual, methodological and application-related issues. It concludes by presenting a research agenda for future studies of cognitive load.", "title": "Cognitive load theory, educational research, and instructional design: some food for thought", "claims": ["- Cognitive load is a theoretical notion with an increasingly central role in the educational research literature.", "- The basic idea of cognitive load theory is that cognitive capacity in working memory is limited.", "- If a learning task requires too much capacity, learning will be hampered.", "- The recommended remedy is to design instructional systems that optimize the use of working memory capacity and avoid cognitive overload.", "- Cognitive load theory has advanced educational research considerably.", "- Cognitive load theory has been used to explain a large set of experimental findings.", "- The article sets out to explore the open questions and the boundaries of cognitive load theory by identifying a number of problematic conceptual, methodological, and application-related issues.", "- The article concludes by presenting a research agenda for future studies of cognitive load."]}, {"metadata": {"year": 2018}, "authors": [], "summary": "Cognitive load theory is supported by a significant number of randomised controlled trials (RCTs). This large body of evidence indicates that instruction is most effective when it is designed according to the limitations of working memory. Cognitive load theory indicates that when teaching students new content and skills, teachers are more effective when they provide explicit guidance accompanied by practice and feedback, not when they require students to discover for themselves many aspects of what they must learn.", "title": "Cognitive load theory: Research that teachers really need to understand", "claims": ["- Cognitive load theory is supported by a significant number of randomised controlled trials (RCTs).", "- This large body of evidence indicates that instruction is most effective when it is designed according to the limitations of working memory.", "- Cognitive load theory indicates that when teaching students new content and skills, teachers are more effective when they provide explicit guidance accompanied by practice and feedback.", "- Cognitive load theory indicates that teachers are not more effective when they require students to discover for themselves many aspects of what they must learn."]}, {"metadata": {"year": 2018}, "authors": [], "summary": "Cognitive load theory is supported by a significant number of randomised controlled trials (RCTs). This large body of evidence indicates that instruction is most effective when it is designed according to the limitations of working memory. Cognitive load theory indicates that when teaching students new content and skills, teachers are more effective when they provide explicit guidance accompanied by practice and feedback, not when they require students to discover for themselves many aspects of what they must learn.", "title": "Cognitive load theory: Research that teachers really need to understand", "claims": ["- Cognitive load theory is supported by a significant number of randomised controlled trials (RCTs).", "- This large body of evidence indicates that instruction is most effective when it is designed according to the limitations of working memory.", "- Cognitive load theory indicates that when teaching students new content and skills, teachers are more effective when they provide explicit guidance accompanied by practice and feedback.", "- Cognitive load theory indicates that teachers are not more effective when they require students to discover for themselves many aspects of what they must learn."]}, {"metadata": {"year": 2021}, "authors": ["M. Kennedy"], "summary": "There are numerous reasons why students with disabilities struggle in school. A key reason is professionals in the field may not pay enough attention to students\u2019 overwhelmed cognitive capacity. Cognitive load theory explains that all humans have limited capacity at any given time to use their auditory, visual, and tactile inputs (independently or collectively) to acquire new information and store it in long-term memory. When available cognition is overwhelmed \u2013 which can be caused by any number of reasons \u2013 learning cannot occur. In this article, we introduce the key aspects of cognitive load theory and give specific examples of how special educators can use this information to shape their instruction to support students\u2019 unique needs.", "title": "Cognitive Load Theory: An Applied Reintroduction for Special and General Educators", "claims": ["", "There are numerous reasons why students with disabilities struggle in school.", "A key reason students with disabilities struggle in school is that professionals in the field may not pay enough attention to students\u2019 overwhelmed cognitive capacity.", "Cognitive load theory explains that all humans have limited capacity at any given time to use their auditory, visual, and tactile inputs (independently or collectively) to acquire new information and store it in long-term memory.", "When available cognition is overwhelmed, learning cannot occur.", "Available cognition can be overwhelmed for any number of reasons.", "The article introduces the key aspects of cognitive load theory.", "The article gives specific examples of how special educators can use information from cognitive load theory to shape their instruction to support students\u2019 unique needs."]}, {"metadata": {"year": 2016}, "authors": ["L. Longo"], "summary": "Cognitive Load Theory is an approach that considers the limitations of the information processing system of the human mind. It is a cognitivist theory that has been conceived in the context of instructional design. One of the main open problems in the literature is the lack of reliable models and technologies to assess cognitive load of learners, thus limiting the application of the theory in practice. This project was aimed at tackling this open problem through the use of a previously developed mobile, responsive web-based prototypical technology, to assess the cognitive load of students in a typical third-level classroom. It was also aimed at exploring the impact of such a technology to instructional design and the potential benefits it can bring to lecturers to improve teaching practices and optimally align their instructional materials to learners.", "title": "Informing Instructional Design by Cognitive Load Assessment in the Classroom.", "claims": ["- Cognitive Load Theory is an approach that considers the limitations of the information processing system of the human mind.", "- Cognitive Load Theory is a cognitivist theory that has been conceived in the context of instructional design.", "- One of the main open problems in the literature is the lack of reliable models and technologies to assess cognitive load of learners.", "- The lack of reliable models and technologies to assess cognitive load limits the application of Cognitive Load Theory in practice.", "- This project was aimed at tackling the open problem of assessing cognitive load through the use of a previously developed mobile, responsive web-based prototypical technology.", "- The project aimed to assess the cognitive load of students in a typical third-level classroom.", "- The project was also aimed at exploring the impact of such a technology on instructional design.", "- The project aimed to explore the potential benefits the technology can bring to lecturers to improve teaching practices.", "- The project aimed to explore how the technology can help lecturers optimally align their instructional materials to learners."]}, {"metadata": {"year": 2021}, "authors": ["T. K. Rao"], "summary": "The present education system has a lot of load in itself. As the education market increasing, the stakeholders of it are also looking to make the curriculum tougher and harder. The competitiveness is clearly visible in the content to be learnt rather than psychological satisfaction of the learning. It is often observed that the curriculum developers are keen to focus more on knowledge and skills in comparison to individual capabilities and pace of learning. When it comes to education system, the parents\u2019 expectations and society needs are far away from needs of the learner actually. Now the student has a big role to play to meet all those expectations. The students have to learn mathematics, they should speak English fluently, and they should get all the prizes in sports and so on. In the process, the learner may undergo a tremendous pressure for each activity he or she takes up. Somewhere, the cognitive fluctuations or cognitive conflict sets in mind and leading work very hard on. The learner has to process all the related incoming information in each and every area of subject he or she chooses, ultimately results in load on memory. As the amount of information to be processed heaps up, heavy cognitive load the outcome will be. Many past researches have been reviewed in this direction to come to solid conclusion.", "title": "Educational Underpinnings of Cognitive Load Theory", "claims": ["- The present education system has a lot of load in itself.", "- As the education market increases, the stakeholders are looking to make the curriculum tougher and harder.", "- The competitiveness is clearly visible in the content to be learned rather than psychological satisfaction of the learning.", "- It is often observed that curriculum developers focus more on knowledge and skills compared to individual capabilities and pace of learning.", "- In the education system, parents\u2019 expectations and society's needs are far from the actual needs of the learner.", "- Students have a big role to play to meet all the expectations from parents and society.", "- Students have to learn mathematics, speak English fluently, and win prizes in sports.", "- In the process of meeting these expectations, learners may undergo tremendous pressure for each activity they take up.", "- Cognitive fluctuations or cognitive conflict can set in the mind of the learner, leading them to work very hard.", "- Learners have to process all related incoming information in each subject they choose, resulting in a load on memory.", "- As the amount of information to be processed increases, the outcome is a heavy cognitive load.", "- Many past researches have been reviewed in this direction to come to a solid conclusion."]}], "query": "cognitive load theory in prekindergarten education", "summary_abstract": null, "summary_extract": "The exploration of cognitive load theory (CLT) in prekindergarten education reveals several insights into how this theory can be applied to early childhood learning environments. Moos and Pitton (2014) highlight that cognitive load theory can elucidate the challenges faced by student teachers, particularly in managing mental effort related to monitoring students' attention, addressing diverse learners' needs, and handling distractions. Their study underscores the importance of understanding cognitive resources and the impact of cognitive overload on lesson planning and teaching modifications.\n\nSpringer (2010) and de Jong (2010) emphasize the foundational concept of CLT, which posits that working memory has limited capacity, and excessive cognitive demands can impede learning. They advocate for instructional designs that optimize working memory use to prevent cognitive overload, a principle that is crucial in structuring prekindergarten curricula.\n\nKennedy (2021) further supports the application of CLT by explaining that students, particularly those with disabilities, struggle when their cognitive capacity is overwhelmed. This highlights the necessity for educators to tailor their instructional strategies to accommodate the cognitive limitations of young learners.\n\nCollectively, these claims suggest that cognitive load theory provides a valuable framework for understanding and improving instructional practices in prekindergarten education by emphasizing the need to manage cognitive demands effectively to enhance learning outcomes."}, {"papers": [{"metadata": {"year": 2000}, "authors": ["Ian Stumpf"], "summary": "Medium\u2010sized regional building contractors in the UK are exhibiting poorer performance in the 1980s and the 1990s and are less likely to survive than their larger or smaller counterparts. The market structure of contracting appears to be changing, putting pressure on these intermediate firms. Evidence drawn from the Department of the Environment (DoE) statistical series shows industry composition is changing, in particular the gradual decline over time of the middle market. An analysis of company accounts for a sample of approximately 200 contractors shows that medium\u2010sized firms are also displaying inferior business ratios. Possible explanations are offered, including barriers to entry, such as capitalization, economies of scale (pecuniary and market), along with changes in construction demand.", "title": "Competitive pressures on middle\u2010market contractors in the UK", "claims": ["", "Medium\u2010sized regional building contractors in the UK are exhibiting poorer performance in the 1980s and the 1990s.", "Medium\u2010sized regional building contractors in the UK are less likely to survive than their larger or smaller counterparts.", "The market structure of contracting appears to be changing, putting pressure on intermediate firms.", "Evidence drawn from the Department of the Environment (DoE) statistical series shows industry composition is changing.", "There is a gradual decline over time of the middle market in the contracting industry.", "An analysis of company accounts for a sample of approximately 200 contractors shows that medium\u2010sized firms are displaying inferior business ratios.", "Possible explanations for the poorer performance of medium-sized firms include barriers to entry, such as capitalization.", "Possible explanations for the poorer performance of medium-sized firms include economies of scale (pecuniary and market).", "Possible explanations for the poorer performance of medium-sized firms include changes in construction demand."]}, {"metadata": {"year": 2008}, "authors": ["T. Brown"], "summary": "This paper explores the dynamics of government-to-government contracting at the local level in order to examine how governments' shared organizational characteristics, notably a governance structure based on political accountability, potentially make them more attractive vendors for services that risk contract failure. Relying on panel data from the 1992 and 1997 International City/County Manager Association's (ICMA) Alternative Service Delivery surveys along with data from the U. S. Census and other sources, this paper identifies service areas in which governments most frequently turn to government vendors. In particular, a comparison of public works and transportation services\u2014a service area with low risks of opportunism leading to contract failure\u2014and health and human services\u2014a service area with high risks of opportunism leading to contract failure\u2014shows that contracting governments are more likely to utilize governments over private firms and nonprofits for high-risk services. This is not the case for low-risk services, suggesting that governments view other governments as trusted contract vendors.", "title": "The Dynamics of Government-to-Government Contracts", "claims": ["- This paper explores the dynamics of government-to-government contracting at the local level to examine how governments' shared organizational characteristics, notably a governance structure based on political accountability, potentially make them more attractive vendors for services that risk contract failure.", "- The paper relies on panel data from the 1992 and 1997 International City/County Manager Association's (ICMA) Alternative Service Delivery surveys along with data from the U.S. Census and other sources.", "- This paper identifies service areas in which governments most frequently turn to government vendors.", "- A comparison of public works and transportation services\u2014a service area with low risks of opportunism leading to contract failure\u2014and health and human services\u2014a service area with high risks of opportunism leading to contract failure\u2014shows that contracting governments are more likely to utilize governments over private firms and nonprofits for high-risk services.", "- Governments are more likely to utilize other governments over private firms and nonprofits for high-risk services.", "- This preference for government vendors is not the case for low-risk services, suggesting that governments view other governments as trusted contract vendors."]}, {"metadata": {"year": 2012}, "authors": ["J. Johnston", "Amanda M. Girth"], "summary": "Theory tells us that competition is the chief driver of improved efficiency and effectiveness in government contracting, yet contract provider markets are often noncompetitive. This study offers a detailed, contextualized examination of public administrative responses to thin contract markets. Following an inductive approach with data from semistructured interviews with contract administrators, the authors offer a preliminary typology of the conditions that give rise to thin markets, and the \u201cmarket management\u201d strategies used to create, enhance, and sustain competition in the markets from where governments purchase goods and services. The authors then review the efficacy and implications of these strategies for public services to citizens.", "title": "Government Contracts and \u201cManaging the Market\u201d", "claims": ["- Theory tells us that competition is the chief driver of improved efficiency and effectiveness in government contracting.", "- Contract provider markets are often noncompetitive.", "- This study offers a detailed, contextualized examination of public administrative responses to thin contract markets.", "- The authors offer a preliminary typology of the conditions that give rise to thin markets.", "- The authors describe the \u201cmarket management\u201d strategies used to create, enhance, and sustain competition in the markets from where governments purchase goods and services.", "- The authors review the efficacy and implications of these strategies for public services to citizens."]}, {"metadata": {"year": 1991}, "authors": ["S. Macmanus"], "summary": "responses varied by type ofproduct or service being provided. Contracting out is one of the most popular forms of cost containment utilized by governments at all levels (David, 1988; Morley, 1989; Chi, 1988; Butler, 1985; MacManus, 1990a). Ironically, at the very time when governments are most actively and aggressively seeking more opportunities to rely on the private sector, news media accounts indicate that the business community has become more cautious about selling to government (Goldstein, 1989). It is estimated that less than 2 percent of all U.S. businesses sell to the federal government (Holtz, 1980: xii) in spite of the fact that the U.S. government spent $195 billion on goods, services, and research and development in 1988 alone. Although the proportion of businesses selling to state and local governments is probably somewhat higher, it is evident that businesses are skeptical about selling to government in spite of the size of the public-sector market. Yet for governments to get the most benefit from contracting out, genuine competition for government contracts must exist. If a significant proportion of the business community does not perceive that government procurement is competitive, or that the competition is fair and equitable and produces costs savings, then government procurement experts must devise strategies to broaden the vendor pools.", "title": "Why Businesses are Reluctant to Sell to Governments", "claims": ["- Contracting out is one of the most popular forms of cost containment utilized by governments at all levels (David, 1988; Morley, 1989; Chi, 1988; Butler, 1985; MacManus, 1990a).", "- At the very time when governments are most actively and aggressively seeking more opportunities to rely on the private sector, news media accounts indicate that the business community has become more cautious about selling to government (Goldstein, 1989).", "- It is estimated that less than 2 percent of all U.S. businesses sell to the federal government (Holtz, 1980: xii).", "- The U.S. government spent $195 billion on goods, services, and research and development in 1988 alone.", "- Although the proportion of businesses selling to state and local governments is probably somewhat higher, it is evident that businesses are skeptical about selling to government in spite of the size of the public-sector market.", "- For governments to get the most benefit from contracting out, genuine competition for government contracts must exist.", "- If a significant proportion of the business community does not perceive that government procurement is competitive, or that the competition is fair and equitable and produces cost savings, then government procurement experts must devise strategies to broaden the vendor pools."]}, {"metadata": {"year": 2014}, "authors": ["Pamela Healy", "Sang Won Sok", "Alejandro Ramirez"], "summary": "Abstract : In the environment of shrinking budgets, there is a trend toward competitive contracting. Research indicates that the government can achieve significant cost savings from competition among industry. This paper will determine how much cost savings could be achieved. It will also analyze numerous contract-related Government Accountability Office reports and provide a summary of the Better Buying Power initiatives. This paper will also identify circumstances that prohibit full and open competition and patterns where competition is most successful. Finally, this paper will provide recommendations to assist federal executives in maximizing competitive contracting and provide the knowledge needed help achieve mandates for improved efficiency and reduced costs.", "title": "The value of competitive contracting", "claims": ["", "In the environment of shrinking budgets, there is a trend toward competitive contracting.", "Research indicates that the government can achieve significant cost savings from competition among industry.", "This paper will determine how much cost savings could be achieved.", "This paper will analyze numerous contract-related Government Accountability Office reports.", "This paper will provide a summary of the Better Buying Power initiatives.", "This paper will identify circumstances that prohibit full and open competition.", "This paper will identify patterns where competition is most successful.", "This paper will provide recommendations to assist federal executives in maximizing competitive contracting.", "This paper will provide the knowledge needed to help achieve mandates for improved efficiency and reduced costs."]}, {"metadata": {"year": 1990}, "authors": ["R. H. DeHoog"], "summary": "Contracting for public services from public or private suppliers is now a common prescription to improve government efficiency. The competitive bidding model is usually viewed as the ideal contracting process. However, this article explains that two other approaches\u2014the negotiation model and the cooperation model-may be more appropriate under certain conditions. The primary factors that are likely to determine which of the three approaches is most suitable are (a) the characteristics of the external environment (especially the number of service suppliers), (b) the level of organizational resources (e.g., personnel, funds, time, and expertise), and (c) the degree of uncertainty about funding, future events, service technologies, and causal relationships between service outputs and desired outcomes. The main point is that there is no one best way to contract for services; rather, government units should adapt their contracting procedures to both internal external conditions to implement service contracting in an effective manner.", "title": "Competition, Negotiation, or Cooperation", "claims": ["", "Contracting for public services from public or private suppliers is now a common prescription to improve government efficiency.", "The competitive bidding model is usually viewed as the ideal contracting process.", "Two other approaches\u2014the negotiation model and the cooperation model\u2014may be more appropriate under certain conditions.", "The primary factors likely to determine which of the three approaches is most suitable are the characteristics of the external environment, the level of organizational resources, and the degree of uncertainty about funding, future events, service technologies, and causal relationships between service outputs and desired outcomes.", "There is no one best way to contract for services.", "Government units should adapt their contracting procedures to both internal and external conditions to implement service contracting in an effective manner."]}, {"metadata": {"year": 1993}, "authors": ["S. F. Bovet"], "summary": "Adapting to a tight economy, recession and a client switch from retainer to project assignments, midsize firms around the country have developed new management structures. Taking on senior partners, stressing firm strengths, a team approach and revised employee reporting and motivation procedures are among restructuring moves firms with 10 to 30 practitioners have made in recent months. To cope with recessionary pressures of the past few years, top executives at \"midsize\" firms--those with 10 to 30 practitioners--have revamped management structures in a variety of creative ways. Innovations include making partial \"of counsel\" or full partnership arrangements with experienced independent counselors, who often share office staff and overhead expenses. Executives at leading midsize firms are refocusing their businesses to handle more projects. Some clients are rejecting retainer arrangements, while others are demanding much more service on a retainer basis. PRJ talked recently with chief operating officers of four midsize firms. Clients today are demanding better and more targeted service, all participants agreed. Clients want senior executives of a firm working on their accounts, they added. There is also much higher client demand for strategic counseling and risk assessment or issues management advice, these sources said. Firms are also zeroing in on specialties as a means of attracting new business, roundtable participants pointed out. Besides strategic planning and issues or risk management, coalition building, public affairs and marketing communications were listed as sought-after areas of expertise. In one case, a firm is developing a unique database service that can be marketed as a separate profit center in addition to its more traditional public relations services. The firms represented in this article illustrate a variety of structures in terms of national and international affiliations. A. Brown-Olmstead Associates (ABOA), Atlanta, is part of the international Shandwick group of companies. Agnew, Carter, McCarthy, Inc., Boston, is a stockholder in the Pinnacle Worldwide corporation of independent firms. DMB&B Public Relations in the Detroit area (Bloomfield Hills, MI) functions as an office of Manning, Selvage & Lee, which is owned by DMB&B, an advertising agency. Nuffer, Smith, Tucker, Inc., San Diego, is a Worldcom partner and Hill and Knowlton associate. In addition to reshaping managements, midsize firms have extensively revamped their employee motivation and reward systems, according to PRJ's executive panel. While the recession has kept salary increases low for most staff, CEOs look to share rewards via bonus payments, profit-sharing or group rewards, such as special luncheons or spot incentive payments. Changing reward systems Midsize firms today stress a team approach to account work, those at the roundtable agreed. They also stress rewards such as staff training and the ability of younger executives to work with senior practitioners on interesting projects. Job satisfaction is a key factor in retaining good workers, roundtable participants said. Employee empowerment can be fostered by flattening the bureaucracy, one executive said. Another firm has established a system of peer reviews to keep employee performance and satisfaction high. Roundtable talk about reward systems also led to a debate on how to find, keep and motivate qualified employees. Characteristics of a firm's own culture were considered important in recruiting and retaining good performers. Created hourglass structure Less than a year ago, the traditional pyramid structure at A. Brown-Olmstead Associates (ABOA) was scrapped in favor of \"an hourglass shape,\" according to CEO and President Amanda Brown-Olmstead. Brown-Olmstead founded the firm 20 years ago as a traditional pyramid, with a CEO, several senior people reporting to her, and account service and support staff in layers below that. \u2026", "title": "PRJ Roundtable Report: Midsize Firms Take New Shapes to Suit Service, Profit Goals", "claims": ["- Midsize firms around the country have developed new management structures to adapt to a tight economy, recession, and a client switch from retainer to project assignments.", "- Firms with 10 to 30 practitioners have made restructuring moves such as taking on senior partners, stressing firm strengths, a team approach, and revised employee reporting and motivation procedures.", "- Top executives at midsize firms have revamped management structures in a variety of creative ways to cope with recessionary pressures of the past few years.", "- Innovations include making partial \"of counsel\" or full partnership arrangements with experienced independent counselors, who often share office staff and overhead expenses.", "- Executives at leading midsize firms are refocusing their businesses to handle more projects.", "- Some clients are rejecting retainer arrangements, while others are demanding much more service on a retainer basis.", "- Clients today are demanding better and more targeted service, according to chief operating officers of four midsize firms.", "- Clients want senior executives of a firm working on their accounts.", "- There is much higher client demand for strategic counseling and risk assessment or issues management advice.", "- Firms are zeroing in on specialties as a means of attracting new business.", "- Strategic planning, issues or risk management, coalition building, public affairs, and marketing communications are listed as sought-after areas of expertise.", "- One firm is developing a unique database service that can be marketed as a separate profit center in addition to its more traditional public relations services.", "- The firms represented in the article illustrate a variety of structures in terms of national and international affiliations.", "- A. Brown-Olmstead Associates (ABOA), Atlanta, is part of the international Shandwick group of companies.", "- Agnew, Carter, McCarthy, Inc., Boston, is a stockholder in the Pinnacle Worldwide corporation of independent firms.", "- DMB&B Public Relations in the Detroit area functions as an office of Manning, Selvage & Lee, which is owned by DMB&B, an advertising agency.", "- Nuffer, Smith, Tucker, Inc., San Diego, is a Worldcom partner and Hill and Knowlton associate.", "- Midsize firms have extensively revamped their employee motivation and reward systems.", "- The recession has kept salary increases low for most staff, but CEOs look to share rewards via bonus payments, profit-sharing, or group rewards, such as special luncheons or spot incentive payments.", "- Midsize firms today stress a team approach to account work.", "- Midsize firms stress rewards such as staff training and the ability of younger executives to work with senior practitioners on interesting projects.", "- Job satisfaction is a key factor in retaining good workers.", "- Employee empowerment can be fostered by flattening the bureaucracy.", "- One firm has established a system of peer reviews to keep employee performance and satisfaction high.", "- Characteristics of a firm's own culture are considered important in recruiting and retaining good performers.", "- Less than a year ago, the traditional pyramid structure at A. Brown-Olmstead Associates (ABOA) was scrapped in favor of \"an hourglass shape.\"", "- Amanda Brown-Olmstead founded A. Brown-Olmstead Associates 20 years ago as a traditional pyramid, with a CEO, several senior people reporting to her, and account service and support staff in layers below that."]}, {"metadata": {"year": 1995}, "authors": ["Karen D. Sorber", "R. Straight"], "summary": "INTRODUCTION Acquiring supplies and services is one function common to most government organizations.(1) Generally, customers submit their requirements to a designated contracting office, which then follows a set of complex rules and regulations while taking action to execute a contract eventually to satisfy the requirements. This process is often frustrating to customers who have no choice but to accept whatever quality of service is provided by their designated (i.e., monopoly) contracting office. Even the people who are doing the contracting have themselves expressed frustration with the system. According to Kelman (1990:10), 29 percent of those providing he service said that the process takes too long. In spite of these problems, contracting offices in the public sector are routinely being asked to take on more and more responsibilities. Today there is much emphasis on contracting out services that government organizations have traditionally performed. According to Osborne and Gaebler (1992:87), procurement of services is challenging primarily because of the difficulty in writing and monitoring contracts for services. Despite the difficulty, Osborne and Gaebler found that customers have tended to be highly satisfied with contracted services (Ibid., 89). The authors believe that establishing competitive contracting offices (CCOs) that succeed or fail on their own performance will reduce much of the frustration associated with the federal government's contracting process. Adopting the CCO concept can lead to reductions in costs and improvements in performance--key goals for the current administration. OVERVIEW OF CCOs The authors presented the concept of CCOs at the 1989 Acquisition Research Symposium (Straight and Sorber, 1989:287). Under that concept, project officers (customers) would have a free hand in selecting any CCO to prepare and award their contracts. Customers would pay the CCO for its services and the chief of each office would be responsible for its financial \"bottom line.\" The project officer's freedom to select the best CCO, and the resultant financial pressure on CCOs to provide timely and effective support, should naturally lead to a more effective and efficient contracting process. In the 1989 paper, the authors discussed the advantages to the customer when dealing in a competitive environment rather than with a monopoly, given the latter's tendency toward inadequate service, inflexibility, and indifference to customer requirements. An important feature of the CCO concept is the provision of financial awards to managers and employees when the organization exceeds its financial operational goals (i.e., revenues exceed expenses). In conjunction with the pressure to compete for contracting business, those awards should motivate both managers and employees to develop a keener customer focus. IMPLEMENTATION ISSUES In a subsequent paper, presented at the 1991 symposium, the authors examined several implementation issues associated with CCO establishment, many of which focused on customer satisfaction (Straight and Dean, 1991:171). Drawing upon the results of a survey of people in the acquisition community, the authors concluded that the proposed CCO system should result in greater customer satisfaction. However, many respondents were concerned that contracting personnel would face a conflict of interest in that they might be tempted to satisfy the customer at the expense of regulatory and legal compliance. PROFESSIONALS' ETHICS Several thoughts on the morality of contracting personnel are offered. First, and most important, contracting personnel are held to a high standard of ethical behavior. They routinely have to disclose financial interests, certify compliance with various procurement integrity laws and regulations, and receive ethics training. When scandals do occur, senior government officials, inspectors general, and others scrutinizing the procurement process generally find that, with the exception of the bad apples involved in the scandal, the procurement workforce is highly ethical. \u2026", "title": "COMPETING CONTRACTING OFFICES: WORKING BETTER, COSTING LESS", "claims": ["- Acquiring supplies and services is one function common to most government organizations.", "- Customers submit their requirements to a designated contracting office, which then follows a set of complex rules and regulations while taking action to execute a contract to satisfy the requirements.", "- The process of acquiring supplies and services is often frustrating to customers who have no choice but to accept whatever quality of service is provided by their designated contracting office.", "- Even the people who are doing the contracting have themselves expressed frustration with the system.", "- According to Kelman (1990:10), 29 percent of those providing the service said that the process takes too long.", "- Contracting offices in the public sector are routinely being asked to take on more and more responsibilities.", "- There is much emphasis on contracting out services that government organizations have traditionally performed.", "- According to Osborne and Gaebler (1992:87), procurement of services is challenging primarily because of the difficulty in writing and monitoring contracts for services.", "- Despite the difficulty, Osborne and Gaebler found that customers have tended to be highly satisfied with contracted services.", "- The authors believe that establishing competitive contracting offices (CCOs) that succeed or fail on their own performance will reduce much of the frustration associated with the federal government's contracting process.", "- Adopting the CCO concept can lead to reductions in costs and improvements in performance, which are key goals for the current administration.", "- The authors presented the concept of CCOs at the 1989 Acquisition Research Symposium.", "- Under the CCO concept, project officers (customers) would have a free hand in selecting any CCO to prepare and award their contracts.", "- Customers would pay the CCO for its services, and the chief of each office would be responsible for its financial \"bottom line.\"", "- The project officer's freedom to select the best CCO, and the resultant financial pressure on CCOs to provide timely and effective support, should naturally lead to a more effective and efficient contracting process.", "- The authors discussed the advantages to the customer when dealing in a competitive environment rather than with a monopoly, given the latter's tendency toward inadequate service, inflexibility, and indifference to customer requirements.", "- An important feature of the CCO concept is the provision of financial awards to managers and employees when the organization exceeds its financial operational goals.", "- Those awards should motivate both managers and employees to develop a keener customer focus.", "- In a subsequent paper, presented at the 1991 symposium, the authors examined several implementation issues associated with CCO establishment, many of which focused on customer satisfaction.", "- Drawing upon the results of a survey of people in the acquisition community, the authors concluded that the proposed CCO system should result in greater customer satisfaction.", "- Many respondents were concerned that contracting personnel would face a conflict of interest in that they might be tempted to satisfy the customer at the expense of regulatory and legal compliance.", "- Contracting personnel are held to a high standard of ethical behavior.", "- Contracting personnel routinely have to disclose financial interests, certify compliance with various procurement integrity laws and regulations, and receive ethics training.", "- When scandals do occur, senior government officials, inspectors general, and others scrutinizing the procurement process generally find that, with the exception of the bad apples involved in the scandal, the procurement workforce is highly ethical."]}], "query": "What are the competitive dynamics of a mid sized company in government contracting", "summary_abstract": null, "summary_extract": "The competitive dynamics of mid-sized companies in government contracting are characterized by several challenges and strategic adaptations. Ian Stumpf (2000) highlights that medium-sized contractors, particularly in the UK, face poorer performance and a higher likelihood of failure compared to their larger and smaller counterparts. This is attributed to changing market structures, barriers to entry, and shifts in construction demand, which collectively exert pressure on these firms. Stumpf also notes a gradual decline in the middle market, suggesting that medium-sized firms struggle to maintain competitive business ratios.\n\nIn response to economic pressures, mid-sized firms have been innovating their management structures. S. F. Bovet (1993) describes how these firms have adapted by restructuring management, emphasizing team approaches, and focusing on specialized services to attract new business. This includes strategic planning and risk management, which are increasingly in demand.\n\nFurthermore, the competitive landscape in government contracting is influenced by the need for genuine competition to achieve cost savings and efficiency. J. Johnston and Amanda M. Girth (2012) discuss the noncompetitive nature of many contract provider markets and the strategies employed to enhance competition. Similarly, Pamela Healy et al. (2014) emphasize the importance of competitive contracting in achieving cost savings, especially in an environment of shrinking budgets.\n\nOverall, mid-sized companies in government contracting must navigate a complex and evolving competitive environment, requiring strategic adaptations and a focus on specialized services to remain viable. These dynamics are shaped by market pressures, economic conditions, and the necessity for competitive practices to ensure efficiency and cost-effectiveness in government procurement."}, {"papers": [{"metadata": {"year": 2006}, "authors": ["R. Lam"], "summary": "Generalized anxiety disorder (GAD) is a common, chronic and disabling anxiety disorder with considerable comorbidity with depression as well as with other anxiety disorders. Although tricyclic antidepressants and benzodiazepines have been found to be efficacious in patients with GAD, tolerability problems and other risks limit their use in clinical practice. In placebo-controlled, acute (<8\u2009weeks) trials, several medications, including the selective serotonin reuptake inhibitors ([SSRIs] escitalopram, paroxetine, and sertraline) and others (venlafaxine, buspirone, pregabalin), have demonstrated efficacy in patients with GAD. Indeed, current guidelines for the treatment of GAD recommend SSRIs as first-line pharmacological therapy because of their efficacy and tolerability profiles. Although GAD is a chronic condition that is usually present for years, with symptoms typically fluctuating in intensity over time, there have been few randomized, controlled trials of pharmacotherapy beyond the acute phase of treatment. However, data from recent relapse-prevention studies and longer-term maintenance studies with paroxetine, venlafaxine and escitalopram strongly support the value of continued treatment for at least a further 6 months. This article focuses on pharmacological treatment, and reviews recently available data from acute, long-term and relapse-prevention trials in patients with GAD. In addition, issues relating to the natural course of GAD are highlighted as important considerations to guide selection of pharmacotherapy.", "title": "Generalized anxiety disorder: how to treat, and for how long?", "claims": ["- Generalized anxiety disorder (GAD) is a common, chronic, and disabling anxiety disorder with considerable comorbidity with depression as well as with other anxiety disorders.", "- Tricyclic antidepressants and benzodiazepines have been found to be efficacious in patients with GAD.", "- Tolerability problems and other risks limit the use of tricyclic antidepressants and benzodiazepines in clinical practice.", "- In placebo-controlled, acute (<8 weeks) trials, several medications, including the selective serotonin reuptake inhibitors (SSRIs) escitalopram, paroxetine, and sertraline, and others (venlafaxine, buspirone, pregabalin), have demonstrated efficacy in patients with GAD.", "- Current guidelines for the treatment of GAD recommend SSRIs as first-line pharmacological therapy because of their efficacy and tolerability profiles.", "- GAD is a chronic condition that is usually present for years, with symptoms typically fluctuating in intensity over time.", "- There have been few randomized, controlled trials of pharmacotherapy beyond the acute phase of treatment for GAD.", "- Data from recent relapse-prevention studies and longer-term maintenance studies with paroxetine, venlafaxine, and escitalopram strongly support the value of continued treatment for at least a further 6 months.", "- The article focuses on pharmacological treatment and reviews recently available data from acute, long-term, and relapse-prevention trials in patients with GAD.", "- Issues relating to the natural course of GAD are highlighted as important considerations to guide the selection of pharmacotherapy."]}, {"metadata": {"year": 2004}, "authors": ["Fr\u00e9d\u00e9ric  Rouillon"], "summary": "Abstract Generalized anxiety disorder (GAD) is a common (lifetime prevalence: 5.1%), recurrent condition, which often heralds other psychiatric disorders, notably depression. As by definition it is a disorder progressing over months, treatment should be designed on a long term basis. And yet, few studies have been conducted beyond the classical 6\u20138 weeks characterizing the acute treatment phase. This is especially true of anxiolytics, but also of antidepressants, with the exception of paroxetine and venlafaxine, which are the only drugs approved in this indication in Western countries. The efficacy of psychotherapy, notably relaxation and cognitive-behavioral therapy, is established in the treatment of GAD, but its preferred indications and possible combination with antidepressants are still to be specified. Long term, not to say very long term studies of GAD, as well as depression, will still be required in the future to improve its management and specify therapeutic modalities (combination treatment, optimal duration, continuous or intermittent therapy, choice of psychotherapeutic techniques or agents, \u2026). Early and adequately prolonged treatment should not only result in more numerous remission periods, but also in decreased frequency of co-morbidities whether depressive, addictive, or of another nature, and should also reduce the social impact of GAD.", "title": "Long term therapy of generalized anxiety disorder", "claims": ["- Generalized anxiety disorder (GAD) is a common condition with a lifetime prevalence of 5.1%.", "- GAD is a recurrent condition that often heralds other psychiatric disorders, notably depression.", "- By definition, GAD is a disorder that progresses over months, requiring long-term treatment design.", "- Few studies have been conducted beyond the classical 6\u20138 weeks characterizing the acute treatment phase of GAD.", "- This lack of long-term studies is especially true for anxiolytics and antidepressants, except for paroxetine and venlafaxine, which are the only drugs approved for GAD in Western countries.", "- The efficacy of psychotherapy, notably relaxation and cognitive-behavioral therapy, is established in the treatment of GAD.", "- The preferred indications for psychotherapy and its possible combination with antidepressants in the treatment of GAD are still to be specified.", "- Long-term, and very long-term studies of GAD and depression will still be required in the future to improve management and specify therapeutic modalities.", "- Early and adequately prolonged treatment of GAD should result in more numerous remission periods.", "- Early and adequately prolonged treatment of GAD should decrease the frequency of co-morbidities, whether depressive, addictive, or of another nature.", "- Early and adequately prolonged treatment of GAD should reduce the social impact of the disorder."]}, {"metadata": {"year": 2015}, "authors": ["M. Stein", "J. Sareen"], "summary": "Key Clinical PointsGeneralized Anxiety Disorder Generalized anxiety disorder is characterized by persistent anxiety and uncontrollable worry that occurs consistently for at least 6 months. This disorder is commonly associated with depression, alcohol and substance abuse, physical health problems, or all these factors. In primary care, patients with this disorder often present with physical symptoms such as headaches, muscle tension, gastrointestinal symptoms, back pain, and insomnia. Brief validated screening tools such as the Generalized Anxiety Disorder 7 (GAD-7) scale should be used to assess the severity of symptoms and response to treatment. First-line treatments for generalized anxiety disorder are cognitive behavioral therapy, pharmacotherapy with a selective serotonin-reuptake inhibitor (SSRI) or a serotonin\u2013norepinephrine reuptake inhibitor (SNRI), or cognitive behavioral therapy in conjunction with either an SSRI or an SNRI. Pregabalin and buspirone are suitable second-line or adjunctive medicat...", "title": "CLINICAL PRACTICE. Generalized Anxiety Disorder.", "claims": ["- Generalized anxiety disorder is characterized by persistent anxiety and uncontrollable worry that occurs consistently for at least 6 months.", "- This disorder is commonly associated with depression, alcohol and substance abuse, physical health problems, or all these factors.", "- In primary care, patients with this disorder often present with physical symptoms such as headaches, muscle tension, gastrointestinal symptoms, back pain, and insomnia.", "- Brief validated screening tools such as the Generalized Anxiety Disorder 7 (GAD-7) scale should be used to assess the severity of symptoms and response to treatment.", "- First-line treatments for generalized anxiety disorder are cognitive behavioral therapy, pharmacotherapy with a selective serotonin-reuptake inhibitor (SSRI) or a serotonin\u2013norepinephrine reuptake inhibitor (SNRI), or cognitive behavioral therapy in conjunction with either an SSRI or an SNRI.", "- Pregabalin and buspirone are suitable second-line or adjunctive medications for generalized anxiety disorder."]}, {"metadata": {"year": 2000}, "authors": ["V. Mah\u00e9", "A. Balogh"], "summary": "&NA; Generalized anxiety disorder (GAD) is one of the most common anxiety disorders and has a poor prognosis, although it is often thought to be a minor complaint. This disorder has a chronic course of 5\u201015 years and longer. Long\u2010term treatment with the commonly used benzodiazepines is controversial because of concerns over tolerance and dependence. We performed a thorough search of the literature for clinical trials of a duration of over 2 months conducted in patients with generalized anxiety disorder in order to identify any successful long\u2010term treatment of this disorder. Only eight long\u2010term reports of studies conducted in well\u2010defined homogeneous groups of patients diagnosed with generalized anxiety disorder were found with the methodology of these studies presenting a number of limiting factors. The results are inconclusive and no reference drug could be identified. In addition, an adequate evaluation of the long\u2010term treatment of GAD has not yet been performed.", "title": "Long\u2010term pharmacological treatment of generalized anxiety disorder", "claims": ["- Generalized anxiety disorder (GAD) is one of the most common anxiety disorders.", "- GAD has a poor prognosis.", "- GAD is often thought to be a minor complaint.", "- GAD has a chronic course of 5\u201015 years and longer.", "- Long\u2010term treatment with the commonly used benzodiazepines is controversial because of concerns over tolerance and dependence.", "- A thorough search of the literature was performed for clinical trials of a duration of over 2 months conducted in patients with generalized anxiety disorder.", "- Only eight long\u2010term reports of studies conducted in well\u2010defined homogeneous groups of patients diagnosed with generalized anxiety disorder were found.", "- The methodology of these studies presents a number of limiting factors.", "- The results of the studies are inconclusive.", "- No reference drug could be identified for the long-term treatment of GAD.", "- An adequate evaluation of the long\u2010term treatment of GAD has not yet been performed."]}, {"metadata": {"year": 1987}, "authors": ["G. Butler", "A. Cullington", "G. Hibbert", "I. Klimes", "M. Gelder"], "summary": "A preliminary controlled investigation of the effectiveness of Anxiety Management as a treatment for generalised anxiety disorder (GAD) is described. Patients with a primary diagnosis of GAD, in which the current episode had lasted for at least 6 months but not more than 2 years, were included. Anxiety Management, a self-help treatment including procedures for managing somatic and cognitive symptoms, and for dealing with avoidance and low self-confidence, was given either immediately or after a 12-week waiting period. The average length of treatment was 8.7 sessions. Highly significant changes in anxiety, depression, and problem ratings were shown after treatment. These changes were replicated when the waiting list group had also received treatment, and gains were maintained by both groups for 6 months. Similar degrees of improvement and maintenance of change were shown in subgroups with and without minor depressive disorder or recurrent panic attacks.", "title": "Anxiety Management for Persistent Generalised Anxiety", "claims": ["", "Patients with a primary diagnosis of generalized anxiety disorder (GAD), in which the current episode had lasted for at least 6 months but not more than 2 years, were included in the investigation.", "Anxiety Management is a self-help treatment that includes procedures for managing somatic and cognitive symptoms, and for dealing with avoidance and low self-confidence.", "Anxiety Management was given either immediately or after a 12-week waiting period.", "The average length of Anxiety Management treatment was 8.7 sessions.", "Highly significant changes in anxiety, depression, and problem ratings were shown after Anxiety Management treatment.", "The changes in anxiety, depression, and problem ratings were replicated when the waiting list group also received Anxiety Management treatment.", "Gains from Anxiety Management treatment were maintained by both groups for 6 months.", "Similar degrees of improvement and maintenance of change were shown in subgroups with and without minor depressive disorder or recurrent panic attacks."]}, {"metadata": {"year": 2000}, "authors": ["M F Gliatto"], "summary": "Patients with generalized anxiety disorder experience worry or anxiety and a number of physical and psychologic symptoms. The disorder is frequently difficult to diagnose because of the variety of presentations and the common occurrence of comorbid medical or psychiatric conditions. The lifetime prevalence is approximately 4 to 6 percent in the general population and is more common in women than in men. It is often chronic, and patients with this disorder are more likely to be seen by family physicians than by psychiatrists. Treatment consists of pharmacotherapy and various forms of psychotherapy. The benzodiazepines are used for short-term treatment, but because of the frequently chronic nature of generalized anxiety disorder, they may need to be continued for months to years. Buspirone and antidepressants are also used for the pharmacologic management of patients with generalized anxiety disorder. Patients must receive an appropriate pharmacologic trial with dosage titrated to optimal levels as judged by the control of symptoms and the tolerance of side effects. Psychiatric consultation should be considered for patients who do not respond to an appropriate trial of pharmacotherapy.", "title": "Generalized anxiety disorder.", "claims": ["- Patients with generalized anxiety disorder experience worry or anxiety and a number of physical and psychologic symptoms.", "- The disorder is frequently difficult to diagnose because of the variety of presentations and the common occurrence of comorbid medical or psychiatric conditions.", "- The lifetime prevalence of generalized anxiety disorder is approximately 4 to 6 percent in the general population.", "- Generalized anxiety disorder is more common in women than in men.", "- Generalized anxiety disorder is often chronic.", "- Patients with generalized anxiety disorder are more likely to be seen by family physicians than by psychiatrists.", "- Treatment of generalized anxiety disorder consists of pharmacotherapy and various forms of psychotherapy.", "- The benzodiazepines are used for short-term treatment of generalized anxiety disorder.", "- Because of the frequently chronic nature of generalized anxiety disorder, benzodiazepines may need to be continued for months to years.", "- Buspirone and antidepressants are also used for the pharmacologic management of patients with generalized anxiety disorder.", "- Patients must receive an appropriate pharmacologic trial with dosage titrated to optimal levels as judged by the control of symptoms and the tolerance of side effects.", "- Psychiatric consultation should be considered for patients who do not respond to an appropriate trial of pharmacotherapy."]}, {"metadata": {"year": 2000}, "authors": ["M. F. Gliatto"], "summary": "Patients with generalized anxiety disorder experience worry or anxiety and a number of physical and psychologic symptoms. The disorder is frequently difficult to diagnose because of the variety of presentations and the common occurrence of comorbid medical or psychiatric conditions. The lifetime prevalence is approximately 4 to 6 percent in the general population and is more common in women than in men. It is often chronic, and patients with this disorder are more likely to be seen by family physicians than by psychiatrists. Treatment consists of pharmacotherapy and various forms of psychotherapy. The benzodiazepines are used for short-term treatment, but because of the frequently chronic nature of generalized anxiety disorder, they may need to be continued for months to years. Buspirone and antidepressants are also used for the pharmacologic management of patients with generalized anxiety disorder. Patients must receive an appropriate pharmacologic trial with dosage titrated to optimal levels as judged by the control of symptoms and the tolerance of side effects. Psychiatric consultation should be considered for patients who do not respond to an appropriate trial of pharmacotherapy.", "title": "Generalized anxiety disorder.", "claims": ["- Patients with generalized anxiety disorder experience worry or anxiety and a number of physical and psychologic symptoms.", "- The disorder is frequently difficult to diagnose because of the variety of presentations and the common occurrence of comorbid medical or psychiatric conditions.", "- The lifetime prevalence of generalized anxiety disorder is approximately 4 to 6 percent in the general population.", "- Generalized anxiety disorder is more common in women than in men.", "- Generalized anxiety disorder is often chronic.", "- Patients with generalized anxiety disorder are more likely to be seen by family physicians than by psychiatrists.", "- Treatment of generalized anxiety disorder consists of pharmacotherapy and various forms of psychotherapy.", "- The benzodiazepines are used for short-term treatment of generalized anxiety disorder.", "- Because of the frequently chronic nature of generalized anxiety disorder, benzodiazepines may need to be continued for months to years.", "- Buspirone and antidepressants are also used for the pharmacologic management of patients with generalized anxiety disorder.", "- Patients must receive an appropriate pharmacologic trial with dosage titrated to optimal levels as judged by the control of symptoms and the tolerance of side effects.", "- Psychiatric consultation should be considered for patients who do not respond to an appropriate trial of pharmacotherapy."]}, {"metadata": {"year": 2003}, "authors": ["C. Allgulander", "B. Bandelow", "E. Hollander", "S. Montgomery", "D. Nutt", "A. Okasha", "M. Pollack", "Dan J Stein", "R. Swinson"], "summary": "ABSTRACT What are the current recommendations for the long-term treatment of generalized anxiety disorder (GAD)? GAD is a common disorder with a lifetime prevalence of 4% to 7% in the general population. GAD is characterized by excessive, uncontrollable worry or anxiety about a number of events or activities that the individual experiences on more days than not over a 6-month period. Onset of GAD symptoms usually occurs during an individual's early twenties; however, high rates of GAD have also been seen in children and adolescents. The clinical course of GAD is often chronic, with 40% of patients reporting illness lasting >5 years. GAD is associated with pronounced functional impairment, resulting in decreased vocational function and reduced quality of life. Patients with GAD tend to be high users of outpatient medical care, which contributes significantly to healtcare costs. Currently, benzodiazepines and buspirone are prescribed frequently to treat GAD. Although both show efficacy in acute treatment trials, few long-term studies have been perform Benzodiazepines are not recommended for long-term treatment of GAD, due to associated development of tolerance, psychomotor impairment, cognitive and memory changes, physical dependence, and a withdrawal reaction on discontinuation. The antidepressant venlafaxine extended-release (XR) has received approval for the treatment of GAD in the United States and many other countries. Venlafaxine XR has demonstrated efficacy over placebo in two randomized treatment trials of 6 months' duration as well as in other acute trials. Paroxetine is the first of the selective serotonin reuptake inhibitors (SSRIs) to receive US approval for the treatment of GAD. Paroxetine demonstrated superiority to placebo in short-term trials, and investigations into the use of other SSRIs are ongoing. This suggests that other SSRIs, and serotonin and noradrenaline reuptake inhibitors, are likely to be effective in the treatment of GAD. Of the psychological therapies, cognitive-behavioral therapy (CBT) shows the greatest benefit in treating GAD patients. Treatment gains after a 12-week course of CBT may be maintained for up to 1 year. Currently, no guidelines exist for the long-term treatment of GAD.", "title": "WCA Recommendations for the Long-Term Treatment of Generalized Anxiety Disorder", "claims": ["", "GAD is a common disorder with a lifetime prevalence of 4% to 7% in the general population.", "GAD is characterized by excessive, uncontrollable worry or anxiety about a number of events or activities that the individual experiences on more days than not over a 6-month period.", "Onset of GAD symptoms usually occurs during an individual's early twenties.", "High rates of GAD have also been seen in children and adolescents.", "The clinical course of GAD is often chronic, with 40% of patients reporting illness lasting >5 years.", "GAD is associated with pronounced functional impairment, resulting in decreased vocational function and reduced quality of life.", "Patients with GAD tend to be high users of outpatient medical care, which contributes significantly to healthcare costs.", "Currently, benzodiazepines and buspirone are prescribed frequently to treat GAD.", "Benzodiazepines show efficacy in acute treatment trials.", "Buspirone shows efficacy in acute treatment trials.", "Few long-term studies have been performed on benzodiazepines and buspirone for GAD.", "Benzodiazepines are not recommended for long-term treatment of GAD due to associated development of tolerance, psychomotor impairment, cognitive and memory changes, physical dependence, and a withdrawal reaction on discontinuation.", "The antidepressant venlafaxine extended-release (XR) has received approval for the treatment of GAD in the United States and many other countries.", "Venlafaxine XR has demonstrated efficacy over placebo in two randomized treatment trials of 6 months' duration as well as in other acute trials.", "Paroxetine is the first of the selective serotonin reuptake inhibitors (SSRIs) to receive US approval for the treatment of GAD.", "Paroxetine demonstrated superiority to placebo in short-term trials.", "Investigations into the use of other SSRIs for GAD are ongoing.", "Other SSRIs, and serotonin and noradrenaline reuptake inhibitors, are likely to be effective in the treatment of GAD.", "Of the psychological therapies, cognitive-behavioral therapy (CBT) shows the greatest benefit in treating GAD patients.", "Treatment gains after a 12-week course of CBT may be maintained for up to 1 year.", "Currently, no guidelines exist for the long-term treatment of GAD."]}], "query": "how long a patient with generalized anxiety disorder should take medication for", "summary_abstract": null, "summary_extract": "The duration for which a patient with generalized anxiety disorder (GAD) should continue medication is a topic of ongoing research and debate. GAD is recognized as a chronic condition, often persisting for years, which necessitates a long-term treatment approach (Lam, 2006; Rouillon, 2004; Mah\u00e9 & Balogh, 2000). Current guidelines suggest that selective serotonin reuptake inhibitors (SSRIs) are the first-line pharmacological therapy due to their efficacy and tolerability (Lam, 2006). \n\nWhile acute treatment trials typically last less than eight weeks, evidence from relapse-prevention and maintenance studies supports the continuation of treatment for at least six months to prevent relapse (Lam, 2006). However, there is a notable scarcity of long-term studies beyond this period, particularly for medications like benzodiazepines, which are not recommended for extended use due to risks of tolerance and dependence (Mah\u00e9 & Balogh, 2000; Allgulander et al., 2003).\n\nThe chronic nature of GAD implies that treatment may need to be prolonged, potentially spanning months to years, to achieve sustained remission and reduce the frequency of comorbidities (Rouillon, 2004; Gliatto, 2000). Despite this, there remains a lack of comprehensive guidelines for the long-term pharmacological management of GAD, highlighting the need for further research to refine treatment durations and strategies (Allgulander et al., 2003)."}, {"papers": [{"metadata": {"year": 2011}, "authors": ["W. Leap"], "summary": "Gay men\u2019s stories about homophobic violence will, at times, disguise reference to the persons who initiate harassment and injury. Instead, these stories emphasize the details of location or allow the victim of narrated violence to confirm the status of narrative hero. Each approach to story-telling has noticeable effects on the connections between sexual sameness and violence as displayed within the narrative. This paper examines these approaches to story-telling and their effects on homophobic formation (Leap, introduction, this volume), and traces the broader implications of these narrative styles within contemporary politics of gay visibility, assimilation and whiteness.", "title": "Homophobia as Moral Geography", "claims": ["", "Gay men\u2019s stories about homophobic violence will, at times, disguise reference to the persons who initiate harassment and injury.", "These stories emphasize the details of location or allow the victim of narrated violence to confirm the status of narrative hero.", "Each approach to story-telling has noticeable effects on the connections between sexual sameness and violence as displayed within the narrative.", "This paper examines these approaches to story-telling and their effects on homophobic formation.", "The paper traces the broader implications of these narrative styles within contemporary politics of gay visibility, assimilation, and whiteness."]}, {"metadata": {"year": 1996}, "authors": ["Debbie  Epstein"], "summary": "Since September 1991 I have been engaged in a research project in which we set out to explore the experiences of lesbian and gay students, teachers, and parents in relation to the English system of education.2 In the course of the project, we have interviewed or held group discussions with some 30 lesbians and gay men, as well as carrying out ethnographic work in four schools and in a lesbian and gay youth group.3 While the majority of our respondents have been white, we have also spoken with lesbians and gays of African and of South Asian descent.4 My own contribution to the field work for this project has been that of interviewing many of our lesbian and gay respondents and participant observation in one of the schools. Doing the research, I have been struck forcibly by the various forms of harassment experienced by our female respondents as well as by those men and boys who identified as and/or were perceived as gay or effeminate by their peers and/or teachers. During the same period, and partly because of the research findings, I have found myself reflecting on my own experiences of harassment and those of my students in both the recent and more distant past. This chapter is, in large part, the result of these reflections and of discussions I have had with students, colleagues, and friends about the issues involved.5", "title": "Keeping them in their Place: Hetero/sexist Harassment, Gender and the Enforcement of Heterosexuality", "claims": ["- Since September 1991, the author has been engaged in a research project exploring the experiences of lesbian and gay students, teachers, and parents in relation to the English system of education.", "- In the course of the project, the research team has interviewed or held group discussions with approximately 30 lesbians and gay men.", "- The research team has carried out ethnographic work in four schools and in a lesbian and gay youth group.", "- While the majority of respondents have been white, the research team has also spoken with lesbians and gays of African and South Asian descent.", "- The author's contribution to the fieldwork for this project has included interviewing many of the lesbian and gay respondents and conducting participant observation in one of the schools.", "- The author has been struck by the various forms of harassment experienced by female respondents and by men and boys who identified as or were perceived as gay or effeminate by their peers and/or teachers.", "- During the same period, and partly because of the research findings, the author has reflected on their own experiences of harassment and those of their students in both the recent and more distant past.", "- The chapter is largely the result of the author's reflections and discussions with students, colleagues, and friends about the issues involved."]}, {"metadata": {"year": 2018}, "authors": ["B. M. Dank", "R. Refinetti"], "summary": "\"Sexuality and Culture\" serves as a compelling forum for the analysis of ethical, cultural, psychological, social, and political issues related to sexual relationships and sexual behavior. These issues include, but are not limited to: sexual consent and sexual responsibility; sexual harassment and freedom of speech and association; sexual privacy; censorship and pornography; impact of film/literature on sexual relationships; and university and governmental regulation of intimate relationships. The central theme of this volume is the politics of sexuality. Theoretical essays, research reports, and book reviews examine the topics of sexual harassment law as a sexual control mechanism, censorship of sexual materials, and criminalization of commercialized sexuality. A special section focuses on the Clinton-Lewinsky affair with contributions by David Steinberg, John Furedy, and Joseph Fulda. Other articles include: \"Trends Towards Increased Sexual Repression in the Final Two Decades of the Twentieth Century\" by Elizabeth Allgeier; \"Naked but Unseen: Sex and labor conflict in San Francisco's Adult Entertainment Theaters\" by Kerwin Kay; \"A test of the Biopolitics Hypothesis\" by Kenneth Westhues; \"Scientific and Fictive Sociology: The Viability of Research\" by Edwina Taborsky and Reena Sommer; and \"Sex Entertainment for Women on the Web\" by Marjorie Kibby. Also included are reviews of books, including \"Faculty-Student Sexual Involvement: Issues and Interventions, \" by Virginia Stamler and Gerald Stone; \"Heterophobia: Sexual Harassment and the Future of Feminism,\" by Daphne Patai; \"Sex among Allies: Military Prostitution in US-Korea Relations, \"by Katharine H. Moon; and \"American Homo\" by Jeffrey Escoffier. \"The Politics of Sexuality\" will be of interest to general readers as well as to scholars (sociologists, psychologists, legal analysts), policymakers, and members of the sex work and sex entertainment communities.", "title": "The Politics of Sexuality", "claims": ["- \"Sexuality and Culture\" serves as a compelling forum for the analysis of ethical, cultural, psychological, social, and political issues related to sexual relationships and sexual behavior.", "- These issues include, but are not limited to: sexual consent and sexual responsibility; sexual harassment and freedom of speech and association; sexual privacy; censorship and pornography; impact of film/literature on sexual relationships; and university and governmental regulation of intimate relationships.", "- The central theme of this volume is the politics of sexuality.", "- Theoretical essays, research reports, and book reviews examine the topics of sexual harassment law as a sexual control mechanism, censorship of sexual materials, and criminalization of commercialized sexuality.", "- A special section focuses on the Clinton-Lewinsky affair with contributions by David Steinberg, John Furedy, and Joseph Fulda.", "- Other articles include: \"Trends Towards Increased Sexual Repression in the Final Two Decades of the Twentieth Century\" by Elizabeth Allgeier.", "- Other articles include: \"Naked but Unseen: Sex and labor conflict in San Francisco's Adult Entertainment Theaters\" by Kerwin Kay.", "- Other articles include: \"A test of the Biopolitics Hypothesis\" by Kenneth Westhues.", "- Other articles include: \"Scientific and Fictive Sociology: The Viability of Research\" by Edwina Taborsky and Reena Sommer.", "- Other articles include: \"Sex Entertainment for Women on the Web\" by Marjorie Kibby.", "- Also included are reviews of books, including \"Faculty-Student Sexual Involvement: Issues and Interventions,\" by Virginia Stamler and Gerald Stone.", "- Also included are reviews of books, including \"Heterophobia: Sexual Harassment and the Future of Feminism,\" by Daphne Patai.", "- Also included are reviews of books, including \"Sex among Allies: Military Prostitution in US-Korea Relations,\" by Katharine H. Moon.", "- Also included are reviews of books, including \"American Homo\" by Jeffrey Escoffier.", "- \"The Politics of Sexuality\" will be of interest to general readers as well as to scholars (sociologists, psychologists, legal analysts), policymakers, and members of the sex work and sex entertainment communities."]}, {"metadata": {"year": 2010}, "authors": ["Marielle Roy"], "summary": "The harassment of sexual minority students in school has recently become a topic of interest to researchers interested in issues of school safety. The Preventing School Harassment (PSH) survey, which specifically addresses harassment based on sexual orientation, is an important part of this line of inquiry. The present analysis is based on a free-response question included in the 2008 version of the PSH survey, which addressed students\u2019 experiences with the inclusion of sexual minority issues in the classroom. Students\u2019 responses were analyzed to identify the major themes in both the content and context of what students learned in school about these issues. Whereas one-quarter of respondents indicated they learned nothing about sexual minority issues in school, the majority of students who learned about these issues reported learning about ideals of acceptance and equality. Respondents reported learning about LGBTQ issues most often outside of the classroom, and most commonly from personal experiences or from members of student clubs. These results provide insight into how students learn about these issues in school, and may inform future research into methods of increasing students\u2019 feelings of safety at school. Exploring the role of LGBTQ issues 4 Introduction \u201cThere\u2019s nothing wrong with being LGBTQ, it's just the way you are. They're people and equal too... Although that also feels obvious.\u201d \u201cPeople are just uninformed about the GLBT community. I strongly believe that ignorance is the basis of unacceptance and that if people knew what we were and that we are normal, they would not be afraid of us, because that is what they are.\u201d \u2014Student respondents to the 2008 Preventing School Harassment survey As the quotes above demonstrate, today\u2019s high school students have strong opinions about discrimination against people who identify as lesbian, gay, bisexual, transgender, or queer/questioning (LGBTQ). However, the experiences of sexual minority students in schools have only very recently become a topic of research, through the use of both widespread surveys and smaller studies. The findings of the research on this issue are disheartening: harassment based on anti-LGBTQ bias is both intense and pervasive, and sexual minority students often feel unsafe in school (Kosciw, Diaz, & Greytak, 2008; O\u2019Shaughnessy, Russell, Heck, Calhoun, & Laub, 2004). One of the most significant findings of these studies is that anti-LGBTQ harassment is qualitatively different from other types of harassment. In particular, antiLGBTQ slurs are damaging both to sexual minority and heterosexual students. For example, male respondents to a survey of middleand high-schoolers have reported that homophobic slurs are significantly more threatening to a student\u2019s reputation than other types of slurs (Thurlow, 2001). Additionally, respondents in a study of 107 New Zealand high schools revealed pervasive anti-LGBTQ sentiment: only 5% of students and 8% of staff believed that LGBTQ students would feel safe at their school. Content analysis of the participants\u2019 responses revealed two main themes: descriptions of harassment Exploring the role of LGBTQ issues 5 (predominantly verbal) and perceived invisibility (for example, \u201cI don\u2019t know any lesbian/gay/bisexual students\u201d) (Nairn & Smith, 2003). The significance of homophobic slurs in sexual harassment is further highlighted in a study performed by the American Association of University Women (AAUW). Equal numbers (approximately 75%) of respondents to a national survey of American high school students reported that they would be \u201cvery upset\u201d if someone \u201cpulled off or down their clothing\u201d or called them gay or lesbian (American Association of University Women [AAUW] Educational Foundation, 2001). The fact that being called gay or lesbian is as upsetting as being the victim of physical sexual harassment is astounding. Additionally, this particular example of harassment (being called gay or lesbian) was the only example rated by both boys and girls to be of equal significance: 74% of boys and 73% of girls reported that they would be \u201cvery upset\u201d by such an incident (AAUW, 2001). Anti-LGBTQ harassment is both powerful and pervasive. The latest version of the National School Climate Survey (NSCS), distributed by the Gay, Lesbian and Straight Education Network (GLSEN), was released in 2007 and reached approximately 6200 sexual minority students across the United States. Of the survey respondents, 86.2% had been verbally harassed and nearly half (44%) physically harassed because of their sexual orientation. Nearly a third of respondents had missed school at least once because they had felt unsafe (Kosciw et al., 2008). In comparison, under 10% of respondents to the California Healthy Kids Survey (CHKS), a survey representative of all California high school students, reported ever missing school because they felt unsafe (California Safe and Healthy Kids Program Office, 2008). Exploring the role of LGBTQ issues 6 Repeated harassment based on sexual orientation affects students\u2019 mental health, performance in school, and future educational and social development. Eight percent of all respondents (both heterosexual and sexual minority students) to the 2001-2002 CHKS had been the victims of harassment based upon their \u201cactual or perceived sexual orientation.\u201d The students harassed on the basis of anti-LGBTQ bias were over twice as likely as non-harassed students to report depressive symptoms (55% compared to 23%), and three times as likely to have seriously considered suicide (45% compared to 14%). In addition, victims of this type of harassment were more likely than non-harassed students to report having engaged in substance abuse, including tobacco and marijuana use, binge drinking, and use of other illegal drugs (O\u2019Shaughnessy et al., 2004). Victims of anti-LGBTQ harassment report lower grades than non-harassed students: 24% of harassed students earned Cs or lower, compared to 17% of students who were not harassed (O\u2019Shaughnessy et al., 2004). Twelve percent of sexual minority students had no plans for future education beyond high school, nearly twice the percentage of the national student body (Kosciw et al., 2008). One might go so far as to say that students who experience these effects as a direct result of harassment at school are being denied an education. These are serious and complicated problems, but multiple studies have identified several key actions that schools can make that produce strong, pervasive improvements. These changes include adopting an anti-harassment policy that explicitly includes sexual minority students; active involvement of teachers in stopping acts of harassment; the presence of a Gay-Straight alliance on campus; and inclusion of LGBTQ-related issues in regular classroom curricula (O\u2019Shaughnessy et al., 2004). Exploring the role of LGBTQ issues 7 The first two actions are important in that they provide a direct and obvious signal to the student body that staff and administration are committed to preventing harassment on their campus. A school\u2019s responsibility to protect all students is included in district, state and national policies. Including sexual minorities in an anti-harassment policy does not increase a school\u2019s liability, but simply emphasizes its pre-existing responsibility to prevent harassment based on sexual orientation. Including sexual minority students in the anti-harassment policy is a first step towards ending harassment in a school: \u201cA comprehensive policy that is publicized and implemented will clarify for all staff that such behavior is unacceptable and must be responded to\u201d (GLSEN, 2002). Once such a policy is implemented, teachers must take an active role in changing their school climate by addressing slurs and other forms of harassment whenever they occur. Inclusive antiharassment policies provide incentive but not instruction, and so teachers should be trained in ways to address teasing, name-calling, and more serious forms of harassment. When teachers are prepared to handle situations of harassment, these situations can be used as \u201cteachable moments\u201d for the students involved. The formation of Gay-Straight Alliances (GSAs) as student-run clubs has also been related with improvements in school environment. The CHKS showed that 75% of students with a GSA on their campus reported feeling safe at school, compared to 61% of students without a GSA at their school. The presence of a GSA was also correlated with decreased anti-LGBTQ harassment and an increase in students\u2019 perceived support from both school staff and other adults (O\u2019Shaughnessy et al., 2004). Respondents to the NSCS reported similar effects: students at schools with GSAs heard fewer homophobic Exploring the role of LGBTQ issues 8 remarks, felt more a part of their school community, and reported acts of harassment to school administrators more often (Kosciw et al., 2008). These positive effects are most likely due to a combination of factors, rather than the simple fact of the club\u2019s formation. Gay-Straight Alliances may be more likely to form in schools that have already established more positive environments; indeed, the formation of GSAs is often a difficult process in schools with pervasive anti-LGBTQ bias. Opposition to GSAs can often be traced to a misunderstanding of their purpose. However, the Gay-Straight Alliance Network provides a description of the true goals of high school GSAs: \u201c[to] create safe environments in schools for students to support each other and learn about homophobia and other oppressions, educate the school community about homophobia, gender identity, and sexual orientation issues, and fight discrimination, harassment, and violence in schools\u201d (GSA Network). The positive effects of GSAs, as described above, are the strongest possible testament to these goals. Finally, schools that present LGBTQ issues as part of their curriculum evidence the greatest increase in the perc", "title": "Exploring the Role of LGBTQ Issues in the Classrooms of California Schools", "claims": ["- The harassment of sexual minority students in school has recently become a topic of interest to researchers interested in issues of school safety.", "- The Preventing School Harassment (PSH) survey specifically addresses harassment based on sexual orientation.", "- The present analysis is based on a free-response question included in the 2008 version of the PSH survey, which addressed students\u2019 experiences with the inclusion of sexual minority issues in the classroom.", "- One-quarter of respondents indicated they learned nothing about sexual minority issues in school.", "- The majority of students who learned about sexual minority issues reported learning about ideals of acceptance and equality.", "- Respondents reported learning about LGBTQ issues most often outside of the classroom, and most commonly from personal experiences or from members of student clubs.", "- Harassment based on anti-LGBTQ bias is both intense and pervasive, and sexual minority students often feel unsafe in school.", "- Anti-LGBTQ harassment is qualitatively different from other types of harassment.", "- Anti-LGBTQ slurs are damaging both to sexual minority and heterosexual students.", "- Male respondents to a survey of middle- and high-schoolers have reported that homophobic slurs are significantly more threatening to a student\u2019s reputation than other types of slurs.", "- Only 5% of students and 8% of staff in a study of 107 New Zealand high schools believed that LGBTQ students would feel safe at their school.", "- Content analysis of participants\u2019 responses revealed two main themes: descriptions of harassment (predominantly verbal) and perceived invisibility.", "- Equal numbers (approximately 75%) of respondents to a national survey of American high school students reported that they would be \u201cvery upset\u201d if someone \u201cpulled off or down their clothing\u201d or called them gay or lesbian.", "- Being called gay or lesbian is as upsetting as being the victim of physical sexual harassment.", "- This particular example of harassment (being called gay or lesbian) was the only example rated by both boys and girls to be of equal significance: 74% of boys and 73% of girls reported that they would be \u201cvery upset\u201d by such an incident.", "- Anti-LGBTQ harassment is both powerful and pervasive.", "- Of the survey respondents to the National School Climate Survey (NSCS), 86.2% had been verbally harassed and nearly half (44%) physically harassed because of their sexual orientation.", "- Nearly a third of respondents to the NSCS had missed school at least once because they had felt unsafe.", "- Under 10% of respondents to the California Healthy Kids Survey (CHKS) reported ever missing school because they felt unsafe.", "- Repeated harassment based on sexual orientation affects students\u2019 mental health, performance in school, and future educational and social development.", "- Eight percent of all respondents to the 2001-2002 CHKS had been the victims of harassment based upon their \u201cactual or perceived sexual orientation.\u201d", "- Students harassed on the basis of anti-LGBTQ bias were over twice as likely as non-harassed students to report depressive symptoms (55% compared to 23%).", "- Students harassed on the basis of anti-LGBTQ bias were three times as likely to have seriously considered suicide (45% compared to 14%).", "- Victims of anti-LGBTQ harassment were more likely than non-harassed students to report having engaged in substance abuse, including tobacco and marijuana use, binge drinking, and use of other illegal drugs.", "- Victims of anti-LGBTQ harassment report lower grades than non-harassed students: 24% of harassed students earned Cs or lower, compared to 17% of students who were not harassed.", "- Twelve percent of sexual minority students had no plans for future education beyond high school, nearly twice the percentage of the national student body.", "- Students who experience these effects as a direct result of harassment at school are being denied an education.", "- Multiple studies have identified several key actions that schools can make that produce strong, pervasive improvements.", "- These changes include adopting an anti-harassment policy that explicitly includes sexual minority students; active involvement of teachers in stopping acts of harassment; the presence of a Gay-Straight alliance on campus; and inclusion of LGBTQ-related issues in regular classroom curricula.", "- A school\u2019s responsibility to protect all students is included in district, state, and national policies.", "- Including sexual minorities in an anti-harassment policy does not increase a school\u2019s liability, but simply emphasizes its pre-existing responsibility to prevent harassment based on sexual orientation.", "- Including sexual minority students in the anti-harassment policy is a first step towards ending harassment in a school.", "- Teachers must take an active role in changing their school climate by addressing slurs and other forms of harassment whenever they occur.", "- Inclusive anti-harassment policies provide incentive but not instruction, and so teachers should be trained in ways to address teasing, name-calling, and more serious forms of harassment.", "- When teachers are prepared to handle situations of harassment, these situations can be used as \u201cteachable moments\u201d for the students involved.", "- The formation of Gay-Straight Alliances (GSAs) as student-run clubs has been related to improvements in school environment.", "- The CHKS showed that 75% of students with a GSA on their campus reported feeling safe at school, compared to 61% of students without a GSA at their school.", "- The presence of a GSA was correlated with decreased anti-LGBTQ harassment and an increase in students\u2019 perceived support from both school staff and other adults.", "- Respondents to the NSCS reported that students at schools with GSAs heard fewer homophobic remarks, felt more a part of their school community, and reported acts of harassment to school administrators more often.", "- Gay-Straight Alliances may be more likely to form in schools that have already established more positive environments.", "- The formation of GSAs is often a difficult process in schools with pervasive anti-LGBTQ bias.", "- Opposition to GSAs can often be traced to a misunderstanding of their purpose.", "- The Gay-Straight Alliance Network provides a description of the true goals of high school GSAs: \u201c[to] create safe environments in schools for students to support each other and learn about homophobia and other oppressions, educate the school community about homophobia, gender identity, and sexual orientation issues, and fight discrimination, harassment, and violence in schools.\u201d"]}, {"metadata": {"year": 2013}, "authors": ["Stephen Tomsen"], "summary": "This chapter examines research evidence to argue that violence directed at gay men, lesbians and transsexual/transgendered people are not wholly distinct from other forms of male-perpetrated violence. It insists that harassment and violence directed against sexual groups are highly gendered and everyday phenomena and narrow views of homophobic prejudice should be refined in order to appreciate this. Furthermore, these acts are widespread and collective social phenomena built on masculine understandings of a sexual mainstream and subordinate others.", "title": "Homophobic violence and masculinities in Australia", "claims": ["- Research evidence argues that violence directed at gay men, lesbians, and transsexual/transgendered people is not wholly distinct from other forms of male-perpetrated violence.", "- Harassment and violence directed against sexual groups are highly gendered and everyday phenomena.", "- Narrow views of homophobic prejudice should be refined to appreciate the gendered and everyday nature of harassment and violence against sexual groups.", "- Acts of violence and harassment against sexual groups are widespread and collective social phenomena.", "- These acts are built on masculine understandings of a sexual mainstream and subordinate others."]}, {"metadata": {"year": 2009}, "authors": ["Stephen  Tomsen", "Kevin  Markwell"], "summary": "Prejudice and violence directed against gay men, lesbians and other sexual groups have been viewed as ubiquitous and relatively fixed phenomena in contemporary societies. This perspective must be reconciled with the increased depiction of marginal sexualities and commercial \u2018queering\u2019 of mainstream media and popular culture. This paper presents and discusses data from two sources. Firstly, interviews conducted with self-identifying heterosexuals at the annual Sydney Gay and Lesbian Mardi Gras (SGLMG) parade suggest attendance and participation can occur through a widely enjoyed public display and the temporary suspension of sexual prejudice in such specific carnivalesque occasions. Secondly, gay and lesbian responses to an internet-based questionnaire concerning perceptions and experiences of safety and hostility at this and similar other public events, suggest an undercurrent of threat and incivility, especially in the post-event context. These data sources are not directly compared but analysed in a complementary way to throw new light on how different groups view and experience this event. Our findings reflect how sexual prejudice is a shifting and contradictory collective social practice.", "title": "Violence, Cultural Display and the Suspension of Sexual Prejudice", "claims": ["- Prejudice and violence directed against gay men, lesbians, and other sexual groups have been viewed as ubiquitous and relatively fixed phenomena in contemporary societies.", "- There is an increased depiction of marginal sexualities and commercial \u2018queering\u2019 of mainstream media and popular culture.", "- Interviews conducted with self-identifying heterosexuals at the annual Sydney Gay and Lesbian Mardi Gras (SGLMG) parade suggest that attendance and participation can occur through a widely enjoyed public display and the temporary suspension of sexual prejudice in such specific carnivalesque occasions.", "- Gay and lesbian responses to an internet-based questionnaire concerning perceptions and experiences of safety and hostility at the SGLMG and similar other public events suggest an undercurrent of threat and incivility, especially in the post-event context.", "- The data sources from interviews and questionnaires are not directly compared but are analyzed in a complementary way to provide new insights into how different groups view and experience the SGLMG event.", "- The findings reflect how sexual prejudice is a shifting and contradictory collective social practice."]}, {"metadata": {"year": 2002}, "authors": ["S. Fineran"], "summary": "This article provides a historical and legal framework for defining peer sexual harassment from three different perspectives: sex discrimination, mental health, and sexual violence. Major court decisions that define sexual harassment in both education and the workplace are highlighted, and arguments regarding sexual harassment between peers of the same sex are profiled. This research also identifies sexism and heterosexism as a major social violence problem in U.S. education and argues that peer sexual harassment is sexual violence with considerable mental health implications for both boys and girls. Recommendations for social work practice regarding peer sexual harassment in schools are discussed.", "title": "Sexual harassment between same-sex peers: intersection of mental health, homophobia, and sexual violence in schools.", "claims": ["", "The article provides a historical and legal framework for defining peer sexual harassment from three different perspectives: sex discrimination, mental health, and sexual violence.", "Major court decisions that define sexual harassment in both education and the workplace are highlighted.", "Arguments regarding sexual harassment between peers of the same sex are profiled.", "The research identifies sexism and heterosexism as a major social violence problem in U.S. education.", "The research argues that peer sexual harassment is sexual violence with considerable mental health implications for both boys and girls.", "Recommendations for social work practice regarding peer sexual harassment in schools are discussed."]}, {"metadata": {"year": 1990}, "authors": ["G. Herek"], "summary": "Hate crimes against lesbians and gay men occur within a broader cultural context that is permeated by heterosexism. Heterosexism is defined here as an ideological system that denies, denigrates, and stigmatizes any nonheterosexual form of behavior, identity, relationship, or community. It operates principally by rendering homosexuality invisible and, when this fails, by trivializing, repressing, or stigmatizing it. This article focuses upon the nexus between cultural heterosexism and individual prejudice against lesbians and gay men. Key components of the ideologies of sex and gender from which heterosexism derives are identified: (a) the personal-public dichotomy, (b) the stigmatization of particular forms of sexuality, and (c) the linkage of heterosexuality to gender-role conformity. Supported by these ideological underpinnings, cultural heterosexism fosters individual anti-gay attitudes by providing a ready-made system of values and stereotypical beliefs that justify such prejudice as \u201cnatural.\u201d By imbuing homosexuality with a variety of symbolic meanings, cultural heterosexism enables expressions of individual prejudice to serve various psychological functions. Further, by discouraging lesbians and gay men from coming out to others, heterosexism perpetuates itself. Recent social trends that may affect the ideology of heterosexism are identified, and their potential for reducing anti-gay prejudice is discussed.", "title": "The Context of Anti-Gay Violence", "claims": ["", "Hate crimes against lesbians and gay men occur within a broader cultural context that is permeated by heterosexism.", "Heterosexism is defined as an ideological system that denies, denigrates, and stigmatizes any nonheterosexual form of behavior, identity, relationship, or community.", "Heterosexism operates principally by rendering homosexuality invisible and, when this fails, by trivializing, repressing, or stigmatizing it.", "The article focuses on the nexus between cultural heterosexism and individual prejudice against lesbians and gay men.", "Key components of the ideologies of sex and gender from which heterosexism derives are identified as the personal-public dichotomy, the stigmatization of particular forms of sexuality, and the linkage of heterosexuality to gender-role conformity.", "Supported by these ideological underpinnings, cultural heterosexism fosters individual anti-gay attitudes by providing a ready-made system of values and stereotypical beliefs that justify such prejudice as \u201cnatural.\u201d", "By imbuing homosexuality with a variety of symbolic meanings, cultural heterosexism enables expressions of individual prejudice to serve various psychological functions.", "By discouraging lesbians and gay men from coming out to others, heterosexism perpetuates itself.", "Recent social trends that may affect the ideology of heterosexism are identified, and their potential for reducing anti-gay prejudice is discussed."]}], "query": "Give me references about gay culture and sexual harassment", "summary_abstract": null, "summary_extract": "The collection of claims provides a multifaceted view of the intersection between gay culture and sexual harassment. Marielle Roy (2010) highlights the pervasive and intense nature of anti-LGBTQ harassment in schools, noting its detrimental effects on students' mental health, academic performance, and future prospects. Roy emphasizes that anti-LGBTQ harassment is qualitatively different from other types of harassment and underscores the importance of inclusive anti-harassment policies and the presence of Gay-Straight Alliances in improving school environments.\n\nDebbie Epstein (1996) also addresses harassment, focusing on the experiences of lesbian and gay students and teachers within the English education system. Epstein notes the various forms of harassment faced by individuals perceived as gay or effeminate, reflecting on the broader implications of these experiences.\n\nStephen Tomsen (2013) and Tomsen and Kevin Markwell (2009) discuss the gendered and everyday nature of harassment and violence against sexual groups, suggesting that such acts are widespread social phenomena rooted in masculine understandings of a sexual mainstream. They argue for a nuanced understanding of homophobic prejudice, recognizing its shifting and contradictory nature.\n\nG. Herek (1990) provides a broader cultural context, describing how heterosexism, an ideological system that stigmatizes nonheterosexual behavior, underpins individual prejudice against lesbians and gay men. Herek argues that cultural heterosexism perpetuates itself by discouraging individuals from coming out and by providing a framework that justifies anti-gay attitudes.\n\nCollectively, these claims underscore the complex interplay between cultural ideologies, individual prejudices, and institutional practices in shaping the experiences of harassment faced by sexual minorities. They highlight the need for systemic changes in educational and social environments to address and mitigate the impact of such harassment."}, {"papers": [{"metadata": {"year": 2014}, "authors": ["Weidong Huang", "T. Bednarz"], "summary": "How we visualize graph data is important for us to make sense of it. A number of aesthetic criteria have been used in practice to guide the visualization process and judge the quality of graph drawings. These aesthetics are limited since they often conflict with each other. It is generally agreed that in order to make visualizations effective, well-grounded perception and cognitive theories and design principles are needed. Some attempts have been made to develop visualization theories. In this paper, we present a preliminary study which we conducted with a cognitive approach to add to this growing body of research. More specifically, we propose a graph visualization model, which is further conceptualized into a two-stage assessment cycle. Examples of potentially useful methodologies and theories are introduced and their implications for producing user-friendly visualizations are discussed.", "title": "Towards a Cognitive Approach to User-Centered Visualization Design and Evaluation", "claims": ["- How we visualize graph data is important for us to make sense of it.", "- A number of aesthetic criteria have been used in practice to guide the visualization process and judge the quality of graph drawings.", "- These aesthetics are limited since they often conflict with each other.", "- It is generally agreed that in order to make visualizations effective, well-grounded perception and cognitive theories and design principles are needed.", "- Some attempts have been made to develop visualization theories.", "- In this paper, we present a preliminary study which we conducted with a cognitive approach to add to this growing body of research.", "- More specifically, we propose a graph visualization model, which is further conceptualized into a two-stage assessment cycle.", "- Examples of potentially useful methodologies and theories are introduced and their implications for producing user-friendly visualizations are discussed."]}, {"metadata": {"year": 2007}, "authors": ["Michael  Workman"], "summary": "In knowledge-work, there are increasing amounts of complex information rendered by information technology, which has led to the common term, information overload. Information visualization is one area where empirically tested semantic theory has not yet caught up with that of the underlying information storage and retrieval theory, contributing to information overload. In spite of a vast body of cognitive theory, much of the human factors research on information visualization has overlooked it. Specifically, information displays have facilitated the data gathering (ontological) aspects of human problem-solving and decision-making, but have exacerbated the meaning-making (epistemological) aspects of those activities by presenting information in linear rather than in graphical (holistic) forms. Drawing from extant empirical research, we present a thesis suggesting that cognitive load may be reduced when holistic information is imbued with transformational grammar to help alleviate the information overload problem, along with a methodological approach for investigation.", "title": "Cognitive Load Research and Semantic Apprehension of Graphical Linguistics", "claims": ["- In knowledge-work, there are increasing amounts of complex information rendered by information technology, which has led to the common term, information overload.", "- Information visualization is one area where empirically tested semantic theory has not yet caught up with that of the underlying information storage and retrieval theory, contributing to information overload.", "- In spite of a vast body of cognitive theory, much of the human factors research on information visualization has overlooked it.", "- Information displays have facilitated the data gathering (ontological) aspects of human problem-solving and decision-making.", "- Information displays have exacerbated the meaning-making (epistemological) aspects of human problem-solving and decision-making by presenting information in linear rather than in graphical (holistic) forms.", "- Cognitive load may be reduced when holistic information is imbued with transformational grammar to help alleviate the information overload problem.", "- A methodological approach for investigation is presented, drawing from extant empirical research."]}, {"metadata": {"year": 2006}, "authors": ["Weidong Huang", "Seok-Hee Hong", "P. Eades"], "summary": "Performance and preference measures are commonly used in the assessment of visualization techniques. This is important and useful in understanding differences in effectiveness between different treatments. However, these measures do not answer how and why the differences are caused. And sometimes, performance measures alone may not be sensitive enough to detect differences. In this paper, we introduce a cognitive approach for visualization effectiveness and efficiency assessment. A model of user performance, mental effort and cognitive load (memory demand) is proposed and further mental effort and visualization efficiency measures are incorporated into our analysis. It is argued that 1) combining cognitive measures with traditional methods provides us new insights and practical guidance in visualization assessment. 2) analyzing human cognitive process not only helps to understand how viewers interact with visualizations, but also helps to predict user performance in initial stage. 3) keeping cognitive load induced by a visualization low allows more memory resources to be available for high level complex cognitive activities. A case study conducted supports our arguments.", "title": "Predicting graph reading performance: a cognitive approach", "claims": ["- Performance and preference measures are commonly used in the assessment of visualization techniques.", "- Performance and preference measures are important and useful in understanding differences in effectiveness between different treatments.", "- Performance and preference measures do not answer how and why the differences in effectiveness between different treatments are caused.", "- Sometimes, performance measures alone may not be sensitive enough to detect differences.", "- A cognitive approach for visualization effectiveness and efficiency assessment is introduced in this paper.", "- A model of user performance, mental effort, and cognitive load (memory demand) is proposed.", "- Mental effort and visualization efficiency measures are incorporated into the analysis.", "- Combining cognitive measures with traditional methods provides new insights and practical guidance in visualization assessment.", "- Analyzing the human cognitive process helps to understand how viewers interact with visualizations.", "- Analyzing the human cognitive process helps to predict user performance in the initial stage.", "- Keeping cognitive load induced by a visualization low allows more memory resources to be available for high-level complex cognitive activities.", "- A case study conducted supports the arguments presented in the paper."]}, {"metadata": {"year": 2011}, "authors": ["M. Hoffmann", "F. Paglieri"], "summary": "External representations play a crucial role in learning. At the same time, cognitive load theory suggests that the possibility of learning depends on limited resources of the working memory and on cognitive load imposed by instructional design and representation tools. Both these observations motivate a critical look at Computer-Supported Argument Visualization (CSAV) tools that are supposed to facilitate learning. This paper uses cognitive load theory to compare the cognitive efficacy of Rationale TM 2 and AGORA.", "title": "Cognitive effects of argument visualization tools", "claims": ["- External representations play a crucial role in learning.", "- Cognitive load theory suggests that the possibility of learning depends on limited resources of the working memory.", "- Cognitive load theory suggests that the possibility of learning depends on cognitive load imposed by instructional design and representation tools.", "- Both the role of external representations and cognitive load theory observations motivate a critical look at Computer-Supported Argument Visualization (CSAV) tools that are supposed to facilitate learning.", "- This paper uses cognitive load theory to compare the cognitive efficacy of Rationale TM 2 and AGORA."]}, {"metadata": {"year": 2013}, "authors": ["Muhammed Yousoof Mohd Sapiyan"], "summary": "Computer programming is a complex skill to acquire for novice learners who are in their initial phase of learning programming. There are many factors that results in difficulties in learning programming. This paper addresses to resolve one core difficulty which is cognitive load [2] [3].Cognitive load theory [13] is a famous theory of learning. It states that the schema of the long term memory is not well built in the case of novices and also there is a limitation of working memory\u2019s capacity. This makes it hard for novices to understand the concepts and equip with the skills necessary to become programmers. Some efforts used to overcome the cognitive load are the visualization tools for learning programming [14] .There is no accountability on how effective these visualization systems helped in reducing the load. The mechanism to measure cognitive load is not used in the visualization systems. There are two methods of cognitive load measurement namely physiological and non physiological measures. Physiological measures include EKG,GSR[12],EEG[11],Temperature[11] etc. and non physiological measures includes rating scale[6] and recent research studies have used EEG as a index for cognitive load measurement [7].We felt that using the physiological measures could be accurate as they are the reflections of the body impulses. There is no user\u2019s control over the measurement. We also found out that among the physiological measures EEG could be more effective as the latest efforts of measuring the cognitive uses EEG. This paper addresses the cognitive load measurement while using visualization tools by the novice programmers using EEG as an index of cognitive load.", "title": "COGNITIVE LOAD MEASUREMENT FOR VISUALIZATIONS IN LEARNING COMPUTER PROGRAMMING USING EEG (ELECTROENCELOGRAPHY)", "claims": ["- Computer programming is a complex skill to acquire for novice learners who are in their initial phase of learning programming.", "- There are many factors that result in difficulties in learning programming.", "- This paper addresses to resolve one core difficulty which is cognitive load.", "- Cognitive load theory is a famous theory of learning.", "- Cognitive load theory states that the schema of the long-term memory is not well built in the case of novices and also there is a limitation of working memory\u2019s capacity.", "- The limitation of working memory\u2019s capacity makes it hard for novices to understand the concepts and equip with the skills necessary to become programmers.", "- Some efforts used to overcome the cognitive load are the visualization tools for learning programming.", "- There is no accountability on how effective these visualization systems helped in reducing the load.", "- The mechanism to measure cognitive load is not used in the visualization systems.", "- There are two methods of cognitive load measurement namely physiological and non-physiological measures.", "- Physiological measures include EKG, GSR, EEG, Temperature, etc.", "- Non-physiological measures include rating scale.", "- Recent research studies have used EEG as an index for cognitive load measurement.", "- Using the physiological measures could be accurate as they are the reflections of the body impulses.", "- There is no user\u2019s control over the measurement when using physiological measures.", "- Among the physiological measures, EEG could be more effective as the latest efforts of measuring the cognitive load use EEG.", "- This paper addresses the cognitive load measurement while using visualization tools by the novice programmers using EEG as an index of cognitive load."]}, {"metadata": {"year": 2009}, "authors": ["Weidong  Huang", "Peter  Eades", "Seok-Hee  Hong"], "summary": "Graph visualizations are typically evaluated by comparing their differences in effectiveness, measured by task performance such as response time and accuracy. Such performance-based measures have proved to be useful in their own right. There are some situations, however, where the performance measures alone may not be sensitive enough to detect differences. This limitation can be seen from the fact that the graph viewer may achieve the same level of performance by devoting different amounts of cognitive effort. In addition, it is not often that individual performance measures are consistently in favor of a particular visualization. This makes design and evaluation difficult in choosing one visualization over another. In an attempt to overcome the above-mentioned limitations, we measure the effectiveness of graph visualizations from a cognitive load perspective. Human memory as an information processing system and recent results from cognitive load research are reviewed first. The construct of cognitive load in the context of graph visualization is proposed and discussed. A model of user task performance, mental effort and cognitive load is proposed thereafter to further reveal the interacting relations between these three concepts. A cognitive load measure called mental effort is introduced and this measure is further combined with traditional performance measures into a single multi-dimensional measure called visualization efficiency. The proposed model and measurements are tested in a user study for validity. Implications of the cognitive load considerations in graph visualization are discussed.", "title": "Measuring Effectiveness of Graph Visualizations: A Cognitive Load Perspective", "claims": ["- Graph visualizations are typically evaluated by comparing their differences in effectiveness, measured by task performance such as response time and accuracy.", "- Performance-based measures have proved to be useful in their own right.", "- There are some situations where performance measures alone may not be sensitive enough to detect differences.", "- The limitation of performance measures can be seen from the fact that the graph viewer may achieve the same level of performance by devoting different amounts of cognitive effort.", "- It is not often that individual performance measures are consistently in favor of a particular visualization.", "- The inconsistency in performance measures makes design and evaluation difficult in choosing one visualization over another.", "- The effectiveness of graph visualizations is measured from a cognitive load perspective to overcome the limitations of performance measures.", "- Human memory as an information processing system and recent results from cognitive load research are reviewed.", "- The construct of cognitive load in the context of graph visualization is proposed and discussed.", "- A model of user task performance, mental effort, and cognitive load is proposed to reveal the interacting relations between these three concepts.", "- A cognitive load measure called mental effort is introduced.", "- The mental effort measure is combined with traditional performance measures into a single multi-dimensional measure called visualization efficiency.", "- The proposed model and measurements are tested in a user study for validity.", "- Implications of the cognitive load considerations in graph visualization are discussed."]}, {"metadata": {"year": 2017}, "authors": ["Ricarda Moses", "S. Humayoun", "Ragaad Altarawneh", "A. Ebert"], "summary": "Understanding cognitive processes during the interaction with visualizations, speci\ufb01cally limitations of working memory, opens a new perspective on evaluations and encourages a more user-centric design approach. In a user study we evaluated two graph data visualization approaches (i.e., the force-directed layout and the Chord layout) using a cognitive load questionnaire to assess the three load types: intrinsic, extraneous, and germane load. Tasks were designed to encourage insight and sensemaking in the participants during the evaluation. This type of evaluation helps to assess the users\u2019 mental processes during sensemaking and graph reading in the underlying layouts. Further, such study \ufb01ndings would help visualization designers in choosing the appropriate layout type for their graph data.", "title": "Evaluating Cognitive Load: Force-directed Layout vs. Chord Layout", "claims": ["- Understanding cognitive processes during the interaction with visualizations, specifically limitations of working memory, opens a new perspective on evaluations and encourages a more user-centric design approach.", "- In a user study, two graph data visualization approaches (i.e., the force-directed layout and the Chord layout) were evaluated using a cognitive load questionnaire.", "- The cognitive load questionnaire was used to assess the three load types: intrinsic, extraneous, and germane load.", "- Tasks were designed to encourage insight and sensemaking in the participants during the evaluation.", "- This type of evaluation helps to assess the users\u2019 mental processes during sensemaking and graph reading in the underlying layouts.", "- Such study findings would help visualization designers in choosing the appropriate layout type for their graph data."]}, {"metadata": {"year": 2019}, "authors": ["Juan C. Castro-Alonso", "Paul  Ayres", "John  Sweller"], "summary": "There are basically two formats used in instructional visualizations, namely, static pictures and dynamic visualizations (e.g., animations and videos). Both can be engaging and fun for university students in the fields of health and natural sciences. However, engagement by itself is not always conducive to learning. Consequently, teachers, lecturers, and instructional designers need to utilize the cognitive processing advantages of visualizations as well as engagement to achieve full instructional effectiveness. A cognitive processing focus has outlined many ways in which instructional visualization can be optimized. Specifically, cognitive load theory and the cognitive theory of multimedia learning are two research paradigms that provide several methods for directing the design of visualizations by considering how learners process visuospatial information. In this chapter, we describe five methods based on these cognitive theories: (a) the split attention effect and spatial contiguity principle, (b) the modality effect, (c) the redundancy effect and coherence principle, (d) the signaling principle, and (e) the transient information effect. For each of these effects, examples of applications for education in health and natural sciences are provided, where the influence of visuospatial processing is also considered. We end this chapter by discussing instructional implications for science education and providing future directions for research.", "title": "Instructional Visualizations, Cognitive Load Theory, and Visuospatial Processing", "claims": ["", "There are basically two formats used in instructional visualizations, namely, static pictures and dynamic visualizations (e.g., animations and videos).", "Both static pictures and dynamic visualizations can be engaging and fun for university students in the fields of health and natural sciences.", "Engagement by itself is not always conducive to learning.", "Teachers, lecturers, and instructional designers need to utilize the cognitive processing advantages of visualizations as well as engagement to achieve full instructional effectiveness.", "A cognitive processing focus has outlined many ways in which instructional visualization can be optimized.", "Cognitive load theory and the cognitive theory of multimedia learning are two research paradigms that provide several methods for directing the design of visualizations by considering how learners process visuospatial information.", "Five methods based on cognitive load theory and the cognitive theory of multimedia learning are described: (a) the split attention effect and spatial contiguity principle, (b) the modality effect, (c) the redundancy effect and coherence principle, (d) the signaling principle, and (e) the transient information effect.", "Examples of applications for education in health and natural sciences are provided for each of these effects, where the influence of visuospatial processing is also considered.", "The chapter ends by discussing instructional implications for science education and providing future directions for research."]}], "query": "Cognitive Load Theory toward visualization", "summary_abstract": null, "summary_extract": "The collection of claims provides a comprehensive exploration of how Cognitive Load Theory (CLT) can be applied to visualization, emphasizing the importance of cognitive considerations in designing effective visualizations. Huang and Bednarz (2014) highlight the necessity of integrating well-grounded perception and cognitive theories into visualization design to enhance effectiveness. They propose a graph visualization model conceptualized into a two-stage assessment cycle, suggesting that cognitive approaches can significantly contribute to user-friendly visualizations.\n\nWorkman (2007) discusses the challenges of information overload in knowledge work, noting that cognitive load can be reduced by presenting information holistically rather than linearly. This aligns with the idea that visualization should facilitate meaning-making, a key aspect of cognitive processing.\n\nHuang, Hong, and Eades (2006) introduce a cognitive approach to assess visualization effectiveness, proposing a model that incorporates user performance, mental effort, and cognitive load. They argue that keeping cognitive load low allows more memory resources for complex cognitive activities, thus enhancing visualization efficiency.\n\nHoffmann and Paglieri (2011) emphasize the role of external representations in learning, suggesting that cognitive load theory can inform the design of Computer-Supported Argument Visualization tools to facilitate learning by managing cognitive load.\n\nMoses et al. (2017) explore cognitive processes during interaction with visualizations, using a cognitive load questionnaire to evaluate different graph layouts. Their findings suggest that understanding cognitive load types can guide the selection of appropriate visualization layouts, enhancing user sensemaking and insight.\n\nCastro-Alonso, Ayres, and Sweller (2019) discuss the application of cognitive load theory and multimedia learning theory in instructional visualizations. They outline methods such as the split attention effect and signaling principle, which can optimize visuospatial processing and instructional effectiveness.\n\nOverall, these claims collectively underscore the critical role of cognitive load considerations in visualization design, advocating for a user-centric approach that leverages cognitive theories to improve visualization effectiveness and learning outcomes."}, {"papers": [{"metadata": {"year": 2018}, "authors": ["Mingfong Jan", "Wan-Lin Yang"], "summary": "There is a need to reframe teachers' roles from content area experts to that of learning experience designers because of 21st century teaching challenges. As learning experience designers, teachers help students develop 21st century competencies via guided cognitive and social participation in designed learning activities such as games and gamified activities. In this qualitative case study, we explore teachers' design thinking in designing a lesson plan that involves the use of a card game designed for complex system understanding. Six teachers' thoughts about learning activity design are unpacked via the following activities: playing a card game, crafting a game-based lesson plan, and reporting their design thinking via semi-structural interviews. We discuss similarities in the teachers' views on game-based learning and the structure of their designed lessons, as well as implications of the study. This baseline study helps us map out how teachers think about learning experience design. Such understanding is critical for developing teachers as designers.", "title": "Understanding Teachers' Design Thinking in Designing Game-Based Activities", "claims": ["- There is a need to reframe teachers' roles from content area experts to that of learning experience designers because of 21st century teaching challenges.", "- As learning experience designers, teachers help students develop 21st century competencies via guided cognitive and social participation in designed learning activities such as games and gamified activities.", "- In this qualitative case study, we explore teachers' design thinking in designing a lesson plan that involves the use of a card game designed for complex system understanding.", "- Six teachers' thoughts about learning activity design are unpacked via the following activities: playing a card game, crafting a game-based lesson plan, and reporting their design thinking via semi-structural interviews.", "- We discuss similarities in the teachers' views on game-based learning and the structure of their designed lessons, as well as implications of the study.", "- This baseline study helps us map out how teachers think about learning experience design.", "- Such understanding is critical for developing teachers as designers."]}, {"metadata": {"year": 2013}, "authors": ["Cesar C. Navarrete"], "summary": "In a case study on middle-school student educational game creation course in south central US state, the students' creative thinking process is investigated in order to understand perceptions of the digital design and programming involved in the game creation learning approach. Interviewing 12 students at with three different levels of game design experience, students in grade 6, 7 and 8, with 1, 2, and 3 years of game design experience respectively, findings suggest that students enjoyed the learning approach as satisfying and engaging, yet technologically challenging. The students experienced positive opportunities for engaging the creative thinking process in synthesizing social issue information for constructing their understanding through the creation of interactive, educational digital games. Findings suggest that the creative thinking process in student-centered game creation learning approach may provide learners a rich and enjoyable learning experience with the authentic technology use as well as provide for deep, insightful learning.", "title": "Creative thinking in digital game design and development: A case study", "claims": ["- In a case study on a middle-school student educational game creation course in a south central US state, the students' creative thinking process is investigated to understand perceptions of the digital design and programming involved in the game creation learning approach.", "- The study involved interviewing 12 students with three different levels of game design experience, specifically students in grades 6, 7, and 8, with 1, 2, and 3 years of game design experience respectively.", "- Findings suggest that students enjoyed the learning approach as satisfying and engaging, yet technologically challenging.", "- The students experienced positive opportunities for engaging the creative thinking process in synthesizing social issue information for constructing their understanding through the creation of interactive, educational digital games.", "- Findings suggest that the creative thinking process in a student-centered game creation learning approach may provide learners a rich and enjoyable learning experience with authentic technology use.", "- The creative thinking process in a student-centered game creation learning approach may provide for deep, insightful learning."]}, {"metadata": {"year": 2012}, "authors": ["Qing Li", "Shahista Nathoo", "Elise Vandermeiden", "Collette Lemieux"], "summary": "\"This research intends to explore practicing teachers\u00e2\u20ac\u2122 experiences with game design and development. Specifical-ly, the study is guided by the following research questions: 1. What design considerations were taken into account during the game design process of practicing teach-ers? 2. What pedagogical components (if any) emerge when practicing teachers design and build digital games? Employing a naturalistic and qualitative approach, data are collected from 32 graduate students who partici-pated in the study. The analysis of the games created by these practicing teachers indicates some key themes: (A) curriculum goals were predominantly the games\u00e2\u20ac\u2122 objec-tives; (B) sounds and animations provided visual appeal and feedback; (C) the game could be or needed to be used with supporting materials within the class; (D) the need to create a sense of accomplishment for the gamer; and (F) the emphasis of the gamer being able to project or custom-ize his/her identity within the game. Further discussion is also provided.\"", "title": "Practicing Teachers as Digital Game Creators: A Study of the Design Considerations", "claims": ["", "This research intends to explore practicing teachers' experiences with game design and development.", "The study is guided by the research question: What design considerations were taken into account during the game design process of practicing teachers?", "The study is guided by the research question: What pedagogical components (if any) emerge when practicing teachers design and build digital games?", "Data are collected from 32 graduate students who participated in the study.", "The analysis of the games created by these practicing teachers indicates that curriculum goals were predominantly the games' objectives.", "The analysis of the games created by these practicing teachers indicates that sounds and animations provided visual appeal and feedback.", "The analysis of the games created by these practicing teachers indicates that the game could be or needed to be used with supporting materials within the class.", "The analysis of the games created by these practicing teachers indicates the need to create a sense of accomplishment for the gamer.", "The analysis of the games created by these practicing teachers indicates the emphasis of the gamer being able to project or customize his/her identity within the game."]}, {"metadata": {"year": 2018}, "authors": ["Ana C. R. Martins", "Lia Raquel Moreira Oliveira"], "summary": "The design of educational games is a powerful pedagogical strategy that can only enter schools if teachers are given the necessary training and support. In this paper we present a training action course for teachers interested in learning how to use simple frameworks and tools to be able to either design educational games themselves or facilitate educational game design by their students. We propose a syllabus, a design framework, and a software solution for digital game creation. This approach has been used in Portugal with middle school teachers and students and has been shown to be effective, resulting in the production of functional educational games (digital and non-digital), with preliminary results showing positive outcomes in learning and engagement.", "title": "Students as creators of educational games: learning to use simple frameworks and tools to empower students as educational game designers", "claims": ["", "The design of educational games is a powerful pedagogical strategy.", "Educational games can only enter schools if teachers are given the necessary training and support.", "A training action course is presented for teachers interested in learning how to use simple frameworks and tools to design educational games or facilitate educational game design by their students.", "A syllabus, a design framework, and a software solution for digital game creation are proposed.", "The approach has been used in Portugal with middle school teachers and students.", "The approach has been shown to be effective, resulting in the production of functional educational games (digital and non-digital).", "Preliminary results show positive outcomes in learning and engagement."]}, {"metadata": {"year": 2015}, "authors": ["Fr\u00e9d\u00e9rique  Frossard", "Anna  Trifonova", "Mario  Barajas"], "summary": "Abstract Creativity has become a key educational objective. How can game-based learning enhance creative pedagogies? This chapter proposes an approach in which teachers become game designers. It provides a model which analyzes creativity according to three dimensions: process, product, and teaching. We describe practical experiences in which teachers designed and applied their own learning games. Results highlight that game design promotes teaching practices that foster students\u2019 creativity.", "title": "Teachers Designing Learning Games", "claims": ["- Creativity has become a key educational objective.", "- Game-based learning can enhance creative pedagogies.", "- This chapter proposes an approach in which teachers become game designers.", "- The chapter provides a model which analyzes creativity according to three dimensions: process, product, and teaching.", "- The chapter describes practical experiences in which teachers designed and applied their own learning games.", "- Results highlight that game design promotes teaching practices that foster students\u2019 creativity."]}, {"metadata": {"year": 2008}, "authors": ["Zhen Zhigao"], "summary": "With the development of electronic game industry,more and more people have focused on how to apply the new technology into the field of education,on the purpose of developing educational games with unique educational goals,content or method.Games-to-Teach Project is a partnership between MIT and Microsoft to develop conceptual prototypes for the next generation of interactive educational entertainment.The members of this project involve instructors,researchers and students from different subjects or fields.As main practical results,fifteen conceptual prototypes focus on college-level science,engineering,social science,and humanities education,which will make a significant milestone.The paper introduces the research objectives firstly,and then places importance on the fifteen conceptual prototypes which is the main practical results.During the description,an example is provided to introdue the design progress.Besides,the main conclusions of this proiect is summaried.According to the introduction above,the authors propose five suggestions for us to design and develop educational digital games.The educational digital games have broad prospects for instruction.The integration of games and course content can be achieved through a variety of ways.The design of educational digital games is necessary to be supported with teaching and learning theory.The design of educational digital games is better to be instructional targeted.", "title": "Introduction and Enlightenment on the Games-to-Teach Project", "claims": ["- With the development of the electronic game industry, more and more people have focused on how to apply new technology into the field of education, on the purpose of developing educational games with unique educational goals, content, or method.", "- Games-to-Teach Project is a partnership between MIT and Microsoft to develop conceptual prototypes for the next generation of interactive educational entertainment.", "- The members of the Games-to-Teach Project involve instructors, researchers, and students from different subjects or fields.", "- As main practical results, fifteen conceptual prototypes focus on college-level science, engineering, social science, and humanities education, which will make a significant milestone.", "- The paper introduces the research objectives firstly, and then places importance on the fifteen conceptual prototypes which are the main practical results.", "- During the description, an example is provided to introduce the design progress.", "- The main conclusions of the Games-to-Teach Project are summarized.", "- According to the introduction above, the authors propose five suggestions for us to design and develop educational digital games.", "- The educational digital games have broad prospects for instruction.", "- The integration of games and course content can be achieved through a variety of ways.", "- The design of educational digital games is necessary to be supported with teaching and learning theory.", "- The design of educational digital games is better to be instructional targeted."]}, {"metadata": {"year": 2013}, "authors": ["R. Sandford"], "summary": "Summary form only given. Researchers have offered, in recent years, compelling reasons for considering the potential of digital games to support learning (Klopfer et al., 2009; Pelletier, 2009; Mitchell & Savill-Smith, 2004; Gee, 2008), and in response policymakers and educators around the world have demonstrated a commitment to exploring their practical use in school (Ulicsak, 2010; Koh et al. 2009). There remain, however, many questions about how games can best support learning, particularly in formal education. For teachers, the use of games in a formal curriculum setting can present practical and operational issues, as well as surfacing more fundamental tensions: between generational expectations of games and technology, between home and school identities, and between pedagogies associated with accounts of games as learning tools and those more commonly embraced within the context of formal schooling (Sandford et al., 2011; Felicia, 2009; Ito\u0305 et al., 2009; Sandford et al. 2006). In managing these tensions, teachers are increasingly asked to construct themselves as `designers' (Towndrow, 2005; Foo, et al., 2006; Carlgren, 1999), mobilising their professional knowledge in the creation of new strategies and practices that enable them to negotiate these practical and pedagogical challenges. This paper examines the implications of formal game-based learning for teachers developing their own digital learning games, exploring two guiding overarching research questions. What strategies are employed by teachers to manage intergenerational, technological, operational and pedagogic tensions in the classroom? And to what extent is the notion of being a `designer' visible in their professional practice? The paper suggests that there are multiple ways of `being a designer' for teachers, and that the notion of `designer' may be a more problematic representation of teacher agency and identity than currently visible in the literature.", "title": "Teachers as game designers: Using a game in formal learning in a Singapore primary school", "claims": ["- Researchers have offered compelling reasons for considering the potential of digital games to support learning in recent years.", "- Policymakers and educators around the world have demonstrated a commitment to exploring the practical use of digital games in school.", "- There remain many questions about how games can best support learning, particularly in formal education.", "- The use of games in a formal curriculum setting can present practical and operational issues for teachers.", "- The use of games in a formal curriculum setting can surface more fundamental tensions between generational expectations of games and technology.", "- The use of games in a formal curriculum setting can surface more fundamental tensions between home and school identities.", "- The use of games in a formal curriculum setting can surface more fundamental tensions between pedagogies associated with accounts of games as learning tools and those more commonly embraced within the context of formal schooling.", "- Teachers are increasingly asked to construct themselves as 'designers' in managing these tensions.", "- Teachers are mobilising their professional knowledge in the creation of new strategies and practices to negotiate practical and pedagogical challenges.", "- The paper examines the implications of formal game-based learning for teachers developing their own digital learning games.", "- The paper explores two guiding overarching research questions: What strategies are employed by teachers to manage intergenerational, technological, operational, and pedagogic tensions in the classroom? And to what extent is the notion of being a 'designer' visible in their professional practice?", "- The paper suggests that there are multiple ways of 'being a designer' for teachers.", "- The paper suggests that the notion of 'designer' may be a more problematic representation of teacher agency and identity than currently visible in the literature."]}, {"metadata": {"year": 2018}, "authors": ["M. Cezarotto", "A. Battaiola", "Virg\u00ednia Kistmann"], "summary": "Digital educational games have been widely used in educational practices. These games are considered as valuable artefacts that can be used to teach a broad range of subjects to different kinds of learners, thus performing a significant role in the internalisation of contents. A large number of companies, both national and international, develop this kind of media. However, the design of educational games is a complex task, encompassing multiple knowledge and several different stages of development. Companies must excel in order to succeed in this highly competitive market. Studies that focus on the connection between design management and game development are still unsatisfactory. With this in mind, this paper aims to contribute to this debate and to the digital educational game industry, by proposing the use of knowledge from design management as a way of improving strategic planning. From a design management perspective, this paper aims to identify ways to promote innovation during the development process of educational games. In order to do so, this study considers the process of development of games and the communication between the academic field and the industry. This research\u2019s approach is exploratory and qualitative, and this study makes use of a literature review and a case study. This paper offers a set of contributions focusing on innovation for developing digital educational games based on strategic design. Therefore, it provides useful information regarding the relevance of the use of design management by educational game companies. Moreover, this study provides a set of actions to improve strategic planning in these companies through a design management perspective.", "title": "The design of educational games and innovation : a case study based on design management", "claims": ["- Digital educational games have been widely used in educational practices.", "- These games are considered as valuable artefacts that can be used to teach a broad range of subjects to different kinds of learners.", "- Digital educational games perform a significant role in the internalisation of contents.", "- A large number of companies, both national and international, develop digital educational games.", "- The design of educational games is a complex task, encompassing multiple knowledge and several different stages of development.", "- Companies must excel in order to succeed in the highly competitive market of digital educational games.", "- Studies that focus on the connection between design management and game development are still unsatisfactory.", "- The paper aims to contribute to the debate on the connection between design management and game development and to the digital educational game industry.", "- The paper proposes the use of knowledge from design management as a way of improving strategic planning in the digital educational game industry.", "- From a design management perspective, the paper aims to identify ways to promote innovation during the development process of educational games.", "- The study considers the process of development of games and the communication between the academic field and the industry.", "- The research\u2019s approach is exploratory and qualitative.", "- The study makes use of a literature review and a case study.", "- The paper offers a set of contributions focusing on innovation for developing digital educational games based on strategic design.", "- The paper provides useful information regarding the relevance of the use of design management by educational game companies.", "- The study provides a set of actions to improve strategic planning in educational game companies through a design management perspective."]}], "query": "what is design thinking in teachers developing digital educational games?", "summary_abstract": null, "summary_extract": "Design thinking in the context of teachers developing digital educational games is a multifaceted process that involves reimagining the role of teachers as designers of learning experiences. According to Jan and Yang (2018), teachers are encouraged to transition from being mere content experts to becoming designers who facilitate students' acquisition of 21st-century skills through interactive and gamified learning activities. This shift is crucial for addressing modern educational challenges and enhancing students' cognitive and social engagement.\n\nFrossard, Trifonova, and Barajas (2015) emphasize that when teachers take on the role of game designers, they can foster creative pedagogies that enhance students' creativity. This approach not only enriches the learning experience but also aligns with the broader educational objective of nurturing creativity.\n\nSandford (2013) further explores the implications of this design-oriented approach, highlighting that teachers are increasingly required to navigate various tensions\u2014technological, pedagogical, and generational\u2014by adopting a designer's mindset. This involves creating new strategies and practices to effectively integrate games into formal education settings.\n\nMartins and Oliveira (2018) support the notion that educational games are a powerful pedagogical tool, but they stress the importance of providing teachers with the necessary training and support to design or facilitate the creation of these games. Their work demonstrates the effectiveness of such training in producing functional educational games and improving learning outcomes.\n\nCollectively, these claims underscore the transformative potential of design thinking in empowering teachers to create engaging and educational digital games, thereby enhancing the learning experience and equipping students with essential skills for the future."}, {"papers": [{"metadata": {"year": 2021}, "authors": ["N. Anh"], "summary": "Japan is the world's 3rd largest economy with a nominal GDP of USD 5380 billion. Japan's economy has a rapid industrial development process after its defeat in World War II. Vietnam's economy in 2020 will achieve GDP growth of 2.9%, nominal GDP of 300 billion dollars, per capita income reached $2786, if calculated according to purchasing power parity (PPP), the average income of Vietnamese people is about $ 8,500. In 2020, Vietnam has a trade surplus of 19.1 billion USD (an important contribution to this result is the total two-way turnover of 39.6 billion USD, a trade deficit of 1.1 billion USD from Japan. No small contribution to the economic success of Vietnam as a strategic partner of Japan - the third largest economy in the world. Japan is the first country in the G7 group to recognize Vietnam as a market economy and partner, the largest ODA sponsor for Vietnam, the number 1 investor in Vietnam and the 3rd largest trading partner of Vietnam. This paper also refers the lessons learned for Vietnam.", "title": "Experience in Supporting Industry Development in Japan and Lessons for Viet Nam", "claims": ["- Japan is the world's 3rd largest economy with a nominal GDP of USD 5380 billion.", "- Japan's economy has a rapid industrial development process after its defeat in World War II.", "- Vietnam's economy in 2020 will achieve GDP growth of 2.9%.", "- Vietnam's nominal GDP in 2020 is 300 billion dollars.", "- Vietnam's per capita income in 2020 reached $2786.", "- If calculated according to purchasing power parity (PPP), the average income of Vietnamese people in 2020 is about $8,500.", "- In 2020, Vietnam has a trade surplus of 19.1 billion USD.", "- An important contribution to Vietnam's trade surplus in 2020 is the total two-way turnover of 39.6 billion USD.", "- In 2020, Vietnam has a trade deficit of 1.1 billion USD from Japan.", "- Japan is a strategic partner of Vietnam, contributing to its economic success.", "- Japan is the first country in the G7 group to recognize Vietnam as a market economy and partner.", "- Japan is the largest ODA sponsor for Vietnam.", "- Japan is the number 1 investor in Vietnam.", "- Japan is the 3rd largest trading partner of Vietnam."]}, {"metadata": {"year": 2013}, "authors": [], "summary": "Vietnam is an emerging country that over the last twenty years has experienced a high GDP growth rate, although in recent years it has not been saved from the effects of the global economic crisis. Since the introduction of the Doi Moi policy (the Renovation) in 1986, Vietnam aims at transforming the structure of its economy. From a purely centralized and state-controlled economy heavily dependent on agriculture, Vietnam aims to evolve into a socialist-oriented market economy structured towards a more balanced equilibrium between manufacturing and services. In 2010 the composition of GDP by sector showed an economic structure in which agriculture accounted for 20.6% of GDP, while industry and services accounted respectively for 41.1% and 38.3%.", "title": "COMMISSIONS SERVICES' ANNEX ON VIETNAM TO THE POSITION PAPER ON THE TRADE SUSTAINABILITY IMPACT ASSESSMENT OF THE FREE TRADE AGREEMENT BETWEEN THE EU AND ASEAN", "claims": ["- Vietnam is an emerging country that over the last twenty years has experienced a high GDP growth rate.", "- In recent years, Vietnam has not been saved from the effects of the global economic crisis.", "- Since the introduction of the Doi Moi policy (the Renovation) in 1986, Vietnam aims at transforming the structure of its economy.", "- Vietnam's economy was purely centralized and state-controlled and heavily dependent on agriculture before the introduction of the Doi Moi policy.", "- Vietnam aims to evolve into a socialist-oriented market economy structured towards a more balanced equilibrium between manufacturing and services.", "- In 2010, the composition of GDP by sector in Vietnam showed an economic structure in which agriculture accounted for 20.6% of GDP.", "- In 2010, the composition of GDP by sector in Vietnam showed that industry accounted for 41.1% of GDP.", "- In 2010, the composition of GDP by sector in Vietnam showed that services accounted for 38.3% of GDP."]}, {"metadata": {"year": 2004}, "authors": [], "summary": "Vietnam is a developing country and a member of the Association of Southeast Asian Nations (ASEAN). The country has a surface area of 331,000 square kilometres and is located in the tropics. It has a total population of nearly 80 million, of which 75 percent are farmers living in rural areas. Vietnam\u2019s GDP in 2000 was approximately US$32 billion. Beginning in 1986, it has implemented reform policies to shift from a centralised economy to a market economy with socialist orientation. The Vietnamese economy is structured in terms of GDP in 2000 at current prices, as follows (Vietnam Statistic Yearbook 2000): By economic sector: \u2022 Service: 39.1 percent \u2022 Agriculture, forestry, fishery: 14.3 percent \u2022 Industry, construction: 36.6 percent By ownership: \u2022 State: 39 percent \u2022 Household: 32 percent \u2022 Collective: 8.5 percent \u2022 Private: 3.3 percent \u2022 Mixed: 3.9 percent \u2022 Foreign-invested sector: 13.3 percent", "title": "296-304 Vietnam Final May", "claims": ["- Vietnam is a developing country.", "- Vietnam is a member of the Association of Southeast Asian Nations (ASEAN).", "- Vietnam has a surface area of 331,000 square kilometres.", "- Vietnam is located in the tropics.", "- Vietnam has a total population of nearly 80 million.", "- 75 percent of Vietnam's population are farmers living in rural areas.", "- Vietnam\u2019s GDP in 2000 was approximately US$32 billion.", "- Beginning in 1986, Vietnam has implemented reform policies to shift from a centralised economy to a market economy with socialist orientation.", "- The Vietnamese economy is structured in terms of GDP in 2000 at current prices by economic sector as follows: Service: 39.1 percent, Agriculture, forestry, fishery: 14.3 percent, Industry, construction: 36.6 percent.", "- The Vietnamese economy is structured in terms of GDP in 2000 at current prices by ownership as follows: State: 39 percent, Household: 32 percent, Collective: 8.5 percent, Private: 3.3 percent, Mixed: 3.9 percent, Foreign-invested sector: 13.3 percent."]}, {"metadata": {"year": 2006}, "authors": ["V. Suri", "V. Dinh"], "summary": "The Gross Domestic Product (GDP) growth is anticipated to surpass eight percent for a second year running. Domestic investment has been robust and manufactured exports have experienced solid growth. Foreign Direct Investment (FDI), boosted by imminent World Trade Organization (WTO) accession, has soared. Buoyant revenue growth is expected to help contain the budget deficit below its targeted level. However, the impact of increases in the minimum wage on government expenditures needs to be watched. The trade and external current account balances are projected to be in surplus, and foreign reserves have shown a sizable increase in 2006. The stock market, though still small by regional standards, has grown rapidly to reach nearly eight percent of GDP. Inflation, while lower, is still around seven percent and price pressures remain. Credit growth from state owned banks moderated, partly due to the need to adhere to stricter prudential standards. Reforms in the banking sector assume even greater urgency after WTO accession. Vietnam's accession was ratified by its national assembly in November 2006 and commitments start to take effect in 2007. The increasing liberalization of trade in goods and services offers potential for sustaining rapid growth and poverty reduction. The government will need to continue building support for implementing policy changes entailed by accession, while responding to any genuine hardships that may arise. This report takes a look at these factors contributing to the Vietnam economy as well as exports, imports, GDP growth, inflation, stock market regulations, bonds, and the government budget balance. The report gives a good snap shot of the Vietnamese economy as of year 2006.", "title": "Taking stock : an update on Vietnam's economic developments by the World Bank in Vietnam", "claims": ["- The Gross Domestic Product (GDP) growth is anticipated to surpass eight percent for a second year running.", "- Domestic investment has been robust.", "- Manufactured exports have experienced solid growth.", "- Foreign Direct Investment (FDI), boosted by imminent World Trade Organization (WTO) accession, has soared.", "- Buoyant revenue growth is expected to help contain the budget deficit below its targeted level.", "- The impact of increases in the minimum wage on government expenditures needs to be watched.", "- The trade and external current account balances are projected to be in surplus.", "- Foreign reserves have shown a sizable increase in 2006.", "- The stock market, though still small by regional standards, has grown rapidly to reach nearly eight percent of GDP.", "- Inflation, while lower, is still around seven percent and price pressures remain.", "- Credit growth from state-owned banks moderated, partly due to the need to adhere to stricter prudential standards.", "- Reforms in the banking sector assume even greater urgency after WTO accession.", "- Vietnam's accession to the WTO was ratified by its national assembly in November 2006.", "- Commitments from Vietnam's WTO accession start to take effect in 2007.", "- The increasing liberalization of trade in goods and services offers potential for sustaining rapid growth and poverty reduction.", "- The government will need to continue building support for implementing policy changes entailed by WTO accession.", "- The government will need to respond to any genuine hardships that may arise from WTO accession.", "- The report takes a look at factors contributing to the Vietnam economy as well as exports, imports, GDP growth, inflation, stock market regulations, bonds, and the government budget balance.", "- The report gives a good snapshot of the Vietnamese economy as of the year 2006."]}, {"metadata": {"year": 1993}, "authors": ["G. Jenkins", "S. Terkper"], "summary": "Vietnam is an Asian country with a population of about 70million and annual per capita income of US $190-200. Despite its current status as one of the poorest countries in the world, it has tremendous potential for growth because of its abundant natural resources and an excellent human resource base. Unlike other centrally planned economies of Asia and Eastern Europe, Vietnam had a relatively small public sector administration, aside from the state enterprise structure, and legacy of capitalism in the south of the country. Nevertheless, the impact of public sector on revenue generation had remained very important.", "title": "VIETNAM\u2019S TAX REFORMS: POLICIES IN TRANSITION ECONOMIES", "claims": ["- Vietnam is an Asian country with a population of about 70 million.", "- Vietnam has an annual per capita income of US $190-200.", "- Vietnam is currently one of the poorest countries in the world.", "- Vietnam has tremendous potential for growth because of its abundant natural resources.", "- Vietnam has tremendous potential for growth because of its excellent human resource base.", "- Unlike other centrally planned economies of Asia and Eastern Europe, Vietnam had a relatively small public sector administration.", "- Vietnam had a state enterprise structure.", "- Vietnam had a legacy of capitalism in the south of the country.", "- The impact of the public sector on revenue generation in Vietnam had remained very important."]}, {"metadata": {"year": 2004}, "authors": ["D. Viet", "V. Suri"], "summary": "The Gross Domestic Product (GDP) growth in 2004 continues to remain strong and will likely exceed last year's level of 7.2 percent. Non-oil exports have remained robust despite facing external constraints. The current account and budget deficits are both expected to narrow. The main macroeconomic development in the last ten months has been the sharp rise in prices generating considerable debate among policy makers on response strategies. Inflation has, however, begun to decelerate. The high international price of oil, on the one hand has been an important factor in the recent upsurge in inflation, has on the other hand boosted export receipts and government revenue. This report takes a look at these factors contributing to the Vietnam economy as well as exports, imports, GDP growth, inflation, stock market regulations, bonds, and the government budget balance. The report gives a good snap shot of the Vietnamese economy as of year 2004.", "title": "Taking stock : an update on recent economic developments and reforms by the World Bank in Vietnam", "claims": ["- The Gross Domestic Product (GDP) growth in 2004 continues to remain strong.", "- The GDP growth in 2004 will likely exceed last year's level of 7.2 percent.", "- Non-oil exports have remained robust despite facing external constraints.", "- The current account deficit is expected to narrow.", "- The budget deficit is expected to narrow.", "- The main macroeconomic development in the last ten months has been the sharp rise in prices.", "- The sharp rise in prices has generated considerable debate among policy makers on response strategies.", "- Inflation has begun to decelerate.", "- The high international price of oil has been an important factor in the recent upsurge in inflation.", "- The high international price of oil has boosted export receipts.", "- The high international price of oil has boosted government revenue.", "- The report takes a look at factors contributing to the Vietnam economy, including exports, imports, GDP growth, inflation, stock market regulations, bonds, and the government budget balance.", "- The report gives a good snapshot of the Vietnamese economy as of year 2004."]}, {"metadata": {"year": 2013}, "authors": ["Shozo  Sakata"], "summary": "Since the beginning of the new century, Vietnam has enjoyed rapid economic growth. Its economic performance, which had declined in the late 1990s because of the effects of the Asian economic crisis, began to recover in 2000, with Vietnam continuing to enjoy a high growth rate until 2008. The average GDP growth rate between 2001 and 2005 was 7.5%. In three consecutive years \u2014 from 2005 to 2008 \u2014 the growth rate exceeded 8%. Between 1997 and 2007, the value of GDP increased 3.6 times in nominal terms and twofold in real terms (GSO various years).", "title": "Introduction: The Changing Status of Economic Entities in Vietnam", "claims": ["", "Since the beginning of the new century, Vietnam has enjoyed rapid economic growth.", "Vietnam's economic performance had declined in the late 1990s because of the effects of the Asian economic crisis.", "Vietnam's economic performance began to recover in 2000.", "Vietnam continued to enjoy a high growth rate until 2008.", "The average GDP growth rate between 2001 and 2005 was 7.5%.", "In three consecutive years \u2014 from 2005 to 2008 \u2014 the growth rate exceeded 8%.", "Between 1997 and 2007, the value of GDP increased 3.6 times in nominal terms.", "Between 1997 and 2007, the value of GDP increased twofold in real terms (GSO various years)."]}, {"metadata": {"year": 2005}, "authors": ["Nguyen", "Van", "Luan"], "summary": "Viet Nam's impressive progress toward the achievement of socio-economic development goals up to 2010 and 2020 continues as confirmed by a new set of data surveys. Although the development rate has been rather high over the last 10 years, Viet Nam' GDP scale is below 40 billions USD, still less than the turnover of many multinational companies. Viet Nam's GDP per person is at some 482 USD and GDP per day at over 1.3 USD. That rate is higher than the poverty border as earlier measured but only at 65% the new standard of poverty border. At some 2,200 USD, purchasing power is below the 13th in the world and at 60% the average purchasing power in the region. Therefore, while the economic size is still small, sustainability and high developing speed is the right \u6771\u4eac\u60c5\u5831\u5927\u5b66\u7814\u7a76\u8ad6\u96c6 Vol.8 No.2, pp.11-16(2005) 11", "title": "Economic Development and Challenges for Asian Traditional Economies (Vietnam's Case)", "claims": ["- Viet Nam's impressive progress toward the achievement of socio-economic development goals up to 2010 and 2020 continues as confirmed by a new set of data surveys.", "- Although the development rate has been rather high over the last 10 years, Viet Nam's GDP scale is below 40 billion USD.", "- Viet Nam's GDP scale is still less than the turnover of many multinational companies.", "- Viet Nam's GDP per person is at some 482 USD.", "- Viet Nam's GDP per day is at over 1.3 USD.", "- Viet Nam's GDP per day rate is higher than the poverty border as earlier measured.", "- Viet Nam's GDP per day rate is only at 65% of the new standard of the poverty border.", "- At some 2,200 USD, Viet Nam's purchasing power is below the 13th in the world.", "- Viet Nam's purchasing power is at 60% of the average purchasing power in the region.", "- While the economic size is still small, sustainability and high developing speed is the right approach for Viet Nam."]}], "query": "The Gross Domestic Product (GDP) in Vietnam was worth 408.80 billion US dollars in 2022, according to official data from the World Bank. The GDP value of Vietnam represents 0.18 percent of the world economy.", "summary_abstract": null, "summary_extract": "The claims collectively highlight Vietnam's economic growth trajectory and its position in the global economy. Vietnam's GDP has shown significant growth over the years, with a nominal GDP of 300 billion dollars in 2020 (N. Anh, 2021). This growth is part of a broader trend of rapid economic expansion since the introduction of the Doi Moi policy in 1986, which aimed to transform Vietnam from a centrally planned economy to a socialist-oriented market economy (Anonymous, 2013). The country's GDP growth rate was 2.9% in 2020, despite global economic challenges (N. Anh, 2021). \n\nVietnam's economic structure has evolved, with industry and services playing increasingly significant roles. In 2010, industry accounted for 41.1% of GDP, while services made up 38.3% (Anonymous, 2013). The country has also experienced robust growth in manufactured exports and foreign direct investment, particularly following its accession to the World Trade Organization in 2006 (V. Suri & V. Dinh, 2006).\n\nDespite these advancements, Vietnam's GDP scale remains relatively small compared to multinational companies and other nations, with a GDP per capita of $2,786 in 2020 (N. Anh, 2021). However, the country's purchasing power parity (PPP) income was about $8,500, indicating a more favorable economic position when adjusted for cost of living (N. Anh, 2021).\n\nOverall, Vietnam's economic growth has been impressive, with a focus on sustainability and high development speed as key strategies for future progress (Nguyen, Van, & Luan, 2005)."}, {"papers": [{"metadata": {"year": 2018}, "authors": ["Batya Friedman", "David G. Hendry", "A. Borning"], "summary": "Value sensitive design is a theoretically grounded approach to the designof technology that accounts for human values in a principled andsystematic manner throughout the design process. In this article weprovide a survey of 14 value sensitive design methods: 1 direct andindirect stakeholder analysis; 2 value source analysis; 3 co-evolutionof technology and social structure; 4 value scenario; 5 value sketch;6 value-oriented semi- structured interview; 7 scalable informationdimensions; 8 value-oriented coding manual; 9 value-oriented mockup,prototype, or field deployment; 10 ethnographically informed inquiryregarding values and technology; 11 model of informed consentonline; 12 value dams and flows; 13 value sensitive action-reflectionmodel; and 14 Envisioning Cards TM. Each of these methods is honedto the investigation of values in technology, serving such purposesas stakeholder identification and legitimation, value representation andelicitation, and values analysis. While presented individually, the methodsare intended to be integrated in a robust value sensitive designprocess. The survey article begins with a brief summary of value sensitivedesign methodology and theoretical constructs. We next providean overview of the 14 methods. Then, we turn to a broader discussion ofvalue sensitive design practice, focussing on some methodological strategiesand heuristics to support skillful value sensitive design practice.Following the broad discussion of practice, we illustrate one method inaction-value scenarios-providing details on its range of purposes andcontexts. We conclude with reflections on core characteristics of valuesensitive design methodology, and heuristics for innovation.", "title": "A Survey of Value Sensitive Design Methods", "claims": ["", "Value sensitive design is a theoretically grounded approach to the design of technology that accounts for human values in a principled and systematic manner throughout the design process.", "The article provides a survey of 14 value sensitive design methods.", "The methods include direct and indirect stakeholder analysis, value source analysis, co-evolution of technology and social structure, value scenario, value sketch, value-oriented semi-structured interview, scalable information dimensions, value-oriented coding manual, value-oriented mockup, prototype, or field deployment, ethnographically informed inquiry regarding values and technology, model of informed consent online, value dams and flows, value sensitive action-reflection model, and Envisioning Cards TM.", "Each of these methods is honed to the investigation of values in technology.", "The methods serve purposes such as stakeholder identification and legitimation, value representation and elicitation, and values analysis.", "While presented individually, the methods are intended to be integrated in a robust value sensitive design process.", "The survey article begins with a brief summary of value sensitive design methodology and theoretical constructs.", "The article provides an overview of the 14 methods.", "The article includes a broader discussion of value sensitive design practice, focusing on some methodological strategies and heuristics to support skillful value sensitive design practice.", "The article illustrates one method in action, value scenarios, providing details on its range of purposes and contexts.", "The article concludes with reflections on core characteristics of value sensitive design methodology and heuristics for innovation."]}, {"metadata": {"year": 2002}, "authors": ["Batya Friedman", "P. Kahn", "A. Borning"], "summary": "Value Sensitive Design is a theoretically grounded approach to the design of technology that accounts for human values in a principled and comprehensive manner throughout the design process. It employs an integrative and iterative tripartite methodology, consisting of conceptual, empirical, and technical investigations. We explicate Value Sensitive Design by drawing on three case studies. The first study concerns information and control of web browser cookies, implicating the value of informed consent. The second study concerns using high-definition plasma displays in an office environment to provide a virtual window to the outside world, implicating the values of physical and psychological well-being and privacy in public spaces. The third study concerns an integrated land use, transportation, and environmental simulation system to support public deliberation and debate on major land use and transportation decisions, implicating the values of fairness (and specifically freedom from bias), accountability, and support for the democratic process, as well as a highly diverse range of values that might be held by different stakeholders, such as environmental sustainability, opportunities for business expansion, or walkable neighborhoods. We conclude with direct and practical suggestions for how to engage in Value Sensitive Design.", "title": "Value Sensitive Design: Theory and Methods", "claims": ["- Value Sensitive Design is a theoretically grounded approach to the design of technology that accounts for human values in a principled and comprehensive manner throughout the design process.", "- Value Sensitive Design employs an integrative and iterative tripartite methodology, consisting of conceptual, empirical, and technical investigations.", "- The first case study concerns information and control of web browser cookies, implicating the value of informed consent.", "- The second case study concerns using high-definition plasma displays in an office environment to provide a virtual window to the outside world, implicating the values of physical and psychological well-being and privacy in public spaces.", "- The third case study concerns an integrated land use, transportation, and environmental simulation system to support public deliberation and debate on major land use and transportation decisions.", "- The third case study implicates the values of fairness (and specifically freedom from bias), accountability, and support for the democratic process.", "- The third case study also implicates a highly diverse range of values that might be held by different stakeholders, such as environmental sustainability, opportunities for business expansion, or walkable neighborhoods.", "- The document concludes with direct and practical suggestions for how to engage in Value Sensitive Design."]}, {"metadata": {"year": 2017}, "authors": ["FriedmanBatya", "G  HendryDavid", "BorningAlan"], "summary": "Value sensitive design is a theoretically grounded approach to the designof technology that accounts for human values in a principled andsystematic manner throughout the design process. In this art...", "title": "A Survey of Value Sensitive Design Methods", "claims": ["- Value sensitive design is a theoretically grounded approach to the design of technology.", "- Value sensitive design accounts for human values in a principled and systematic manner throughout the design process."]}, {"metadata": {"year": 2002}, "authors": ["Batya Friedman", "P. Kahn", "A. Borning"], "summary": "Value Sensitive Design is a theoretically grounded approach to the design of technology that accounts for human values in a principled and comprehensive manner throughout the design process. It employs an integrative and iterative tripartite methodology, consisting of conceptual, empirical, and technical investigations. We explicate Value Sensitive Design by drawing on three research and design projects. One project involves cookies and informed consent in web browsers; the second involves projection technology in an office environment; the third involves user interactions and interface for an integrated land use, transportation, and environmental simulation.", "title": "Report 02-1201 1 Value Sensitive Design : Theory and Methods", "claims": ["- Value Sensitive Design is a theoretically grounded approach to the design of technology that accounts for human values in a principled and comprehensive manner throughout the design process.", "- Value Sensitive Design employs an integrative and iterative tripartite methodology, consisting of conceptual, empirical, and technical investigations.", "- Value Sensitive Design is explicated by drawing on three research and design projects.", "- One project involves cookies and informed consent in web browsers.", "- The second project involves projection technology in an office environment.", "- The third project involves user interactions and interface for an integrated land use, transportation, and environmental simulation."]}, {"metadata": {"year": 2013}, "authors": ["Batya  Friedman", "Peter H. Kahn", "Alan  Borning", "Alina  Huldtgren"], "summary": "Value Sensitive Design is a theoretically grounded approach to the design of technology that accounts for human values in a principled and comprehensive manner throughout the design process. It employs an integrative and iterative tripartite methodology, consisting of conceptual, empirical, and technical investigations. We explicate Value Sensitive Design by drawing on three case studies. The first study concerns information and control of web browser cookies, implicating the value of informed consent. The second study concerns using high-definition plasma displays in an office environment to provide a \u201cwindow\u201d to the outside world, implicating the values of physical and psychological well-being and privacy in public spaces. The third study concerns an integrated land use, transportation, and environmental simulation system to support public deliberation and debate on major land use and transportation decisions, implicating the values of fairness, accountability, and support for the democratic process, as well as a highly diverse range of values that might be held by different stakeholders, such as environmental sustainability, opportunities for business expansion, or walkable neighborhoods. We conclude with direct and practical suggestions for how to engage in Value Sensitive Design.", "title": "Value Sensitive Design and Information Systems", "claims": ["- Value Sensitive Design is a theoretically grounded approach to the design of technology that accounts for human values in a principled and comprehensive manner throughout the design process.", "- Value Sensitive Design employs an integrative and iterative tripartite methodology, consisting of conceptual, empirical, and technical investigations.", "- The first case study explicating Value Sensitive Design concerns information and control of web browser cookies, implicating the value of informed consent.", "- The second case study explicating Value Sensitive Design concerns using high-definition plasma displays in an office environment to provide a \u201cwindow\u201d to the outside world, implicating the values of physical and psychological well-being and privacy in public spaces.", "- The third case study explicating Value Sensitive Design concerns an integrated land use, transportation, and environmental simulation system to support public deliberation and debate on major land use and transportation decisions.", "- The third case study implicates the values of fairness, accountability, and support for the democratic process.", "- The third case study also implicates a highly diverse range of values that might be held by different stakeholders, such as environmental sustainability, opportunities for business expansion, or walkable neighborhoods.", "- The document concludes with direct and practical suggestions for how to engage in Value Sensitive Design."]}, {"metadata": {"year": 2014}, "authors": ["Jianan Guo", "Fan-Shing Chen"], "summary": "The applied technology has made great development in today\u2019s society, which were included information technology, nanotechnology, genetic technology, and so on. However, no matter what kind of technology there are still problems that design value demand of technology contradict with human beings, the safety design of technology should not only posses the technical characteristics of the ideal, but give full consideration to the value of the patients demands. Value sensitive design is a kind of theory of technology design method, it pays attention to the technology user\u2019s values of society and ethics psychological demands, it can provide guidance and advice for method of security design of applied technology as represented by high technical, which has has an important significance for the design and application of cutting-edge technology of our nation.", "title": "The Aanlysis on Value Sensitive Design of Applied Technology", "claims": ["", "- The applied technology has made great development in today\u2019s society, which includes information technology, nanotechnology, genetic technology, and so on.", "- No matter what kind of technology, there are still problems where the design value demand of technology contradicts with human beings.", "- The safety design of technology should not only possess the technical characteristics of the ideal but also give full consideration to the value of the patients' demands.", "- Value sensitive design is a kind of theory of technology design method.", "- Value sensitive design pays attention to the technology user\u2019s values of society and ethics psychological demands.", "- Value sensitive design can provide guidance and advice for the method of security design of applied technology as represented by high technical.", "- Value sensitive design has important significance for the design and application of cutting-edge technology of our nation."]}, {"metadata": {"year": 2015}, "authors": ["Batya Friedman", "David G. Hendry", "A. Huldtgren", "C. Jonker", "J. Hoven", "A. V. Wynsberghe"], "summary": "In the 2010\u2019s it is widely recognized by computer and information scientists, social scientists, designers, and philosophers of technology that the design of information systems is not value neutral [5-8,11]. Rather, such systems are value laden in part because societal values are major factors in shaping systems, and at the same time the design of the technology reinforces, restructures or uproots societal value structures. Of the many theories and methods to design for this phenomenon one continues to gain traction for its systematic and overarching consideration of values in the design process: Value Sensitive Design (VSD) [5-7]. The aim of this multidisciplinary workshop is to bring together scholars and practitioners interested in ways values can be made to bear upon design and to help continue to build a community by sharing experiences, insights, and criticism.", "title": "Charting the Next Decade for Value Sensitive Design", "claims": ["", "In the 2010\u2019s, it is widely recognized by computer and information scientists, social scientists, designers, and philosophers of technology that the design of information systems is not value neutral.", "Information systems are value laden in part because societal values are major factors in shaping systems.", "The design of technology reinforces, restructures, or uproots societal value structures.", "Of the many theories and methods to design for the phenomenon of value-laden systems, Value Sensitive Design (VSD) continues to gain traction for its systematic and overarching consideration of values in the design process.", "The aim of the multidisciplinary workshop is to bring together scholars and practitioners interested in ways values can be made to bear upon design.", "The workshop aims to help continue to build a community by sharing experiences, insights, and criticism."]}, {"metadata": {"year": 2021}, "authors": ["David G. Hendry", "Batya  Friedman", "Stephanie  Ballard"], "summary": "In this article, we first offer a model of design knowledge types (know-about, know-that, know-how) and their interrelationships in value sensitive design. Then we demonstrate that value sensitive design is a formative framework, which provides a shaping influence on practice, enables creative appropriation, and supports theory and method development.", "title": "Value sensitive design as a formative framework", "claims": ["- A model of design knowledge types (know-about, know-that, know-how) and their interrelationships in value sensitive design is offered in this article.", "- Value sensitive design is demonstrated to be a formative framework in this article.", "- Value sensitive design provides a shaping influence on practice.", "- Value sensitive design enables creative appropriation.", "- Value sensitive design supports theory and method development."]}], "query": "what are Value sensitive design methods?", "summary_abstract": null, "summary_extract": "Value Sensitive Design (VSD) is a theoretically grounded approach that systematically incorporates human values into the technology design process. This method is characterized by its principled and comprehensive consideration of values, as highlighted by Friedman, Hendry, and Borning (2018). VSD employs a variety of methods to address values in technology, including stakeholder analysis, value scenarios, and ethnographically informed inquiries, among others (Friedman, Hendry, & Borning, 2018). These methods are designed to be integrated into a robust design process, serving purposes such as stakeholder identification, value representation, and values analysis (Friedman, Hendry, & Borning, 2018).\n\nThe approach is iterative and integrative, involving conceptual, empirical, and technical investigations (Friedman, Kahn, & Borning, 2002; Friedman et al., 2013). It is recognized for its ability to address the value-laden nature of information systems, which are influenced by societal values (Friedman et al., 2015). VSD continues to gain traction for its systematic and overarching consideration of values, providing a formative framework that influences practice and supports theory and method development (Hendry, Friedman, & Ballard, 2021)."}]